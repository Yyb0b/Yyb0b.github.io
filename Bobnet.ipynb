{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler\n",
    "\n",
    "class BobNet(nn.Module):\n",
    "    \"\"\"\n",
    "        The BobNet model that will be used to swing.\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, input_size: int, output_size: int, hidden_dim: int,\n",
    "                 n_layers: int, seq_length: int, bidirectional: bool=True, drop_prob: float=0.1):\n",
    "        \"\"\"\n",
    "            Initialize the model by setting up the layers.\n",
    "        \"\"\"\n",
    "        super(BobNet, self).__init__()\n",
    " \n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        self.seq_length = seq_length\n",
    "        self.input_size = input_size\n",
    "        self.num_directions = 2 if self.bidirectional else 1\n",
    "        \n",
    "        #LSTM layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, \n",
    "                            dropout=drop_prob, batch_first=False,\n",
    "                            bidirectional=bidirectional)\n",
    "        \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        if bidirectional:\n",
    "          self.fc = nn.Linear(hidden_dim*2, output_size)\n",
    "        else:\n",
    "          self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        \n",
    "        \n",
    " \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "            Perform a forward pass of our model on some input and hidden state.\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        # assert x.shape==(batch_size,self.seq_length, self.input_size)\n",
    "        # If not batch_first, switch seq_length and batch_size position.\n",
    "        x.transpose_(1,0)\n",
    "        lstm_out, hidden = self.lstm(x, hidden)\n",
    "        h_n, c_n = hidden\n",
    "        # assert lstm_out.shape==(self.seq_length, batch_size, self.hidden_dim )\n",
    "        # assert h_n.shape==c_n.shape==(self.n_layers*self.num_directions, batch_size, self.hidden_dim)\n",
    "        # dropout and fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        # use last seq as out\n",
    "        out = out[-1]\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # reshape to be batch_size first\n",
    "        out = out.view(batch_size, -1)\n",
    "        return out, hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size: int):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden = (weight.new(self.n_layers*self.num_directions, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers*self.num_directions, batch_size, self.hidden_dim).zero_()\n",
    "                     )\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score\n",
    "# from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler, StandardScaler\n",
    "class BiLSTM_Attention(nn.Module):\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_dim: int,\n",
    "                n_layers: int, seq_length: int, bidirectional: bool=True, drop_prob: float=0.1):\n",
    "        super(BiLSTM_Attention, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        self.seq_length = seq_length\n",
    "        self.input_size = input_size\n",
    "        self.num_directions = 2 if self.bidirectional else 1\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, dropout=drop_prob, batch_first=False, bidirectional=bidirectional)\n",
    "        # self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # self.lstm = nn.LSTM(embedding_dim, n_hidden, bidirectional=True)\n",
    "        # self.out = nn.Linear(n_hidden * 2, num_classes)\n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(drop_prob)\n",
    "        \n",
    "        # linear and sigmoid layers\n",
    "        if bidirectional:\n",
    "          self.fc = nn.Linear(hidden_dim*2, output_size)\n",
    "        else:\n",
    "          self.fc = nn.Linear(hidden_dim, output_size)\n",
    "\n",
    "\n",
    "    def attention_net(self,lstm_output, final_state):\n",
    "        # lstm_output : [batch_size, n_step, n_hidden * num_directions(=2)], F matrix\n",
    "        # final_state : [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
    "\n",
    "        batch_size = len(lstm_output)\n",
    "        # hidden = final_state.view(batch_size,-1,1)\n",
    "        if self.bidirectional:\n",
    "            hidden = torch.cat((final_state[0],final_state[1]),dim=1).unsqueeze(2)\n",
    "        else:\n",
    "            hidden = final_state[0].unsqueeze(2)\n",
    "        # hidden : [batch_size, n_hidden * num_directions(=2), n_layer(=1)]\n",
    "        attn_weights = torch.bmm(lstm_output, hidden).squeeze(2)\n",
    "        # attn_weights : [batch_size,n_step]\n",
    "        soft_attn_weights = F.softmax(attn_weights,1)\n",
    "\n",
    "        # context: [batch_size, n_hidden * num_directions(=2)]\n",
    "        context = torch.bmm(lstm_output.transpose(1,2),soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "\n",
    "        return context, soft_attn_weights\n",
    "\n",
    "    def forward(self,X, hidden):\n",
    "        '''\n",
    "        :param X: [batch_size, seq_len]\n",
    "        :return:\n",
    "        '''\n",
    "        input = X # input : [batch_size, seq_len, embedding_dim]\n",
    "        input = input.transpose(0, 1) # input : [seq_len, batch_size, embedding_dim]\n",
    "\n",
    "        # final_hidden_state, final_cell_state : [num_layers(=1) * num_directions(=2), batch_size, n_hidden]\n",
    "        # output : [seq_len, batch_size, n_hidden * num_directions(=2)]\n",
    "        output, (final_hidden_state, final_cell_state) = self.lstm(input, hidden)\n",
    "        output = output.transpose(0, 1) #output : [batch_size, seq_len, n_hidden * num_directions(=2)]\n",
    "\n",
    "        attn_output, attention = self.attention_net(output,final_hidden_state)\n",
    "        return self.fc(attn_output),attention # attn_output : [batch_size, num_classes], attention : [batch_size, n_step]\n",
    "\n",
    "    def init_hidden(self, batch_size: int):\n",
    "        ''' Initializes hidden state '''\n",
    "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        # initialized to zero, for hidden state and cell state of LSTM\n",
    "        weight = next(self.parameters()).data\n",
    "        \n",
    "        hidden = (weight.new(self.n_layers*self.num_directions, batch_size, self.hidden_dim).zero_(),\n",
    "                      weight.new(self.n_layers*self.num_directions, batch_size, self.hidden_dim).zero_()\n",
    "                      )\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "batch_size=50\n",
    "hidden_dim=5\n",
    "input_size=5\n",
    "seq_length=5\n",
    "n_layers=1\n",
    "output_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dian\n",
    "data = pd.read_csv('84数据/51formant.csv')\n",
    "dian = []\n",
    "dian_y = []\n",
    "for i in range(len(data)):\n",
    "    if data.iloc[i, 1] is np.nan:\n",
    "        list = []\n",
    "        for j in range(5):\n",
    "            list.append([0, 0, 0, 0, 0])\n",
    "        dian.append(list)\n",
    "        dian_y.append([float(data.iloc[i, 0])])\n",
    "    else:\n",
    "        list = []\n",
    "        for t in range(5-len(data.iloc[i, 1].split(','))):\n",
    "            list.append([0, 0, 0, 0, 0])\n",
    "        for j in range(len(data.iloc[i, 1].split(','))):\n",
    "            list.append([float(data.iloc[i, 1].split(',')[j]), float(data.iloc[i, 2].split(';')[j]),float(data.iloc[i, 3].split(';')[j]),float(data.iloc[i, 4].split(';')[j]),float(data.iloc[i, 5].split(';')[j])])\n",
    "        dian.append(list)\n",
    "        dian_y.append([float(data.iloc[i, 0])])\n",
    "dian =np.array(dian).astype(np.float32)\n",
    "dian_y = np.array(dian_y).astype(np.float32)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(dian, dian_y, test_size=0.3, random_state=100)\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_val = torch.from_numpy(X_val)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_val = torch.from_numpy(y_val)\n",
    "dataset_x = Data.TensorDataset(X_train, y_train)\n",
    "dataset_y = Data.TensorDataset(X_val, y_val)\n",
    "train_loader = Data.DataLoader(dataset_x, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = Data.DataLoader(dataset_y, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dian, 带宽\n",
    "data = pd.read_csv('84数据/51formant.csv')\n",
    "dian = []\n",
    "dian_y = []\n",
    "for i in range(len(data)):\n",
    "    if data.iloc[i, 1] is np.nan:\n",
    "        list = []\n",
    "        for j in range(5):\n",
    "            list.append([0, 0, 0, 0, 0])\n",
    "        dian.append(list)\n",
    "        dian_y.append([float(data.iloc[i, 0])])\n",
    "    else:\n",
    "        list = []\n",
    "        for t in range(5-len(data.iloc[i, 1].split(','))):\n",
    "            list.append([0, 0, 0, 0, 0])\n",
    "        for j in range(len(data.iloc[i, 1].split(','))):\n",
    "            list.append([float(data.iloc[i, 1].split(',')[j]), float(data.iloc[i, 2].split(';')[j]),float(data.iloc[i, 3].split(';')[j]),float(data.iloc[i, 4].split(';')[j]),float(data.iloc[i, 5].split(';')[j])])\n",
    "        dian.append(list)\n",
    "        dian_y.append([float(data.iloc[i, 0])])\n",
    "dian =np.array(dian).astype(np.float32)\n",
    "dian_y = np.array(dian_y).astype(np.float32)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(dian, dian_y, test_size=0.3, random_state=100)\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_val = torch.from_numpy(X_val)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_val = torch.from_numpy(y_val)\n",
    "dataset_x = Data.TensorDataset(X_train, y_train)\n",
    "dataset_y = Data.TensorDataset(X_val, y_val)\n",
    "train_loader = Data.DataLoader(dataset_x, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = Data.DataLoader(dataset_y, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ci\n",
    "data = pd.read_csv('84数据/51formant.csv')\n",
    "ci = []\n",
    "ci_y = []\n",
    "for i in range(len(data)):\n",
    "    if data.iloc[i, 6] is np.nan:\n",
    "        list = []\n",
    "        for j in range(2):\n",
    "            list.append([0, 0, 0, 0, 0])\n",
    "        ci.append(list)\n",
    "        ci_y.append([float(data.iloc[i, 0])])\n",
    "    else:\n",
    "        list = []\n",
    "        for t in range(2-len(data.iloc[i, 6].split(','))):\n",
    "            list.append([0, 0, 0, 0, 0])\n",
    "        for j in range(len(data.iloc[i, 6].split(','))):\n",
    "            list.append([float(data.iloc[i, 6].split(',')[j]), float(data.iloc[i, 7].split(';')[j]),float(data.iloc[i, 8].split(';')[j]),float(data.iloc[i, 9].split(';')[j]),float(data.iloc[i, 10].split(';')[j])])\n",
    "        ci.append(list)\n",
    "        ci_y.append([float(data.iloc[i, 0])])\n",
    "ci =np.array(ci).astype(np.float32)\n",
    "ci_y = np.array(ci_y).astype(np.float32)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(ci, ci_y, test_size=0.3, random_state=2022)\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_val = torch.from_numpy(X_val)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_val = torch.from_numpy(y_val)\n",
    "dataset_x = Data.TensorDataset(X_train, y_train)\n",
    "dataset_y = Data.TensorDataset(X_val, y_val)\n",
    "train_loader = Data.DataLoader(dataset_x, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = Data.DataLoader(dataset_y, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dian,ci\n",
    "data = pd.read_csv('84数据/51formant.csv')\n",
    "dici = []\n",
    "dici_y = []\n",
    "for i in range(len(data)):\n",
    "    if data.iloc[i, 1] is np.nan:\n",
    "        list = []\n",
    "        for j in range(5):\n",
    "            list.append([0, 0, 0, 0, 0])\n",
    "        if data.iloc[i, 6] is np.nan:\n",
    "            for j in range(2):\n",
    "                list.append([0, 0, 0, 0, 0])\n",
    "            dici.append(list)\n",
    "            dici_y.append([float(data.iloc[i, 0])])\n",
    "        else:\n",
    "            for t in range(2-len(data.iloc[i, 6].split(','))):\n",
    "                list.append([0, 0, 0, 0, 0])\n",
    "            for j in range(len(data.iloc[i, 6].split(','))):\n",
    "                list.append([float(data.iloc[i, 6].split(',')[j]), float(data.iloc[i, 7].split(';')[j]),float(data.iloc[i, 8].split(';')[j]),float(data.iloc[i, 9].split(';')[j]),float(data.iloc[i, 10].split(';')[j])])\n",
    "            dici.append(list)\n",
    "            dici_y.append([float(data.iloc[i, 0])])\n",
    "    else:\n",
    "        list = []\n",
    "        for t in range(5-len(data.iloc[i, 1].split(','))):\n",
    "            list.append([0, 0, 0, 0, 0])\n",
    "        for j in range(len(data.iloc[i, 1].split(','))):\n",
    "            list.append([float(data.iloc[i, 1].split(',')[j]), float(data.iloc[i, 2].split(';')[j]),float(data.iloc[i, 3].split(';')[j]),float(data.iloc[i, 4].split(';')[j]),float(data.iloc[i, 5].split(';')[j])])\n",
    "        if data.iloc[i, 6] is np.nan:\n",
    "            for j in range(2):\n",
    "                list.append([0, 0, 0, 0, 0])\n",
    "            dici.append(list)\n",
    "            dici_y.append([float(data.iloc[i, 0])])\n",
    "        else:\n",
    "            for t in range(2-len(data.iloc[i, 6].split(','))):\n",
    "                list.append([0, 0, 0, 0, 0])\n",
    "            for j in range(len(data.iloc[i, 6].split(','))):\n",
    "                list.append([float(data.iloc[i, 6].split(',')[j]), float(data.iloc[i, 7].split(';')[j]),float(data.iloc[i, 8].split(';')[j]),float(data.iloc[i, 9].split(';')[j]),float(data.iloc[i, 10].split(';')[j])])\n",
    "            dici.append(list)\n",
    "            dici_y.append([float(data.iloc[i, 0])])\n",
    "dici =np.array(dici).astype(np.float32)\n",
    "dici_y = np.array(dici_y).astype(np.float32)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(dici, dici_y, test_size=0.3, random_state=2022)\n",
    "X_train = torch.from_numpy(X_train)\n",
    "X_val = torch.from_numpy(X_val)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_val = torch.from_numpy(y_val)\n",
    "dataset_x = Data.TensorDataset(X_train, y_train)\n",
    "dataset_y = Data.TensorDataset(X_val, y_val)\n",
    "train_loader = Data.DataLoader(dataset_x, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = Data.DataLoader(dataset_y, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = BobNet(input_size=input_size, output_size=output_size, hidden_dim=hidden_dim,\n",
    "                n_layers=n_layers, seq_length=seq_length, bidirectional=True, drop_prob=0)\n",
    "\n",
    "# Set optimizer and loss function\n",
    "optimizer = torch.optim.Adam(bob.parameters(), lr=0.005)\n",
    "criterion = nn.SmoothL1Loss() # SmoothL1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = BiLSTM_Attention(input_size=input_size, output_size=output_size, hidden_dim=hidden_dim,\n",
    "                n_layers=n_layers, seq_length=seq_length, bidirectional=True, drop_prob=0)\n",
    "optimizer = torch.optim.Adam(bob.parameters(), lr=0.005)\n",
    "criterion = nn.SmoothL1Loss() # SmoothL1Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_r2 = []\n",
    "test_loss = []\n",
    "test_r2 = []\n",
    "best_score = -1\n",
    "flag = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:  4.883158206939697\n",
      "train r2:  -0.006070438059383676\n",
      "test loss:  6.79273796081543\n",
      "test r2:  -0.25129557912214917\n",
      "train loss:  4.881232738494873\n",
      "train r2:  -0.0052176059844177836\n",
      "test loss:  6.793751239776611\n",
      "test r2:  -0.25143738986694375\n",
      "train loss:  4.879312992095947\n",
      "train r2:  -0.004367018238182752\n",
      "test loss:  6.794764518737793\n",
      "test r2:  -0.25157880772056096\n",
      "train loss:  4.877399444580078\n",
      "train r2:  -0.003518860847038452\n",
      "test loss:  6.795774459838867\n",
      "test r2:  -0.25171945399796525\n",
      "train loss:  4.875491142272949\n",
      "train r2:  -0.002672870103889613\n",
      "test loss:  6.796780586242676\n",
      "test r2:  -0.2518587483815291\n",
      "train loss:  4.873586177825928\n",
      "train r2:  -0.0018290444587456545\n",
      "test loss:  6.797781467437744\n",
      "test r2:  -0.25199623742168353\n",
      "train loss:  4.871681213378906\n",
      "train r2:  -0.0009871240855987562\n",
      "test loss:  6.798774719238281\n",
      "test r2:  -0.25213143078122724\n",
      "train loss:  4.869773864746094\n",
      "train r2:  -0.0001471388897529291\n",
      "test loss:  6.799759387969971\n",
      "test r2:  -0.252263837508506\n",
      "train loss:  4.867855072021484\n",
      "train r2:  0.0006913157274253123\n",
      "test loss:  6.800734996795654\n",
      "test r2:  -0.25239301890490773\n",
      "train loss:  4.865907192230225\n",
      "train r2:  0.0015285175548351848\n",
      "test loss:  6.801698207855225\n",
      "test r2:  -0.2525183275361569\n",
      "train loss:  4.863892078399658\n",
      "train r2:  0.002364841770755466\n",
      "test loss:  6.802649021148682\n",
      "test r2:  -0.252639685104618\n",
      "train loss:  4.861715793609619\n",
      "train r2:  0.003201493424177526\n",
      "test loss:  6.803586959838867\n",
      "test r2:  -0.25275630778599134\n",
      "train loss:  4.859133243560791\n",
      "train r2:  0.004041856995195436\n",
      "test loss:  6.804510593414307\n",
      "test r2:  -0.2528674185129065\n",
      "train loss:  4.855785369873047\n",
      "train r2:  0.004890822628088154\n",
      "test loss:  6.805419445037842\n",
      "test r2:  -0.2529696432651716\n",
      "train loss:  4.852290153503418\n",
      "train r2:  0.005742974609872609\n",
      "test loss:  6.806304454803467\n",
      "test r2:  -0.25305792553691564\n",
      "train loss:  4.849696159362793\n",
      "train r2:  0.0065897778660184425\n",
      "test loss:  6.807159423828125\n",
      "test r2:  -0.2531293044473828\n",
      "train loss:  4.847560882568359\n",
      "train r2:  0.007441277414020786\n",
      "test loss:  6.807985305786133\n",
      "test r2:  -0.253184001043816\n",
      "train loss:  4.845530033111572\n",
      "train r2:  0.008302699324348684\n",
      "test loss:  6.8087849617004395\n",
      "test r2:  -0.2532235488747485\n",
      "train loss:  4.843522071838379\n",
      "train r2:  0.009174577863687916\n",
      "test loss:  6.809560775756836\n",
      "test r2:  -0.2532496434051428\n",
      "train loss:  4.841516971588135\n",
      "train r2:  0.010056162305740024\n",
      "test loss:  6.810319423675537\n",
      "test r2:  -0.2532646589266163\n",
      "train loss:  4.8395094871521\n",
      "train r2:  0.010947145408870318\n",
      "test loss:  6.811062812805176\n",
      "test r2:  -0.2532700766261069\n",
      "train loss:  4.837497711181641\n",
      "train r2:  0.011846979574062111\n",
      "test loss:  6.811795234680176\n",
      "test r2:  -0.25326830706841186\n",
      "train loss:  4.835480213165283\n",
      "train r2:  0.012754667018075927\n",
      "test loss:  6.812518119812012\n",
      "test r2:  -0.253261341835449\n",
      "train loss:  4.833456516265869\n",
      "train r2:  0.013670053413568861\n",
      "test loss:  6.813236713409424\n",
      "test r2:  -0.25325101860516686\n",
      "train loss:  4.831427097320557\n",
      "train r2:  0.014592258842531569\n",
      "test loss:  6.813952922821045\n",
      "test r2:  -0.2532393588956099\n",
      "train loss:  4.829390048980713\n",
      "train r2:  0.015520459794636898\n",
      "test loss:  6.814671516418457\n",
      "test r2:  -0.25322798086747\n",
      "train loss:  4.827347755432129\n",
      "train r2:  0.016453674830522957\n",
      "test loss:  6.8153977394104\n",
      "test r2:  -0.25321856860604974\n",
      "train loss:  4.825300216674805\n",
      "train r2:  0.017390858626890382\n",
      "test loss:  6.81613302230835\n",
      "test r2:  -0.2532125151960376\n",
      "train loss:  4.823246955871582\n",
      "train r2:  0.01833108419033369\n",
      "test loss:  6.816882610321045\n",
      "test r2:  -0.2532111013961065\n",
      "train loss:  4.821190357208252\n",
      "train r2:  0.019272971829227825\n",
      "test loss:  6.817646503448486\n",
      "test r2:  -0.25321544983147914\n",
      "train loss:  4.819130897521973\n",
      "train r2:  0.020215403028263634\n",
      "test loss:  6.8184285163879395\n",
      "test r2:  -0.25322640003067165\n",
      "train loss:  4.817070484161377\n",
      "train r2:  0.021157509065720892\n",
      "test loss:  6.819230556488037\n",
      "test r2:  -0.2532447862420051\n",
      "train loss:  4.815009117126465\n",
      "train r2:  0.02209804594577114\n",
      "test loss:  6.820052623748779\n",
      "test r2:  -0.2532707539534971\n",
      "train loss:  4.812948226928711\n",
      "train r2:  0.023036138240399406\n",
      "test loss:  6.820894241333008\n",
      "test r2:  -0.2533051499052885\n",
      "train loss:  4.810888767242432\n",
      "train r2:  0.023971321869130424\n",
      "test loss:  6.821756362915039\n",
      "test r2:  -0.2533475600198791\n",
      "train loss:  4.808831214904785\n",
      "train r2:  0.02490279426066755\n",
      "test loss:  6.822638034820557\n",
      "test r2:  -0.2533979739990446\n",
      "train loss:  4.806777000427246\n",
      "train r2:  0.025830347741752635\n",
      "test loss:  6.823538303375244\n",
      "test r2:  -0.253456338704932\n",
      "train loss:  4.804727077484131\n",
      "train r2:  0.0267532786469854\n",
      "test loss:  6.824455738067627\n",
      "test r2:  -0.25352216778404\n",
      "train loss:  4.802680015563965\n",
      "train r2:  0.027671887273885476\n",
      "test loss:  6.825387954711914\n",
      "test r2:  -0.2535947471073696\n",
      "train loss:  4.800637722015381\n",
      "train r2:  0.02858594609955989\n",
      "test loss:  6.8263325691223145\n",
      "test r2:  -0.2536734508038321\n",
      "train loss:  4.798599720001221\n",
      "train r2:  0.029495498757690086\n",
      "test loss:  6.827287197113037\n",
      "test r2:  -0.2537573726522351\n",
      "train loss:  4.796566963195801\n",
      "train r2:  0.03040057664458029\n",
      "test loss:  6.828249931335449\n",
      "test r2:  -0.25384590842045984\n",
      "train loss:  4.794538974761963\n",
      "train r2:  0.031301328883789115\n",
      "test loss:  6.829216480255127\n",
      "test r2:  -0.25393805440442296\n",
      "train loss:  4.792515754699707\n",
      "train r2:  0.032198381674964804\n",
      "test loss:  6.830184459686279\n",
      "test r2:  -0.2540323919602596\n",
      "train loss:  4.790497779846191\n",
      "train r2:  0.03309148401899964\n",
      "test loss:  6.831150531768799\n",
      "test r2:  -0.2541286586061453\n",
      "train loss:  4.788484573364258\n",
      "train r2:  0.03398127268593354\n",
      "test loss:  6.832110404968262\n",
      "test r2:  -0.25422528167340364\n",
      "train loss:  4.7864766120910645\n",
      "train r2:  0.034867909293904376\n",
      "test loss:  6.833063125610352\n",
      "test r2:  -0.2543215456402763\n",
      "train loss:  4.784472942352295\n",
      "train r2:  0.03575167770151921\n",
      "test loss:  6.834005355834961\n",
      "test r2:  -0.2544167097453438\n",
      "train loss:  4.782473564147949\n",
      "train r2:  0.03663280163977778\n",
      "test loss:  6.83493185043335\n",
      "test r2:  -0.25450954755368005\n",
      "train loss:  4.7804789543151855\n",
      "train r2:  0.037511628474311\n",
      "test loss:  6.835843086242676\n",
      "test r2:  -0.25459964829558746\n",
      "train loss:  4.778489589691162\n",
      "train r2:  0.03838834712602701\n",
      "test loss:  6.836736679077148\n",
      "test r2:  -0.25468628612036115\n",
      "train loss:  4.776503562927246\n",
      "train r2:  0.03926321415990941\n",
      "test loss:  6.837608814239502\n",
      "test r2:  -0.25476866305285983\n",
      "train loss:  4.774521350860596\n",
      "train r2:  0.04013643540824241\n",
      "test loss:  6.8384599685668945\n",
      "test r2:  -0.25484675542027624\n",
      "train loss:  4.772543430328369\n",
      "train r2:  0.04100802475056753\n",
      "test loss:  6.839287281036377\n",
      "test r2:  -0.2549197280956228\n",
      "train loss:  4.770569324493408\n",
      "train r2:  0.04187799097181899\n",
      "test loss:  6.840091228485107\n",
      "test r2:  -0.2549877374099554\n",
      "train loss:  4.768599033355713\n",
      "train r2:  0.04274677720241471\n",
      "test loss:  6.840871810913086\n",
      "test r2:  -0.25505076422512674\n",
      "train loss:  4.766631603240967\n",
      "train r2:  0.04361419817865009\n",
      "test loss:  6.84162712097168\n",
      "test r2:  -0.25510850273426566\n",
      "train loss:  4.764667987823486\n",
      "train r2:  0.04448029766615047\n",
      "test loss:  6.842358589172363\n",
      "test r2:  -0.2551611643909637\n",
      "train loss:  4.762707710266113\n",
      "train r2:  0.045345035699689173\n",
      "test loss:  6.843066692352295\n",
      "test r2:  -0.25520923669774787\n",
      "train loss:  4.760749340057373\n",
      "train r2:  0.046208406758297516\n",
      "test loss:  6.843752861022949\n",
      "test r2:  -0.25525255206064723\n",
      "train loss:  4.758794784545898\n",
      "train r2:  0.04707021815274337\n",
      "test loss:  6.844417095184326\n",
      "test r2:  -0.2552919332315764\n",
      "train loss:  4.7568440437316895\n",
      "train r2:  0.047930333606504893\n",
      "test loss:  6.845061779022217\n",
      "test r2:  -0.2553275095077294\n",
      "train loss:  4.754895210266113\n",
      "train r2:  0.048788690768711396\n",
      "test loss:  6.845687389373779\n",
      "test r2:  -0.2553598603424039\n",
      "train loss:  4.75294828414917\n",
      "train r2:  0.049645493489249515\n",
      "test loss:  6.846296310424805\n",
      "test r2:  -0.25538967610986485\n",
      "train loss:  4.751004695892334\n",
      "train r2:  0.05050013955819366\n",
      "test loss:  6.846889019012451\n",
      "test r2:  -0.2554172479663872\n",
      "train loss:  4.749063968658447\n",
      "train r2:  0.051352639812038636\n",
      "test loss:  6.847468852996826\n",
      "test r2:  -0.2554430538003649\n",
      "train loss:  4.747124671936035\n",
      "train r2:  0.05220299594239952\n",
      "test loss:  6.848036289215088\n",
      "test r2:  -0.2554678356041702\n",
      "train loss:  4.745187759399414\n",
      "train r2:  0.05305086614279253\n",
      "test loss:  6.848593235015869\n",
      "test r2:  -0.2554920694760918\n",
      "train loss:  4.743253707885742\n",
      "train r2:  0.05389649206021063\n",
      "test loss:  6.849142074584961\n",
      "test r2:  -0.2555159040521926\n",
      "train loss:  4.741321563720703\n",
      "train r2:  0.05473940603730243\n",
      "test loss:  6.849682331085205\n",
      "test r2:  -0.25554001303459284\n",
      "train loss:  4.739390850067139\n",
      "train r2:  0.055579762145527845\n",
      "test loss:  6.850216388702393\n",
      "test r2:  -0.2555646355723069\n",
      "train loss:  4.737462997436523\n",
      "train r2:  0.05641737296170568\n",
      "test loss:  6.850744724273682\n",
      "test r2:  -0.2555901009340509\n",
      "train loss:  4.735536575317383\n",
      "train r2:  0.0572521798821608\n",
      "test loss:  6.851268291473389\n",
      "test r2:  -0.2556168274390953\n",
      "train loss:  4.733611583709717\n",
      "train r2:  0.05808427955911122\n",
      "test loss:  6.851787090301514\n",
      "test r2:  -0.25564467507009825\n",
      "train loss:  4.731688976287842\n",
      "train r2:  0.058913519143192095\n",
      "test loss:  6.8523030281066895\n",
      "test r2:  -0.25567377630302124\n",
      "train loss:  4.729767799377441\n",
      "train r2:  0.05973992634007408\n",
      "test loss:  6.852816581726074\n",
      "test r2:  -0.25570443747930893\n",
      "train loss:  4.727847576141357\n",
      "train r2:  0.06056343733273484\n",
      "test loss:  6.853325366973877\n",
      "test r2:  -0.2557362725261587\n",
      "train loss:  4.7259297370910645\n",
      "train r2:  0.06138429358112629\n",
      "test loss:  6.853830337524414\n",
      "test r2:  -0.25576946969133885\n",
      "train loss:  4.724012851715088\n",
      "train r2:  0.06220250502264868\n",
      "test loss:  6.8543314933776855\n",
      "test r2:  -0.25580379728119174\n",
      "train loss:  4.722097396850586\n",
      "train r2:  0.06301802980995042\n",
      "test loss:  6.85482931137085\n",
      "test r2:  -0.25583913054547236\n",
      "train loss:  4.7201828956604\n",
      "train r2:  0.06383113677779761\n",
      "test loss:  6.855321884155273\n",
      "test r2:  -0.2558751392610148\n",
      "train loss:  4.7182698249816895\n",
      "train r2:  0.06464164976958975\n",
      "test loss:  6.855807304382324\n",
      "test r2:  -0.255911560425758\n",
      "train loss:  4.716357231140137\n",
      "train r2:  0.0654499604619363\n",
      "test loss:  6.856287956237793\n",
      "test r2:  -0.2559484727305874\n",
      "train loss:  4.714446544647217\n",
      "train r2:  0.06625590991862618\n",
      "test loss:  6.856760025024414\n",
      "test r2:  -0.25598503999575306\n",
      "train loss:  4.7125372886657715\n",
      "train r2:  0.0670597280772085\n",
      "test loss:  6.85722541809082\n",
      "test r2:  -0.2560214942631014\n",
      "train loss:  4.710628032684326\n",
      "train r2:  0.06786150823244963\n",
      "test loss:  6.857682704925537\n",
      "test r2:  -0.2560575702857719\n",
      "train loss:  4.7087202072143555\n",
      "train r2:  0.06866140343451888\n",
      "test loss:  6.858129978179932\n",
      "test r2:  -0.2560928358455783\n",
      "train loss:  4.706813335418701\n",
      "train r2:  0.06945940140596685\n",
      "test loss:  6.858567714691162\n",
      "test r2:  -0.2561271844415145\n",
      "train loss:  4.704905986785889\n",
      "train r2:  0.07025560851558665\n",
      "test loss:  6.85899543762207\n",
      "test r2:  -0.25616031644605375\n",
      "train loss:  4.703001022338867\n",
      "train r2:  0.07105015569586426\n",
      "test loss:  6.859412670135498\n",
      "test r2:  -0.25619232870920094\n",
      "train loss:  4.701096057891846\n",
      "train r2:  0.0718432432002869\n",
      "test loss:  6.859819412231445\n",
      "test r2:  -0.256222797139928\n",
      "train loss:  4.699193000793457\n",
      "train r2:  0.07263465262967095\n",
      "test loss:  6.860215663909912\n",
      "test r2:  -0.2562519727584722\n",
      "train loss:  4.6972880363464355\n",
      "train r2:  0.07342461287499069\n",
      "test loss:  6.860600471496582\n",
      "test r2:  -0.2562797232322438\n",
      "train loss:  4.695385932922363\n",
      "train r2:  0.07421312724673246\n",
      "test loss:  6.86097526550293\n",
      "test r2:  -0.2563059730982815\n",
      "train loss:  4.693482875823975\n",
      "train r2:  0.07500034461739669\n",
      "test loss:  6.861339092254639\n",
      "test r2:  -0.2563307116364373\n",
      "train loss:  4.6915812492370605\n",
      "train r2:  0.07578624323914185\n",
      "test loss:  6.861692905426025\n",
      "test r2:  -0.25635430845218643\n",
      "train loss:  4.6896796226501465\n",
      "train r2:  0.07657077273094026\n",
      "test loss:  6.8620381355285645\n",
      "test r2:  -0.2563767053445871\n",
      "train loss:  4.687779426574707\n",
      "train r2:  0.0773538229779609\n",
      "test loss:  6.8623738288879395\n",
      "test r2:  -0.25639780970335635\n",
      "train loss:  4.685878276824951\n",
      "train r2:  0.07813563544362068\n",
      "test loss:  6.862701416015625\n",
      "test r2:  -0.25641823200754765\n",
      "train loss:  4.683978080749512\n",
      "train r2:  0.07891610513426994\n",
      "test loss:  6.8630218505859375\n",
      "test r2:  -0.2564377180827342\n",
      "train loss:  4.682079315185547\n",
      "train r2:  0.07969510006614611\n",
      "test loss:  6.863334655761719\n",
      "test r2:  -0.2564565176055502\n",
      "train loss:  4.680179595947266\n",
      "train r2:  0.08047289739454266\n",
      "test loss:  6.863641262054443\n",
      "test r2:  -0.2564751211384966\n",
      "train loss:  4.678281307220459\n",
      "train r2:  0.08124923453325694\n",
      "test loss:  6.863943099975586\n",
      "test r2:  -0.25649320847807955\n",
      "train loss:  4.676382541656494\n",
      "train r2:  0.08202413679255904\n",
      "test loss:  6.864238262176514\n",
      "test r2:  -0.25651121999831883\n",
      "train loss:  4.674484729766846\n",
      "train r2:  0.08279769751292831\n",
      "test loss:  6.864529132843018\n",
      "test r2:  -0.2565291053427827\n",
      "train loss:  4.6725873947143555\n",
      "train r2:  0.08356989170736473\n",
      "test loss:  6.864816188812256\n",
      "test r2:  -0.25654688905270495\n",
      "train loss:  4.670688152313232\n",
      "train r2:  0.0843408167224895\n",
      "test loss:  6.865097522735596\n",
      "test r2:  -0.25656408854117774\n",
      "train loss:  4.668788433074951\n",
      "train r2:  0.08511100588376674\n",
      "test loss:  6.865375995635986\n",
      "test r2:  -0.2565809730039439\n",
      "train loss:  4.666887283325195\n",
      "train r2:  0.08588038485759375\n",
      "test loss:  6.86564826965332\n",
      "test r2:  -0.2565971343462221\n",
      "train loss:  4.6649861335754395\n",
      "train r2:  0.08664920190176295\n",
      "test loss:  6.865917682647705\n",
      "test r2:  -0.25661249196003566\n",
      "train loss:  4.663083076477051\n",
      "train r2:  0.08741771495828499\n",
      "test loss:  6.86618185043335\n",
      "test r2:  -0.25662703480572113\n",
      "train loss:  4.661179065704346\n",
      "train r2:  0.08818602837283629\n",
      "test loss:  6.866443157196045\n",
      "test r2:  -0.25664066073259617\n",
      "train loss:  4.659274101257324\n",
      "train r2:  0.08895427980929249\n",
      "test loss:  6.866700649261475\n",
      "test r2:  -0.2566534413694386\n",
      "train loss:  4.6573686599731445\n",
      "train r2:  0.08972249587358239\n",
      "test loss:  6.866954326629639\n",
      "test r2:  -0.2566653638782872\n",
      "train loss:  4.655460834503174\n",
      "train r2:  0.09049080544548727\n",
      "test loss:  6.86720609664917\n",
      "test r2:  -0.2566762961846225\n",
      "train loss:  4.653552055358887\n",
      "train r2:  0.09125955225401738\n",
      "test loss:  6.867455959320068\n",
      "test r2:  -0.2566866923770441\n",
      "train loss:  4.651642322540283\n",
      "train r2:  0.09202829067774831\n",
      "test loss:  6.867703437805176\n",
      "test r2:  -0.25669635071440666\n",
      "train loss:  4.649731159210205\n",
      "train r2:  0.09279747416296491\n",
      "test loss:  6.867949962615967\n",
      "test r2:  -0.25670545654835886\n",
      "train loss:  4.647818565368652\n",
      "train r2:  0.09356688092076637\n",
      "test loss:  6.8681960105896\n",
      "test r2:  -0.2567141679939178\n",
      "train loss:  4.645905017852783\n",
      "train r2:  0.0943367202438834\n",
      "test loss:  6.868442058563232\n",
      "test r2:  -0.2567224601206963\n",
      "train loss:  4.643990516662598\n",
      "train r2:  0.09510695755348675\n",
      "test loss:  6.868689060211182\n",
      "test r2:  -0.2567307869886202\n",
      "train loss:  4.6420745849609375\n",
      "train r2:  0.09587750163974851\n",
      "test loss:  6.868936538696289\n",
      "test r2:  -0.2567390202631372\n",
      "train loss:  4.6401567459106445\n",
      "train r2:  0.09664838641844098\n",
      "test loss:  6.869185924530029\n",
      "test r2:  -0.256747166949006\n",
      "train loss:  4.638238430023193\n",
      "train r2:  0.09741989214421343\n",
      "test loss:  6.8694376945495605\n",
      "test r2:  -0.2567555050818926\n",
      "train loss:  4.636319160461426\n",
      "train r2:  0.09819161722081693\n",
      "test loss:  6.869690418243408\n",
      "test r2:  -0.25676397283148855\n",
      "train loss:  4.634397983551025\n",
      "train r2:  0.09896388784062637\n",
      "test loss:  6.869946479797363\n",
      "test r2:  -0.25677274088860536\n",
      "train loss:  4.632476329803467\n",
      "train r2:  0.0997364500129706\n",
      "test loss:  6.870205402374268\n",
      "test r2:  -0.2567815759620098\n",
      "train loss:  4.630552768707275\n",
      "train r2:  0.10050949210001536\n",
      "test loss:  6.870466232299805\n",
      "test r2:  -0.256790816848528\n",
      "train loss:  4.628628730773926\n",
      "train r2:  0.1012832535249677\n",
      "test loss:  6.870730400085449\n",
      "test r2:  -0.2568000842466238\n",
      "train loss:  4.626703262329102\n",
      "train r2:  0.10205730846218297\n",
      "test loss:  6.870995044708252\n",
      "test r2:  -0.25680943014717283\n",
      "train loss:  4.624776840209961\n",
      "train r2:  0.10283195425755898\n",
      "test loss:  6.871263027191162\n",
      "test r2:  -0.2568190838556599\n",
      "train loss:  4.622849941253662\n",
      "train r2:  0.10360714803957838\n",
      "test loss:  6.871533393859863\n",
      "test r2:  -0.25682854055428583\n",
      "train loss:  4.620920658111572\n",
      "train r2:  0.10438294705496687\n",
      "test loss:  6.871804714202881\n",
      "test r2:  -0.2568380476011507\n",
      "train loss:  4.618991374969482\n",
      "train r2:  0.10515931714542937\n",
      "test loss:  6.872077465057373\n",
      "test r2:  -0.2568473329822236\n",
      "train loss:  4.617060661315918\n",
      "train r2:  0.10593628453104964\n",
      "test loss:  6.872351169586182\n",
      "test r2:  -0.256856587480913\n",
      "train loss:  4.615129470825195\n",
      "train r2:  0.10671403800003232\n",
      "test loss:  6.872625350952148\n",
      "test r2:  -0.25686531167840965\n",
      "train loss:  4.613196849822998\n",
      "train r2:  0.10749243674086129\n",
      "test loss:  6.872900485992432\n",
      "test r2:  -0.25687389505567926\n",
      "train loss:  4.611263751983643\n",
      "train r2:  0.10827148306133927\n",
      "test loss:  6.873174667358398\n",
      "test r2:  -0.25688207811304076\n",
      "train loss:  4.6093292236328125\n",
      "train r2:  0.10905126011867483\n",
      "test loss:  6.873449802398682\n",
      "test r2:  -0.25688984295354\n",
      "train loss:  4.607394218444824\n",
      "train r2:  0.10983175515208676\n",
      "test loss:  6.873724460601807\n",
      "test r2:  -0.2568972512272465\n",
      "train loss:  4.6054582595825195\n",
      "train r2:  0.1106129658624363\n",
      "test loss:  6.873997688293457\n",
      "test r2:  -0.2569041558547098\n",
      "train loss:  4.603521347045898\n",
      "train r2:  0.11139490190722334\n",
      "test loss:  6.874269008636475\n",
      "test r2:  -0.2569106910938044\n",
      "train loss:  4.601583480834961\n",
      "train r2:  0.11217739640276281\n",
      "test loss:  6.874539375305176\n",
      "test r2:  -0.2569169665997253\n",
      "train loss:  4.599644660949707\n",
      "train r2:  0.1129608008507107\n",
      "test loss:  6.8748064041137695\n",
      "test r2:  -0.25692294260101\n",
      "train loss:  4.597704887390137\n",
      "train r2:  0.11374471520605489\n",
      "test loss:  6.8750691413879395\n",
      "test r2:  -0.2569285956624392\n",
      "train loss:  4.595764636993408\n",
      "train r2:  0.1145292928102073\n",
      "test loss:  6.875328540802002\n",
      "test r2:  -0.2569338606561433\n",
      "train loss:  4.593822956085205\n",
      "train r2:  0.115314602296264\n",
      "test loss:  6.875580310821533\n",
      "test r2:  -0.2569390626029231\n",
      "train loss:  4.5918803215026855\n",
      "train r2:  0.11610054033496198\n",
      "test loss:  6.875823497772217\n",
      "test r2:  -0.25694388815247926\n",
      "train loss:  4.589937210083008\n",
      "train r2:  0.11688693483788704\n",
      "test loss:  6.876053333282471\n",
      "test r2:  -0.25694845333392746\n",
      "train loss:  4.587991714477539\n",
      "train r2:  0.11767401080716688\n",
      "test loss:  6.876265048980713\n",
      "test r2:  -0.256952525519643\n",
      "train loss:  4.586045742034912\n",
      "train r2:  0.11846166023649951\n",
      "test loss:  6.876451015472412\n",
      "test r2:  -0.25695635573395914\n",
      "train loss:  4.584096908569336\n",
      "train r2:  0.11924996535841326\n",
      "test loss:  6.87660026550293\n",
      "test r2:  -0.25695955621637667\n",
      "train loss:  4.582146644592285\n",
      "train r2:  0.12003888408145158\n",
      "test loss:  6.876694202423096\n",
      "test r2:  -0.256961649885483\n",
      "train loss:  4.5801920890808105\n",
      "train r2:  0.12082847945930386\n",
      "test loss:  6.876704216003418\n",
      "test r2:  -0.25696236410460194\n",
      "train loss:  4.5782341957092285\n",
      "train r2:  0.12161856015970762\n",
      "test loss:  6.876579761505127\n",
      "test r2:  -0.2569607432444152\n",
      "train loss:  4.576269149780273\n",
      "train r2:  0.1224094224125557\n",
      "test loss:  6.876233100891113\n",
      "test r2:  -0.256955406568681\n",
      "train loss:  4.574293613433838\n",
      "train r2:  0.12320097749743975\n",
      "test loss:  6.8754963874816895\n",
      "test r2:  -0.2569434998799365\n",
      "train loss:  4.572300434112549\n",
      "train r2:  0.1239933325846686\n",
      "test loss:  6.874038219451904\n",
      "test r2:  -0.2569199897757257\n",
      "train loss:  4.5702738761901855\n",
      "train r2:  0.12478715770232152\n",
      "test loss:  6.8712310791015625\n",
      "test r2:  -0.25687609758938557\n",
      "train loss:  4.56817626953125\n",
      "train r2:  0.12558260852970426\n",
      "test loss:  6.866270542144775\n",
      "test r2:  -0.2568036153454567\n",
      "train loss:  4.565891742706299\n",
      "train r2:  0.12638193695987676\n",
      "test loss:  6.859906196594238\n",
      "test r2:  -0.25672058741281\n",
      "train loss:  4.5629801750183105\n",
      "train r2:  0.12719145527806675\n",
      "test loss:  6.856082439422607\n",
      "test r2:  -0.25667114913303\n",
      "train loss:  4.558098316192627\n",
      "train r2:  0.12803137063765357\n",
      "test loss:  6.8553667068481445\n",
      "test r2:  -0.25664726117329506\n",
      "train loss:  4.553965091705322\n",
      "train r2:  0.12887299866115132\n",
      "test loss:  6.855357646942139\n",
      "test r2:  -0.25661148992726335\n",
      "train loss:  4.551511287689209\n",
      "train r2:  0.12970954345774777\n",
      "test loss:  6.855151176452637\n",
      "test r2:  -0.25655573893851114\n",
      "train loss:  4.548466205596924\n",
      "train r2:  0.13057031759758397\n",
      "test loss:  6.854020595550537\n",
      "test r2:  -0.25647560498707933\n",
      "train loss:  4.542137145996094\n",
      "train r2:  0.13149221274074263\n",
      "test loss:  6.84837007522583\n",
      "test r2:  -0.2563202470718364\n",
      "train loss:  4.534125804901123\n",
      "train r2:  0.13245857654455362\n",
      "test loss:  6.836255073547363\n",
      "test r2:  -0.25607485872239066\n",
      "train loss:  4.523853302001953\n",
      "train r2:  0.1334807376030861\n",
      "test loss:  6.83091402053833\n",
      "test r2:  -0.2558719979421815\n",
      "train loss:  4.520057201385498\n",
      "train r2:  0.13446328633992943\n",
      "test loss:  6.827463150024414\n",
      "test r2:  -0.25563905972427614\n",
      "train loss:  4.517638683319092\n",
      "train r2:  0.1354765301937786\n",
      "test loss:  6.827234268188477\n",
      "test r2:  -0.2554115074442993\n",
      "train loss:  4.51527214050293\n",
      "train r2:  0.13652983778471262\n",
      "test loss:  6.827220439910889\n",
      "test r2:  -0.2551715438334097\n",
      "train loss:  4.512869358062744\n",
      "train r2:  0.13761524320942353\n",
      "test loss:  6.825222969055176\n",
      "test r2:  -0.2548949219666665\n",
      "train loss:  4.510422229766846\n",
      "train r2:  0.13872399835365512\n",
      "test loss:  6.8165669441223145\n",
      "test r2:  -0.2544851684405458\n",
      "train loss:  4.507932662963867\n",
      "train r2:  0.13984848270853256\n",
      "test loss:  6.804813861846924\n",
      "test r2:  -0.25407185701829405\n",
      "train loss:  4.505402565002441\n",
      "train r2:  0.14098257393630598\n",
      "test loss:  6.800666332244873\n",
      "test r2:  -0.25388755688531783\n",
      "train loss:  4.502835273742676\n",
      "train r2:  0.14212172827576475\n",
      "test loss:  6.799992084503174\n",
      "test r2:  -0.25383116157039565\n",
      "train loss:  4.500232696533203\n",
      "train r2:  0.1432632478361714\n",
      "test loss:  6.80037260055542\n",
      "test r2:  -0.25385224069769663\n",
      "train loss:  4.497596263885498\n",
      "train r2:  0.1444058111635379\n",
      "test loss:  6.80118989944458\n",
      "test r2:  -0.25393326244186554\n",
      "train loss:  4.494929313659668\n",
      "train r2:  0.14554977813888514\n",
      "test loss:  6.802242755889893\n",
      "test r2:  -0.25406003930227317\n",
      "train loss:  4.492234706878662\n",
      "train r2:  0.14669658661147056\n",
      "test loss:  6.803433418273926\n",
      "test r2:  -0.2542182997170914\n",
      "train loss:  4.489514350891113\n",
      "train r2:  0.1478482693721045\n",
      "test loss:  6.804692268371582\n",
      "test r2:  -0.2543926974839137\n",
      "train loss:  4.486772060394287\n",
      "train r2:  0.14900753259317112\n",
      "test loss:  6.805959701538086\n",
      "test r2:  -0.2545680291775916\n",
      "train loss:  4.4840087890625\n",
      "train r2:  0.15017678634199572\n",
      "test loss:  6.807182788848877\n",
      "test r2:  -0.2547303658027893\n",
      "train loss:  4.481227874755859\n",
      "train r2:  0.15135857937792463\n",
      "test loss:  6.808321952819824\n",
      "test r2:  -0.2548681428675592\n",
      "train loss:  4.478431224822998\n",
      "train r2:  0.15255424154856723\n",
      "test loss:  6.809347152709961\n",
      "test r2:  -0.25497342831736725\n",
      "train loss:  4.475618839263916\n",
      "train r2:  0.1537648158705034\n",
      "test loss:  6.810245990753174\n",
      "test r2:  -0.2550414793407363\n",
      "train loss:  4.472793102264404\n",
      "train r2:  0.1549904146516069\n",
      "test loss:  6.811017036437988\n",
      "test r2:  -0.2550719371445074\n",
      "train loss:  4.4699554443359375\n",
      "train r2:  0.15623005823719893\n",
      "test loss:  6.811673164367676\n",
      "test r2:  -0.25506748669670465\n",
      "train loss:  4.467107772827148\n",
      "train r2:  0.1574820322086713\n",
      "test loss:  6.812237739562988\n",
      "test r2:  -0.25503438241319043\n",
      "train loss:  4.464251518249512\n",
      "train r2:  0.15874426933029862\n",
      "test loss:  6.812740802764893\n",
      "test r2:  -0.2549806774069092\n",
      "train loss:  4.461387634277344\n",
      "train r2:  0.16001396266933177\n",
      "test loss:  6.813215732574463\n",
      "test r2:  -0.25491587112394787\n",
      "train loss:  4.458517551422119\n",
      "train r2:  0.16128825675009661\n",
      "test loss:  6.813693523406982\n",
      "test r2:  -0.2548495443664669\n",
      "train loss:  4.455643177032471\n",
      "train r2:  0.1625641065734995\n",
      "test loss:  6.814199924468994\n",
      "test r2:  -0.254790442561297\n",
      "train loss:  4.452764511108398\n",
      "train r2:  0.16383873488158895\n",
      "test loss:  6.814756870269775\n",
      "test r2:  -0.2547463509369843\n",
      "train loss:  4.4498820304870605\n",
      "train r2:  0.16511032215921395\n",
      "test loss:  6.815373420715332\n",
      "test r2:  -0.25472243265401784\n",
      "train loss:  4.446996688842773\n",
      "train r2:  0.16637706151749876\n",
      "test loss:  6.816053867340088\n",
      "test r2:  -0.254721532545092\n",
      "train loss:  4.444108486175537\n",
      "train r2:  0.16763779015175206\n",
      "test loss:  6.816795349121094\n",
      "test r2:  -0.2547440550904714\n",
      "train loss:  4.441217422485352\n",
      "train r2:  0.16889225066397084\n",
      "test loss:  6.817585468292236\n",
      "test r2:  -0.2547881380602204\n",
      "train loss:  4.43832540512085\n",
      "train r2:  0.17014086809967244\n",
      "test loss:  6.818410873413086\n",
      "test r2:  -0.2548499397779238\n",
      "train loss:  4.435431003570557\n",
      "train r2:  0.1713843792632862\n",
      "test loss:  6.819253444671631\n",
      "test r2:  -0.25492376872612943\n",
      "train loss:  4.432535648345947\n",
      "train r2:  0.17262367175152238\n",
      "test loss:  6.820094585418701\n",
      "test r2:  -0.2550039456216473\n",
      "train loss:  4.4296393394470215\n",
      "train r2:  0.17386038833841155\n",
      "test loss:  6.820918560028076\n",
      "test r2:  -0.25508422608262404\n",
      "train loss:  4.426742076873779\n",
      "train r2:  0.175095691724949\n",
      "test loss:  6.821708679199219\n",
      "test r2:  -0.25515888698980294\n",
      "train loss:  4.423844814300537\n",
      "train r2:  0.17633118051434848\n",
      "test loss:  6.822455883026123\n",
      "test r2:  -0.25522330678367\n",
      "train loss:  4.4209465980529785\n",
      "train r2:  0.17756774235900563\n",
      "test loss:  6.823153495788574\n",
      "test r2:  -0.25527421693093544\n",
      "train loss:  4.418048858642578\n",
      "train r2:  0.17880585626927192\n",
      "test loss:  6.8237996101379395\n",
      "test r2:  -0.2553101844069854\n",
      "train loss:  4.4151506423950195\n",
      "train r2:  0.18004621245629115\n",
      "test loss:  6.824398517608643\n",
      "test r2:  -0.2553311677826151\n",
      "train loss:  4.412252426147461\n",
      "train r2:  0.18128857694030676\n",
      "test loss:  6.824956893920898\n",
      "test r2:  -0.25533882922535\n",
      "train loss:  4.409354209899902\n",
      "train r2:  0.18253263417141674\n",
      "test loss:  6.825484752655029\n",
      "test r2:  -0.2553357762837336\n",
      "train loss:  4.406456470489502\n",
      "train r2:  0.18377739632371426\n",
      "test loss:  6.825994491577148\n",
      "test r2:  -0.2553258996674923\n",
      "train loss:  4.403558731079102\n",
      "train r2:  0.18502223191860334\n",
      "test loss:  6.8264970779418945\n",
      "test r2:  -0.2553128686823425\n",
      "train loss:  4.400661468505859\n",
      "train r2:  0.18626596150640506\n",
      "test loss:  6.82700777053833\n",
      "test r2:  -0.25530091099621566\n",
      "train loss:  4.397764682769775\n",
      "train r2:  0.18750759346216617\n",
      "test loss:  6.827532768249512\n",
      "test r2:  -0.255293413522822\n",
      "train loss:  4.394868850708008\n",
      "train r2:  0.18874630829718098\n",
      "test loss:  6.828081130981445\n",
      "test r2:  -0.2552929371534063\n",
      "train loss:  4.391973495483398\n",
      "train r2:  0.1899814420551701\n",
      "test loss:  6.8286590576171875\n",
      "test r2:  -0.255301402176497\n",
      "train loss:  4.389077663421631\n",
      "train r2:  0.1912124700990302\n",
      "test loss:  6.829266548156738\n",
      "test r2:  -0.255319525120723\n",
      "train loss:  4.386183738708496\n",
      "train r2:  0.19243933418070025\n",
      "test loss:  6.829900741577148\n",
      "test r2:  -0.2553464946406483\n",
      "train loss:  4.3832902908325195\n",
      "train r2:  0.1936620393479983\n",
      "test loss:  6.8305583000183105\n",
      "test r2:  -0.2553812360078156\n",
      "train loss:  4.380396842956543\n",
      "train r2:  0.19488089743971326\n",
      "test loss:  6.831231594085693\n",
      "test r2:  -0.25542150533964136\n",
      "train loss:  4.377504825592041\n",
      "train r2:  0.1960964222094178\n",
      "test loss:  6.831913471221924\n",
      "test r2:  -0.255464818995067\n",
      "train loss:  4.374612808227539\n",
      "train r2:  0.19730913378243498\n",
      "test loss:  6.832595348358154\n",
      "test r2:  -0.25550864341123125\n",
      "train loss:  4.371723175048828\n",
      "train r2:  0.19851969107560763\n",
      "test loss:  6.83327054977417\n",
      "test r2:  -0.25555061978729743\n",
      "train loss:  4.368834972381592\n",
      "train r2:  0.19972863850309408\n",
      "test loss:  6.8339338302612305\n",
      "test r2:  -0.25558912573915626\n",
      "train loss:  4.365968227386475\n",
      "train r2:  0.20093605803363446\n",
      "test loss:  6.8345842361450195\n",
      "test r2:  -0.2556239474465818\n",
      "train loss:  4.3631272315979\n",
      "train r2:  0.20214076363451805\n",
      "test loss:  6.835221767425537\n",
      "test r2:  -0.2556554618571012\n",
      "train loss:  4.36031436920166\n",
      "train r2:  0.20334206373460018\n",
      "test loss:  6.835847854614258\n",
      "test r2:  -0.2556841476055076\n",
      "train loss:  4.357531547546387\n",
      "train r2:  0.20453894109935378\n",
      "test loss:  6.836465358734131\n",
      "test r2:  -0.2557106978178898\n",
      "train loss:  4.3547797203063965\n",
      "train r2:  0.20573045035984383\n",
      "test loss:  6.837074279785156\n",
      "test r2:  -0.2557360079148465\n",
      "train loss:  4.352059841156006\n",
      "train r2:  0.20691596581141947\n",
      "test loss:  6.8376784324646\n",
      "test r2:  -0.2557611518066132\n",
      "train loss:  4.349372863769531\n",
      "train r2:  0.20809470423582688\n",
      "test loss:  6.8382792472839355\n",
      "test r2:  -0.2557865763854825\n",
      "train loss:  4.346719264984131\n",
      "train r2:  0.20926571537036676\n",
      "test loss:  6.8388776779174805\n",
      "test r2:  -0.2558132836172078\n",
      "train loss:  4.344099044799805\n",
      "train r2:  0.21042884904245773\n",
      "test loss:  6.839472770690918\n",
      "test r2:  -0.25584140145601575\n",
      "train loss:  4.3415141105651855\n",
      "train r2:  0.21158328640418345\n",
      "test loss:  6.840064525604248\n",
      "test r2:  -0.25587116696479595\n",
      "train loss:  4.338963508605957\n",
      "train r2:  0.21272890976989134\n",
      "test loss:  6.8406524658203125\n",
      "test r2:  -0.25590231775718353\n",
      "train loss:  4.336447715759277\n",
      "train r2:  0.2138655285868568\n",
      "test loss:  6.841232776641846\n",
      "test r2:  -0.2559347259764102\n",
      "train loss:  4.333967208862305\n",
      "train r2:  0.21499276540399725\n",
      "test loss:  6.8418049812316895\n",
      "test r2:  -0.2559677858151299\n",
      "train loss:  4.331521034240723\n",
      "train r2:  0.21611066007129653\n",
      "test loss:  6.8423662185668945\n",
      "test r2:  -0.2560008202602313\n",
      "train loss:  4.329110145568848\n",
      "train r2:  0.2172192156945315\n",
      "test loss:  6.842913627624512\n",
      "test r2:  -0.2560332047454137\n",
      "train loss:  4.3267340660095215\n",
      "train r2:  0.2183183916071244\n",
      "test loss:  6.84344482421875\n",
      "test r2:  -0.256064666852295\n",
      "train loss:  4.324392318725586\n",
      "train r2:  0.21940825932928487\n",
      "test loss:  6.843958854675293\n",
      "test r2:  -0.256094285983959\n",
      "train loss:  4.322085380554199\n",
      "train r2:  0.22048894133762575\n",
      "test loss:  6.844454765319824\n",
      "test r2:  -0.2561220743861159\n",
      "train loss:  4.319811820983887\n",
      "train r2:  0.22156027369878595\n",
      "test loss:  6.8449320793151855\n",
      "test r2:  -0.25614806371663157\n",
      "train loss:  4.317573070526123\n",
      "train r2:  0.22262235032684452\n",
      "test loss:  6.845391750335693\n",
      "test r2:  -0.2561717594718924\n",
      "train loss:  4.315366744995117\n",
      "train r2:  0.22367502645291604\n",
      "test loss:  6.845834255218506\n",
      "test r2:  -0.25619398993498166\n",
      "train loss:  4.313194751739502\n",
      "train r2:  0.2247184027303657\n",
      "test loss:  6.846261978149414\n",
      "test r2:  -0.25621475781121816\n",
      "train loss:  4.311054229736328\n",
      "train r2:  0.2257524370520262\n",
      "test loss:  6.846674919128418\n",
      "test r2:  -0.25623433051977673\n",
      "train loss:  4.30894660949707\n",
      "train r2:  0.2267767476494741\n",
      "test loss:  6.847076416015625\n",
      "test r2:  -0.25625340054236645\n",
      "train loss:  4.306870937347412\n",
      "train r2:  0.22779166703796117\n",
      "test loss:  6.847467422485352\n",
      "test r2:  -0.2562723512525833\n",
      "train loss:  4.304826736450195\n",
      "train r2:  0.2287969147670459\n",
      "test loss:  6.847848415374756\n",
      "test r2:  -0.25629113775783874\n",
      "train loss:  4.302814483642578\n",
      "train r2:  0.22979243274231786\n",
      "test loss:  6.8482208251953125\n",
      "test r2:  -0.25631033421669014\n",
      "train loss:  4.3008317947387695\n",
      "train r2:  0.23077845029396626\n",
      "test loss:  6.848584175109863\n",
      "test r2:  -0.25632986552262227\n",
      "train loss:  4.298880100250244\n",
      "train r2:  0.23175475596036255\n",
      "test loss:  6.848940849304199\n",
      "test r2:  -0.25634958167964816\n",
      "train loss:  4.296957492828369\n",
      "train r2:  0.23272165849881854\n",
      "test loss:  6.849288463592529\n",
      "test r2:  -0.25636963379845845\n",
      "train loss:  4.295064926147461\n",
      "train r2:  0.23367899827754968\n",
      "test loss:  6.849626541137695\n",
      "test r2:  -0.25638977613944314\n",
      "train loss:  4.293201446533203\n",
      "train r2:  0.2346271515469952\n",
      "test loss:  6.849954605102539\n",
      "test r2:  -0.25640943421364915\n",
      "train loss:  4.2913665771484375\n",
      "train r2:  0.23556616229980543\n",
      "test loss:  6.8502726554870605\n",
      "test r2:  -0.25642869663501777\n",
      "train loss:  4.289559364318848\n",
      "train r2:  0.23649603222185367\n",
      "test loss:  6.850578784942627\n",
      "test r2:  -0.2564471474305907\n",
      "train loss:  4.287780284881592\n",
      "train r2:  0.23741728127795658\n",
      "test loss:  6.850874423980713\n",
      "test r2:  -0.25646470167847846\n",
      "train loss:  4.286027431488037\n",
      "train r2:  0.23832974070025648\n",
      "test loss:  6.851158618927002\n",
      "test r2:  -0.25648131149663667\n",
      "train loss:  4.284302234649658\n",
      "train r2:  0.23923356429864184\n",
      "test loss:  6.851431369781494\n",
      "test r2:  -0.2564967546025805\n",
      "train loss:  4.2826032638549805\n",
      "train r2:  0.2401289285223014\n",
      "test loss:  6.851693630218506\n",
      "test r2:  -0.256511202788392\n",
      "train loss:  4.280930995941162\n",
      "train r2:  0.24101587939029367\n",
      "test loss:  6.851945877075195\n",
      "test r2:  -0.25652484600744097\n",
      "train loss:  4.27928352355957\n",
      "train r2:  0.24189446575329077\n",
      "test loss:  6.852189540863037\n",
      "test r2:  -0.2565379972197137\n",
      "train loss:  4.277661323547363\n",
      "train r2:  0.24276482491964302\n",
      "test loss:  6.8524250984191895\n",
      "test r2:  -0.25655040828049125\n",
      "train loss:  4.276063919067383\n",
      "train r2:  0.24362693409386293\n",
      "test loss:  6.852653980255127\n",
      "test r2:  -0.25656244106081183\n",
      "train loss:  4.2744903564453125\n",
      "train r2:  0.24448082239571123\n",
      "test loss:  6.852876663208008\n",
      "test r2:  -0.2565745081396158\n",
      "train loss:  4.272941589355469\n",
      "train r2:  0.2453266586819337\n",
      "test loss:  6.853094100952148\n",
      "test r2:  -0.2565863704897451\n",
      "train loss:  4.271416187286377\n",
      "train r2:  0.2461644285907454\n",
      "test loss:  6.853306770324707\n",
      "test r2:  -0.256598290674086\n",
      "train loss:  4.269913673400879\n",
      "train r2:  0.24699431212819634\n",
      "test loss:  6.853515625\n",
      "test r2:  -0.25661038806894676\n",
      "train loss:  4.268434047698975\n",
      "train r2:  0.24781627208293955\n",
      "test loss:  6.853719711303711\n",
      "test r2:  -0.25662268663490906\n",
      "train loss:  4.266977310180664\n",
      "train r2:  0.24863059329571524\n",
      "test loss:  6.853919982910156\n",
      "test r2:  -0.25663464433764394\n",
      "train loss:  4.265542507171631\n",
      "train r2:  0.24943716357625145\n",
      "test loss:  6.854116439819336\n",
      "test r2:  -0.25664665729186265\n",
      "train loss:  4.264129161834717\n",
      "train r2:  0.2502360947081167\n",
      "test loss:  6.854307174682617\n",
      "test r2:  -0.25665835186118646\n",
      "train loss:  4.262738227844238\n",
      "train r2:  0.25102779045132084\n",
      "test loss:  6.8544921875\n",
      "test r2:  -0.2566696449401624\n",
      "train loss:  4.261366844177246\n",
      "train r2:  0.2518121064285851\n",
      "test loss:  6.854673862457275\n",
      "test r2:  -0.2566805663428924\n",
      "train loss:  4.260017395019531\n",
      "train r2:  0.25258928043374673\n",
      "test loss:  6.854849338531494\n",
      "test r2:  -0.2566908834743382\n",
      "train loss:  4.258688449859619\n",
      "train r2:  0.2533593665770938\n",
      "test loss:  6.855020523071289\n",
      "test r2:  -0.2567007708794624\n",
      "train loss:  4.257379055023193\n",
      "train r2:  0.25412255706909503\n",
      "test loss:  6.855186939239502\n",
      "test r2:  -0.2567102486818591\n",
      "train loss:  4.256089210510254\n",
      "train r2:  0.2548787555749773\n",
      "test loss:  6.855349540710449\n",
      "test r2:  -0.2567193146893836\n",
      "train loss:  4.254818439483643\n",
      "train r2:  0.2556281066434778\n",
      "test loss:  6.855508327484131\n",
      "test r2:  -0.2567280004280854\n",
      "train loss:  4.253567695617676\n",
      "train r2:  0.2563707797741016\n",
      "test loss:  6.855664253234863\n",
      "test r2:  -0.2567366215754392\n",
      "train loss:  4.252335071563721\n",
      "train r2:  0.2571066412297712\n",
      "test loss:  6.85581636428833\n",
      "test r2:  -0.2567448915525048\n",
      "train loss:  4.251121997833252\n",
      "train r2:  0.25783590739267204\n",
      "test loss:  6.855966567993164\n",
      "test r2:  -0.2567531470766833\n",
      "train loss:  4.2499260902404785\n",
      "train r2:  0.2585586762610992\n",
      "test loss:  6.856114387512207\n",
      "test r2:  -0.2567613026234976\n",
      "train loss:  4.248748302459717\n",
      "train r2:  0.25927483296724074\n",
      "test loss:  6.856259346008301\n",
      "test r2:  -0.25676940451790253\n",
      "train loss:  4.247588634490967\n",
      "train r2:  0.2599845712694272\n",
      "test loss:  6.856402397155762\n",
      "test r2:  -0.25677746579544025\n",
      "train loss:  4.246446132659912\n",
      "train r2:  0.2606879888584678\n",
      "test loss:  6.856544494628906\n",
      "test r2:  -0.2567857690825168\n",
      "train loss:  4.2453203201293945\n",
      "train r2:  0.26138513281897047\n",
      "test loss:  6.856684684753418\n",
      "test r2:  -0.2567937800534832\n",
      "train loss:  4.244211196899414\n",
      "train r2:  0.262076088372743\n",
      "test loss:  6.856823444366455\n",
      "test r2:  -0.2568019744482053\n",
      "train loss:  4.243119239807129\n",
      "train r2:  0.26276079972110533\n",
      "test loss:  6.856959342956543\n",
      "test r2:  -0.2568098145452884\n",
      "train loss:  4.2420430183410645\n",
      "train r2:  0.2634396143895389\n",
      "test loss:  6.8570942878723145\n",
      "test r2:  -0.2568176020326034\n",
      "train loss:  4.240983486175537\n",
      "train r2:  0.2641124071620856\n",
      "test loss:  6.857227802276611\n",
      "test r2:  -0.25682516560422175\n",
      "train loss:  4.239938735961914\n",
      "train r2:  0.2647793867101277\n",
      "test loss:  6.857358932495117\n",
      "test r2:  -0.256832582068228\n",
      "train loss:  4.238911151885986\n",
      "train r2:  0.26544047213674793\n",
      "test loss:  6.857488632202148\n",
      "test r2:  -0.2568396921628193\n",
      "train loss:  4.237897872924805\n",
      "train r2:  0.26609585457206286\n",
      "test loss:  6.857615947723389\n",
      "test r2:  -0.2568465614388775\n",
      "train loss:  4.236899375915527\n",
      "train r2:  0.2667454973287454\n",
      "test loss:  6.857741832733154\n",
      "test r2:  -0.25685327334747066\n",
      "train loss:  4.235915660858154\n",
      "train r2:  0.2673896347618805\n",
      "test loss:  6.857865810394287\n",
      "test r2:  -0.2568597691984309\n",
      "train loss:  4.2349467277526855\n",
      "train r2:  0.2680280599964777\n",
      "test loss:  6.857988357543945\n",
      "test r2:  -0.2568662872129812\n",
      "train loss:  4.2339911460876465\n",
      "train r2:  0.26866100598007747\n",
      "test loss:  6.8581085205078125\n",
      "test r2:  -0.2568721034993682\n",
      "train loss:  4.233043193817139\n",
      "train r2:  0.2692890211660329\n",
      "test loss:  6.858224391937256\n",
      "test r2:  -0.2568768640456729\n",
      "train loss:  4.232100963592529\n",
      "train r2:  0.2699126585728554\n",
      "test loss:  6.858334541320801\n",
      "test r2:  -0.2568796250780858\n",
      "train loss:  4.23116397857666\n",
      "train r2:  0.2705326329766943\n",
      "test loss:  6.85844087600708\n",
      "test r2:  -0.2568806072471126\n",
      "train loss:  4.230231285095215\n",
      "train r2:  0.2711495489722302\n",
      "test loss:  6.8585429191589355\n",
      "test r2:  -0.25687968622871993\n",
      "train loss:  4.229302883148193\n",
      "train r2:  0.27176372668236026\n",
      "test loss:  6.858642101287842\n",
      "test r2:  -0.2568774244168597\n",
      "train loss:  4.228378772735596\n",
      "train r2:  0.27237533707475936\n",
      "test loss:  6.8587422370910645\n",
      "test r2:  -0.2568745363517022\n",
      "train loss:  4.227457046508789\n",
      "train r2:  0.272984775303704\n",
      "test loss:  6.85884428024292\n",
      "test r2:  -0.2568712225586087\n",
      "train loss:  4.226538181304932\n",
      "train r2:  0.2735917439917339\n",
      "test loss:  6.858953475952148\n",
      "test r2:  -0.2568685271166653\n",
      "train loss:  4.225620746612549\n",
      "train r2:  0.2741963895287115\n",
      "test loss:  6.859068393707275\n",
      "test r2:  -0.2568668823063356\n",
      "train loss:  4.224704742431641\n",
      "train r2:  0.2747982628980109\n",
      "test loss:  6.859194755554199\n",
      "test r2:  -0.25686701565142744\n",
      "train loss:  4.223787307739258\n",
      "train r2:  0.2753965853616861\n",
      "test loss:  6.8593292236328125\n",
      "test r2:  -0.256868677823209\n",
      "train loss:  4.2228684425354\n",
      "train r2:  0.27598990387660116\n",
      "test loss:  6.859475612640381\n",
      "test r2:  -0.25687234172369555\n",
      "train loss:  4.221944808959961\n",
      "train r2:  0.2765792403663798\n",
      "test loss:  6.859631538391113\n",
      "test r2:  -0.2568777450600066\n",
      "train loss:  4.221010684967041\n",
      "train r2:  0.277160973868538\n",
      "test loss:  6.859797954559326\n",
      "test r2:  -0.2568849922930061\n",
      "train loss:  4.220060348510742\n",
      "train r2:  0.2777272956500144\n",
      "test loss:  6.859975814819336\n",
      "test r2:  -0.25689402394913086\n",
      "train loss:  4.219081401824951\n",
      "train r2:  0.2782672605562456\n",
      "test loss:  6.860166549682617\n",
      "test r2:  -0.2569057133487773\n",
      "train loss:  4.21805477142334\n",
      "train r2:  0.2787576676011748\n",
      "test loss:  6.860373020172119\n",
      "test r2:  -0.2569207223731196\n",
      "train loss:  4.216952800750732\n",
      "train r2:  0.2791817093154598\n",
      "test loss:  6.8606061935424805\n",
      "test r2:  -0.25694176299607374\n",
      "train loss:  4.215723991394043\n",
      "train r2:  0.2795113204758506\n",
      "test loss:  6.860877513885498\n",
      "test r2:  -0.25697278648303756\n",
      "train loss:  4.2142863273620605\n",
      "train r2:  0.2796039333755531\n",
      "test loss:  6.8612141609191895\n",
      "test r2:  -0.25702139023530446\n",
      "train loss:  4.2125163078308105\n",
      "train r2:  0.27925175727454676\n",
      "test loss:  6.861656665802002\n",
      "test r2:  -0.2570983986761979\n",
      "train loss:  4.2108259201049805\n",
      "train r2:  0.2781907227916195\n",
      "test loss:  6.861996650695801\n",
      "test r2:  -0.25714153352901437\n",
      "train loss:  4.209543228149414\n",
      "train r2:  0.27803547998620093\n",
      "test loss:  6.862057209014893\n",
      "test r2:  -0.25709787298586306\n",
      "train loss:  4.207570552825928\n",
      "train r2:  0.2798126081528238\n",
      "test loss:  6.862154006958008\n",
      "test r2:  -0.2570606942708096\n",
      "train loss:  4.206282138824463\n",
      "train r2:  0.2812069791173232\n",
      "test loss:  6.862450122833252\n",
      "test r2:  -0.2570796018024082\n",
      "train loss:  4.204820156097412\n",
      "train r2:  0.28192008920450573\n",
      "test loss:  6.862949848175049\n",
      "test r2:  -0.2571555416339595\n",
      "train loss:  4.202962875366211\n",
      "train r2:  0.28211704377730673\n",
      "test loss:  6.863533020019531\n",
      "test r2:  -0.2572524840238839\n",
      "train loss:  4.2012939453125\n",
      "train r2:  0.28189292891935014\n",
      "test loss:  6.86391019821167\n",
      "test r2:  -0.25728510711350605\n",
      "train loss:  4.199963569641113\n",
      "train r2:  0.28208849110379075\n",
      "test loss:  6.863905429840088\n",
      "test r2:  -0.25720070583992194\n",
      "train loss:  4.198017120361328\n",
      "train r2:  0.28344376602175503\n",
      "test loss:  6.863833904266357\n",
      "test r2:  -0.2570933551717909\n",
      "train loss:  4.196516036987305\n",
      "train r2:  0.2848026262187966\n",
      "test loss:  6.863976001739502\n",
      "test r2:  -0.2570460529036882\n",
      "train loss:  4.194986343383789\n",
      "train r2:  0.28565326147826\n",
      "test loss:  6.864383220672607\n",
      "test r2:  -0.25707406699664537\n",
      "train loss:  4.193129062652588\n",
      "train r2:  0.28604770861092843\n",
      "test loss:  6.864904880523682\n",
      "test r2:  -0.25713332414071477\n",
      "train loss:  4.191509246826172\n",
      "train r2:  0.28620384840887414\n",
      "test loss:  6.865249156951904\n",
      "test r2:  -0.2571371933994038\n",
      "train loss:  4.189956188201904\n",
      "train r2:  0.28680803339458927\n",
      "test loss:  6.865350246429443\n",
      "test r2:  -0.257066644879292\n",
      "train loss:  4.188100337982178\n",
      "train r2:  0.2880223801524866\n",
      "test loss:  6.865492343902588\n",
      "test r2:  -0.25700584184304054\n",
      "train loss:  4.186555862426758\n",
      "train r2:  0.28917268680963204\n",
      "test loss:  6.8658905029296875\n",
      "test r2:  -0.2570184072224966\n",
      "train loss:  4.18489408493042\n",
      "train r2:  0.2899392476473278\n",
      "test loss:  6.86651611328125\n",
      "test r2:  -0.25709648629795234\n",
      "train loss:  4.183096408843994\n",
      "train r2:  0.29038914471292177\n",
      "test loss:  6.867143154144287\n",
      "test r2:  -0.2571729781378753\n",
      "train loss:  4.181545257568359\n",
      "train r2:  0.2908355036210708\n",
      "test loss:  6.867537021636963\n",
      "test r2:  -0.2571793272157481\n",
      "train loss:  4.179813385009766\n",
      "train r2:  0.2917226028830382\n",
      "test loss:  6.86778450012207\n",
      "test r2:  -0.2571405835724476\n",
      "train loss:  4.178102493286133\n",
      "train r2:  0.2928383029589158\n",
      "test loss:  6.868129253387451\n",
      "test r2:  -0.2571291797637836\n",
      "train loss:  4.176512241363525\n",
      "train r2:  0.2937665222566579\n",
      "test loss:  6.868657112121582\n",
      "test r2:  -0.2571711729697781\n",
      "train loss:  4.174754619598389\n",
      "train r2:  0.29441243482343327\n",
      "test loss:  6.869241714477539\n",
      "test r2:  -0.2572289305648281\n",
      "train loss:  4.173098087310791\n",
      "train r2:  0.2949429844875672\n",
      "test loss:  6.8696675300598145\n",
      "test r2:  -0.2572394405603158\n",
      "train loss:  4.171448707580566\n",
      "train r2:  0.29569714823706295\n",
      "test loss:  6.869920253753662\n",
      "test r2:  -0.25719777398714205\n",
      "train loss:  4.169702053070068\n",
      "train r2:  0.296710159770055\n",
      "test loss:  6.870195388793945\n",
      "test r2:  -0.25716257808406473\n",
      "train loss:  4.168079376220703\n",
      "train r2:  0.2976698998099033\n",
      "test loss:  6.870631217956543\n",
      "test r2:  -0.2571747990089288\n",
      "train loss:  4.166362285614014\n",
      "train r2:  0.29841184471706583\n",
      "test loss:  6.8711652755737305\n",
      "test r2:  -0.2572159675835741\n",
      "train loss:  4.164666652679443\n",
      "train r2:  0.29902653657445377\n",
      "test loss:  6.871623516082764\n",
      "test r2:  -0.25723460477157256\n",
      "train loss:  4.163013458251953\n",
      "train r2:  0.29976318026764326\n",
      "test loss:  6.871954441070557\n",
      "test r2:  -0.2572160005639128\n",
      "train loss:  4.1612772941589355\n",
      "train r2:  0.3007050897957414\n",
      "test loss:  6.872300624847412\n",
      "test r2:  -0.25720187081871604\n",
      "train loss:  4.15962028503418\n",
      "train r2:  0.30163661078163784\n",
      "test loss:  6.872776508331299\n",
      "test r2:  -0.25722657119767445\n",
      "train loss:  4.157910346984863\n",
      "train r2:  0.30240413013151834\n",
      "test loss:  6.8733320236206055\n",
      "test r2:  -0.2572754096999559\n",
      "train loss:  4.156208038330078\n",
      "train r2:  0.30306983273324184\n",
      "test loss:  6.873819351196289\n",
      "test r2:  -0.25730468271101525\n",
      "train loss:  4.154531955718994\n",
      "train r2:  0.30382767718584414\n",
      "test loss:  6.874197483062744\n",
      "test r2:  -0.25730185450649357\n",
      "train loss:  4.152805328369141\n",
      "train r2:  0.3047362389560223\n",
      "test loss:  6.874575614929199\n",
      "test r2:  -0.2572995347488811\n",
      "train loss:  4.151128768920898\n",
      "train r2:  0.30563051313740885\n",
      "test loss:  6.8750386238098145\n",
      "test r2:  -0.25732334352668107\n",
      "train loss:  4.149411201477051\n",
      "train r2:  0.3063974532738939\n",
      "test loss:  6.87553596496582\n",
      "test r2:  -0.257357937711862\n",
      "train loss:  4.147710800170898\n",
      "train r2:  0.3071023059594514\n",
      "test loss:  6.87595796585083\n",
      "test r2:  -0.2573707316281113\n",
      "train loss:  4.146012306213379\n",
      "train r2:  0.30789645275026234\n",
      "test loss:  6.876297473907471\n",
      "test r2:  -0.2573601446745548\n",
      "train loss:  4.144292831420898\n",
      "train r2:  0.3087911928314886\n",
      "test loss:  6.8766560554504395\n",
      "test r2:  -0.2573559608010221\n",
      "train loss:  4.1426005363464355\n",
      "train r2:  0.309649846085594\n",
      "test loss:  6.877087116241455\n",
      "test r2:  -0.2573740326053895\n",
      "train loss:  4.140877723693848\n",
      "train r2:  0.3104085932578946\n",
      "test loss:  6.877530097961426\n",
      "test r2:  -0.2573966634299105\n",
      "train loss:  4.139177322387695\n",
      "train r2:  0.31114754541432843\n",
      "test loss:  6.877912998199463\n",
      "test r2:  -0.2574022460117804\n",
      "train loss:  4.1374616622924805\n",
      "train r2:  0.311972858121471\n",
      "test loss:  6.878261089324951\n",
      "test r2:  -0.25739842519077927\n",
      "train loss:  4.135748863220215\n",
      "train r2:  0.3128490009193796\n",
      "test loss:  6.878652572631836\n",
      "test r2:  -0.2574082481441944\n",
      "train loss:  4.134040355682373\n",
      "train r2:  0.31366920299163625\n",
      "test loss:  6.879095554351807\n",
      "test r2:  -0.2574345582307387\n",
      "train loss:  4.13231897354126\n",
      "train r2:  0.314421352477231\n",
      "test loss:  6.879524230957031\n",
      "test r2:  -0.25745715288122417\n",
      "train loss:  4.130611419677734\n",
      "train r2:  0.3151931082768782\n",
      "test loss:  6.879900932312012\n",
      "test r2:  -0.25746498563530373\n",
      "train loss:  4.128888130187988\n",
      "train r2:  0.31603581839832584\n",
      "test loss:  6.880267143249512\n",
      "test r2:  -0.2574709066782914\n",
      "train loss:  4.1271772384643555\n",
      "train r2:  0.3168849339037635\n",
      "test loss:  6.880671501159668\n",
      "test r2:  -0.25748894037482595\n",
      "train loss:  4.125455856323242\n",
      "train r2:  0.31767466090945984\n",
      "test loss:  6.88109016418457\n",
      "test r2:  -0.257511880526647\n",
      "train loss:  4.123739242553711\n",
      "train r2:  0.31843516420056994\n",
      "test loss:  6.881470203399658\n",
      "test r2:  -0.257524111505506\n",
      "train loss:  4.1220197677612305\n",
      "train r2:  0.3192389815105664\n",
      "test loss:  6.881814479827881\n",
      "test r2:  -0.2575262955006681\n",
      "train loss:  4.120298385620117\n",
      "train r2:  0.32008417614283646\n",
      "test loss:  6.882171630859375\n",
      "test r2:  -0.25753294188878173\n",
      "train loss:  4.118580341339111\n",
      "train r2:  0.32090409011653453\n",
      "test loss:  6.882555961608887\n",
      "test r2:  -0.25754857301441825\n",
      "train loss:  4.116856098175049\n",
      "train r2:  0.3216790689576471\n",
      "test loss:  6.882933139801025\n",
      "test r2:  -0.25756271257783014\n",
      "train loss:  4.115137100219727\n",
      "train r2:  0.3224600024447274\n",
      "test loss:  6.883279323577881\n",
      "test r2:  -0.2575680305722876\n",
      "train loss:  4.113412380218506\n",
      "train r2:  0.32328365318981067\n",
      "test loss:  6.883619785308838\n",
      "test r2:  -0.2575726644708407\n",
      "train loss:  4.111691474914551\n",
      "train r2:  0.3241139220399476\n",
      "test loss:  6.8839874267578125\n",
      "test r2:  -0.2575855332989001\n",
      "train loss:  4.10996675491333\n",
      "train r2:  0.32490820070440973\n",
      "test loss:  6.884366989135742\n",
      "test r2:  -0.2576028631618432\n",
      "train loss:  4.108242988586426\n",
      "train r2:  0.325683290766428\n",
      "test loss:  6.884727954864502\n",
      "test r2:  -0.25761558994608325\n",
      "train loss:  4.106518745422363\n",
      "train r2:  0.32648405780081535\n",
      "test loss:  6.885072708129883\n",
      "test r2:  -0.2576236674360226\n",
      "train loss:  4.104793071746826\n",
      "train r2:  0.32730872362602503\n",
      "test loss:  6.8854265213012695\n",
      "test r2:  -0.2576351630463072\n",
      "train loss:  4.103068828582764\n",
      "train r2:  0.3281168148467355\n",
      "test loss:  6.885796070098877\n",
      "test r2:  -0.2576517482194953\n",
      "train loss:  4.101341724395752\n",
      "train r2:  0.3288979713186736\n",
      "test loss:  6.886158466339111\n",
      "test r2:  -0.25766677501297197\n",
      "train loss:  4.099616527557373\n",
      "train r2:  0.3296844813628347\n",
      "test loss:  6.886499404907227\n",
      "test r2:  -0.25767599006637054\n",
      "train loss:  4.0978899002075195\n",
      "train r2:  0.3304962293619019\n",
      "test loss:  6.886836528778076\n",
      "test r2:  -0.2576840302992376\n",
      "train loss:  4.096163272857666\n",
      "train r2:  0.33131016473597585\n",
      "test loss:  6.8871846199035645\n",
      "test r2:  -0.257695927799485\n",
      "train loss:  4.094435214996338\n",
      "train r2:  0.3321015968931641\n",
      "test loss:  6.887535572052002\n",
      "test r2:  -0.25770916303505054\n",
      "train loss:  4.092708587646484\n",
      "train r2:  0.332883373557745\n",
      "test loss:  6.887874126434326\n",
      "test r2:  -0.25771894081270075\n",
      "train loss:  4.0909810066223145\n",
      "train r2:  0.33368167948656213\n",
      "test loss:  6.888203144073486\n",
      "test r2:  -0.25772602906673736\n",
      "train loss:  4.089253902435303\n",
      "train r2:  0.3344925246710897\n",
      "test loss:  6.8885393142700195\n",
      "test r2:  -0.2577356302644327\n",
      "train loss:  4.087526321411133\n",
      "train r2:  0.33529162635032117\n",
      "test loss:  6.888885974884033\n",
      "test r2:  -0.25774866953777886\n",
      "train loss:  4.0857977867126465\n",
      "train r2:  0.33607499677061314\n",
      "test loss:  6.889230251312256\n",
      "test r2:  -0.25776117116844066\n",
      "train loss:  4.084070205688477\n",
      "train r2:  0.3368625271811768\n",
      "test loss:  6.8895649909973145\n",
      "test r2:  -0.25777106964773444\n",
      "train loss:  4.082342147827148\n",
      "train r2:  0.33766444140558327\n",
      "test loss:  6.8899006843566895\n",
      "test r2:  -0.25778114026429955\n",
      "train loss:  4.08061408996582\n",
      "train r2:  0.3384658973899102\n",
      "test loss:  6.890244007110596\n",
      "test r2:  -0.2577942106779709\n",
      "train loss:  4.078886032104492\n",
      "train r2:  0.33925351883969057\n",
      "test loss:  6.890590190887451\n",
      "test r2:  -0.25780790205831194\n",
      "train loss:  4.077157497406006\n",
      "train r2:  0.3400357111179688\n",
      "test loss:  6.890928268432617\n",
      "test r2:  -0.25781955372455756\n",
      "train loss:  4.075429916381836\n",
      "train r2:  0.34082753809998734\n",
      "test loss:  6.891258716583252\n",
      "test r2:  -0.25782963856493035\n",
      "train loss:  4.073701858520508\n",
      "train r2:  0.3416262381163653\n",
      "test loss:  6.891592502593994\n",
      "test r2:  -0.2578404037420383\n",
      "train loss:  4.071974277496338\n",
      "train r2:  0.34241778207809737\n",
      "test loss:  6.891930103302002\n",
      "test r2:  -0.25785281694370266\n",
      "train loss:  4.070246696472168\n",
      "train r2:  0.3431997610634334\n",
      "test loss:  6.8922648429870605\n",
      "test r2:  -0.2578643938072036\n",
      "train loss:  4.068519592285156\n",
      "train r2:  0.3439835010128153\n",
      "test loss:  6.892591953277588\n",
      "test r2:  -0.2578742054074563\n",
      "train loss:  4.0667924880981445\n",
      "train r2:  0.34477555180106334\n",
      "test loss:  6.892918109893799\n",
      "test r2:  -0.2578837397157232\n",
      "train loss:  4.065065860748291\n",
      "train r2:  0.345567817176211\n",
      "test loss:  6.89324951171875\n",
      "test r2:  -0.2578949825519572\n",
      "train loss:  4.0633392333984375\n",
      "train r2:  0.34635171063837245\n",
      "test loss:  6.893583297729492\n",
      "test r2:  -0.257906891514496\n",
      "train loss:  4.061613082885742\n",
      "train r2:  0.3471309856385212\n",
      "test loss:  6.893913269042969\n",
      "test r2:  -0.25791824930295415\n",
      "train loss:  4.059886932373047\n",
      "train r2:  0.34791471977883337\n",
      "test loss:  6.894241809844971\n",
      "test r2:  -0.25792884797207183\n",
      "train loss:  4.058161735534668\n",
      "train r2:  0.34870295234146065\n",
      "test loss:  6.894571304321289\n",
      "test r2:  -0.2579401918651345\n",
      "train loss:  4.056437015533447\n",
      "train r2:  0.3494877777267731\n",
      "test loss:  6.894905090332031\n",
      "test r2:  -0.2579525079884224\n",
      "train loss:  4.054712295532227\n",
      "train r2:  0.3502659547850644\n",
      "test loss:  6.895238876342773\n",
      "test r2:  -0.25796506635033256\n",
      "train loss:  4.0529890060424805\n",
      "train r2:  0.351043136794988\n",
      "test loss:  6.895568370819092\n",
      "test r2:  -0.25797667896684096\n",
      "train loss:  4.051265716552734\n",
      "train r2:  0.3518244851986645\n",
      "test loss:  6.8958964347839355\n",
      "test r2:  -0.25798775649742756\n",
      "train loss:  4.0495429039001465\n",
      "train r2:  0.35260728095964167\n",
      "test loss:  6.896225452423096\n",
      "test r2:  -0.2579991527890162\n",
      "train loss:  4.047820568084717\n",
      "train r2:  0.3533858469424568\n",
      "test loss:  6.896556377410889\n",
      "test r2:  -0.25801121518201153\n",
      "train loss:  4.0460991859436035\n",
      "train r2:  0.35416002725583673\n",
      "test loss:  6.896886825561523\n",
      "test r2:  -0.2580229616394625\n",
      "train loss:  4.044378757476807\n",
      "train r2:  0.3549345873048678\n",
      "test loss:  6.897213935852051\n",
      "test r2:  -0.25803403469875485\n",
      "train loss:  4.04265832901001\n",
      "train r2:  0.3557120248864032\n",
      "test loss:  6.89754056930542\n",
      "test r2:  -0.2580449333218915\n",
      "train loss:  4.0409393310546875\n",
      "train r2:  0.35648918975136945\n",
      "test loss:  6.897868633270264\n",
      "test r2:  -0.25805660827217514\n",
      "train loss:  4.039220809936523\n",
      "train r2:  0.35726241375287027\n",
      "test loss:  6.898199081420898\n",
      "test r2:  -0.2580687237479151\n",
      "train loss:  4.037503719329834\n",
      "train r2:  0.3580325080084189\n",
      "test loss:  6.898529052734375\n",
      "test r2:  -0.25808059119945037\n",
      "train loss:  4.035787105560303\n",
      "train r2:  0.35880311303037404\n",
      "test loss:  6.8988566398620605\n",
      "test r2:  -0.2580921178169291\n",
      "train loss:  4.034071445465088\n",
      "train r2:  0.3595755268918762\n",
      "test loss:  6.899183750152588\n",
      "test r2:  -0.25810390264809135\n",
      "train loss:  4.0323567390441895\n",
      "train r2:  0.3603468746194666\n",
      "test loss:  6.899512767791748\n",
      "test r2:  -0.25811603494818125\n",
      "train loss:  4.030643939971924\n",
      "train r2:  0.3611147188865177\n",
      "test loss:  6.899840831756592\n",
      "test r2:  -0.2581284387240801\n",
      "train loss:  4.028931140899658\n",
      "train r2:  0.3618803247755933\n",
      "test loss:  6.900167465209961\n",
      "test r2:  -0.2581405981882834\n",
      "train loss:  4.027219772338867\n",
      "train r2:  0.362646121663725\n",
      "test loss:  6.900491714477539\n",
      "test r2:  -0.2581523895496678\n",
      "train loss:  4.025509357452393\n",
      "train r2:  0.36341294580775374\n",
      "test loss:  6.900816440582275\n",
      "test r2:  -0.25816418040969724\n",
      "train loss:  4.023800373077393\n",
      "train r2:  0.364178647406458\n",
      "test loss:  6.901141166687012\n",
      "test r2:  -0.25817614021434143\n",
      "train loss:  4.022092819213867\n",
      "train r2:  0.3649414246376539\n",
      "test loss:  6.901464462280273\n",
      "test r2:  -0.25818830346075594\n",
      "train loss:  4.020386695861816\n",
      "train r2:  0.36570205838940373\n",
      "test loss:  6.901786804199219\n",
      "test r2:  -0.2582001349022376\n",
      "train loss:  4.018681526184082\n",
      "train r2:  0.36646257302802676\n",
      "test loss:  6.902108669281006\n",
      "test r2:  -0.2582118851127131\n",
      "train loss:  4.016977787017822\n",
      "train r2:  0.367223523338832\n",
      "test loss:  6.902429580688477\n",
      "test r2:  -0.2582236317836222\n",
      "train loss:  4.015275478363037\n",
      "train r2:  0.3679832605718325\n",
      "test loss:  6.9027509689331055\n",
      "test r2:  -0.258235736995317\n",
      "train loss:  4.013575077056885\n",
      "train r2:  0.3687405877368293\n",
      "test loss:  6.903071880340576\n",
      "test r2:  -0.2582478549601017\n",
      "train loss:  4.011876106262207\n",
      "train r2:  0.3694958451884116\n",
      "test loss:  6.903392314910889\n",
      "test r2:  -0.25826021930376664\n",
      "train loss:  4.010178089141846\n",
      "train r2:  0.3702505066023556\n",
      "test loss:  6.903712749481201\n",
      "test r2:  -0.2582723935358242\n",
      "train loss:  4.008481979370117\n",
      "train r2:  0.3710049262892787\n",
      "test loss:  6.904031753540039\n",
      "test r2:  -0.25828466284039076\n",
      "train loss:  4.006787300109863\n",
      "train r2:  0.3717584774576401\n",
      "test loss:  6.904350757598877\n",
      "test r2:  -0.25829682116587294\n",
      "train loss:  4.0050950050354\n",
      "train r2:  0.37251005951942573\n",
      "test loss:  6.904670238494873\n",
      "test r2:  -0.2583092306717336\n",
      "train loss:  4.003403186798096\n",
      "train r2:  0.3732594321163222\n",
      "test loss:  6.9049882888793945\n",
      "test r2:  -0.2583218611235807\n",
      "train loss:  4.001713275909424\n",
      "train r2:  0.374007757319999\n",
      "test loss:  6.9053053855896\n",
      "test r2:  -0.25833405675311494\n",
      "train loss:  4.000024795532227\n",
      "train r2:  0.3747553751497762\n",
      "test loss:  6.905622482299805\n",
      "test r2:  -0.25834636710957404\n",
      "train loss:  3.9983370304107666\n",
      "train r2:  0.3755021713152953\n",
      "test loss:  6.905937671661377\n",
      "test r2:  -0.25835876189532847\n",
      "train loss:  3.9966514110565186\n",
      "train r2:  0.3762472148306306\n",
      "test loss:  6.906254291534424\n",
      "test r2:  -0.25837123024122577\n",
      "train loss:  3.9949653148651123\n",
      "train r2:  0.3769899631392224\n",
      "test loss:  6.906569957733154\n",
      "test r2:  -0.2583839233839347\n",
      "train loss:  3.993279218673706\n",
      "train r2:  0.37773054069913214\n",
      "test loss:  6.906886577606201\n",
      "test r2:  -0.25839694263099333\n",
      "train loss:  3.991590976715088\n",
      "train r2:  0.37846915018350513\n",
      "test loss:  6.907201766967773\n",
      "test r2:  -0.2584099446280659\n",
      "train loss:  3.9898972511291504\n",
      "train r2:  0.3792046052007523\n",
      "test loss:  6.90751838684082\n",
      "test r2:  -0.258423246647451\n",
      "train loss:  3.9881932735443115\n",
      "train r2:  0.37993366352906877\n",
      "test loss:  6.907835483551025\n",
      "test r2:  -0.25843707589736664\n",
      "train loss:  3.9864745140075684\n",
      "train r2:  0.3806489618009441\n",
      "test loss:  6.908151149749756\n",
      "test r2:  -0.25845021813445634\n",
      "train loss:  3.9847464561462402\n",
      "train r2:  0.3813355428616473\n",
      "test loss:  6.908454418182373\n",
      "test r2:  -0.25845966916936636\n",
      "train loss:  3.983055353164673\n",
      "train r2:  0.3819785304878893\n",
      "test loss:  6.908717155456543\n",
      "test r2:  -0.25845586876963034\n",
      "train loss:  3.981337308883667\n",
      "train r2:  0.38281924079845586\n",
      "test loss:  6.909027576446533\n",
      "test r2:  -0.25846635980567756\n",
      "train loss:  3.979640007019043\n",
      "train r2:  0.38358575343841994\n",
      "test loss:  6.909409999847412\n",
      "test r2:  -0.2584985844888985\n",
      "train loss:  3.9778892993927\n",
      "train r2:  0.38420971358598055\n",
      "test loss:  6.909769058227539\n",
      "test r2:  -0.2585231027330914\n",
      "train loss:  3.9761545658111572\n",
      "train r2:  0.38493875296675917\n",
      "test loss:  6.910089492797852\n",
      "test r2:  -0.2585349361417173\n",
      "train loss:  3.9744205474853516\n",
      "train r2:  0.38575665542632276\n",
      "test loss:  6.910426139831543\n",
      "test r2:  -0.2585516607759759\n",
      "train loss:  3.972689628601074\n",
      "train r2:  0.3865035429592617\n",
      "test loss:  6.910781383514404\n",
      "test r2:  -0.2585741405341464\n",
      "train loss:  3.9709274768829346\n",
      "train r2:  0.3871804815156845\n",
      "test loss:  6.911109447479248\n",
      "test r2:  -0.2585879168638274\n",
      "train loss:  3.969165086746216\n",
      "train r2:  0.3878716546085118\n",
      "test loss:  6.911376476287842\n",
      "test r2:  -0.2585822420926387\n",
      "train loss:  3.967374563217163\n",
      "train r2:  0.38869237587080785\n",
      "test loss:  6.911675930023193\n",
      "test r2:  -0.25858589209731364\n",
      "train loss:  3.9655961990356445\n",
      "train r2:  0.3894315859780081\n",
      "test loss:  6.912014961242676\n",
      "test r2:  -0.2586008958403725\n",
      "train loss:  3.9638373851776123\n",
      "train r2:  0.39008661503259423\n",
      "test loss:  6.912286758422852\n",
      "test r2:  -0.2585934491642161\n",
      "train loss:  3.962062358856201\n",
      "train r2:  0.39099070350700116\n",
      "test loss:  6.9126973152160645\n",
      "test r2:  -0.2586279280015551\n",
      "train loss:  3.9602112770080566\n",
      "train r2:  0.3916444183706802\n",
      "test loss:  6.913098335266113\n",
      "test r2:  -0.2586587152256714\n",
      "train loss:  3.958441972732544\n",
      "train r2:  0.39232236615310834\n",
      "test loss:  6.913380146026611\n",
      "test r2:  -0.2586506930579\n",
      "train loss:  3.9566259384155273\n",
      "train r2:  0.39321640897497445\n",
      "test loss:  6.913755416870117\n",
      "test r2:  -0.2586716869327952\n",
      "train loss:  3.954803466796875\n",
      "train r2:  0.3939526839495493\n",
      "test loss:  6.914190769195557\n",
      "test r2:  -0.25871094218128254\n",
      "train loss:  3.952998399734497\n",
      "train r2:  0.39459107301760066\n",
      "test loss:  6.914491653442383\n",
      "test r2:  -0.2587070430117615\n",
      "train loss:  3.951129674911499\n",
      "train r2:  0.39542126701270597\n",
      "test loss:  6.914790630340576\n",
      "test r2:  -0.25870195527717454\n",
      "train loss:  3.9493167400360107\n",
      "train r2:  0.396242118211645\n",
      "test loss:  6.915204048156738\n",
      "test r2:  -0.25873145918617513\n",
      "train loss:  3.9474642276763916\n",
      "train r2:  0.3969041271355864\n",
      "test loss:  6.915524482727051\n",
      "test r2:  -0.2587308378433455\n",
      "train loss:  3.9456098079681396\n",
      "train r2:  0.39769924995867667\n",
      "test loss:  6.915830612182617\n",
      "test r2:  -0.25872424788578274\n",
      "train loss:  3.9437808990478516\n",
      "train r2:  0.3985252900050704\n",
      "test loss:  6.916258335113525\n",
      "test r2:  -0.25875541153624515\n",
      "train loss:  3.9419209957122803\n",
      "train r2:  0.39920063453462185\n",
      "test loss:  6.9165873527526855\n",
      "test r2:  -0.2587536280200453\n",
      "train loss:  3.9400441646575928\n",
      "train r2:  0.4000265720514611\n",
      "test loss:  6.91696310043335\n",
      "test r2:  -0.2587658201294707\n",
      "train loss:  3.9381837844848633\n",
      "train r2:  0.4008052438567222\n",
      "test loss:  6.917405605316162\n",
      "test r2:  -0.2587977317503527\n",
      "train loss:  3.9363269805908203\n",
      "train r2:  0.40151454100863604\n",
      "test loss:  6.917749404907227\n",
      "test r2:  -0.2587981993421222\n",
      "train loss:  3.9344482421875\n",
      "train r2:  0.40235043530345094\n",
      "test loss:  6.9181718826293945\n",
      "test r2:  -0.2588224305926998\n",
      "train loss:  3.9325613975524902\n",
      "train r2:  0.4030998864391646\n",
      "test loss:  6.918595790863037\n",
      "test r2:  -0.258846813376868\n",
      "train loss:  3.9306845664978027\n",
      "train r2:  0.40384655608631703\n",
      "test loss:  6.918932914733887\n",
      "test r2:  -0.258843263228151\n",
      "train loss:  3.9288010597229004\n",
      "train r2:  0.4046920307520192\n",
      "test loss:  6.919384956359863\n",
      "test r2:  -0.25887581891738876\n",
      "train loss:  3.9268949031829834\n",
      "train r2:  0.4054066876969782\n",
      "test loss:  6.919735431671143\n",
      "test r2:  -0.25887584216731185\n",
      "train loss:  3.924978733062744\n",
      "train r2:  0.40623356537766864\n",
      "test loss:  6.9201250076293945\n",
      "test r2:  -0.25888840367957133\n",
      "train loss:  3.9230575561523438\n",
      "train r2:  0.40701881122204475\n",
      "test loss:  6.920537948608398\n",
      "test r2:  -0.2589081998227931\n",
      "train loss:  3.921128511428833\n",
      "train r2:  0.4077848927297367\n",
      "test loss:  6.920875072479248\n",
      "test r2:  -0.2589044788637662\n",
      "train loss:  3.9191818237304688\n",
      "train r2:  0.40864411301461034\n",
      "test loss:  6.921338081359863\n",
      "test r2:  -0.2589411545191871\n",
      "train loss:  3.9172000885009766\n",
      "train r2:  0.4093866148861025\n",
      "test loss:  6.921670913696289\n",
      "test r2:  -0.25893714376950605\n",
      "train loss:  3.9151744842529297\n",
      "train r2:  0.4102825549180408\n",
      "test loss:  6.9221296310424805\n",
      "test r2:  -0.2589738225318803\n",
      "train loss:  3.9130866527557373\n",
      "train r2:  0.41108476430065366\n",
      "test loss:  6.922529697418213\n",
      "test r2:  -0.25899396807539476\n",
      "train loss:  3.9109277725219727\n",
      "train r2:  0.41197469841693635\n",
      "test loss:  6.922916889190674\n",
      "test r2:  -0.25901293868636843\n",
      "train loss:  3.908658504486084\n",
      "train r2:  0.41291700797616215\n",
      "test loss:  6.923377990722656\n",
      "test r2:  -0.2590594709067169\n",
      "train loss:  3.906219482421875\n",
      "train r2:  0.4138384267842844\n",
      "test loss:  6.923719882965088\n",
      "test r2:  -0.2590738046384029\n",
      "train loss:  3.9035778045654297\n",
      "train r2:  0.41492649366055656\n",
      "test loss:  6.924188613891602\n",
      "test r2:  -0.2591347143553935\n",
      "train loss:  3.9007201194763184\n",
      "train r2:  0.41595777450043125\n",
      "test loss:  6.924544811248779\n",
      "test r2:  -0.2591691031049692\n",
      "train loss:  3.8976926803588867\n",
      "train r2:  0.41713805333063647\n",
      "test loss:  6.924954414367676\n",
      "test r2:  -0.2592319851691458\n",
      "train loss:  3.894545793533325\n",
      "train r2:  0.41829687426858864\n",
      "test loss:  6.925338268280029\n",
      "test r2:  -0.25929954558265034\n",
      "train loss:  3.8913702964782715\n",
      "train r2:  0.41946949050656845\n",
      "test loss:  6.925643444061279\n",
      "test r2:  -0.2593576015598169\n",
      "train loss:  3.8882551193237305\n",
      "train r2:  0.42065455665208606\n",
      "test loss:  6.925970077514648\n",
      "test r2:  -0.2594391337512578\n",
      "train loss:  3.885260581970215\n",
      "train r2:  0.42171566494511914\n",
      "test loss:  6.926100254058838\n",
      "test r2:  -0.2594757686424267\n",
      "train loss:  3.8823914527893066\n",
      "train r2:  0.42281779551570364\n",
      "test loss:  6.926235675811768\n",
      "test r2:  -0.25953078950567665\n",
      "train loss:  3.8796346187591553\n",
      "train r2:  0.42376342051693583\n",
      "test loss:  6.926141738891602\n",
      "test r2:  -0.2595294374406536\n",
      "train loss:  3.8769731521606445\n",
      "train r2:  0.42476058492807955\n",
      "test loss:  6.9259867668151855\n",
      "test r2:  -0.25952216028042474\n",
      "train loss:  3.8743984699249268\n",
      "train r2:  0.4256734712164669\n",
      "test loss:  6.9257049560546875\n",
      "test r2:  -0.25948720119023405\n",
      "train loss:  3.871891736984253\n",
      "train r2:  0.42657962965159657\n",
      "test loss:  6.9253082275390625\n",
      "test r2:  -0.25942468461314094\n",
      "train loss:  3.869431257247925\n",
      "train r2:  0.4275032993569228\n",
      "test loss:  6.9249348640441895\n",
      "test r2:  -0.2593751442081651\n",
      "train loss:  3.866999626159668\n",
      "train r2:  0.4283558045608179\n",
      "test loss:  6.924481391906738\n",
      "test r2:  -0.2593031298678685\n",
      "train loss:  3.8645846843719482\n",
      "train r2:  0.4292677081026709\n",
      "test loss:  6.924120903015137\n",
      "test r2:  -0.25926012130596865\n",
      "train loss:  3.862186908721924\n",
      "train r2:  0.43011381224174183\n",
      "test loss:  6.923785209655762\n",
      "test r2:  -0.2592225880066734\n",
      "train loss:  3.859808921813965\n",
      "train r2:  0.43097732991763593\n",
      "test loss:  6.923506259918213\n",
      "test r2:  -0.25919789855802944\n",
      "train loss:  3.857447624206543\n",
      "train r2:  0.4318407066525606\n",
      "test loss:  6.923326015472412\n",
      "test r2:  -0.2591984822890787\n",
      "train loss:  3.8550989627838135\n",
      "train r2:  0.4326617569888085\n",
      "test loss:  6.92314338684082\n",
      "test r2:  -0.25919101302496794\n",
      "train loss:  3.8527567386627197\n",
      "train r2:  0.43352626941675065\n",
      "test loss:  6.92303466796875\n",
      "test r2:  -0.25919849357214697\n",
      "train loss:  3.8504233360290527\n",
      "train r2:  0.4343483683909134\n",
      "test loss:  6.922922134399414\n",
      "test r2:  -0.25919620364482787\n",
      "train loss:  3.8481011390686035\n",
      "train r2:  0.43518852880392545\n",
      "test loss:  6.922807216644287\n",
      "test r2:  -0.25918344297881224\n",
      "train loss:  3.8457906246185303\n",
      "train r2:  0.43603769640112433\n",
      "test loss:  6.922726154327393\n",
      "test r2:  -0.25917101968006073\n",
      "train loss:  3.84348726272583\n",
      "train r2:  0.43686059178234615\n",
      "test loss:  6.922624111175537\n",
      "test r2:  -0.25914122446050003\n",
      "train loss:  3.841189384460449\n",
      "train r2:  0.437718667103034\n",
      "test loss:  6.922572135925293\n",
      "test r2:  -0.25911585607024334\n",
      "train loss:  3.8388986587524414\n",
      "train r2:  0.4385542470117282\n",
      "test loss:  6.922563076019287\n",
      "test r2:  -0.2590909647034745\n",
      "train loss:  3.8366167545318604\n",
      "train r2:  0.439393836197731\n",
      "test loss:  6.9225993156433105\n",
      "test r2:  -0.25906800706254285\n",
      "train loss:  3.834340810775757\n",
      "train r2:  0.4402475495573631\n",
      "test loss:  6.9227294921875\n",
      "test r2:  -0.25906176012546345\n",
      "train loss:  3.8320693969726562\n",
      "train r2:  0.4410758833203884\n",
      "test loss:  6.922915935516357\n",
      "test r2:  -0.25905976387217056\n",
      "train loss:  3.829801559448242\n",
      "train r2:  0.4419227442443384\n",
      "test loss:  6.923177719116211\n",
      "test r2:  -0.25906872949650794\n",
      "train loss:  3.8275389671325684\n",
      "train r2:  0.44276246513081174\n",
      "test loss:  6.923509120941162\n",
      "test r2:  -0.2590866735499895\n",
      "train loss:  3.8252804279327393\n",
      "train r2:  0.44359204032459054\n",
      "test loss:  6.923871040344238\n",
      "test r2:  -0.2591021148642043\n",
      "train loss:  3.8230245113372803\n",
      "train r2:  0.44443948074291406\n",
      "test loss:  6.924278736114502\n",
      "test r2:  -0.25912058898615475\n",
      "train loss:  3.8207693099975586\n",
      "train r2:  0.4452738328361123\n",
      "test loss:  6.924708843231201\n",
      "test r2:  -0.2591345590577052\n",
      "train loss:  3.8185181617736816\n",
      "train r2:  0.4461121792014461\n",
      "test loss:  6.925151348114014\n",
      "test r2:  -0.2591417528559299\n",
      "train loss:  3.816267728805542\n",
      "train r2:  0.44696135655452907\n",
      "test loss:  6.9256272315979\n",
      "test r2:  -0.2591488977108358\n",
      "train loss:  3.814018487930298\n",
      "train r2:  0.4477984321898184\n",
      "test loss:  6.926124095916748\n",
      "test r2:  -0.25915237276212677\n",
      "train loss:  3.811769962310791\n",
      "train r2:  0.4486445470953726\n",
      "test loss:  6.9266557693481445\n",
      "test r2:  -0.2591563583713232\n",
      "train loss:  3.8095221519470215\n",
      "train r2:  0.4494930254172985\n",
      "test loss:  6.927238941192627\n",
      "test r2:  -0.25916674005136864\n",
      "train loss:  3.80727481842041\n",
      "train r2:  0.45033148553662494\n",
      "test loss:  6.9278645515441895\n",
      "test r2:  -0.2591805438012169\n",
      "train loss:  3.805027484893799\n",
      "train r2:  0.4511778617346439\n",
      "test loss:  6.928539752960205\n",
      "test r2:  -0.25920048636247994\n",
      "train loss:  3.8027801513671875\n",
      "train r2:  0.4520218961952822\n",
      "test loss:  6.929264545440674\n",
      "test r2:  -0.2592271918091249\n",
      "train loss:  3.8005330562591553\n",
      "train r2:  0.4528584884233041\n",
      "test loss:  6.930019855499268\n",
      "test r2:  -0.25925532111952276\n",
      "train loss:  3.798285484313965\n",
      "train r2:  0.45370226439916683\n",
      "test loss:  6.930807113647461\n",
      "test r2:  -0.2592851480226859\n",
      "train loss:  3.7960376739501953\n",
      "train r2:  0.4545435703390367\n",
      "test loss:  6.931616306304932\n",
      "test r2:  -0.25931497004276083\n",
      "train loss:  3.7937896251678467\n",
      "train r2:  0.4553804750437225\n",
      "test loss:  6.932436943054199\n",
      "test r2:  -0.25934123508786366\n",
      "train loss:  3.79154109954834\n",
      "train r2:  0.45622399207909137\n",
      "test loss:  6.93326997756958\n",
      "test r2:  -0.25936514363068586\n",
      "train loss:  3.7892932891845703\n",
      "train r2:  0.45706597350047673\n",
      "test loss:  6.934119701385498\n",
      "test r2:  -0.2593881648599319\n",
      "train loss:  3.7870447635650635\n",
      "train r2:  0.4579042543033518\n",
      "test loss:  6.934981822967529\n",
      "test r2:  -0.25940919250190486\n",
      "train loss:  3.7847957611083984\n",
      "train r2:  0.4587473962398966\n",
      "test loss:  6.935866832733154\n",
      "test r2:  -0.25943155446075994\n",
      "train loss:  3.782547950744629\n",
      "train r2:  0.4595886718601512\n",
      "test loss:  6.936779975891113\n",
      "test r2:  -0.25945725389165997\n",
      "train loss:  3.780299186706543\n",
      "train r2:  0.46042553583216317\n",
      "test loss:  6.937716960906982\n",
      "test r2:  -0.25948505137540123\n",
      "train loss:  3.778050422668457\n",
      "train r2:  0.46126485499596337\n",
      "test loss:  6.938681125640869\n",
      "test r2:  -0.2595162152027748\n",
      "train loss:  3.77580189704895\n",
      "train r2:  0.46210307537420015\n",
      "test loss:  6.939668655395508\n",
      "test r2:  -0.25955024388221815\n",
      "train loss:  3.7735533714294434\n",
      "train r2:  0.4629366620657115\n",
      "test loss:  6.940675735473633\n",
      "test r2:  -0.25958523168900705\n",
      "train loss:  3.771306037902832\n",
      "train r2:  0.46377145438768863\n",
      "test loss:  6.941693305969238\n",
      "test r2:  -0.25961966443779927\n",
      "train loss:  3.7690584659576416\n",
      "train r2:  0.464607021605712\n",
      "test loss:  6.942721843719482\n",
      "test r2:  -0.2596535217845841\n",
      "train loss:  3.7668111324310303\n",
      "train r2:  0.4654391461883365\n",
      "test loss:  6.9437575340271\n",
      "test r2:  -0.2596856519437589\n",
      "train loss:  3.7645645141601562\n",
      "train r2:  0.4662711296801306\n",
      "test loss:  6.944798469543457\n",
      "test r2:  -0.25971560305360253\n",
      "train loss:  3.7623181343078613\n",
      "train r2:  0.4671048472956547\n",
      "test loss:  6.94584846496582\n",
      "test r2:  -0.259745161123776\n",
      "train loss:  3.7600722312927246\n",
      "train r2:  0.46793618001205217\n",
      "test loss:  6.94691276550293\n",
      "test r2:  -0.25977488033821716\n",
      "train loss:  3.757827043533325\n",
      "train r2:  0.46876541832522245\n",
      "test loss:  6.9479875564575195\n",
      "test r2:  -0.25980495372103873\n",
      "train loss:  3.755582571029663\n",
      "train r2:  0.4695954179447709\n",
      "test loss:  6.949080944061279\n",
      "test r2:  -0.25983662446431066\n",
      "train loss:  3.753338575363159\n",
      "train r2:  0.47042396517509\n",
      "test loss:  6.950190544128418\n",
      "test r2:  -0.25987051305037334\n",
      "train loss:  3.7510945796966553\n",
      "train r2:  0.47124934505742366\n",
      "test loss:  6.9513163566589355\n",
      "test r2:  -0.25990556855754\n",
      "train loss:  3.748852491378784\n",
      "train r2:  0.47207395409576547\n",
      "test loss:  6.952453136444092\n",
      "test r2:  -0.2599410481659754\n",
      "train loss:  3.746609687805176\n",
      "train r2:  0.47289861063086913\n",
      "test loss:  6.953598499298096\n",
      "test r2:  -0.2599767496061052\n",
      "train loss:  3.7443687915802\n",
      "train r2:  0.47372097851412853\n",
      "test loss:  6.9547529220581055\n",
      "test r2:  -0.2600119254456039\n",
      "train loss:  3.742128372192383\n",
      "train r2:  0.47454147312700057\n",
      "test loss:  6.955911159515381\n",
      "test r2:  -0.2600457116454442\n",
      "train loss:  3.739888906478882\n",
      "train r2:  0.4753621839619402\n",
      "test loss:  6.957074165344238\n",
      "test r2:  -0.26007828477674866\n",
      "train loss:  3.737650156021118\n",
      "train r2:  0.47618226693530796\n",
      "test loss:  6.958244800567627\n",
      "test r2:  -0.2601104347837637\n",
      "train loss:  3.7354118824005127\n",
      "train r2:  0.47700014209496866\n",
      "test loss:  6.959422588348389\n",
      "test r2:  -0.26014215166320276\n",
      "train loss:  3.7331748008728027\n",
      "train r2:  0.47781669621694944\n",
      "test loss:  6.960608959197998\n",
      "test r2:  -0.26017398359273014\n",
      "train loss:  3.730938196182251\n",
      "train r2:  0.47863297273054595\n",
      "test loss:  6.96180534362793\n",
      "test r2:  -0.2602065406089933\n",
      "train loss:  3.7287027835845947\n",
      "train r2:  0.47944758098628226\n",
      "test loss:  6.963012218475342\n",
      "test r2:  -0.2602402843829359\n",
      "train loss:  3.726468563079834\n",
      "train r2:  0.48025994362105606\n",
      "test loss:  6.964227676391602\n",
      "test r2:  -0.2602744780794899\n",
      "train loss:  3.7242343425750732\n",
      "train r2:  0.4810709242809471\n",
      "test loss:  6.965450763702393\n",
      "test r2:  -0.2603091112734448\n",
      "train loss:  3.7220020294189453\n",
      "train r2:  0.48188123125882765\n",
      "test loss:  6.966676712036133\n",
      "test r2:  -0.26034364998508464\n",
      "train loss:  3.7197704315185547\n",
      "train r2:  0.4826899820223006\n",
      "test loss:  6.9679059982299805\n",
      "test r2:  -0.26037786041113264\n",
      "train loss:  3.7175393104553223\n",
      "train r2:  0.4834969041141658\n",
      "test loss:  6.969133377075195\n",
      "test r2:  -0.26041113832356544\n",
      "train loss:  3.7153100967407227\n",
      "train r2:  0.4843027298737004\n",
      "test loss:  6.970359802246094\n",
      "test r2:  -0.2604435791263766\n",
      "train loss:  3.713081121444702\n",
      "train r2:  0.4851079727549341\n",
      "test loss:  6.971581935882568\n",
      "test r2:  -0.26047536212090594\n",
      "train loss:  3.7108538150787354\n",
      "train r2:  0.48591174982265883\n",
      "test loss:  6.972801208496094\n",
      "test r2:  -0.26050690105080077\n",
      "train loss:  3.708627223968506\n",
      "train r2:  0.4867138284550605\n",
      "test loss:  6.974016189575195\n",
      "test r2:  -0.26053830878689155\n",
      "train loss:  3.706402063369751\n",
      "train r2:  0.4875145424949646\n",
      "test loss:  6.975225448608398\n",
      "test r2:  -0.26057004944564266\n",
      "train loss:  3.704177141189575\n",
      "train r2:  0.4883141511326893\n",
      "test loss:  6.97642707824707\n",
      "test r2:  -0.2606019079645785\n",
      "train loss:  3.7019541263580322\n",
      "train r2:  0.48911236029454697\n",
      "test loss:  6.9776201248168945\n",
      "test r2:  -0.26063403710888267\n",
      "train loss:  3.699732780456543\n",
      "train r2:  0.4899086381949025\n",
      "test loss:  6.978802680969238\n",
      "test r2:  -0.26066619774182986\n",
      "train loss:  3.697512149810791\n",
      "train r2:  0.4907034273243708\n",
      "test loss:  6.979971408843994\n",
      "test r2:  -0.2606979142116337\n",
      "train loss:  3.6952929496765137\n",
      "train r2:  0.49149716241993757\n",
      "test loss:  6.981126308441162\n",
      "test r2:  -0.2607290880092674\n",
      "train loss:  3.693075656890869\n",
      "train r2:  0.492289681428019\n",
      "test loss:  6.982265949249268\n",
      "test r2:  -0.26075964553560915\n",
      "train loss:  3.690859794616699\n",
      "train r2:  0.49308062735592073\n",
      "test loss:  6.983389377593994\n",
      "test r2:  -0.26078956641950946\n",
      "train loss:  3.688645601272583\n",
      "train r2:  0.49387005612035895\n",
      "test loss:  6.984498977661133\n",
      "test r2:  -0.2608189626838546\n",
      "train loss:  3.6864326000213623\n",
      "train r2:  0.4946583741780445\n",
      "test loss:  6.985594272613525\n",
      "test r2:  -0.26084821819761084\n",
      "train loss:  3.684222459793091\n",
      "train r2:  0.49544527074973177\n",
      "test loss:  6.986676216125488\n",
      "test r2:  -0.2608775000631871\n",
      "train loss:  3.6820130348205566\n",
      "train r2:  0.49623083180653327\n",
      "test loss:  6.987743854522705\n",
      "test r2:  -0.2609067688327322\n",
      "train loss:  3.679806709289551\n",
      "train r2:  0.497014554787516\n",
      "test loss:  6.988797187805176\n",
      "test r2:  -0.2609363673953262\n",
      "train loss:  3.6776022911071777\n",
      "train r2:  0.49779675024259873\n",
      "test loss:  6.989835739135742\n",
      "test r2:  -0.26096597657975606\n",
      "train loss:  3.6753995418548584\n",
      "train r2:  0.49857754589627057\n",
      "test loss:  6.99085807800293\n",
      "test r2:  -0.2609955831793891\n",
      "train loss:  3.67319917678833\n",
      "train r2:  0.49935696214863645\n",
      "test loss:  6.991860866546631\n",
      "test r2:  -0.2610248906102861\n",
      "train loss:  3.6710011959075928\n",
      "train r2:  0.5001348867815174\n",
      "test loss:  6.992844104766846\n",
      "test r2:  -0.2610539927116353\n",
      "train loss:  3.6688058376312256\n",
      "train r2:  0.5009110676476842\n",
      "test loss:  6.993804931640625\n",
      "test r2:  -0.26108268083584485\n",
      "train loss:  3.666611909866333\n",
      "train r2:  0.5016860011216919\n",
      "test loss:  6.994744777679443\n",
      "test r2:  -0.2611110721590091\n",
      "train loss:  3.6644208431243896\n",
      "train r2:  0.5024594559038937\n",
      "test loss:  6.995660305023193\n",
      "test r2:  -0.2611389645590221\n",
      "train loss:  3.6622321605682373\n",
      "train r2:  0.5032315142107515\n",
      "test loss:  6.996551990509033\n",
      "test r2:  -0.26116697473729267\n",
      "train loss:  3.660045862197876\n",
      "train r2:  0.5040019378582675\n",
      "test loss:  6.997419834136963\n",
      "test r2:  -0.2611947578384928\n",
      "train loss:  3.6578617095947266\n",
      "train r2:  0.5047707104610439\n",
      "test loss:  6.998263835906982\n",
      "test r2:  -0.26122279802662396\n",
      "train loss:  3.655679941177368\n",
      "train r2:  0.5055379356033366\n",
      "test loss:  6.999083995819092\n",
      "test r2:  -0.26125073416336697\n",
      "train loss:  3.6535003185272217\n",
      "train r2:  0.5063036816521914\n",
      "test loss:  6.999877452850342\n",
      "test r2:  -0.26127855858445015\n",
      "train loss:  3.651322603225708\n",
      "train r2:  0.507067987120328\n",
      "test loss:  7.000646591186523\n",
      "test r2:  -0.26130641645223185\n",
      "train loss:  3.6491472721099854\n",
      "train r2:  0.5078306555059682\n",
      "test loss:  7.00139045715332\n",
      "test r2:  -0.2613339125549523\n",
      "train loss:  3.646972894668579\n",
      "train r2:  0.5085918639871565\n",
      "test loss:  7.002108573913574\n",
      "test r2:  -0.26136119551228876\n",
      "train loss:  3.6447994709014893\n",
      "train r2:  0.509351640186642\n",
      "test loss:  7.002801895141602\n",
      "test r2:  -0.2613882602242852\n",
      "train loss:  3.6426260471343994\n",
      "train r2:  0.5101102025245972\n",
      "test loss:  7.003471374511719\n",
      "test r2:  -0.2614151951352368\n",
      "train loss:  3.6404495239257812\n",
      "train r2:  0.5108677496049472\n",
      "test loss:  7.004116535186768\n",
      "test r2:  -0.26144197340995357\n",
      "train loss:  3.6382665634155273\n",
      "train r2:  0.5116246571400771\n",
      "test loss:  7.004739284515381\n",
      "test r2:  -0.2614690475353627\n",
      "train loss:  3.6360654830932617\n",
      "train r2:  0.512381945221575\n",
      "test loss:  7.005340576171875\n",
      "test r2:  -0.26149669283124943\n",
      "train loss:  3.6338133811950684\n",
      "train r2:  0.5131429957783009\n",
      "test loss:  7.005923748016357\n",
      "test r2:  -0.26152562220590103\n",
      "train loss:  3.631380319595337\n",
      "train r2:  0.513921469991917\n",
      "test loss:  7.006496906280518\n",
      "test r2:  -0.26155812914428433\n",
      "train loss:  3.627810478210449\n",
      "train r2:  0.514817135151382\n",
      "test loss:  7.007113933563232\n",
      "test r2:  -0.2616097504755295\n",
      "train loss:  3.6035726070404053\n",
      "train r2:  0.5177158684431998\n",
      "test loss:  7.008557319641113\n",
      "test r2:  -0.2619078890160875\n",
      "train loss:  3.5422213077545166\n",
      "train r2:  0.5226023849176569\n",
      "test loss:  7.009669303894043\n",
      "test r2:  -0.2621230157922927\n",
      "train loss:  3.5354349613189697\n",
      "train r2:  0.5235418856255696\n",
      "test loss:  7.010047435760498\n",
      "test r2:  -0.26213677956544457\n",
      "train loss:  3.533054828643799\n",
      "train r2:  0.5242956414931438\n",
      "test loss:  7.009757995605469\n",
      "test r2:  -0.26196744782850634\n",
      "train loss:  3.5308499336242676\n",
      "train r2:  0.5250648479703233\n",
      "test loss:  7.009092330932617\n",
      "test r2:  -0.26169877237195593\n",
      "train loss:  3.5287060737609863\n",
      "train r2:  0.5258302071070513\n",
      "test loss:  7.008430480957031\n",
      "test r2:  -0.26144196679434817\n",
      "train loss:  3.5266366004943848\n",
      "train r2:  0.526560785827199\n",
      "test loss:  7.008102893829346\n",
      "test r2:  -0.26129345358515965\n",
      "train loss:  3.5246529579162598\n",
      "train r2:  0.5272305082584453\n",
      "test loss:  7.008269786834717\n",
      "test r2:  -0.2612994607555721\n",
      "train loss:  3.5227553844451904\n",
      "train r2:  0.52782842103246\n",
      "test loss:  7.008883476257324\n",
      "test r2:  -0.26144352182209296\n",
      "train loss:  3.520927667617798\n",
      "train r2:  0.5283649891888884\n",
      "test loss:  7.0097246170043945\n",
      "test r2:  -0.26165787881628644\n",
      "train loss:  3.519134283065796\n",
      "train r2:  0.5288707687441547\n",
      "test loss:  7.010501384735107\n",
      "test r2:  -0.26185431931327363\n",
      "train loss:  3.517315149307251\n",
      "train r2:  0.5293910355740645\n",
      "test loss:  7.010974407196045\n",
      "test r2:  -0.26195976184274605\n",
      "train loss:  3.515395164489746\n",
      "train r2:  0.5299723453895937\n",
      "test loss:  7.011042594909668\n",
      "test r2:  -0.26194338824808816\n",
      "train loss:  3.513310432434082\n",
      "train r2:  0.5306481675088779\n",
      "test loss:  7.010777473449707\n",
      "test r2:  -0.2618253770965646\n",
      "train loss:  3.5110275745391846\n",
      "train r2:  0.5314285020494176\n",
      "test loss:  7.0103864669799805\n",
      "test r2:  -0.2616656325106175\n",
      "train loss:  3.5085532665252686\n",
      "train r2:  0.5322977826822238\n",
      "test loss:  7.010116100311279\n",
      "test r2:  -0.2615369309012676\n",
      "train loss:  3.5059266090393066\n",
      "train r2:  0.5332237186736448\n",
      "test loss:  7.010159492492676\n",
      "test r2:  -0.26149573421569183\n",
      "train loss:  3.5032012462615967\n",
      "train r2:  0.5341709472947413\n",
      "test loss:  7.010586261749268\n",
      "test r2:  -0.26156153517335645\n",
      "train loss:  3.500431537628174\n",
      "train r2:  0.535112364493136\n",
      "test loss:  7.011320114135742\n",
      "test r2:  -0.2617116147981431\n",
      "train loss:  3.49766206741333\n",
      "train r2:  0.536034922880152\n",
      "test loss:  7.012189865112305\n",
      "test r2:  -0.2618935177951818\n",
      "train loss:  3.4949216842651367\n",
      "train r2:  0.5369383626665569\n",
      "test loss:  7.012992858886719\n",
      "test r2:  -0.2620475447202588\n",
      "train loss:  3.492225408554077\n",
      "train r2:  0.5378294780571362\n",
      "test loss:  7.013583183288574\n",
      "test r2:  -0.26212930923613076\n",
      "train loss:  3.4895780086517334\n",
      "train r2:  0.5387157966558975\n",
      "test loss:  7.013915538787842\n",
      "test r2:  -0.26212617116570325\n",
      "train loss:  3.4869778156280518\n",
      "train r2:  0.5396004532255338\n",
      "test loss:  7.014059543609619\n",
      "test r2:  -0.262058111005425\n",
      "train loss:  3.484421491622925\n",
      "train r2:  0.5404809135566055\n",
      "test loss:  7.014158725738525\n",
      "test r2:  -0.26196807273080824\n",
      "train loss:  3.481902837753296\n",
      "train r2:  0.5413501617565348\n",
      "test loss:  7.014370441436768\n",
      "test r2:  -0.2619023940410008\n",
      "train loss:  3.4794187545776367\n",
      "train r2:  0.5422004573420046\n",
      "test loss:  7.014805793762207\n",
      "test r2:  -0.2618942773035473\n",
      "train loss:  3.476961612701416\n",
      "train r2:  0.5430267818446408\n",
      "test loss:  7.015488147735596\n",
      "test r2:  -0.2619511174667273\n",
      "train loss:  3.4745283126831055\n",
      "train r2:  0.5438294519189049\n",
      "test loss:  7.016354560852051\n",
      "test r2:  -0.2620542314178014\n",
      "train loss:  3.4721145629882812\n",
      "train r2:  0.5446137777681509\n",
      "test loss:  7.017288684844971\n",
      "test r2:  -0.262169311897102\n",
      "train loss:  3.4697179794311523\n",
      "train r2:  0.5453885776600176\n",
      "test loss:  7.01816987991333\n",
      "test r2:  -0.2622604352948563\n",
      "train loss:  3.467336654663086\n",
      "train r2:  0.5461626727019344\n",
      "test loss:  7.018915176391602\n",
      "test r2:  -0.262304401727542\n",
      "train loss:  3.464967966079712\n",
      "train r2:  0.5469418080759089\n",
      "test loss:  7.019518852233887\n",
      "test r2:  -0.262298845987198\n",
      "train loss:  3.462611436843872\n",
      "train r2:  0.5477269630733537\n",
      "test loss:  7.020035266876221\n",
      "test r2:  -0.26226082014285046\n",
      "train loss:  3.460264205932617\n",
      "train r2:  0.548514994730421\n",
      "test loss:  7.020561218261719\n",
      "test r2:  -0.2622186743247674\n",
      "train loss:  3.4579269886016846\n",
      "train r2:  0.549300015675025\n",
      "test loss:  7.021184921264648\n",
      "test r2:  -0.26219985593416295\n",
      "train loss:  3.4555981159210205\n",
      "train r2:  0.5500765267759967\n",
      "test loss:  7.021957874298096\n",
      "test r2:  -0.2622202493427006\n",
      "train loss:  3.453277826309204\n",
      "train r2:  0.5508412361469542\n",
      "test loss:  7.022876262664795\n",
      "test r2:  -0.2622785644213066\n",
      "train loss:  3.45096492767334\n",
      "train r2:  0.5515947827590744\n",
      "test loss:  7.023885726928711\n",
      "test r2:  -0.26235921246877036\n",
      "train loss:  3.4486594200134277\n",
      "train r2:  0.5523406211209043\n",
      "test loss:  7.024904251098633\n",
      "test r2:  -0.2624390812470756\n",
      "train loss:  3.4463605880737305\n",
      "train r2:  0.5530838703486582\n",
      "test loss:  7.025864124298096\n",
      "test r2:  -0.2624974661971251\n",
      "train loss:  3.4440696239471436\n",
      "train r2:  0.5538289981339461\n",
      "test loss:  7.026727676391602\n",
      "test r2:  -0.2625245296638312\n",
      "train loss:  3.441784381866455\n",
      "train r2:  0.554578219566177\n",
      "test loss:  7.027507305145264\n",
      "test r2:  -0.26252383633200127\n",
      "train loss:  3.4395053386688232\n",
      "train r2:  0.5553307028067214\n",
      "test loss:  7.028247356414795\n",
      "test r2:  -0.26250961477534207\n",
      "train loss:  3.4372332096099854\n",
      "train r2:  0.5560834691827137\n",
      "test loss:  7.029008865356445\n",
      "test r2:  -0.26250019169136474\n",
      "train loss:  3.4349677562713623\n",
      "train r2:  0.5568326550400111\n",
      "test loss:  7.0298380851745605\n",
      "test r2:  -0.2625103488207956\n",
      "train loss:  3.4327077865600586\n",
      "train r2:  0.5575749949398452\n",
      "test loss:  7.030752658843994\n",
      "test r2:  -0.26254580766278424\n",
      "train loss:  3.430454730987549\n",
      "train r2:  0.5583092690127252\n",
      "test loss:  7.031734943389893\n",
      "test r2:  -0.2626010387182056\n",
      "train loss:  3.4282073974609375\n",
      "train r2:  0.5590368821889011\n",
      "test loss:  7.032739162445068\n",
      "test r2:  -0.2626636017323314\n",
      "train loss:  3.425966262817383\n",
      "train r2:  0.5597603840844517\n",
      "test loss:  7.033714294433594\n",
      "test r2:  -0.26271894788699757\n",
      "train loss:  3.4237310886383057\n",
      "train r2:  0.5604829063472746\n",
      "test loss:  7.034624099731445\n",
      "test r2:  -0.2627563116833407\n",
      "train loss:  3.421501874923706\n",
      "train r2:  0.5612067093939523\n",
      "test loss:  7.03546142578125\n",
      "test r2:  -0.2627743429152165\n",
      "train loss:  3.419278621673584\n",
      "train r2:  0.5619322381344303\n",
      "test loss:  7.0362443923950195\n",
      "test r2:  -0.2627784550526344\n",
      "train loss:  3.4170610904693604\n",
      "train r2:  0.562658042011142\n",
      "test loss:  7.0370073318481445\n",
      "test r2:  -0.26277986699896716\n",
      "train loss:  3.4148502349853516\n",
      "train r2:  0.5633819880469801\n",
      "test loss:  7.037788391113281\n",
      "test r2:  -0.2627897921029363\n",
      "train loss:  3.412644863128662\n",
      "train r2:  0.5641015717845033\n",
      "test loss:  7.038605213165283\n",
      "test r2:  -0.26281446772934736\n",
      "train loss:  3.4104459285736084\n",
      "train r2:  0.5648154109492682\n",
      "test loss:  7.039454936981201\n",
      "test r2:  -0.26285353947018386\n",
      "train loss:  3.408252239227295\n",
      "train r2:  0.5655235892650975\n",
      "test loss:  7.040315628051758\n",
      "test r2:  -0.26290074132715313\n",
      "train loss:  3.406064510345459\n",
      "train r2:  0.5662275758220918\n",
      "test loss:  7.041154861450195\n",
      "test r2:  -0.2629468923228573\n",
      "train loss:  3.4038829803466797\n",
      "train r2:  0.5669291948442501\n",
      "test loss:  7.041945934295654\n",
      "test r2:  -0.2629835722171683\n",
      "train loss:  3.4017069339752197\n",
      "train r2:  0.5676302480500115\n",
      "test loss:  7.042675495147705\n",
      "test r2:  -0.2630073584481454\n",
      "train loss:  3.3995370864868164\n",
      "train r2:  0.5683315745009125\n",
      "test loss:  7.043351650238037\n",
      "test r2:  -0.26302047161439845\n",
      "train loss:  3.3973727226257324\n",
      "train r2:  0.5690326930863722\n",
      "test loss:  7.043994426727295\n",
      "test r2:  -0.2630291479337554\n",
      "train loss:  3.3952136039733887\n",
      "train r2:  0.5697321865231711\n",
      "test loss:  7.044630527496338\n",
      "test r2:  -0.263040669659808\n",
      "train loss:  3.393061637878418\n",
      "train r2:  0.5704284342436217\n",
      "test loss:  7.045276165008545\n",
      "test r2:  -0.26306061276886994\n",
      "train loss:  3.390913963317871\n",
      "train r2:  0.5711204291146847\n",
      "test loss:  7.045935153961182\n",
      "test r2:  -0.263089935233372\n",
      "train loss:  3.388772487640381\n",
      "train r2:  0.5718078586760708\n",
      "test loss:  7.046599864959717\n",
      "test r2:  -0.26312573408880313\n",
      "train loss:  3.386636972427368\n",
      "train r2:  0.5724912966480977\n",
      "test loss:  7.0472493171691895\n",
      "test r2:  -0.2631623412851891\n",
      "train loss:  3.384507179260254\n",
      "train r2:  0.5731720991554248\n",
      "test loss:  7.047868251800537\n",
      "test r2:  -0.2631943636048757\n",
      "train loss:  3.382382869720459\n",
      "train r2:  0.5738513845703616\n",
      "test loss:  7.048444747924805\n",
      "test r2:  -0.26321822073548007\n",
      "train loss:  3.380263566970825\n",
      "train r2:  0.5745299873038228\n",
      "test loss:  7.048980712890625\n",
      "test r2:  -0.2632346419952676\n",
      "train loss:  3.378150701522827\n",
      "train r2:  0.5752075806227108\n",
      "test loss:  7.0494890213012695\n",
      "test r2:  -0.26324687154603676\n",
      "train loss:  3.3760428428649902\n",
      "train r2:  0.575883602140002\n",
      "test loss:  7.049985885620117\n",
      "test r2:  -0.26325978194705724\n",
      "train loss:  3.3739407062530518\n",
      "train r2:  0.5765569845591699\n",
      "test loss:  7.050487041473389\n",
      "test r2:  -0.26327770391698735\n",
      "train loss:  3.3718442916870117\n",
      "train r2:  0.5772268479062583\n",
      "test loss:  7.050996780395508\n",
      "test r2:  -0.26330138984883256\n",
      "train loss:  3.369752883911133\n",
      "train r2:  0.5778929705868843\n",
      "test loss:  7.051511764526367\n",
      "test r2:  -0.26332985318583124\n",
      "train loss:  3.367666721343994\n",
      "train r2:  0.5785556596911464\n",
      "test loss:  7.052021503448486\n",
      "test r2:  -0.26335967864525656\n",
      "train loss:  3.365586280822754\n",
      "train r2:  0.5792156713538452\n",
      "test loss:  7.052513122558594\n",
      "test r2:  -0.26338670237736683\n",
      "train loss:  3.363511323928833\n",
      "train r2:  0.5798737832582043\n",
      "test loss:  7.052980422973633\n",
      "test r2:  -0.2634088499454197\n",
      "train loss:  3.3614413738250732\n",
      "train r2:  0.5805305047455491\n",
      "test loss:  7.05342435836792\n",
      "test r2:  -0.2634257931539421\n",
      "train loss:  3.359376907348633\n",
      "train r2:  0.5811859756490392\n",
      "test loss:  7.0538530349731445\n",
      "test r2:  -0.2634400585292582\n",
      "train loss:  3.3573179244995117\n",
      "train r2:  0.5818395914797219\n",
      "test loss:  7.054279804229736\n",
      "test r2:  -0.26345451112006213\n",
      "train loss:  3.3552639484405518\n",
      "train r2:  0.58249082469985\n",
      "test loss:  7.054710388183594\n",
      "test r2:  -0.263471788676775\n",
      "train loss:  3.353214979171753\n",
      "train r2:  0.583139062290106\n",
      "test loss:  7.055152893066406\n",
      "test r2:  -0.26349298593257164\n",
      "train loss:  3.3511712551116943\n",
      "train r2:  0.5837841001127684\n",
      "test loss:  7.055604934692383\n",
      "test r2:  -0.26351760976882854\n",
      "train loss:  3.3491322994232178\n",
      "train r2:  0.5844261331014595\n",
      "test loss:  7.056058883666992\n",
      "test r2:  -0.2635428585237729\n",
      "train loss:  3.3470985889434814\n",
      "train r2:  0.5850656574552964\n",
      "test loss:  7.0565080642700195\n",
      "test r2:  -0.2635662960570453\n",
      "train loss:  3.3450679779052734\n",
      "train r2:  0.5857048809865569\n",
      "test loss:  7.056947708129883\n",
      "test r2:  -0.26358627895805187\n",
      "train loss:  3.3430395126342773\n",
      "train r2:  0.5863454464454407\n",
      "test loss:  7.057380199432373\n",
      "test r2:  -0.26360253780575116\n",
      "train loss:  3.3410139083862305\n",
      "train r2:  0.5869871613141546\n",
      "test loss:  7.057809829711914\n",
      "test r2:  -0.26361663710274574\n",
      "train loss:  3.338991165161133\n",
      "train r2:  0.5876283625876944\n",
      "test loss:  7.058248996734619\n",
      "test r2:  -0.2636314503034405\n",
      "train loss:  3.336987257003784\n",
      "train r2:  0.5882650548741601\n",
      "test loss:  7.058703899383545\n",
      "test r2:  -0.26364977101208775\n",
      "train loss:  3.3350043296813965\n",
      "train r2:  0.5888922441292135\n",
      "test loss:  7.059176445007324\n",
      "test r2:  -0.26367211475024965\n",
      "train loss:  3.333042860031128\n",
      "train r2:  0.5895090728933265\n",
      "test loss:  7.059661865234375\n",
      "test r2:  -0.2636973313570383\n",
      "train loss:  3.331104040145874\n",
      "train r2:  0.5901179609055855\n",
      "test loss:  7.060153484344482\n",
      "test r2:  -0.26372319522810406\n",
      "train loss:  3.329190969467163\n",
      "train r2:  0.5907234149655061\n",
      "test loss:  7.060643196105957\n",
      "test r2:  -0.2637469166916899\n",
      "train loss:  3.3273022174835205\n",
      "train r2:  0.5913290724934305\n",
      "test loss:  7.061124801635742\n",
      "test r2:  -0.26376694783131516\n",
      "train loss:  3.3254384994506836\n",
      "train r2:  0.5919364064078202\n",
      "test loss:  7.061600208282471\n",
      "test r2:  -0.2637835835596076\n",
      "train loss:  3.3235998153686523\n",
      "train r2:  0.5925437187688392\n",
      "test loss:  7.062074661254883\n",
      "test r2:  -0.2637986774954626\n",
      "train loss:  3.321786880493164\n",
      "train r2:  0.5931476423400042\n",
      "test loss:  7.062557697296143\n",
      "test r2:  -0.2638144190151097\n",
      "train loss:  3.3199996948242188\n",
      "train r2:  0.5937449340388896\n",
      "test loss:  7.063056468963623\n",
      "test r2:  -0.26383293283389286\n",
      "train loss:  3.3182387351989746\n",
      "train r2:  0.5943334819664747\n",
      "test loss:  7.063571453094482\n",
      "test r2:  -0.2638541836207924\n",
      "train loss:  3.316502332687378\n",
      "train r2:  0.5949133407777618\n",
      "test loss:  7.064101696014404\n",
      "test r2:  -0.2638774229193952\n",
      "train loss:  3.314791202545166\n",
      "train r2:  0.5954861133742275\n",
      "test loss:  7.064640998840332\n",
      "test r2:  -0.2639002857552324\n",
      "train loss:  3.313106060028076\n",
      "train r2:  0.5960538359428835\n",
      "test loss:  7.065186023712158\n",
      "test r2:  -0.2639212574250298\n",
      "train loss:  3.311445951461792\n",
      "train r2:  0.5966182411639114\n",
      "test loss:  7.065734386444092\n",
      "test r2:  -0.26393957038747917\n",
      "train loss:  3.3098111152648926\n",
      "train r2:  0.5971799576772328\n",
      "test loss:  7.066288948059082\n",
      "test r2:  -0.2639554379804929\n",
      "train loss:  3.3082001209259033\n",
      "train r2:  0.5977383489113987\n",
      "test loss:  7.066858291625977\n",
      "test r2:  -0.26397085291043676\n",
      "train loss:  3.3066136837005615\n",
      "train r2:  0.5982920504089608\n",
      "test loss:  7.067450046539307\n",
      "test r2:  -0.2639876681366937\n",
      "train loss:  3.3050506114959717\n",
      "train r2:  0.5988397822672289\n",
      "test loss:  7.068068981170654\n",
      "test r2:  -0.26400654496992493\n",
      "train loss:  3.303511142730713\n",
      "train r2:  0.5993805433206965\n",
      "test loss:  7.068717956542969\n",
      "test r2:  -0.26402800281503214\n",
      "train loss:  3.301995038986206\n",
      "train r2:  0.5999143248028698\n",
      "test loss:  7.069396495819092\n",
      "test r2:  -0.2640507902247753\n",
      "train loss:  3.3005013465881348\n",
      "train r2:  0.6004416038156211\n",
      "test loss:  7.070098400115967\n",
      "test r2:  -0.2640731449698299\n",
      "train loss:  3.299029588699341\n",
      "train r2:  0.6009633047961463\n",
      "test loss:  7.070826530456543\n",
      "test r2:  -0.26409414437601386\n",
      "train loss:  3.297579288482666\n",
      "train r2:  0.601480263487635\n",
      "test loss:  7.071579456329346\n",
      "test r2:  -0.2641134236920262\n",
      "train loss:  3.2961504459381104\n",
      "train r2:  0.601992657317207\n",
      "test loss:  7.072364330291748\n",
      "test r2:  -0.26413171418189907\n",
      "train loss:  3.2947423458099365\n",
      "train r2:  0.6025005128300298\n",
      "test loss:  7.073185443878174\n",
      "test r2:  -0.2641502604396784\n",
      "train loss:  3.2933547496795654\n",
      "train r2:  0.6030033743079133\n",
      "test loss:  7.07405424118042\n",
      "test r2:  -0.26417079842889235\n",
      "train loss:  3.2919869422912598\n",
      "train r2:  0.6035009374176221\n",
      "test loss:  7.074972629547119\n",
      "test r2:  -0.26419363416737385\n",
      "train loss:  3.290637731552124\n",
      "train r2:  0.6039928286571801\n",
      "test loss:  7.075944900512695\n",
      "test r2:  -0.26421874251172617\n",
      "train loss:  3.289308547973633\n",
      "train r2:  0.6044791624196344\n",
      "test loss:  7.076972961425781\n",
      "test r2:  -0.26424550504416966\n",
      "train loss:  3.287996530532837\n",
      "train r2:  0.6049602165479706\n",
      "test loss:  7.078052043914795\n",
      "test r2:  -0.26427229260121576\n",
      "train loss:  3.2867026329040527\n",
      "train r2:  0.6054363270709042\n",
      "test loss:  7.079188346862793\n",
      "test r2:  -0.2642987441346647\n",
      "train loss:  3.285426139831543\n",
      "train r2:  0.6059076766033024\n",
      "test loss:  7.080382823944092\n",
      "test r2:  -0.26432521336434567\n",
      "train loss:  3.2841663360595703\n",
      "train r2:  0.6063743702538142\n",
      "test loss:  7.0816426277160645\n",
      "test r2:  -0.26435191330456\n",
      "train loss:  3.2829232215881348\n",
      "train r2:  0.6068362395517978\n",
      "test loss:  7.082976818084717\n",
      "test r2:  -0.26438038165139477\n",
      "train loss:  3.2816948890686035\n",
      "train r2:  0.6072932378409465\n",
      "test loss:  7.0843915939331055\n",
      "test r2:  -0.2644114144813332\n",
      "train loss:  3.280482292175293\n",
      "train r2:  0.6077452299499767\n",
      "test loss:  7.085892200469971\n",
      "test r2:  -0.2644458193816013\n",
      "train loss:  3.2792840003967285\n",
      "train r2:  0.608192384990828\n",
      "test loss:  7.087484359741211\n",
      "test r2:  -0.2644828620937356\n",
      "train loss:  3.2781004905700684\n",
      "train r2:  0.6086349315228858\n",
      "test loss:  7.089168071746826\n",
      "test r2:  -0.26452215630324893\n",
      "train loss:  3.276930332183838\n",
      "train r2:  0.6090732597020372\n",
      "test loss:  7.090948104858398\n",
      "test r2:  -0.26456327605937013\n",
      "train loss:  3.275773048400879\n",
      "train r2:  0.6095076649976108\n",
      "test loss:  7.092826843261719\n",
      "test r2:  -0.26460609773835\n",
      "train loss:  3.2746286392211914\n",
      "train r2:  0.609938142288373\n",
      "test loss:  7.094809055328369\n",
      "test r2:  -0.2646510116363283\n",
      "train loss:  3.2734954357147217\n",
      "train r2:  0.6103648645214511\n",
      "test loss:  7.0969038009643555\n",
      "test r2:  -0.264698872100368\n",
      "train loss:  3.2723748683929443\n",
      "train r2:  0.6107874612672628\n",
      "test loss:  7.099113941192627\n",
      "test r2:  -0.26475065241095974\n",
      "train loss:  3.2712645530700684\n",
      "train r2:  0.6112058889114155\n",
      "test loss:  7.101443767547607\n",
      "test r2:  -0.2648070313783728\n",
      "train loss:  3.2701644897460938\n",
      "train r2:  0.6116202528371907\n",
      "test loss:  7.10389518737793\n",
      "test r2:  -0.2648677117591558\n",
      "train loss:  3.2690744400024414\n",
      "train r2:  0.6120304120320381\n",
      "test loss:  7.106461048126221\n",
      "test r2:  -0.26493277839691176\n",
      "train loss:  3.267993450164795\n",
      "train r2:  0.6124370159409331\n",
      "test loss:  7.109137058258057\n",
      "test r2:  -0.2650017339210058\n",
      "train loss:  3.266921281814575\n",
      "train r2:  0.6128402156107824\n",
      "test loss:  7.111911296844482\n",
      "test r2:  -0.2650742434466262\n",
      "train loss:  3.265857458114624\n",
      "train r2:  0.6132403365114958\n",
      "test loss:  7.114767551422119\n",
      "test r2:  -0.2651501808553465\n",
      "train loss:  3.2648017406463623\n",
      "train r2:  0.6136377309254921\n",
      "test loss:  7.117680549621582\n",
      "test r2:  -0.2652293488628501\n",
      "train loss:  3.2637524604797363\n",
      "train r2:  0.6140324686098144\n",
      "test loss:  7.1206159591674805\n",
      "test r2:  -0.2653113029619003\n",
      "train loss:  3.2627105712890625\n",
      "train r2:  0.6144245112834812\n",
      "test loss:  7.123523235321045\n",
      "test r2:  -0.26539516768055704\n",
      "train loss:  3.26167368888855\n",
      "train r2:  0.6148137954975227\n",
      "test loss:  7.126336574554443\n",
      "test r2:  -0.26547885113572245\n",
      "train loss:  3.2606430053710938\n",
      "train r2:  0.6152004078926756\n",
      "test loss:  7.128967761993408\n",
      "test r2:  -0.26555939913393156\n",
      "train loss:  3.259617805480957\n",
      "train r2:  0.6155844746888222\n",
      "test loss:  7.131316661834717\n",
      "test r2:  -0.2656331685657549\n",
      "train loss:  3.2585980892181396\n",
      "train r2:  0.6159660895447484\n",
      "test loss:  7.133266925811768\n",
      "test r2:  -0.2656959636299201\n",
      "train loss:  3.257582664489746\n",
      "train r2:  0.6163456654181487\n",
      "test loss:  7.1347150802612305\n",
      "test r2:  -0.26574405235077925\n",
      "train loss:  3.2565717697143555\n",
      "train r2:  0.616723462378322\n",
      "test loss:  7.135591506958008\n",
      "test r2:  -0.26577469528192355\n",
      "train loss:  3.2555649280548096\n",
      "train r2:  0.6170997036706709\n",
      "test loss:  7.135891437530518\n",
      "test r2:  -0.26578748364857874\n",
      "train loss:  3.254559278488159\n",
      "train r2:  0.6174746268078286\n",
      "test loss:  7.135693073272705\n",
      "test r2:  -0.2657845816262283\n",
      "train loss:  3.2535572052001953\n",
      "train r2:  0.6178485964129474\n",
      "test loss:  7.13514518737793\n",
      "test r2:  -0.26577074649465793\n",
      "train loss:  3.252556800842285\n",
      "train r2:  0.6182215661293696\n",
      "test loss:  7.134437561035156\n",
      "test r2:  -0.26575173547319064\n",
      "train loss:  3.251559257507324\n",
      "train r2:  0.6185935324460464\n",
      "test loss:  7.133758068084717\n",
      "test r2:  -0.2657337248254741\n",
      "train loss:  3.250563859939575\n",
      "train r2:  0.6189646551868193\n",
      "test loss:  7.133262634277344\n",
      "test r2:  -0.2657216585634119\n",
      "train loss:  3.249570369720459\n",
      "train r2:  0.6193348818407489\n",
      "test loss:  7.133059978485107\n",
      "test r2:  -0.26571846292288015\n",
      "train loss:  3.2485780715942383\n",
      "train r2:  0.6197042868379072\n",
      "test loss:  7.133205890655518\n",
      "test r2:  -0.26572651892784727\n",
      "train loss:  3.247586727142334\n",
      "train r2:  0.6200730258915368\n",
      "test loss:  7.133702278137207\n",
      "test r2:  -0.26574541033589205\n",
      "train loss:  3.2465953826904297\n",
      "train r2:  0.6204413415227752\n",
      "test loss:  7.134506702423096\n",
      "test r2:  -0.26577365044229295\n",
      "train loss:  3.2456042766571045\n",
      "train r2:  0.6208092322638242\n",
      "test loss:  7.135539531707764\n",
      "test r2:  -0.2658090098863468\n",
      "train loss:  3.244612455368042\n",
      "train r2:  0.6211768073591286\n",
      "test loss:  7.136688709259033\n",
      "test r2:  -0.2658482814102734\n",
      "train loss:  3.243619918823242\n",
      "train r2:  0.621543807786769\n",
      "test loss:  7.137825012207031\n",
      "test r2:  -0.26588712693427263\n",
      "train loss:  3.2426252365112305\n",
      "train r2:  0.6219098751631003\n",
      "test loss:  7.138819694519043\n",
      "test r2:  -0.2659219727247004\n",
      "train loss:  3.241626501083374\n",
      "train r2:  0.6222746928951939\n",
      "test loss:  7.1395649909973145\n",
      "test r2:  -0.26594938409851565\n",
      "train loss:  3.240624189376831\n",
      "train r2:  0.6226376393040929\n",
      "test loss:  7.14000129699707\n",
      "test r2:  -0.2659675502723562\n",
      "train loss:  3.239614486694336\n",
      "train r2:  0.6229981232056756\n",
      "test loss:  7.140140056610107\n",
      "test r2:  -0.26597626594944446\n",
      "train loss:  3.2385950088500977\n",
      "train r2:  0.6233549895363848\n",
      "test loss:  7.140054225921631\n",
      "test r2:  -0.26597774894287296\n",
      "train loss:  3.237560749053955\n",
      "train r2:  0.6237063451777982\n",
      "test loss:  7.139863967895508\n",
      "test r2:  -0.2659755128272887\n",
      "train loss:  3.236506700515747\n",
      "train r2:  0.6240492485276211\n",
      "test loss:  7.139700412750244\n",
      "test r2:  -0.26597437348486164\n",
      "train loss:  3.2354249954223633\n",
      "train r2:  0.6243790914472349\n",
      "test loss:  7.139674186706543\n",
      "test r2:  -0.26597759926633713\n",
      "train loss:  3.2343051433563232\n",
      "train r2:  0.6246890751627909\n",
      "test loss:  7.1398515701293945\n",
      "test r2:  -0.2659882300034757\n",
      "train loss:  3.233132839202881\n",
      "train r2:  0.6249685490551669\n",
      "test loss:  7.1402506828308105\n",
      "test r2:  -0.2660066885870742\n",
      "train loss:  3.231893539428711\n",
      "train r2:  0.6252011619939175\n",
      "test loss:  7.140838146209717\n",
      "test r2:  -0.2660323652795189\n",
      "train loss:  3.2305731773376465\n",
      "train r2:  0.6253609026189751\n",
      "test loss:  7.14154052734375\n",
      "test r2:  -0.2660626196800506\n",
      "train loss:  3.2291665077209473\n",
      "train r2:  0.6254055957072009\n",
      "test loss:  7.142263412475586\n",
      "test r2:  -0.26609362572805195\n",
      "train loss:  3.227708101272583\n",
      "train r2:  0.6252656621241904\n",
      "test loss:  7.1429033279418945\n",
      "test r2:  -0.2661200789778715\n",
      "train loss:  3.2263410091400146\n",
      "train r2:  0.6248410738494359\n",
      "test loss:  7.143365383148193\n",
      "test r2:  -0.26613176177650577\n",
      "train loss:  3.2253715991973877\n",
      "train r2:  0.6244883183733141\n",
      "test loss:  7.1435770988464355\n",
      "test r2:  -0.2661137658387822\n",
      "train loss:  3.2239904403686523\n",
      "train r2:  0.625193960944999\n",
      "test loss:  7.143653869628906\n",
      "test r2:  -0.26609922135865327\n",
      "train loss:  3.222731113433838\n",
      "train r2:  0.6260040079502445\n",
      "test loss:  7.143738269805908\n",
      "test r2:  -0.2661161090862103\n",
      "train loss:  3.2212953567504883\n",
      "train r2:  0.626565324507155\n",
      "test loss:  7.1439008712768555\n",
      "test r2:  -0.26616109416646405\n",
      "train loss:  3.219906806945801\n",
      "train r2:  0.626884989189952\n",
      "test loss:  7.144139289855957\n",
      "test r2:  -0.2662069320330711\n",
      "train loss:  3.2188303470611572\n",
      "train r2:  0.6271949847583395\n",
      "test loss:  7.144430637359619\n",
      "test r2:  -0.2662300464011891\n",
      "train loss:  3.217327356338501\n",
      "train r2:  0.6277068852196179\n",
      "test loss:  7.144781589508057\n",
      "test r2:  -0.2662327527695705\n",
      "train loss:  3.2159838676452637\n",
      "train r2:  0.6281865988810642\n",
      "test loss:  7.145199298858643\n",
      "test r2:  -0.2662302573058697\n",
      "train loss:  3.2146527767181396\n",
      "train r2:  0.6284310915566362\n",
      "test loss:  7.145665168762207\n",
      "test r2:  -0.2662312971069898\n",
      "train loss:  3.2132294178009033\n",
      "train r2:  0.6284632690576217\n",
      "test loss:  7.146117687225342\n",
      "test r2:  -0.2662309647742036\n",
      "train loss:  3.2120096683502197\n",
      "train r2:  0.6285538216095414\n",
      "test loss:  7.146503925323486\n",
      "test r2:  -0.26622490621507944\n",
      "train loss:  3.210592269897461\n",
      "train r2:  0.6290825805169212\n",
      "test loss:  7.146855354309082\n",
      "test r2:  -0.26623203184062993\n",
      "train loss:  3.2091925144195557\n",
      "train r2:  0.6298186700175554\n",
      "test loss:  7.147224426269531\n",
      "test r2:  -0.2662721863942623\n",
      "train loss:  3.207908868789673\n",
      "train r2:  0.6304243239165704\n",
      "test loss:  7.14760160446167\n",
      "test r2:  -0.2663358005359162\n",
      "train loss:  3.206528902053833\n",
      "train r2:  0.630805487213611\n",
      "test loss:  7.14793062210083\n",
      "test r2:  -0.26639005681977523\n",
      "train loss:  3.205230474472046\n",
      "train r2:  0.6310802033847778\n",
      "test loss:  7.148162364959717\n",
      "test r2:  -0.2664042200812762\n",
      "train loss:  3.203866958618164\n",
      "train r2:  0.6314394803537182\n",
      "test loss:  7.14833402633667\n",
      "test r2:  -0.2663804066054747\n",
      "train loss:  3.2024731636047363\n",
      "train r2:  0.6318885915508912\n",
      "test loss:  7.1485490798950195\n",
      "test r2:  -0.26634889952470187\n",
      "train loss:  3.201171636581421\n",
      "train r2:  0.6322750487728837\n",
      "test loss:  7.148889541625977\n",
      "test r2:  -0.26633932852971576\n",
      "train loss:  3.1998250484466553\n",
      "train r2:  0.6325523347209354\n",
      "test loss:  7.149354457855225\n",
      "test r2:  -0.2663569964071464\n",
      "train loss:  3.19851016998291\n",
      "train r2:  0.6328428323297202\n",
      "test loss:  7.149882793426514\n",
      "test r2:  -0.26639183660605625\n",
      "train loss:  3.1971569061279297\n",
      "train r2:  0.6333164165234975\n",
      "test loss:  7.150413990020752\n",
      "test r2:  -0.2664348690832117\n",
      "train loss:  3.1957955360412598\n",
      "train r2:  0.6339178141000654\n",
      "test loss:  7.150911331176758\n",
      "test r2:  -0.2664821732874878\n",
      "train loss:  3.1944875717163086\n",
      "train r2:  0.6344632312649687\n",
      "test loss:  7.151333332061768\n",
      "test r2:  -0.26652347252518793\n",
      "train loss:  3.1931567192077637\n",
      "train r2:  0.634880458950119\n",
      "test loss:  7.151648044586182\n",
      "test r2:  -0.26654341127163694\n",
      "train loss:  3.1918435096740723\n",
      "train r2:  0.6352462863730189\n",
      "test loss:  7.151867389678955\n",
      "test r2:  -0.2665373377813167\n",
      "train loss:  3.190492630004883\n",
      "train r2:  0.6356588848796553\n",
      "test loss:  7.152062892913818\n",
      "test r2:  -0.2665205656445664\n",
      "train loss:  3.189161777496338\n",
      "train r2:  0.6360877283874137\n",
      "test loss:  7.15232515335083\n",
      "test r2:  -0.2665156554070687\n",
      "train loss:  3.187844753265381\n",
      "train r2:  0.6364597995681238\n",
      "test loss:  7.1526899337768555\n",
      "test r2:  -0.2665310932478986\n",
      "train loss:  3.186527729034424\n",
      "train r2:  0.6368041539275022\n",
      "test loss:  7.153137683868408\n",
      "test r2:  -0.26656005072351174\n",
      "train loss:  3.1852076053619385\n",
      "train r2:  0.63722929878047\n",
      "test loss:  7.153628826141357\n",
      "test r2:  -0.266594032257806\n",
      "train loss:  3.1838693618774414\n",
      "train r2:  0.6377542401446574\n",
      "test loss:  7.154137134552002\n",
      "test r2:  -0.2666309412527845\n",
      "train loss:  3.1825520992279053\n",
      "train r2:  0.6382729914257375\n",
      "test loss:  7.154627799987793\n",
      "test r2:  -0.2666661633953764\n",
      "train loss:  3.1812338829040527\n",
      "train r2:  0.6387210156009504\n",
      "test loss:  7.155060291290283\n",
      "test r2:  -0.26669080237174314\n",
      "train loss:  3.1799237728118896\n",
      "train r2:  0.6391429997026161\n",
      "test loss:  7.155419826507568\n",
      "test r2:  -0.26670028910071175\n",
      "train loss:  3.1785950660705566\n",
      "train r2:  0.6395892729789839\n",
      "test loss:  7.155734062194824\n",
      "test r2:  -0.26670347330013766\n",
      "train loss:  3.177274703979492\n",
      "train r2:  0.6400181974657659\n",
      "test loss:  7.1560468673706055\n",
      "test r2:  -0.2667108953744475\n",
      "train loss:  3.175955295562744\n",
      "train r2:  0.6403969012943882\n",
      "test loss:  7.156374931335449\n",
      "test r2:  -0.26672396935091935\n",
      "train loss:  3.1746456623077393\n",
      "train r2:  0.6407858995021998\n",
      "test loss:  7.156727313995361\n",
      "test r2:  -0.2667408947853791\n",
      "train loss:  3.173325300216675\n",
      "train r2:  0.6412499302387359\n",
      "test loss:  7.157119274139404\n",
      "test r2:  -0.26676449707385186\n",
      "train loss:  3.172006845474243\n",
      "train r2:  0.6417430518302727\n",
      "test loss:  7.157554626464844\n",
      "test r2:  -0.2667960549944257\n",
      "train loss:  3.1706857681274414\n",
      "train r2:  0.642202509350196\n",
      "test loss:  7.158008098602295\n",
      "test r2:  -0.2668279530759108\n",
      "train loss:  3.169374465942383\n",
      "train r2:  0.6426509724388243\n",
      "test loss:  7.158449172973633\n",
      "test r2:  -0.2668524626485784\n",
      "train loss:  3.168057441711426\n",
      "train r2:  0.6431230056310111\n",
      "test loss:  7.158874034881592\n",
      "test r2:  -0.26687080068478664\n",
      "train loss:  3.166741371154785\n",
      "train r2:  0.6435724095777967\n",
      "test loss:  7.1592817306518555\n",
      "test r2:  -0.26688619240481093\n",
      "train loss:  3.1654205322265625\n",
      "train r2:  0.6439731613332735\n",
      "test loss:  7.159667491912842\n",
      "test r2:  -0.2668976824578848\n",
      "train loss:  3.1641061305999756\n",
      "train r2:  0.6443843799581634\n",
      "test loss:  7.160037517547607\n",
      "test r2:  -0.2669082716703224\n",
      "train loss:  3.1627907752990723\n",
      "train r2:  0.6448401713650518\n",
      "test loss:  7.16041898727417\n",
      "test r2:  -0.2669255692991508\n",
      "train loss:  3.1614747047424316\n",
      "train r2:  0.6452932420685786\n",
      "test loss:  7.160818576812744\n",
      "test r2:  -0.2669511124505828\n",
      "train loss:  3.16015625\n",
      "train r2:  0.6457351532205641\n",
      "test loss:  7.161223888397217\n",
      "test r2:  -0.266978912908018\n",
      "train loss:  3.1588387489318848\n",
      "train r2:  0.6462075344766306\n",
      "test loss:  7.161627292633057\n",
      "test r2:  -0.26700618508785734\n",
      "train loss:  3.157524347305298\n",
      "train r2:  0.6466855884527991\n",
      "test loss:  7.162031173706055\n",
      "test r2:  -0.26703189575133357\n",
      "train loss:  3.1562070846557617\n",
      "train r2:  0.6471225827664222\n",
      "test loss:  7.162420749664307\n",
      "test r2:  -0.267051009029988\n",
      "train loss:  3.1548900604248047\n",
      "train r2:  0.6475517069683829\n",
      "test loss:  7.162796497344971\n",
      "test r2:  -0.26706321140557066\n",
      "train loss:  3.1535723209381104\n",
      "train r2:  0.6479997515965603\n",
      "test loss:  7.163179397583008\n",
      "test r2:  -0.2670751473176767\n",
      "train loss:  3.1522552967071533\n",
      "train r2:  0.6484319112955192\n",
      "test loss:  7.163578510284424\n",
      "test r2:  -0.26709079406826475\n",
      "train loss:  3.1509392261505127\n",
      "train r2:  0.6488628346247962\n",
      "test loss:  7.163995265960693\n",
      "test r2:  -0.26711061355357746\n",
      "train loss:  3.149620771408081\n",
      "train r2:  0.6493290282375763\n",
      "test loss:  7.164431571960449\n",
      "test r2:  -0.26713723044439\n",
      "train loss:  3.1483030319213867\n",
      "train r2:  0.6497927448806409\n",
      "test loss:  7.16487455368042\n",
      "test r2:  -0.26716789087104575\n",
      "train loss:  3.1469855308532715\n",
      "train r2:  0.6502396986422083\n",
      "test loss:  7.165301322937012\n",
      "test r2:  -0.267195035543796\n",
      "train loss:  3.145667791366577\n",
      "train r2:  0.650701027492125\n",
      "test loss:  7.165704250335693\n",
      "test r2:  -0.2672170877733968\n",
      "train loss:  3.144350051879883\n",
      "train r2:  0.6511496808287117\n",
      "test loss:  7.166082382202148\n",
      "test r2:  -0.267233724316863\n",
      "train loss:  3.143031597137451\n",
      "train r2:  0.6515775258600612\n",
      "test loss:  7.166442394256592\n",
      "test r2:  -0.2672455351755936\n",
      "train loss:  3.1417126655578613\n",
      "train r2:  0.6520241416437818\n",
      "test loss:  7.166806221008301\n",
      "test r2:  -0.26725858252169377\n",
      "train loss:  3.140394926071167\n",
      "train r2:  0.65246983772891\n",
      "test loss:  7.167190074920654\n",
      "test r2:  -0.26727721931700277\n",
      "train loss:  3.1390764713287354\n",
      "train r2:  0.6529109951815992\n",
      "test loss:  7.1675944328308105\n",
      "test r2:  -0.26730056395324797\n",
      "train loss:  3.1377575397491455\n",
      "train r2:  0.6533748398026403\n",
      "test loss:  7.168017864227295\n",
      "test r2:  -0.2673286522653\n",
      "train loss:  3.1364388465881348\n",
      "train r2:  0.6538288762919853\n",
      "test loss:  7.168444633483887\n",
      "test r2:  -0.26735671749851586\n",
      "train loss:  3.1351206302642822\n",
      "train r2:  0.6542757813083016\n",
      "test loss:  7.168858051300049\n",
      "test r2:  -0.26737991572301634\n",
      "train loss:  3.133801221847534\n",
      "train r2:  0.6547312323332415\n",
      "test loss:  7.169256687164307\n",
      "test r2:  -0.2673988194610748\n",
      "train loss:  3.132481575012207\n",
      "train r2:  0.6551664940840154\n",
      "test loss:  7.169640064239502\n",
      "test r2:  -0.26741329955067705\n",
      "train loss:  3.131162643432617\n",
      "train r2:  0.6556099887989223\n",
      "test loss:  7.170021057128906\n",
      "test r2:  -0.2674276357846568\n",
      "train loss:  3.1298439502716064\n",
      "train r2:  0.6560574125260175\n",
      "test loss:  7.170413017272949\n",
      "test r2:  -0.26744629924310837\n",
      "train loss:  3.1285247802734375\n",
      "train r2:  0.6564985357403634\n",
      "test loss:  7.170815944671631\n",
      "test r2:  -0.2674690329578946\n",
      "train loss:  3.1272056102752686\n",
      "train r2:  0.6569576800708004\n",
      "test loss:  7.171229362487793\n",
      "test r2:  -0.267496054875322\n",
      "train loss:  3.1258862018585205\n",
      "train r2:  0.6574033796237714\n",
      "test loss:  7.171638011932373\n",
      "test r2:  -0.26752212655832364\n",
      "train loss:  3.1245665550231934\n",
      "train r2:  0.6578562869011966\n",
      "test loss:  7.172033786773682\n",
      "test r2:  -0.2675453649106696\n",
      "train loss:  3.1232473850250244\n",
      "train r2:  0.658302029355648\n",
      "test loss:  7.172414779663086\n",
      "test r2:  -0.2675640262758865\n",
      "train loss:  3.1219284534454346\n",
      "train r2:  0.6587422671725951\n",
      "test loss:  7.172782897949219\n",
      "test r2:  -0.26757918495865085\n",
      "train loss:  3.1206090450286865\n",
      "train r2:  0.65918947698052\n",
      "test loss:  7.173156261444092\n",
      "test r2:  -0.26759527620009016\n",
      "train loss:  3.1192901134490967\n",
      "train r2:  0.6596257019361824\n",
      "test loss:  7.173536777496338\n",
      "test r2:  -0.26761337559523146\n",
      "train loss:  3.117971181869507\n",
      "train r2:  0.6600813093936709\n",
      "test loss:  7.17393684387207\n",
      "test r2:  -0.26763701595518197\n",
      "train loss:  3.116652727127075\n",
      "train r2:  0.6605166609702806\n",
      "test loss:  7.174341201782227\n",
      "test r2:  -0.26766132869003556\n",
      "train loss:  3.1153347492218018\n",
      "train r2:  0.660981745822517\n",
      "test loss:  7.174752712249756\n",
      "test r2:  -0.26768834387715956\n",
      "train loss:  3.1140191555023193\n",
      "train r2:  0.661403180579721\n",
      "test loss:  7.175143718719482\n",
      "test r2:  -0.26770837785555535\n",
      "train loss:  3.1127092838287354\n",
      "train r2:  0.6618852129629433\n",
      "test loss:  7.175537109375\n",
      "test r2:  -0.26773136109541085\n",
      "train loss:  3.1114156246185303\n",
      "train r2:  0.6622642817226335\n",
      "test loss:  7.17588996887207\n",
      "test r2:  -0.26774089884032315\n",
      "train loss:  3.1101789474487305\n",
      "train r2:  0.662808243143558\n",
      "test loss:  7.176292419433594\n",
      "test r2:  -0.267769812210535\n",
      "train loss:  3.109002113342285\n",
      "train r2:  0.6630824103857931\n",
      "test loss:  7.176620006561279\n",
      "test r2:  -0.26777138804773815\n",
      "train loss:  3.107954502105713\n",
      "train r2:  0.6637464391100267\n",
      "test loss:  7.177060127258301\n",
      "test r2:  -0.26781568804211475\n",
      "train loss:  3.1062939167022705\n",
      "train r2:  0.6639696972551635\n",
      "test loss:  7.177420139312744\n",
      "test r2:  -0.26783098304731356\n",
      "train loss:  3.104815721511841\n",
      "train r2:  0.6644718304176348\n",
      "test loss:  7.177757263183594\n",
      "test r2:  -0.2678388003784429\n",
      "train loss:  3.1037027835845947\n",
      "train r2:  0.6650096051735025\n",
      "test loss:  7.178158283233643\n",
      "test r2:  -0.2678711216456624\n",
      "train loss:  3.1023569107055664\n",
      "train r2:  0.6653070881059631\n",
      "test loss:  7.178500652313232\n",
      "test r2:  -0.26788070949712917\n",
      "train loss:  3.100898027420044\n",
      "train r2:  0.6658464576874299\n",
      "test loss:  7.178871154785156\n",
      "test r2:  -0.26790001523050333\n",
      "train loss:  3.099632501602173\n",
      "train r2:  0.6663114144623161\n",
      "test loss:  7.179281711578369\n",
      "test r2:  -0.2679344630850984\n",
      "train loss:  3.0984015464782715\n",
      "train r2:  0.6666497852241717\n",
      "test loss:  7.1796345710754395\n",
      "test r2:  -0.26794708012191104\n",
      "train loss:  3.097024440765381\n",
      "train r2:  0.6671857555680142\n",
      "test loss:  7.180015563964844\n",
      "test r2:  -0.2679713555472081\n",
      "train loss:  3.0956640243530273\n",
      "train r2:  0.6675871667145883\n",
      "test loss:  7.180389404296875\n",
      "test r2:  -0.26799474789773914\n",
      "train loss:  3.094447135925293\n",
      "train r2:  0.6679549899627806\n",
      "test loss:  7.180708408355713\n",
      "test r2:  -0.26799836217705675\n",
      "train loss:  3.0931475162506104\n",
      "train r2:  0.6684880273862521\n",
      "test loss:  7.18107795715332\n",
      "test r2:  -0.2680212026795934\n",
      "train loss:  3.091747522354126\n",
      "train r2:  0.6688628209907665\n",
      "test loss:  7.181446552276611\n",
      "test r2:  -0.26804335329942686\n",
      "train loss:  3.09049916267395\n",
      "train r2:  0.6692664171128286\n",
      "test loss:  7.181788444519043\n",
      "test r2:  -0.26805471822948745\n",
      "train loss:  3.089247226715088\n",
      "train r2:  0.6697954391768829\n",
      "test loss:  7.182185173034668\n",
      "test r2:  -0.2680872834384507\n",
      "train loss:  3.087850332260132\n",
      "train r2:  0.6701605194319755\n",
      "test loss:  7.182556629180908\n",
      "test r2:  -0.26811055104692905\n",
      "train loss:  3.0865561962127686\n",
      "train r2:  0.6705927843208142\n",
      "test loss:  7.182895183563232\n",
      "test r2:  -0.2681223050155497\n",
      "train loss:  3.0853209495544434\n",
      "train r2:  0.6710992740746119\n",
      "test loss:  7.18326997756958\n",
      "test r2:  -0.26814900446829837\n",
      "train loss:  3.083963632583618\n",
      "train r2:  0.6714567551368138\n",
      "test loss:  7.183610439300537\n",
      "test r2:  -0.2681629682826101\n",
      "train loss:  3.082627773284912\n",
      "train r2:  0.6719101616855745\n",
      "test loss:  7.183947563171387\n",
      "test r2:  -0.2681754670086398\n",
      "train loss:  3.0813722610473633\n",
      "train r2:  0.6723780028808914\n",
      "test loss:  7.184323310852051\n",
      "test r2:  -0.2682020813720043\n",
      "train loss:  3.0800719261169434\n",
      "train r2:  0.672739637745239\n",
      "test loss:  7.18467378616333\n",
      "test r2:  -0.2682179470520225\n",
      "train loss:  3.0787320137023926\n",
      "train r2:  0.6732131303048874\n",
      "test loss:  7.185037136077881\n",
      "test r2:  -0.2682390342020251\n",
      "train loss:  3.077432155609131\n",
      "train r2:  0.6736416799584988\n",
      "test loss:  7.185410976409912\n",
      "test r2:  -0.2682641357423401\n",
      "train loss:  3.076162338256836\n",
      "train r2:  0.6740299154941775\n",
      "test loss:  7.1857523918151855\n",
      "test r2:  -0.2682768470853245\n",
      "train loss:  3.074859619140625\n",
      "train r2:  0.6745159367450562\n",
      "test loss:  7.1861186027526855\n",
      "test r2:  -0.268299674024846\n",
      "train loss:  3.073530912399292\n",
      "train r2:  0.6749114245265851\n",
      "test loss:  7.18647575378418\n",
      "test r2:  -0.2683188730974566\n",
      "train loss:  3.0722362995147705\n",
      "train r2:  0.6753379178160329\n",
      "test loss:  7.186822414398193\n",
      "test r2:  -0.26833406973290463\n",
      "train loss:  3.0709617137908936\n",
      "train r2:  0.6758034527442256\n",
      "test loss:  7.187197685241699\n",
      "test r2:  -0.2683600560930304\n",
      "train loss:  3.069659948348999\n",
      "train r2:  0.6761823004112709\n",
      "test loss:  7.18754768371582\n",
      "test r2:  -0.2683768738344463\n",
      "train loss:  3.068343162536621\n",
      "train r2:  0.6766413913132836\n",
      "test loss:  7.18790864944458\n",
      "test r2:  -0.26839749691714054\n",
      "train loss:  3.0670413970947266\n",
      "train r2:  0.6770579681097407\n",
      "test loss:  7.188267230987549\n",
      "test r2:  -0.2684184420835527\n",
      "train loss:  3.065757989883423\n",
      "train r2:  0.6774611430830368\n",
      "test loss:  7.188607692718506\n",
      "test r2:  -0.26843236102234935\n",
      "train loss:  3.0644729137420654\n",
      "train r2:  0.677922483880081\n",
      "test loss:  7.188971042633057\n",
      "test r2:  -0.2684551183075341\n",
      "train loss:  3.0631701946258545\n",
      "train r2:  0.6783071908237546\n",
      "test loss:  7.189321517944336\n",
      "test r2:  -0.268471698776064\n",
      "train loss:  3.0618627071380615\n",
      "train r2:  0.6787571522329419\n",
      "test loss:  7.189682483673096\n",
      "test r2:  -0.2684927405589894\n",
      "train loss:  3.0605649948120117\n",
      "train r2:  0.679174532233539\n",
      "test loss:  7.190046787261963\n",
      "test r2:  -0.26851470569199476\n",
      "train loss:  3.0592780113220215\n",
      "train r2:  0.6795847892742162\n",
      "test loss:  7.190399646759033\n",
      "test r2:  -0.2685320003919327\n",
      "train loss:  3.0579934120178223\n",
      "train r2:  0.6800357375282744\n",
      "test loss:  7.190767288208008\n",
      "test r2:  -0.2685555268897364\n",
      "train loss:  3.0567026138305664\n",
      "train r2:  0.6804232552668862\n",
      "test loss:  7.191115856170654\n",
      "test r2:  -0.26857091602496386\n",
      "train loss:  3.0554075241088867\n",
      "train r2:  0.6808775551211581\n",
      "test loss:  7.191479682922363\n",
      "test r2:  -0.2685928039130956\n",
      "train loss:  3.054107666015625\n",
      "train r2:  0.6812703347369021\n",
      "test loss:  7.191833019256592\n",
      "test r2:  -0.26861005196379883\n",
      "train loss:  3.0528106689453125\n",
      "train r2:  0.6817056348873876\n",
      "test loss:  7.192193984985352\n",
      "test r2:  -0.26863008358269713\n",
      "train loss:  3.051517963409424\n",
      "train r2:  0.6821182730662765\n",
      "test loss:  7.192556858062744\n",
      "test r2:  -0.2686505880269001\n",
      "train loss:  3.050229549407959\n",
      "train r2:  0.6825309225219971\n",
      "test loss:  7.192914962768555\n",
      "test r2:  -0.2686691589160326\n",
      "train loss:  3.048943519592285\n",
      "train r2:  0.6829630491004299\n",
      "test loss:  7.193282604217529\n",
      "test r2:  -0.2686914217389913\n",
      "train loss:  3.047659397125244\n",
      "train r2:  0.6833580622225434\n",
      "test loss:  7.193635940551758\n",
      "test r2:  -0.26870798943919794\n",
      "train loss:  3.0463781356811523\n",
      "train r2:  0.6838051995134902\n",
      "test loss:  7.194007396697998\n",
      "test r2:  -0.26873148058550034\n",
      "train loss:  3.0450994968414307\n",
      "train r2:  0.6841836302033362\n",
      "test loss:  7.194357395172119\n",
      "test r2:  -0.2687462645300627\n",
      "train loss:  3.043829917907715\n",
      "train r2:  0.6846463153374436\n",
      "test loss:  7.194734573364258\n",
      "test r2:  -0.2687723303266094\n",
      "train loss:  3.04256534576416\n",
      "train r2:  0.6850016064503203\n",
      "test loss:  7.195080280303955\n",
      "test r2:  -0.2687843954171152\n",
      "train loss:  3.041325092315674\n",
      "train r2:  0.6854872703034616\n",
      "test loss:  7.195466995239258\n",
      "test r2:  -0.26881417581668954\n",
      "train loss:  3.0400726795196533\n",
      "train r2:  0.6858102686700338\n",
      "test loss:  7.195805549621582\n",
      "test r2:  -0.2688228390195335\n",
      "train loss:  3.0388400554656982\n",
      "train r2:  0.6863205434810822\n",
      "test loss:  7.196197032928467\n",
      "test r2:  -0.2688543956784315\n",
      "train loss:  3.0375094413757324\n",
      "train r2:  0.686628060269854\n",
      "test loss:  7.196536540985107\n",
      "test r2:  -0.268863525234347\n",
      "train loss:  3.036161184310913\n",
      "train r2:  0.6871224892993548\n",
      "test loss:  7.19691276550293\n",
      "test r2:  -0.26888846532521593\n",
      "train loss:  3.0347983837127686\n",
      "train r2:  0.6874821617800573\n",
      "test loss:  7.197273254394531\n",
      "test r2:  -0.2689063089934143\n",
      "train loss:  3.033501625061035\n",
      "train r2:  0.6879016895339933\n",
      "test loss:  7.197629928588867\n",
      "test r2:  -0.2689220057809185\n",
      "train loss:  3.0322623252868652\n",
      "train r2:  0.6883481676686485\n",
      "test loss:  7.198020935058594\n",
      "test r2:  -0.2689508940691785\n",
      "train loss:  3.031022548675537\n",
      "train r2:  0.6886964949956108\n",
      "test loss:  7.198375225067139\n",
      "test r2:  -0.26896407280570767\n",
      "train loss:  3.029757499694824\n",
      "train r2:  0.6891810845836419\n",
      "test loss:  7.1987714767456055\n",
      "test r2:  -0.26899479795059844\n",
      "train loss:  3.0284173488616943\n",
      "train r2:  0.6895164215540186\n",
      "test loss:  7.199127674102783\n",
      "test r2:  -0.2690090629900137\n",
      "train loss:  3.027073383331299\n",
      "train r2:  0.6899665414377492\n",
      "test loss:  7.199495315551758\n",
      "test r2:  -0.2690289581431051\n",
      "train loss:  3.0257554054260254\n",
      "train r2:  0.6903525990478354\n",
      "test loss:  7.199862957000732\n",
      "test r2:  -0.26904857438800844\n",
      "train loss:  3.024472236633301\n",
      "train r2:  0.6907336913001069\n",
      "test loss:  7.200218200683594\n",
      "test r2:  -0.2690618541077596\n",
      "train loss:  3.0231974124908447\n",
      "train r2:  0.6911731251177803\n",
      "test loss:  7.2006120681762695\n",
      "test r2:  -0.2690901261574985\n",
      "train loss:  3.021885871887207\n",
      "train r2:  0.6915067689227214\n",
      "test loss:  7.200976848602295\n",
      "test r2:  -0.2691050806986566\n",
      "train loss:  3.0205349922180176\n",
      "train r2:  0.6919522007854731\n",
      "test loss:  7.201372146606445\n",
      "test r2:  -0.26913295365739187\n",
      "train loss:  3.019134283065796\n",
      "train r2:  0.6922802679003359\n",
      "test loss:  7.201736927032471\n",
      "test r2:  -0.26914819200187634\n",
      "train loss:  3.0177109241485596\n",
      "train r2:  0.6926758651148429\n",
      "test loss:  7.202103137969971\n",
      "test r2:  -0.26916505162437554\n",
      "train loss:  3.0162858963012695\n",
      "train r2:  0.6930136728878713\n",
      "test loss:  7.202463150024414\n",
      "test r2:  -0.26917967924812225\n",
      "train loss:  3.0148839950561523\n",
      "train r2:  0.6933187220505276\n",
      "test loss:  7.202796936035156\n",
      "test r2:  -0.2691839588648135\n",
      "train loss:  3.013524055480957\n",
      "train r2:  0.6936596622960736\n",
      "test loss:  7.203144550323486\n",
      "test r2:  -0.26919563115221345\n",
      "train loss:  3.012188673019409\n",
      "train r2:  0.6939581351625085\n",
      "test loss:  7.203453063964844\n",
      "test r2:  -0.2691921864740783\n",
      "train loss:  3.010798931121826\n",
      "train r2:  0.6945315880976154\n",
      "test loss:  7.20388650894165\n",
      "test r2:  -0.2692346765453262\n",
      "train loss:  3.009445905685425\n",
      "train r2:  0.6949635376447774\n",
      "test loss:  7.20433235168457\n",
      "test r2:  -0.2692775022510183\n",
      "train loss:  3.0082106590270996\n",
      "train r2:  0.6955733726552111\n",
      "test loss:  7.2048845291137695\n",
      "test r2:  -0.2693675390837198\n",
      "train loss:  3.006873846054077\n",
      "train r2:  0.6958620133722317\n",
      "test loss:  7.2052321434021\n",
      "test r2:  -0.26939131130927607\n",
      "train loss:  3.0054373741149902\n",
      "train r2:  0.6963715130939243\n",
      "test loss:  7.205508708953857\n",
      "test r2:  -0.2694116032307403\n",
      "train loss:  3.003711462020874\n",
      "train r2:  0.6965929211466264\n",
      "test loss:  7.205542087554932\n",
      "test r2:  -0.2693573075850533\n",
      "train loss:  3.002140522003174\n",
      "train r2:  0.6969954330788056\n",
      "test loss:  7.205546855926514\n",
      "test r2:  -0.26929784595444395\n",
      "train loss:  3.0008351802825928\n",
      "train r2:  0.6974261174431338\n",
      "test loss:  7.205741882324219\n",
      "test r2:  -0.26930187507932746\n",
      "train loss:  2.999493360519409\n",
      "train r2:  0.6977562175720317\n",
      "test loss:  7.206010341644287\n",
      "test r2:  -0.26932195672694914\n",
      "train loss:  2.997971296310425\n",
      "train r2:  0.6983394391382792\n",
      "test loss:  7.206506252288818\n",
      "test r2:  -0.26941685694719264\n",
      "train loss:  2.996401071548462\n",
      "train r2:  0.6987553226438173\n",
      "test loss:  7.206972122192383\n",
      "test r2:  -0.2695033476761308\n",
      "train loss:  2.9950203895568848\n",
      "train r2:  0.6991867259706581\n",
      "test loss:  7.207237243652344\n",
      "test r2:  -0.2695280253097536\n",
      "train loss:  2.9936788082122803\n",
      "train r2:  0.6996873386647251\n",
      "test loss:  7.2074079513549805\n",
      "test r2:  -0.2695328463287463\n",
      "train loss:  2.99215030670166\n",
      "train r2:  0.7000097386196256\n",
      "test loss:  7.207386493682861\n",
      "test r2:  -0.26947638128063267\n",
      "train loss:  2.990586757659912\n",
      "train r2:  0.7004559144627169\n",
      "test loss:  7.207414150238037\n",
      "test r2:  -0.2694361337152753\n",
      "train loss:  2.9891562461853027\n",
      "train r2:  0.7008617930296102\n",
      "test loss:  7.20761251449585\n",
      "test r2:  -0.269449121942851\n",
      "train loss:  2.9877758026123047\n",
      "train r2:  0.7012138534459604\n",
      "test loss:  7.207854747772217\n",
      "test r2:  -0.2694705082083366\n",
      "train loss:  2.9863104820251465\n",
      "train r2:  0.7017562018706447\n",
      "test loss:  7.208282947540283\n",
      "test r2:  -0.269553646734243\n",
      "train loss:  2.9847664833068848\n",
      "train r2:  0.7021585511517205\n",
      "test loss:  7.208636283874512\n",
      "test r2:  -0.26961291732337367\n",
      "train loss:  2.9832825660705566\n",
      "train r2:  0.7026379236111815\n",
      "test loss:  7.2088704109191895\n",
      "test r2:  -0.2696397477569161\n",
      "train loss:  2.9818642139434814\n",
      "train r2:  0.7031043281815219\n",
      "test loss:  7.209028244018555\n",
      "test r2:  -0.2696501694286353\n",
      "train loss:  2.9804282188415527\n",
      "train r2:  0.703459408881241\n",
      "test loss:  7.209001064300537\n",
      "test r2:  -0.269604063677118\n",
      "train loss:  2.978945732116699\n",
      "train r2:  0.7039386328063337\n",
      "test loss:  7.2090559005737305\n",
      "test r2:  -0.26958983950698756\n",
      "train loss:  2.9774370193481445\n",
      "train r2:  0.7043008603049035\n",
      "test loss:  7.209132194519043\n",
      "test r2:  -0.26958202771002693\n",
      "train loss:  2.9759459495544434\n",
      "train r2:  0.7047600213978754\n",
      "test loss:  7.209315776824951\n",
      "test r2:  -0.2696096012870166\n",
      "train loss:  2.974485397338867\n",
      "train r2:  0.7052318534052382\n",
      "test loss:  7.209619045257568\n",
      "test r2:  -0.2696777777467698\n",
      "train loss:  2.973043441772461\n",
      "train r2:  0.7056405480806258\n",
      "test loss:  7.2098283767700195\n",
      "test r2:  -0.2697176804690882\n",
      "train loss:  2.971588373184204\n",
      "train r2:  0.7061397238083701\n",
      "test loss:  7.210012912750244\n",
      "test r2:  -0.2697580783786864\n",
      "train loss:  2.9700937271118164\n",
      "train r2:  0.7065146600492185\n",
      "test loss:  7.209991931915283\n",
      "test r2:  -0.26973757679783206\n",
      "train loss:  2.9685897827148438\n",
      "train r2:  0.7069734236799415\n",
      "test loss:  7.209925651550293\n",
      "test r2:  -0.269708558335759\n",
      "train loss:  2.967106342315674\n",
      "train r2:  0.7073838349657784\n",
      "test loss:  7.209871292114258\n",
      "test r2:  -0.2696855102793563\n",
      "train loss:  2.9656429290771484\n",
      "train r2:  0.7078093623918427\n",
      "test loss:  7.209884166717529\n",
      "test r2:  -0.26968358346278154\n",
      "train loss:  2.9641833305358887\n",
      "train r2:  0.7082877765868314\n",
      "test loss:  7.21006965637207\n",
      "test r2:  -0.2697387472110746\n",
      "train loss:  2.9627206325531006\n",
      "train r2:  0.7086902474356751\n",
      "test loss:  7.21022367477417\n",
      "test r2:  -0.26978330055651134\n",
      "train loss:  2.961254596710205\n",
      "train r2:  0.7091820603067515\n",
      "test loss:  7.210391521453857\n",
      "test r2:  -0.26983901306005453\n",
      "train loss:  2.9597716331481934\n",
      "train r2:  0.7095627974041996\n",
      "test loss:  7.210344314575195\n",
      "test r2:  -0.2698303975755929\n",
      "train loss:  2.958280086517334\n",
      "train r2:  0.7100356670187932\n",
      "test loss:  7.210243225097656\n",
      "test r2:  -0.2698121344493387\n",
      "train loss:  2.956789016723633\n",
      "train r2:  0.7104285071931922\n",
      "test loss:  7.210060119628906\n",
      "test r2:  -0.269770110829475\n",
      "train loss:  2.9553022384643555\n",
      "train r2:  0.7108941179192707\n",
      "test loss:  7.209994316101074\n",
      "test r2:  -0.269767346825448\n",
      "train loss:  2.9538164138793945\n",
      "train r2:  0.7113203885981223\n",
      "test loss:  7.210026741027832\n",
      "test r2:  -0.2697962827296816\n",
      "train loss:  2.952333927154541\n",
      "train r2:  0.7117706249108632\n",
      "test loss:  7.210132122039795\n",
      "test r2:  -0.2698504500531056\n",
      "train loss:  2.9508557319641113\n",
      "train r2:  0.7122072852299983\n",
      "test loss:  7.210200309753418\n",
      "test r2:  -0.2698977904773092\n",
      "train loss:  2.949378252029419\n",
      "train r2:  0.7126285519865195\n",
      "test loss:  7.210115432739258\n",
      "test r2:  -0.26990265219354015\n",
      "train loss:  2.947901725769043\n",
      "train r2:  0.7130722755422676\n",
      "test loss:  7.209932327270508\n",
      "test r2:  -0.26988355169140177\n",
      "train loss:  2.946429967880249\n",
      "train r2:  0.713479812012594\n",
      "test loss:  7.209649562835693\n",
      "test r2:  -0.2698368002199314\n",
      "train loss:  2.9449710845947266\n",
      "train r2:  0.7139563352293817\n",
      "test loss:  7.209510803222656\n",
      "test r2:  -0.2698404025215215\n",
      "train loss:  2.943533420562744\n",
      "train r2:  0.7143418524819602\n",
      "test loss:  7.209366321563721\n",
      "test r2:  -0.2698414592938201\n",
      "train loss:  2.9421608448028564\n",
      "train r2:  0.7148597310431543\n",
      "test loss:  7.209466457366943\n",
      "test r2:  -0.2699274055440979\n",
      "train loss:  2.9408624172210693\n",
      "train r2:  0.71517344003342\n",
      "test loss:  7.209271430969238\n",
      "test r2:  -0.2699189100949828\n",
      "train loss:  2.939695119857788\n",
      "train r2:  0.7157463599847023\n",
      "test loss:  7.209273815155029\n",
      "test r2:  -0.26998853180439486\n",
      "train loss:  2.938183069229126\n",
      "train r2:  0.7160097354145062\n",
      "test loss:  7.208807468414307\n",
      "test r2:  -0.26990891908893344\n",
      "train loss:  2.936394691467285\n",
      "train r2:  0.7165838761359491\n",
      "test loss:  7.208532333374023\n",
      "test r2:  -0.26990166000429716\n",
      "train loss:  2.934591293334961\n",
      "train r2:  0.7169554308039265\n",
      "test loss:  7.208256721496582\n",
      "test r2:  -0.2698984278570935\n",
      "train loss:  2.933290958404541\n",
      "train r2:  0.7173485715642498\n",
      "test loss:  7.207887649536133\n",
      "test r2:  -0.26986540407402715\n",
      "train loss:  2.9320743083953857\n",
      "train r2:  0.7178802539600238\n",
      "test loss:  7.207859992980957\n",
      "test r2:  -0.2699508057473321\n",
      "train loss:  2.930358648300171\n",
      "train r2:  0.718198849263016\n",
      "test loss:  7.207588195800781\n",
      "test r2:  -0.2699617746176881\n",
      "train loss:  2.9286911487579346\n",
      "train r2:  0.718669706132893\n",
      "test loss:  7.207209587097168\n",
      "test r2:  -0.2699467314192254\n",
      "train loss:  2.927396297454834\n",
      "train r2:  0.7191411112025066\n",
      "test loss:  7.206923007965088\n",
      "test r2:  -0.26997224213166104\n",
      "train loss:  2.925976514816284\n",
      "train r2:  0.7194830767238019\n",
      "test loss:  7.206374645233154\n",
      "test r2:  -0.26991709873403513\n",
      "train loss:  2.9243171215057373\n",
      "train r2:  0.7199847504143293\n",
      "test loss:  7.205958366394043\n",
      "test r2:  -0.2699107096240372\n",
      "train loss:  2.922825574874878\n",
      "train r2:  0.7204056932503276\n",
      "test loss:  7.205658435821533\n",
      "test r2:  -0.2699478696228672\n",
      "train loss:  2.9214859008789062\n",
      "train r2:  0.7207671399214792\n",
      "test loss:  7.20517110824585\n",
      "test r2:  -0.2699273566992195\n",
      "train loss:  2.9199578762054443\n",
      "train r2:  0.7212616665879268\n",
      "test loss:  7.204808235168457\n",
      "test r2:  -0.2699547106585918\n",
      "train loss:  2.918370008468628\n",
      "train r2:  0.7216518783897601\n",
      "test loss:  7.204368591308594\n",
      "test r2:  -0.269963270813653\n",
      "train loss:  2.9169747829437256\n",
      "train r2:  0.7220524020869126\n",
      "test loss:  7.203750133514404\n",
      "test r2:  -0.26991868483669146\n",
      "train loss:  2.9155478477478027\n",
      "train r2:  0.7225435238663922\n",
      "test loss:  7.203307628631592\n",
      "test r2:  -0.2699369914784726\n",
      "train loss:  2.913968801498413\n",
      "train r2:  0.7229216818427151\n",
      "test loss:  7.202803134918213\n",
      "test r2:  -0.2699383925448995\n",
      "train loss:  2.9124860763549805\n",
      "train r2:  0.7233466725070902\n",
      "test loss:  7.202244758605957\n",
      "test r2:  -0.2699253240452475\n",
      "train loss:  2.9110851287841797\n",
      "train r2:  0.7238070959363527\n",
      "test loss:  7.201817035675049\n",
      "test r2:  -0.2699595953758285\n",
      "train loss:  2.9095733165740967\n",
      "train r2:  0.724173383807222\n",
      "test loss:  7.201218128204346\n",
      "test r2:  -0.2699422070988693\n",
      "train loss:  2.908038377761841\n",
      "train r2:  0.7246201972353623\n",
      "test loss:  7.200595378875732\n",
      "test r2:  -0.26992110364539323\n",
      "train loss:  2.9065968990325928\n",
      "train r2:  0.7250583778978732\n",
      "test loss:  7.2000627517700195\n",
      "test r2:  -0.2699325065486189\n",
      "train loss:  2.9051499366760254\n",
      "train r2:  0.7254388037531447\n",
      "test loss:  7.1994218826293945\n",
      "test r2:  -0.26990978586432224\n",
      "train loss:  2.9036316871643066\n",
      "train r2:  0.7259005665039509\n",
      "test loss:  7.198888778686523\n",
      "test r2:  -0.2699245692108174\n",
      "train loss:  2.902128219604492\n",
      "train r2:  0.726307659022728\n",
      "test loss:  7.198369026184082\n",
      "test r2:  -0.269945443833985\n",
      "train loss:  2.9006826877593994\n",
      "train r2:  0.726705441767921\n",
      "test loss:  7.197729587554932\n",
      "test r2:  -0.26992939852491915\n",
      "train loss:  2.8992197513580322\n",
      "train r2:  0.7271603288966062\n",
      "test loss:  7.197163105010986\n",
      "test r2:  -0.26994051566266664\n",
      "train loss:  2.8977091312408447\n",
      "train r2:  0.7275468853705283\n",
      "test loss:  7.196506977081299\n",
      "test r2:  -0.26992363546420095\n",
      "train loss:  2.896212577819824\n",
      "train r2:  0.7279765406402785\n",
      "test loss:  7.1958513259887695\n",
      "test r2:  -0.26990805230944814\n",
      "train loss:  2.8947527408599854\n",
      "train r2:  0.7284085661771804\n",
      "test loss:  7.1952900886535645\n",
      "test r2:  -0.26992435989961727\n",
      "train loss:  2.893289566040039\n",
      "train r2:  0.7287946163888289\n",
      "test loss:  7.1946563720703125\n",
      "test r2:  -0.26991583238017713\n",
      "train loss:  2.891796827316284\n",
      "train r2:  0.7292406309024608\n",
      "test loss:  7.194097518920898\n",
      "test r2:  -0.26993328029999386\n",
      "train loss:  2.8902957439422607\n",
      "train r2:  0.7296371719000574\n",
      "test loss:  7.193489074707031\n",
      "test r2:  -0.26993531094675416\n",
      "train loss:  2.8888139724731445\n",
      "train r2:  0.730053698545804\n",
      "test loss:  7.192838668823242\n",
      "test r2:  -0.2699238307454024\n",
      "train loss:  2.8873484134674072\n",
      "train r2:  0.7304855731047101\n",
      "test loss:  7.192245960235596\n",
      "test r2:  -0.2699326912940079\n",
      "train loss:  2.885878086090088\n",
      "train r2:  0.7308749220588411\n",
      "test loss:  7.191586494445801\n",
      "test r2:  -0.2699177283307541\n",
      "train loss:  2.8843936920166016\n",
      "train r2:  0.7313166266908602\n",
      "test loss:  7.1910200119018555\n",
      "test r2:  -0.26993356669630986\n",
      "train loss:  2.882899761199951\n",
      "train r2:  0.7317053539208458\n",
      "test loss:  7.190404891967773\n",
      "test r2:  -0.26993205410265575\n",
      "train loss:  2.8814072608947754\n",
      "train r2:  0.7321315350433093\n",
      "test loss:  7.189811706542969\n",
      "test r2:  -0.26993796029394224\n",
      "train loss:  2.8799211978912354\n",
      "train r2:  0.732538765592514\n",
      "test loss:  7.189213752746582\n",
      "test r2:  -0.2699412215129424\n",
      "train loss:  2.8784420490264893\n",
      "train r2:  0.7329462446587217\n",
      "test loss:  7.188589572906494\n",
      "test r2:  -0.2699349433771647\n",
      "train loss:  2.876967430114746\n",
      "train r2:  0.7333718851673297\n",
      "test loss:  7.188024997711182\n",
      "test r2:  -0.26994752088419904\n",
      "train loss:  2.8754966259002686\n",
      "train r2:  0.7337622384614477\n",
      "test loss:  7.187408924102783\n",
      "test r2:  -0.26994013781943127\n",
      "train loss:  2.874032974243164\n",
      "train r2:  0.7342001926090269\n",
      "test loss:  7.186892986297607\n",
      "test r2:  -0.26996580822397864\n",
      "train loss:  2.87258243560791\n",
      "train r2:  0.7345707669672357\n",
      "test loss:  7.186257839202881\n",
      "test r2:  -0.269948117038316\n",
      "train loss:  2.8711698055267334\n",
      "train r2:  0.735028434871351\n",
      "test loss:  7.185781478881836\n",
      "test r2:  -0.26998460691113935\n",
      "train loss:  2.8698105812072754\n",
      "train r2:  0.73536608735558\n",
      "test loss:  7.185085773468018\n",
      "test r2:  -0.26994150537771433\n",
      "train loss:  2.8685998916625977\n",
      "train r2:  0.7358647124046941\n",
      "test loss:  7.184710502624512\n",
      "test r2:  -0.27000868318008786\n",
      "train loss:  2.8673596382141113\n",
      "train r2:  0.7361456919536171\n",
      "test loss:  7.183971881866455\n",
      "test r2:  -0.2699433573949366\n",
      "train loss:  2.866049289703369\n",
      "train r2:  0.7366882588450938\n",
      "test loss:  7.183658123016357\n",
      "test r2:  -0.2700256379526067\n",
      "train loss:  2.8640358448028564\n",
      "train r2:  0.7369755452163995\n",
      "test loss:  7.183029651641846\n",
      "test r2:  -0.26999588922601125\n",
      "train loss:  2.862149715423584\n",
      "train r2:  0.7374423677008821\n",
      "test loss:  7.182441234588623\n",
      "test r2:  -0.2699783814093637\n",
      "train loss:  2.8608646392822266\n",
      "train r2:  0.7378725138692774\n",
      "test loss:  7.182073593139648\n",
      "test r2:  -0.2700353541468179\n",
      "train loss:  2.8596372604370117\n",
      "train r2:  0.7381866232518137\n",
      "test loss:  7.181423664093018\n",
      "test r2:  -0.26999017896724564\n",
      "train loss:  2.857963800430298\n",
      "train r2:  0.7386815181283319\n",
      "test loss:  7.181039810180664\n",
      "test r2:  -0.27003387431577175\n",
      "train loss:  2.856234550476074\n",
      "train r2:  0.7390442966537776\n",
      "test loss:  7.1806321144104\n",
      "test r2:  -0.27006823266921387\n",
      "train loss:  2.854959726333618\n",
      "train r2:  0.7394063449301216\n",
      "test loss:  7.179989337921143\n",
      "test r2:  -0.27001954873230205\n",
      "train loss:  2.8535873889923096\n",
      "train r2:  0.7398844267416378\n",
      "test loss:  7.179626941680908\n",
      "test r2:  -0.27006498995342687\n",
      "train loss:  2.851850986480713\n",
      "train r2:  0.7402273493598572\n",
      "test loss:  7.179161071777344\n",
      "test r2:  -0.2700713216039221\n",
      "train loss:  2.850389003753662\n",
      "train r2:  0.7406242344244905\n",
      "test loss:  7.1785993576049805\n",
      "test r2:  -0.2700411972379275\n",
      "train loss:  2.849080801010132\n",
      "train r2:  0.7410779818890396\n",
      "test loss:  7.178316116333008\n",
      "test r2:  -0.2701018683814411\n",
      "train loss:  2.8474602699279785\n",
      "train r2:  0.7414146475482095\n",
      "test loss:  7.177877902984619\n",
      "test r2:  -0.27010580630108993\n",
      "train loss:  2.8459017276763916\n",
      "train r2:  0.7418283948757058\n",
      "test loss:  7.17738676071167\n",
      "test r2:  -0.2700890293838991\n",
      "train loss:  2.8445558547973633\n",
      "train r2:  0.7422611309281884\n",
      "test loss:  7.177095413208008\n",
      "test r2:  -0.27013660419306174\n",
      "train loss:  2.8430416584014893\n",
      "train r2:  0.742603466663887\n",
      "test loss:  7.176641941070557\n",
      "test r2:  -0.270124310268151\n",
      "train loss:  2.841456651687622\n",
      "train r2:  0.7430297537774516\n",
      "test loss:  7.176235675811768\n",
      "test r2:  -0.27012335967734313\n",
      "train loss:  2.840041399002075\n",
      "train r2:  0.7434414266151621\n",
      "test loss:  7.175988674163818\n",
      "test r2:  -0.2701717824883223\n",
      "train loss:  2.838599920272827\n",
      "train r2:  0.7437897675700991\n",
      "test loss:  7.17558479309082\n",
      "test r2:  -0.270161430294797\n",
      "train loss:  2.837038278579712\n",
      "train r2:  0.7442206985551703\n",
      "test loss:  7.175268650054932\n",
      "test r2:  -0.2701768748454483\n",
      "train loss:  2.83554744720459\n",
      "train r2:  0.7446112672647163\n",
      "test loss:  7.175013542175293\n",
      "test r2:  -0.27020836429553063\n",
      "train loss:  2.834130048751831\n",
      "train r2:  0.7449746401480897\n",
      "test loss:  7.174630641937256\n",
      "test r2:  -0.2701911668798107\n",
      "train loss:  2.8326311111450195\n",
      "train r2:  0.74540719474733\n",
      "test loss:  7.174402236938477\n",
      "test r2:  -0.2702212809967375\n",
      "train loss:  2.8310935497283936\n",
      "train r2:  0.7457779751949931\n",
      "test loss:  7.174167156219482\n",
      "test r2:  -0.2702438175050379\n",
      "train loss:  2.829632043838501\n",
      "train r2:  0.7461614772084036\n",
      "test loss:  7.173873424530029\n",
      "test r2:  -0.27024041113596886\n",
      "train loss:  2.8281900882720947\n",
      "train r2:  0.7465811515018618\n",
      "test loss:  7.1737165451049805\n",
      "test r2:  -0.27027983166872604\n",
      "train loss:  2.82668399810791\n",
      "train r2:  0.7469387242481174\n",
      "test loss:  7.173465251922607\n",
      "test r2:  -0.270281540289117\n",
      "train loss:  2.8251633644104004\n",
      "train r2:  0.7473477035147644\n",
      "test loss:  7.173253059387207\n",
      "test r2:  -0.27029221284998983\n",
      "train loss:  2.823687791824341\n",
      "train r2:  0.7477408640478298\n",
      "test loss:  7.173110485076904\n",
      "test r2:  -0.27032217974409445\n",
      "train loss:  2.8222358226776123\n",
      "train r2:  0.748107569289084\n",
      "test loss:  7.17289400100708\n",
      "test r2:  -0.27032038716081574\n",
      "train loss:  2.8207590579986572\n",
      "train r2:  0.7485245644796719\n",
      "test loss:  7.172798156738281\n",
      "test r2:  -0.2703566507389712\n",
      "train loss:  2.8192501068115234\n",
      "train r2:  0.7488861597269596\n",
      "test loss:  7.172639846801758\n",
      "test r2:  -0.2703660201279916\n",
      "train loss:  2.817744731903076\n",
      "train r2:  0.749286897459814\n",
      "test loss:  7.172511100769043\n",
      "test r2:  -0.2703820033855462\n",
      "train loss:  2.8162620067596436\n",
      "train r2:  0.7496741499680415\n",
      "test loss:  7.172416687011719\n",
      "test r2:  -0.2704063521641842\n",
      "train loss:  2.8147952556610107\n",
      "train r2:  0.7500467001585205\n",
      "test loss:  7.172277450561523\n",
      "test r2:  -0.2704094076194232\n",
      "train loss:  2.81333065032959\n",
      "train r2:  0.750454614185904\n",
      "test loss:  7.172242641448975\n",
      "test r2:  -0.27044667898572317\n",
      "train loss:  2.8118579387664795\n",
      "train r2:  0.7508107062138102\n",
      "test loss:  7.172125339508057\n",
      "test r2:  -0.27044895713805195\n",
      "train loss:  2.8103787899017334\n",
      "train r2:  0.7512241416025407\n",
      "test loss:  7.172114372253418\n",
      "test r2:  -0.27048737244698007\n",
      "train loss:  2.8088934421539307\n",
      "train r2:  0.7515766384359098\n",
      "test loss:  7.172008037567139\n",
      "test r2:  -0.2704868054998393\n",
      "train loss:  2.80741024017334\n",
      "train r2:  0.7519896058786248\n",
      "test loss:  7.172004699707031\n",
      "test r2:  -0.27052232322276404\n",
      "train loss:  2.805928945541382\n",
      "train r2:  0.7523413213125832\n",
      "test loss:  7.1719160079956055\n",
      "test r2:  -0.2705211896643833\n",
      "train loss:  2.8044588565826416\n",
      "train r2:  0.7527551123478724\n",
      "test loss:  7.17194938659668\n",
      "test r2:  -0.2705636008931811\n",
      "train loss:  2.8030011653900146\n",
      "train r2:  0.7530986068206421\n",
      "test loss:  7.171874523162842\n",
      "test r2:  -0.27055903941483317\n",
      "train loss:  2.801579475402832\n",
      "train r2:  0.7535216811536138\n",
      "test loss:  7.171961784362793\n",
      "test r2:  -0.27061390044285516\n",
      "train loss:  2.800196886062622\n",
      "train r2:  0.7538434559360544\n",
      "test loss:  7.171857833862305\n",
      "test r2:  -0.270590492178004\n",
      "train loss:  2.798922538757324\n",
      "train r2:  0.7542918722882759\n",
      "test loss:  7.172018051147461\n",
      "test r2:  -0.2706666745156885\n",
      "train loss:  2.797642707824707\n",
      "train r2:  0.7545753218182537\n",
      "test loss:  7.171873092651367\n",
      "test r2:  -0.27061924665898873\n",
      "train loss:  2.796372175216675\n",
      "train r2:  0.7550561519359544\n",
      "test loss:  7.172094821929932\n",
      "test r2:  -0.27071153861843533\n",
      "train loss:  2.7946054935455322\n",
      "train r2:  0.7553296126312999\n",
      "test loss:  7.171998500823975\n",
      "test r2:  -0.2706783765343974\n",
      "train loss:  2.792698860168457\n",
      "train r2:  0.7557855916601011\n",
      "test loss:  7.172073841094971\n",
      "test r2:  -0.27070991744282935\n",
      "train loss:  2.791039228439331\n",
      "train r2:  0.7561413282102365\n",
      "test loss:  7.172178745269775\n",
      "test r2:  -0.2707506321928177\n",
      "train loss:  2.7897872924804688\n",
      "train r2:  0.7564800789187468\n",
      "test loss:  7.172115802764893\n",
      "test r2:  -0.2707227510618637\n",
      "train loss:  2.7885220050811768\n",
      "train r2:  0.756922478212805\n",
      "test loss:  7.172352313995361\n",
      "test r2:  -0.2708059760371424\n",
      "train loss:  2.7868332862854004\n",
      "train r2:  0.7572242840160207\n",
      "test loss:  7.172366142272949\n",
      "test r2:  -0.2708038571345195\n",
      "train loss:  2.785121440887451\n",
      "train r2:  0.757635662507434\n",
      "test loss:  7.172399997711182\n",
      "test r2:  -0.2708101850737217\n",
      "train loss:  2.7837281227111816\n",
      "train r2:  0.7580203598248001\n",
      "test loss:  7.1725568771362305\n",
      "test r2:  -0.2708625308690573\n",
      "train loss:  2.7824032306671143\n",
      "train r2:  0.7583397127517155\n",
      "test loss:  7.172512531280518\n",
      "test r2:  -0.27083589581093204\n",
      "train loss:  2.7808449268341064\n",
      "train r2:  0.7587691795235134\n",
      "test loss:  7.1726789474487305\n",
      "test r2:  -0.27088549029273334\n",
      "train loss:  2.779198408126831\n",
      "train r2:  0.7591075513422733\n",
      "test loss:  7.172805309295654\n",
      "test r2:  -0.27091812919503466\n",
      "train loss:  2.7777717113494873\n",
      "train r2:  0.7594648619414031\n",
      "test loss:  7.1728129386901855\n",
      "test r2:  -0.270905825512618\n",
      "train loss:  2.776407480239868\n",
      "train r2:  0.7598742374303967\n",
      "test loss:  7.173003673553467\n",
      "test r2:  -0.2709617506658868\n",
      "train loss:  2.7748522758483887\n",
      "train r2:  0.76019642927047\n",
      "test loss:  7.1730451583862305\n",
      "test r2:  -0.270959492323507\n",
      "train loss:  2.773266077041626\n",
      "train r2:  0.7605907420359178\n",
      "test loss:  7.173129558563232\n",
      "test r2:  -0.2709715083438353\n",
      "train loss:  2.7718262672424316\n",
      "train r2:  0.7609673894381603\n",
      "test loss:  7.173327922821045\n",
      "test r2:  -0.2710231471787843\n",
      "train loss:  2.7704155445098877\n",
      "train r2:  0.7612978987592508\n",
      "test loss:  7.1733808517456055\n",
      "test r2:  -0.27101737151769334\n",
      "train loss:  2.768894672393799\n",
      "train r2:  0.7617025969507529\n",
      "test loss:  7.173559665679932\n",
      "test r2:  -0.27105835402970113\n",
      "train loss:  2.767336368560791\n",
      "train r2:  0.7620464610943151\n",
      "test loss:  7.17369270324707\n",
      "test r2:  -0.27108088845295963\n",
      "train loss:  2.765871047973633\n",
      "train r2:  0.7624067809182052\n",
      "test loss:  7.173760890960693\n",
      "test r2:  -0.2710769995789104\n",
      "train loss:  2.7644455432891846\n",
      "train r2:  0.7627976476431486\n",
      "test loss:  7.1739702224731445\n",
      "test r2:  -0.27112388272755394\n",
      "train loss:  2.762951612472534\n",
      "train r2:  0.7631278165027601\n",
      "test loss:  7.174077987670898\n",
      "test r2:  -0.27112872787404885\n",
      "train loss:  2.761413812637329\n",
      "train r2:  0.7635149292245205\n",
      "test loss:  7.174253463745117\n",
      "test r2:  -0.27115710542528393\n",
      "train loss:  2.759913682937622\n",
      "train r2:  0.7638714190153528\n",
      "test loss:  7.174443244934082\n",
      "test r2:  -0.27118987749173384\n",
      "train loss:  2.7584633827209473\n",
      "train r2:  0.764218670432605\n",
      "test loss:  7.1745500564575195\n",
      "test r2:  -0.271189357861533\n",
      "train loss:  2.7570061683654785\n",
      "train r2:  0.7646058854303509\n",
      "test loss:  7.174772262573242\n",
      "test r2:  -0.2712306308784962\n",
      "train loss:  2.7555041313171387\n",
      "train r2:  0.7649399470881374\n",
      "test loss:  7.174914836883545\n",
      "test r2:  -0.2712383590566625\n",
      "train loss:  2.753986120223999\n",
      "train r2:  0.7653193763749719\n",
      "test loss:  7.175117015838623\n",
      "test r2:  -0.2712666624189013\n",
      "train loss:  2.752488613128662\n",
      "train r2:  0.7656731577293229\n",
      "test loss:  7.175329685211182\n",
      "test r2:  -0.271297225950492\n",
      "train loss:  2.7510199546813965\n",
      "train r2:  0.7660233497949244\n",
      "test loss:  7.175490856170654\n",
      "test r2:  -0.27130604057082053\n",
      "train loss:  2.7495574951171875\n",
      "train r2:  0.7663997562693625\n",
      "test loss:  7.175734043121338\n",
      "test r2:  -0.27134531256992345\n",
      "train loss:  2.748080253601074\n",
      "train r2:  0.7667340559282876\n",
      "test loss:  7.1758928298950195\n",
      "test r2:  -0.2713494494329105\n",
      "train loss:  2.7465853691101074\n",
      "train r2:  0.7671142604108072\n",
      "test loss:  7.176137924194336\n",
      "test r2:  -0.27138615038246106\n",
      "train loss:  2.7450814247131348\n",
      "train r2:  0.7674522960362957\n",
      "test loss:  7.176335334777832\n",
      "test r2:  -0.27140163835032705\n",
      "train loss:  2.743581771850586\n",
      "train r2:  0.7678190283654027\n",
      "test loss:  7.1765642166137695\n",
      "test r2:  -0.27142775971795885\n",
      "train loss:  2.742091655731201\n",
      "train r2:  0.7681706579371456\n",
      "test loss:  7.176794528961182\n",
      "test r2:  -0.2714537161911146\n",
      "train loss:  2.7406113147735596\n",
      "train r2:  0.7685207726104433\n",
      "test loss:  7.177000522613525\n",
      "test r2:  -0.2714684739477107\n",
      "train loss:  2.739135980606079\n",
      "train r2:  0.7688852554665259\n",
      "test loss:  7.17725944519043\n",
      "test r2:  -0.27150293834746386\n",
      "train loss:  2.7376632690429688\n",
      "train r2:  0.769222524783775\n",
      "test loss:  7.177459239959717\n",
      "test r2:  -0.27151219774129176\n",
      "train loss:  2.736191511154175\n",
      "train r2:  0.7695950398452167\n",
      "test loss:  7.1777424812316895\n",
      "test r2:  -0.27155410597926255\n",
      "train loss:  2.734720468521118\n",
      "train r2:  0.7699227107708116\n",
      "test loss:  7.177935600280762\n",
      "test r2:  -0.27155798506713147\n",
      "train loss:  2.7332544326782227\n",
      "train r2:  0.7703014003042608\n",
      "test loss:  7.178234577178955\n",
      "test r2:  -0.2716045308321895\n",
      "train loss:  2.7317919731140137\n",
      "train r2:  0.7706200877678174\n",
      "test loss:  7.178413391113281\n",
      "test r2:  -0.271601127244542\n",
      "train loss:  2.730343818664551\n",
      "train r2:  0.7710062427152091\n",
      "test loss:  7.178736686706543\n",
      "test r2:  -0.27165601477594903\n",
      "train loss:  2.728902578353882\n",
      "train r2:  0.7713126440025271\n",
      "test loss:  7.178898811340332\n",
      "test r2:  -0.27164362225189187\n",
      "train loss:  2.7274858951568604\n",
      "train r2:  0.7717093999355448\n",
      "test loss:  7.179255485534668\n",
      "test r2:  -0.27171015406804955\n",
      "train loss:  2.7260611057281494\n",
      "train r2:  0.7720002098911679\n",
      "test loss:  7.17939567565918\n",
      "test r2:  -0.27168720819509984\n",
      "train loss:  2.7246434688568115\n",
      "train r2:  0.7724085965569313\n",
      "test loss:  7.179771900177002\n",
      "test r2:  -0.27176103596304446\n",
      "train loss:  2.723146915435791\n",
      "train r2:  0.7726904514429507\n",
      "test loss:  7.179908752441406\n",
      "test r2:  -0.2717360982357697\n",
      "train loss:  2.7215988636016846\n",
      "train r2:  0.7730989403629029\n",
      "test loss:  7.180263996124268\n",
      "test r2:  -0.271799823064899\n",
      "train loss:  2.719972848892212\n",
      "train r2:  0.7733953474400267\n",
      "test loss:  7.180455207824707\n",
      "test r2:  -0.27179684354779776\n",
      "train loss:  2.7183685302734375\n",
      "train r2:  0.7737747691232008\n",
      "test loss:  7.180736064910889\n",
      "test r2:  -0.2718296381318841\n",
      "train loss:  2.716839075088501\n",
      "train r2:  0.7741084717836477\n",
      "test loss:  7.181016445159912\n",
      "test r2:  -0.2718624298075618\n",
      "train loss:  2.7153923511505127\n",
      "train r2:  0.7744411293563871\n",
      "test loss:  7.181222915649414\n",
      "test r2:  -0.2718645291992694\n",
      "train loss:  2.713984727859497\n",
      "train r2:  0.774811186951694\n",
      "test loss:  7.181565761566162\n",
      "test r2:  -0.2719219835118323\n",
      "train loss:  2.7125494480133057\n",
      "train r2:  0.7751132638252556\n",
      "test loss:  7.181738376617432\n",
      "test r2:  -0.27191062173596126\n",
      "train loss:  2.711061954498291\n",
      "train r2:  0.7754976569217767\n",
      "test loss:  7.182069778442383\n",
      "test r2:  -0.27196527381326185\n",
      "train loss:  2.70951509475708\n",
      "train r2:  0.7758014535700379\n",
      "test loss:  7.182262897491455\n",
      "test r2:  -0.2719653054739515\n",
      "train loss:  2.707963228225708\n",
      "train r2:  0.7761691317749109\n",
      "test loss:  7.182530403137207\n",
      "test r2:  -0.27199641644586414\n",
      "train loss:  2.7064459323883057\n",
      "train r2:  0.7764984229044114\n",
      "test loss:  7.18278694152832\n",
      "test r2:  -0.2720235230307513\n",
      "train loss:  2.704974889755249\n",
      "train r2:  0.7768319868745527\n",
      "test loss:  7.182992458343506\n",
      "test r2:  -0.27203042860856774\n",
      "train loss:  2.7035300731658936\n",
      "train r2:  0.7771886319665329\n",
      "test loss:  7.183293342590332\n",
      "test r2:  -0.272076648197654\n",
      "train loss:  2.7020764350891113\n",
      "train r2:  0.7774981041326615\n",
      "test loss:  7.183465957641602\n",
      "test r2:  -0.2720716041733626\n",
      "train loss:  2.7005977630615234\n",
      "train r2:  0.7778667888501228\n",
      "test loss:  7.183764934539795\n",
      "test r2:  -0.27211821391521607\n",
      "train loss:  2.699087619781494\n",
      "train r2:  0.7781743088737204\n",
      "test loss:  7.183950424194336\n",
      "test r2:  -0.27211898603214735\n",
      "train loss:  2.6975677013397217\n",
      "train r2:  0.7785344327377035\n",
      "test loss:  7.18421745300293\n",
      "test r2:  -0.27215286154470864\n",
      "train loss:  2.6960554122924805\n",
      "train r2:  0.7788561524241381\n",
      "test loss:  7.184447765350342\n",
      "test r2:  -0.2721712094162534\n",
      "train loss:  2.6945619583129883\n",
      "train r2:  0.7791950495259042\n",
      "test loss:  7.1846723556518555\n",
      "test r2:  -0.27218773115541217\n",
      "train loss:  2.6930859088897705\n",
      "train r2:  0.7795350771666539\n",
      "test loss:  7.184937000274658\n",
      "test r2:  -0.2722207690708862\n",
      "train loss:  2.691619634628296\n",
      "train r2:  0.7798544935642915\n",
      "test loss:  7.1851301193237305\n",
      "test r2:  -0.27222422171642213\n",
      "train loss:  2.690152168273926\n",
      "train r2:  0.7802073871922939\n",
      "test loss:  7.185417652130127\n",
      "test r2:  -0.2722656740920739\n",
      "train loss:  2.6886770725250244\n",
      "train r2:  0.7805160272978706\n",
      "test loss:  7.185603141784668\n",
      "test r2:  -0.2722650051499125\n",
      "train loss:  2.6871938705444336\n",
      "train r2:  0.7808727749890128\n",
      "test loss:  7.18589448928833\n",
      "test r2:  -0.2723072916448501\n",
      "train loss:  2.685701847076416\n",
      "train r2:  0.7811792513748443\n",
      "test loss:  7.1860857009887695\n",
      "test r2:  -0.27230814807285864\n",
      "train loss:  2.6842052936553955\n",
      "train r2:  0.7815327555226951\n",
      "test loss:  7.186368942260742\n",
      "test r2:  -0.27234606156251595\n",
      "train loss:  2.682706356048584\n",
      "train r2:  0.7818429302381887\n",
      "test loss:  7.186576843261719\n",
      "test r2:  -0.27235258452075284\n",
      "train loss:  2.681208610534668\n",
      "train r2:  0.782188876959344\n",
      "test loss:  7.1868486404418945\n",
      "test r2:  -0.27238477447127774\n",
      "train loss:  2.679713249206543\n",
      "train r2:  0.7825048754603876\n",
      "test loss:  7.187074184417725\n",
      "test r2:  -0.27239740506700927\n",
      "train loss:  2.678220510482788\n",
      "train r2:  0.7828425177058839\n",
      "test loss:  7.187335014343262\n",
      "test r2:  -0.27242389793263033\n",
      "train loss:  2.676730155944824\n",
      "train r2:  0.7831639317358803\n",
      "test loss:  7.187576770782471\n",
      "test r2:  -0.2724419479544642\n",
      "train loss:  2.675241470336914\n",
      "train r2:  0.7834943386745108\n",
      "test loss:  7.187828063964844\n",
      "test r2:  -0.27246388950887845\n",
      "train loss:  2.6737546920776367\n",
      "train r2:  0.7838196743070567\n",
      "test loss:  7.188081741333008\n",
      "test r2:  -0.2724858860117325\n",
      "train loss:  2.672267436981201\n",
      "train r2:  0.7841443625202961\n",
      "test loss:  7.188327312469482\n",
      "test r2:  -0.272504235120375\n",
      "train loss:  2.6707818508148193\n",
      "train r2:  0.7844725376847226\n",
      "test loss:  7.188592433929443\n",
      "test r2:  -0.2725298209967386\n",
      "train loss:  2.669296979904175\n",
      "train r2:  0.7847918745899088\n",
      "test loss:  7.188830852508545\n",
      "test r2:  -0.27254438590126906\n",
      "train loss:  2.667813301086426\n",
      "train r2:  0.785123071227338\n",
      "test loss:  7.1891069412231445\n",
      "test r2:  -0.27257429042434733\n",
      "train loss:  2.6663331985473633\n",
      "train r2:  0.7854359800942282\n",
      "test loss:  7.189332962036133\n",
      "test r2:  -0.2725829915430076\n",
      "train loss:  2.6648590564727783\n",
      "train r2:  0.7857724841878382\n",
      "test loss:  7.189631462097168\n",
      "test r2:  -0.272621176485496\n",
      "train loss:  2.6633975505828857\n",
      "train r2:  0.7860747213583574\n",
      "test loss:  7.18983268737793\n",
      "test r2:  -0.27261841739299264\n",
      "train loss:  2.6619625091552734\n",
      "train r2:  0.7864224380613246\n",
      "test loss:  7.190173149108887\n",
      "test r2:  -0.27267355654270364\n",
      "train loss:  2.6605780124664307\n",
      "train r2:  0.7867038183803209\n",
      "test loss:  7.1903181076049805\n",
      "test r2:  -0.27264720914666674\n",
      "train loss:  2.6592981815338135\n",
      "train r2:  0.787074376291101\n",
      "test loss:  7.190741062164307\n",
      "test r2:  -0.27273526417339\n",
      "train loss:  2.658140182495117\n",
      "train r2:  0.7873161340659622\n",
      "test loss:  7.190789699554443\n",
      "test r2:  -0.27266825905265435\n",
      "train loss:  2.6571204662323\n",
      "train r2:  0.7877238507919799\n",
      "test loss:  7.191318035125732\n",
      "test r2:  -0.27279794765707543\n",
      "train loss:  2.6557648181915283\n",
      "train r2:  0.7879285938829396\n",
      "test loss:  7.19132661819458\n",
      "test r2:  -0.27271346379968153\n",
      "train loss:  2.6538748741149902\n",
      "train r2:  0.7883569095386302\n",
      "test loss:  7.191766262054443\n",
      "test r2:  -0.27280605409220837\n",
      "train loss:  2.6516385078430176\n",
      "train r2:  0.788613879301736\n",
      "test loss:  7.191995620727539\n",
      "test r2:  -0.27281382869840654\n",
      "train loss:  2.650024175643921\n",
      "train r2:  0.7889421537567973\n",
      "test loss:  7.192131519317627\n",
      "test r2:  -0.2727837977373866\n",
      "train loss:  2.6490094661712646\n",
      "train r2:  0.7892988052383607\n",
      "test loss:  7.192605972290039\n",
      "test r2:  -0.2728899149643924\n",
      "train loss:  2.6476857662200928\n",
      "train r2:  0.7895326672771137\n",
      "test loss:  7.192699909210205\n",
      "test r2:  -0.2728412486581715\n",
      "train loss:  2.6458005905151367\n",
      "train r2:  0.7899195783621005\n",
      "test loss:  7.193032741546631\n",
      "test r2:  -0.2728910628968657\n",
      "train loss:  2.6440415382385254\n",
      "train r2:  0.7902109770145074\n",
      "test loss:  7.193354606628418\n",
      "test r2:  -0.27293860224802224\n",
      "train loss:  2.642822265625\n",
      "train r2:  0.790493083211562\n",
      "test loss:  7.193436145782471\n",
      "test r2:  -0.2728898791540999\n",
      "train loss:  2.641525983810425\n",
      "train r2:  0.7908633645071411\n",
      "test loss:  7.193853855133057\n",
      "test r2:  -0.27297461688279046\n",
      "train loss:  2.6397621631622314\n",
      "train r2:  0.7911226678736377\n",
      "test loss:  7.194068908691406\n",
      "test r2:  -0.27297810109889653\n",
      "train loss:  2.6381146907806396\n",
      "train r2:  0.7914527309664847\n",
      "test loss:  7.194250583648682\n",
      "test r2:  -0.2729694883262186\n",
      "train loss:  2.6368331909179688\n",
      "train r2:  0.7917862885475904\n",
      "test loss:  7.194641590118408\n",
      "test r2:  -0.2730456488590316\n",
      "train loss:  2.6354196071624756\n",
      "train r2:  0.7920450479567074\n",
      "test loss:  7.1947712898254395\n",
      "test r2:  -0.2730178594617416\n",
      "train loss:  2.6337358951568604\n",
      "train r2:  0.7923978669312498\n",
      "test loss:  7.195046901702881\n",
      "test r2:  -0.273047326146441\n",
      "train loss:  2.6321942806243896\n",
      "train r2:  0.7926993468121329\n",
      "test loss:  7.195382595062256\n",
      "test r2:  -0.273100772450805\n",
      "train loss:  2.6308608055114746\n",
      "train r2:  0.7929775987609624\n",
      "test loss:  7.195518493652344\n",
      "test r2:  -0.2730743282211483\n",
      "train loss:  2.6293835639953613\n",
      "train r2:  0.7933262891898625\n",
      "test loss:  7.195858478546143\n",
      "test r2:  -0.27312962007459785\n",
      "train loss:  2.6277549266815186\n",
      "train r2:  0.7936054807027089\n",
      "test loss:  7.196107864379883\n",
      "test r2:  -0.27314910505196255\n",
      "train loss:  2.6262729167938232\n",
      "train r2:  0.79391161880365\n",
      "test loss:  7.1962809562683105\n",
      "test r2:  -0.27313718495996064\n",
      "train loss:  2.624891996383667\n",
      "train r2:  0.7942427017955017\n",
      "test loss:  7.196640491485596\n",
      "test r2:  -0.2731991628719219\n",
      "train loss:  2.6233785152435303\n",
      "train r2:  0.7945134559451438\n",
      "test loss:  7.196844100952148\n",
      "test r2:  -0.2731978036865783\n",
      "train loss:  2.62180233001709\n",
      "train r2:  0.7948391644967729\n",
      "test loss:  7.197093486785889\n",
      "test r2:  -0.2732148439949835\n",
      "train loss:  2.6203384399414062\n",
      "train r2:  0.7951462540077155\n",
      "test loss:  7.197418689727783\n",
      "test r2:  -0.27326242381398247\n",
      "train loss:  2.6189181804656982\n",
      "train r2:  0.79542508953768\n",
      "test loss:  7.197596549987793\n",
      "test r2:  -0.2732497496945312\n",
      "train loss:  2.6174075603485107\n",
      "train r2:  0.7957559904720732\n",
      "test loss:  7.197908401489258\n",
      "test r2:  -0.2732901654109634\n",
      "train loss:  2.615863084793091\n",
      "train r2:  0.7960423823422634\n",
      "test loss:  7.198188304901123\n",
      "test r2:  -0.2733164961676262\n",
      "train loss:  2.614393711090088\n",
      "train r2:  0.7963397021636339\n",
      "test loss:  7.198402404785156\n",
      "test r2:  -0.2733159225229529\n",
      "train loss:  2.6129539012908936\n",
      "train r2:  0.7966587205172929\n",
      "test loss:  7.198739528656006\n",
      "test r2:  -0.2733645318038844\n",
      "train loss:  2.611454486846924\n",
      "train r2:  0.7969356293531812\n",
      "test loss:  7.198965072631836\n",
      "test r2:  -0.2733679405734146\n",
      "train loss:  2.6099283695220947\n",
      "train r2:  0.7972503505752218\n",
      "test loss:  7.199235439300537\n",
      "test r2:  -0.2733886352111523\n",
      "train loss:  2.608445405960083\n",
      "train r2:  0.7975495227914597\n",
      "test loss:  7.199552536010742\n",
      "test r2:  -0.2734271790840277\n",
      "train loss:  2.606992244720459\n",
      "train r2:  0.7978331847677627\n",
      "test loss:  7.1997761726379395\n",
      "test r2:  -0.2734271761346556\n",
      "train loss:  2.6055097579956055\n",
      "train r2:  0.7981496873356796\n",
      "test loss:  7.200097560882568\n",
      "test r2:  -0.27346677541984143\n",
      "train loss:  2.603997230529785\n",
      "train r2:  0.7984318381943005\n",
      "test loss:  7.200363636016846\n",
      "test r2:  -0.2734833565233057\n",
      "train loss:  2.60250186920166\n",
      "train r2:  0.7987324948247754\n",
      "test loss:  7.200620651245117\n",
      "test r2:  -0.27349595245981906\n",
      "train loss:  2.601034164428711\n",
      "train r2:  0.7990353506861589\n",
      "test loss:  7.200944900512695\n",
      "test r2:  -0.27353547914539234\n",
      "train loss:  2.599562883377075\n",
      "train r2:  0.7993154818409998\n",
      "test loss:  7.201187610626221\n",
      "test r2:  -0.2735407683362363\n",
      "train loss:  2.5980679988861084\n",
      "train r2:  0.7996247085267644\n",
      "test loss:  7.201498031616211\n",
      "test r2:  -0.27357390963949024\n",
      "train loss:  2.596567153930664\n",
      "train r2:  0.7999095990077169\n",
      "test loss:  7.201780796051025\n",
      "test r2:  -0.2735957266238982\n",
      "train loss:  2.595082998275757\n",
      "train r2:  0.8002027007739778\n",
      "test loss:  7.20203971862793\n",
      "test r2:  -0.2736078755216307\n",
      "train loss:  2.593611240386963\n",
      "train r2:  0.8005032002754002\n",
      "test loss:  7.2023606300354\n",
      "test r2:  -0.27364477293622747\n",
      "train loss:  2.5921313762664795\n",
      "train r2:  0.8007826886947134\n",
      "test loss:  7.202613830566406\n",
      "test r2:  -0.27365368375933774\n",
      "train loss:  2.590639352798462\n",
      "train r2:  0.8010853954018086\n",
      "test loss:  7.202919006347656\n",
      "test r2:  -0.2736844208000291\n",
      "train loss:  2.5891454219818115\n",
      "train r2:  0.8013693126329502\n",
      "test loss:  7.203203201293945\n",
      "test r2:  -0.2737065658611155\n",
      "train loss:  2.587661027908325\n",
      "train r2:  0.801659252251556\n",
      "test loss:  7.2034687995910645\n",
      "test r2:  -0.27372110014133266\n",
      "train loss:  2.586184024810791\n",
      "train r2:  0.8019546176135255\n",
      "test loss:  7.203780651092529\n",
      "test r2:  -0.27375464453362763\n",
      "train loss:  2.5847036838531494\n",
      "train r2:  0.8022338158459341\n",
      "test loss:  7.204038619995117\n",
      "test r2:  -0.2737660098487451\n",
      "train loss:  2.5832159519195557\n",
      "train r2:  0.8025314272514799\n",
      "test loss:  7.204343795776367\n",
      "test r2:  -0.2737966351287171\n",
      "train loss:  2.5817253589630127\n",
      "train r2:  0.8028122497249991\n",
      "test loss:  7.204620838165283\n",
      "test r2:  -0.2738164587472469\n",
      "train loss:  2.5802390575408936\n",
      "train r2:  0.803101180478522\n",
      "test loss:  7.204895496368408\n",
      "test r2:  -0.27383525561972455\n",
      "train loss:  2.5787575244903564\n",
      "train r2:  0.803390136321321\n",
      "test loss:  7.205195426940918\n",
      "test r2:  -0.273864682078266\n",
      "train loss:  2.577277183532715\n",
      "train r2:  0.8036695059749936\n",
      "test loss:  7.205456256866455\n",
      "test r2:  -0.27387793688811257\n",
      "train loss:  2.575793743133545\n",
      "train r2:  0.8039621973265798\n",
      "test loss:  7.2057600021362305\n",
      "test r2:  -0.2739090022430706\n",
      "train loss:  2.5743067264556885\n",
      "train r2:  0.8042395446746275\n",
      "test loss:  7.206027507781982\n",
      "test r2:  -0.27392559201850775\n",
      "train loss:  2.572819232940674\n",
      "train r2:  0.8045279383447557\n",
      "test loss:  7.206312656402588\n",
      "test r2:  -0.27394944692479406\n",
      "train loss:  2.571333646774292\n",
      "train r2:  0.8048098872068369\n",
      "test loss:  7.206599235534668\n",
      "test r2:  -0.2739739391985754\n",
      "train loss:  2.5698513984680176\n",
      "train r2:  0.805090404618151\n",
      "test loss:  7.20686674118042\n",
      "test r2:  -0.27399093823215703\n",
      "train loss:  2.568369150161743\n",
      "train r2:  0.8053767887273158\n",
      "test loss:  7.207164287567139\n",
      "test r2:  -0.2740202693399576\n",
      "train loss:  2.5668859481811523\n",
      "train r2:  0.8056523178687786\n",
      "test loss:  7.207427501678467\n",
      "test r2:  -0.2740354242254055\n",
      "train loss:  2.565401077270508\n",
      "train r2:  0.8059386733751543\n",
      "test loss:  7.207720756530762\n",
      "test r2:  -0.2740632739906068\n",
      "train loss:  2.5639150142669678\n",
      "train r2:  0.8062142894966973\n",
      "test loss:  7.207993030548096\n",
      "test r2:  -0.27408258948967945\n",
      "train loss:  2.562429428100586\n",
      "train r2:  0.8064962690057085\n",
      "test loss:  7.2082743644714355\n",
      "test r2:  -0.2741050998837482\n",
      "train loss:  2.560945749282837\n",
      "train r2:  0.8067747799298278\n",
      "test loss:  7.208559036254883\n",
      "test r2:  -0.27412962816444675\n",
      "train loss:  2.559462308883667\n",
      "train r2:  0.8070512252519586\n",
      "test loss:  7.208828926086426\n",
      "test r2:  -0.27414765337059177\n",
      "train loss:  2.5579793453216553\n",
      "train r2:  0.8073321443833381\n",
      "test loss:  7.209122180938721\n",
      "test r2:  -0.2741753284223656\n",
      "train loss:  2.5564959049224854\n",
      "train r2:  0.8076048421187322\n",
      "test loss:  7.209390163421631\n",
      "test r2:  -0.27419236914040557\n",
      "train loss:  2.555011749267578\n",
      "train r2:  0.8078855588141605\n",
      "test loss:  7.209682941436768\n",
      "test r2:  -0.2742195100854772\n",
      "train loss:  2.5535271167755127\n",
      "train r2:  0.8081574614084176\n",
      "test loss:  7.209954738616943\n",
      "test r2:  -0.27423819844154473\n",
      "train loss:  2.552042245864868\n",
      "train r2:  0.8084354604113463\n",
      "test loss:  7.210240364074707\n",
      "test r2:  -0.2742625346402916\n",
      "train loss:  2.550558090209961\n",
      "train r2:  0.8087083612828426\n",
      "test loss:  7.2105207443237305\n",
      "test r2:  -0.27428458572291436\n",
      "train loss:  2.5490739345550537\n",
      "train r2:  0.8089825236847608\n",
      "test loss:  7.210800647735596\n",
      "test r2:  -0.27430614226548045\n",
      "train loss:  2.547590732574463\n",
      "train r2:  0.8092566787368876\n",
      "test loss:  7.211089611053467\n",
      "test r2:  -0.2743309356947272\n",
      "train loss:  2.546107292175293\n",
      "train r2:  0.8095273587764247\n",
      "test loss:  7.211364269256592\n",
      "test r2:  -0.27435017127810624\n",
      "train loss:  2.544624090194702\n",
      "train r2:  0.8098020370016166\n",
      "test loss:  7.211656093597412\n",
      "test r2:  -0.27437640508645167\n",
      "train loss:  2.5431406497955322\n",
      "train r2:  0.8100703792308375\n",
      "test loss:  7.211929798126221\n",
      "test r2:  -0.2743949649727877\n",
      "train loss:  2.5416574478149414\n",
      "train r2:  0.8103443127631091\n",
      "test loss:  7.212224006652832\n",
      "test r2:  -0.2744214434397383\n",
      "train loss:  2.5401735305786133\n",
      "train r2:  0.810611434742514\n",
      "test loss:  7.212501525878906\n",
      "test r2:  -0.27444088790010435\n",
      "train loss:  2.5386898517608643\n",
      "train r2:  0.8108836522751419\n",
      "test loss:  7.212794303894043\n",
      "test r2:  -0.27446657983097156\n",
      "train loss:  2.5372061729431152\n",
      "train r2:  0.8111502140033388\n",
      "test loss:  7.21307373046875\n",
      "test r2:  -0.27448665704634245\n",
      "train loss:  2.5357227325439453\n",
      "train r2:  0.8114204021721476\n",
      "test loss:  7.213363170623779\n",
      "test r2:  -0.2745111112035863\n",
      "train loss:  2.5342392921447754\n",
      "train r2:  0.8116867253566012\n",
      "test loss:  7.213647365570068\n",
      "test r2:  -0.27453288623727334\n",
      "train loss:  2.5327558517456055\n",
      "train r2:  0.8119546046805458\n",
      "test loss:  7.2139363288879395\n",
      "test r2:  -0.2745562576390699\n",
      "train loss:  2.5312724113464355\n",
      "train r2:  0.8122205670419667\n",
      "test loss:  7.214223861694336\n",
      "test r2:  -0.274579005121689\n",
      "train loss:  2.529789686203003\n",
      "train r2:  0.8124863795721601\n",
      "test loss:  7.214509963989258\n",
      "test r2:  -0.27460122354840544\n",
      "train loss:  2.528306484222412\n",
      "train r2:  0.8127519355272915\n",
      "test loss:  7.21480131149292\n",
      "test r2:  -0.2746253995307075\n",
      "train loss:  2.5268235206604004\n",
      "train r2:  0.8130157511053329\n",
      "test loss:  7.215087413787842\n",
      "test r2:  -0.2746468488513103\n",
      "train loss:  2.5253407955169678\n",
      "train r2:  0.8132806749595393\n",
      "test loss:  7.21537971496582\n",
      "test r2:  -0.27467139697472875\n",
      "train loss:  2.523858070373535\n",
      "train r2:  0.8135426969410409\n",
      "test loss:  7.215663433074951\n",
      "test r2:  -0.2746922487033956\n",
      "train loss:  2.5223755836486816\n",
      "train r2:  0.8138070056416088\n",
      "test loss:  7.215959548950195\n",
      "test r2:  -0.27471784446834824\n",
      "train loss:  2.520892858505249\n",
      "train r2:  0.8140670499586643\n",
      "test loss:  7.216242790222168\n",
      "test r2:  -0.27473787846312936\n",
      "train loss:  2.5194108486175537\n",
      "train r2:  0.8143308549510617\n",
      "test loss:  7.216540813446045\n",
      "test r2:  -0.27476449522695523\n",
      "train loss:  2.5179283618927\n",
      "train r2:  0.8145888635031824\n",
      "test loss:  7.216821193695068\n",
      "test r2:  -0.2747829294946196\n",
      "train loss:  2.5164473056793213\n",
      "train r2:  0.814852477837996\n",
      "test loss:  7.217124938964844\n",
      "test r2:  -0.274811891140317\n",
      "train loss:  2.5149660110473633\n",
      "train r2:  0.8151077003910756\n",
      "test loss:  7.2173991203308105\n",
      "test r2:  -0.27482777123129476\n",
      "train loss:  2.5134856700897217\n",
      "train r2:  0.8153720266048273\n",
      "test loss:  7.217711925506592\n",
      "test r2:  -0.2748599868659347\n",
      "train loss:  2.5120065212249756\n",
      "train r2:  0.8156234726319124\n",
      "test loss:  7.217974662780762\n",
      "test r2:  -0.2748713271441603\n",
      "train loss:  2.510530710220337\n",
      "train r2:  0.8158899145527476\n",
      "test loss:  7.218303203582764\n",
      "test r2:  -0.2749098486714461\n",
      "train loss:  2.509058952331543\n",
      "train r2:  0.8161352983959106\n",
      "test loss:  7.2185468673706055\n",
      "test r2:  -0.2749128150925162\n",
      "train loss:  2.507596254348755\n",
      "train r2:  0.8164066540454049\n",
      "test loss:  7.218904495239258\n",
      "test r2:  -0.27496319871567954\n",
      "train loss:  2.5061495304107666\n",
      "train r2:  0.816641679473253\n",
      "test loss:  7.219107151031494\n",
      "test r2:  -0.27494963316900467\n",
      "train loss:  2.5047333240509033\n",
      "train r2:  0.8169234002593437\n",
      "test loss:  7.219520092010498\n",
      "test r2:  -0.2750225986429675\n",
      "train loss:  2.5033695697784424\n",
      "train r2:  0.8171394176947032\n",
      "test loss:  7.219650745391846\n",
      "test r2:  -0.27497873833032727\n",
      "train loss:  2.502091407775879\n",
      "train r2:  0.8174400424971\n",
      "test loss:  7.220158576965332\n",
      "test r2:  -0.27509067256288566\n",
      "train loss:  2.5009124279022217\n",
      "train r2:  0.817624528341857\n",
      "test loss:  7.220183849334717\n",
      "test r2:  -0.27500234092193\n",
      "train loss:  2.4997730255126953\n",
      "train r2:  0.8179529398402222\n",
      "test loss:  7.220791339874268\n",
      "test r2:  -0.2751547098083469\n",
      "train loss:  2.4984307289123535\n",
      "train r2:  0.818112188150776\n",
      "test loss:  7.220779895782471\n",
      "test r2:  -0.2750509026032735\n",
      "train loss:  2.4966366291046143\n",
      "train r2:  0.8184557442064236\n",
      "test loss:  7.221311569213867\n",
      "test r2:  -0.27517075336417496\n",
      "train loss:  2.494551658630371\n",
      "train r2:  0.8186496949496729\n",
      "test loss:  7.2215189933776855\n",
      "test r2:  -0.2751574253976121\n",
      "train loss:  2.4927573204040527\n",
      "train r2:  0.8189290820290729\n",
      "test loss:  7.221746921539307\n",
      "test r2:  -0.2751532600854738\n",
      "train loss:  2.4914956092834473\n",
      "train r2:  0.8191938127620111\n",
      "test loss:  7.222225666046143\n",
      "test r2:  -0.2752529606627201\n",
      "train loss:  2.490367889404297\n",
      "train r2:  0.8193860145833352\n",
      "test loss:  7.222288608551025\n",
      "test r2:  -0.2751812344206812\n",
      "train loss:  2.4888718128204346\n",
      "train r2:  0.8196972622514103\n",
      "test loss:  7.2227678298950195\n",
      "test r2:  -0.27528131477464024\n",
      "train loss:  2.487041711807251\n",
      "train r2:  0.8198988787107557\n",
      "test loss:  7.222995281219482\n",
      "test r2:  -0.2752777243729472\n",
      "train loss:  2.485377550125122\n",
      "train r2:  0.820165412182828\n",
      "test loss:  7.223213195800781\n",
      "test r2:  -0.27527142206460753\n",
      "train loss:  2.4840776920318604\n",
      "train r2:  0.820427402951475\n",
      "test loss:  7.22366189956665\n",
      "test r2:  -0.2753607442644588\n",
      "train loss:  2.482790231704712\n",
      "train r2:  0.8206264411878956\n",
      "test loss:  7.223775863647461\n",
      "test r2:  -0.27531134764046294\n",
      "train loss:  2.4812066555023193\n",
      "train r2:  0.8209192924907663\n",
      "test loss:  7.224180221557617\n",
      "test r2:  -0.2753816858916245\n",
      "train loss:  2.479513168334961\n",
      "train r2:  0.8211361822562725\n",
      "test loss:  7.224465847015381\n",
      "test r2:  -0.2754040590825435\n",
      "train loss:  2.4780356884002686\n",
      "train r2:  0.8213797283740307\n",
      "test loss:  7.2246503829956055\n",
      "test r2:  -0.2753852824214573\n",
      "train loss:  2.4767160415649414\n",
      "train r2:  0.8216464482729954\n",
      "test loss:  7.225080490112305\n",
      "test r2:  -0.27546752303152156\n",
      "train loss:  2.475268840789795\n",
      "train r2:  0.8218502089976619\n",
      "test loss:  7.225250720977783\n",
      "test r2:  -0.2754419593573756\n",
      "train loss:  2.4736578464508057\n",
      "train r2:  0.822124687422503\n",
      "test loss:  7.225584030151367\n",
      "test r2:  -0.27548339115706066\n",
      "train loss:  2.47210693359375\n",
      "train r2:  0.8223554711659061\n",
      "test loss:  7.225918292999268\n",
      "test r2:  -0.27552616020203846\n",
      "train loss:  2.4707095623016357\n",
      "train r2:  0.8225823400475887\n",
      "test loss:  7.226099014282227\n",
      "test r2:  -0.27550476955345804\n",
      "train loss:  2.469306707382202\n",
      "train r2:  0.8228490199814833\n",
      "test loss:  7.226498126983643\n",
      "test r2:  -0.27557372208312025\n",
      "train loss:  2.467780351638794\n",
      "train r2:  0.8230600261564702\n",
      "test loss:  7.2267255783081055\n",
      "test r2:  -0.2755707451835867\n",
      "train loss:  2.4662225246429443\n",
      "train r2:  0.823316551627358\n",
      "test loss:  7.227014064788818\n",
      "test r2:  -0.27559249996491886\n",
      "train loss:  2.4647579193115234\n",
      "train r2:  0.8235556651874443\n",
      "test loss:  7.227373123168945\n",
      "test r2:  -0.27564374079030096\n",
      "train loss:  2.463348150253296\n",
      "train r2:  0.8237747150807092\n",
      "test loss:  7.227573871612549\n",
      "test r2:  -0.2756285531053779\n",
      "train loss:  2.461881637573242\n",
      "train r2:  0.8240353913879761\n",
      "test loss:  7.227941989898682\n",
      "test r2:  -0.2756829881990144\n",
      "train loss:  2.460353136062622\n",
      "train r2:  0.8242527188736571\n",
      "test loss:  7.228212356567383\n",
      "test r2:  -0.2756956332466691\n",
      "train loss:  2.4588499069213867\n",
      "train r2:  0.8244954689108426\n",
      "test loss:  7.228484630584717\n",
      "test r2:  -0.2757085724573196\n",
      "train loss:  2.4574058055877686\n",
      "train r2:  0.8247367810352293\n",
      "test loss:  7.228847980499268\n",
      "test r2:  -0.2757597264277909\n",
      "train loss:  2.455965518951416\n",
      "train r2:  0.824953472260808\n",
      "test loss:  7.2290730476379395\n",
      "test r2:  -0.2757529048538254\n",
      "train loss:  2.454479217529297\n",
      "train r2:  0.8252058898055015\n",
      "test loss:  7.229421615600586\n",
      "test r2:  -0.27579692374027376\n",
      "train loss:  2.4529716968536377\n",
      "train r2:  0.8254264012665318\n",
      "test loss:  7.229714870452881\n",
      "test r2:  -0.2758176489203974\n",
      "train loss:  2.45149302482605\n",
      "train r2:  0.8256607434216998\n",
      "test loss:  7.229988098144531\n",
      "test r2:  -0.2758291693601962\n",
      "train loss:  2.4500436782836914\n",
      "train r2:  0.8258997371256396\n",
      "test loss:  7.230346202850342\n",
      "test r2:  -0.2758760718477087\n",
      "train loss:  2.448587417602539\n",
      "train r2:  0.8261161203898055\n",
      "test loss:  7.230591297149658\n",
      "test r2:  -0.2758762730604247\n",
      "train loss:  2.447103500366211\n",
      "train r2:  0.82636089011107\n",
      "test loss:  7.230930805206299\n",
      "test r2:  -0.2759151259168908\n",
      "train loss:  2.4456119537353516\n",
      "train r2:  0.826581565534884\n",
      "test loss:  7.231231689453125\n",
      "test r2:  -0.27593777210906123\n",
      "train loss:  2.444138526916504\n",
      "train r2:  0.8268115265754752\n",
      "test loss:  7.231512546539307\n",
      "test r2:  -0.2759519365912746\n",
      "train loss:  2.4426817893981934\n",
      "train r2:  0.8270460040675566\n",
      "test loss:  7.231860637664795\n",
      "test r2:  -0.2759941293125663\n",
      "train loss:  2.441220760345459\n",
      "train r2:  0.8272624407879641\n",
      "test loss:  7.232119560241699\n",
      "test r2:  -0.27599911869974014\n",
      "train loss:  2.439743995666504\n",
      "train r2:  0.8275010667472722\n",
      "test loss:  7.232454299926758\n",
      "test r2:  -0.2760359577659266\n",
      "train loss:  2.4382617473602295\n",
      "train r2:  0.8277198679660325\n",
      "test loss:  7.232752799987793\n",
      "test r2:  -0.27605736445991025\n",
      "train loss:  2.436788320541382\n",
      "train r2:  0.8279476073331766\n",
      "test loss:  7.23304557800293\n",
      "test r2:  -0.2760758837759951\n",
      "train loss:  2.435325860977173\n",
      "train r2:  0.8281764111535643\n",
      "test loss:  7.2333784103393555\n",
      "test r2:  -0.2761128016764387\n",
      "train loss:  2.433863639831543\n",
      "train r2:  0.8283930700135663\n",
      "test loss:  7.233645915985107\n",
      "test r2:  -0.2761216167391729\n",
      "train loss:  2.43239426612854\n",
      "train r2:  0.828626195201853\n",
      "test loss:  7.233980178833008\n",
      "test r2:  -0.27615822745022744\n",
      "train loss:  2.430917978286743\n",
      "train r2:  0.8288422642310296\n",
      "test loss:  7.23427152633667\n",
      "test r2:  -0.2761768009610239\n",
      "train loss:  2.4294445514678955\n",
      "train r2:  0.8290685760200057\n",
      "test loss:  7.234572887420654\n",
      "test r2:  -0.2762001409438153\n",
      "train loss:  2.4279773235321045\n",
      "train r2:  0.8292913385637517\n",
      "test loss:  7.23489236831665\n",
      "test r2:  -0.2762315740486021\n",
      "train loss:  2.426514148712158\n",
      "train r2:  0.8295082947508745\n",
      "test loss:  7.23516845703125\n",
      "test r2:  -0.2762444053286206\n",
      "train loss:  2.425048828125\n",
      "train r2:  0.8297357787601809\n",
      "test loss:  7.235496997833252\n",
      "test r2:  -0.27627993290326747\n",
      "train loss:  2.423579454421997\n",
      "train r2:  0.829949231424777\n",
      "test loss:  7.235781669616699\n",
      "test r2:  -0.2762962639409443\n",
      "train loss:  2.4221079349517822\n",
      "train r2:  0.8301738408503883\n",
      "test loss:  7.236093044281006\n",
      "test r2:  -0.27632433459772776\n",
      "train loss:  2.4206383228302\n",
      "train r2:  0.8303905107242266\n",
      "test loss:  7.236396789550781\n",
      "test r2:  -0.27634958328713033\n",
      "train loss:  2.4191722869873047\n",
      "train r2:  0.830608063709991\n",
      "test loss:  7.236684799194336\n",
      "test r2:  -0.276367908399354\n",
      "train loss:  2.417708396911621\n",
      "train r2:  0.8308290743953703\n",
      "test loss:  7.237005710601807\n",
      "test r2:  -0.2764005678735255\n",
      "train loss:  2.416243314743042\n",
      "train r2:  0.831041203907451\n",
      "test loss:  7.237287521362305\n",
      "test r2:  -0.27641627814621406\n",
      "train loss:  2.41477632522583\n",
      "train r2:  0.8312627276850695\n",
      "test loss:  7.237606525421143\n",
      "test r2:  -0.27644778310917406\n",
      "train loss:  2.413308620452881\n",
      "train r2:  0.8314743736889846\n",
      "test loss:  7.237897872924805\n",
      "test r2:  -0.27646771356461053\n",
      "train loss:  2.4118406772613525\n",
      "train r2:  0.8316920525722755\n",
      "test loss:  7.2382001876831055\n",
      "test r2:  -0.27649226040996777\n",
      "train loss:  2.410374641418457\n",
      "train r2:  0.8319063381575672\n",
      "test loss:  7.238509654998779\n",
      "test r2:  -0.2765196349166321\n",
      "train loss:  2.4089107513427734\n",
      "train r2:  0.8321185551138072\n",
      "test loss:  7.238799571990967\n",
      "test r2:  -0.2765387626021498\n",
      "train loss:  2.407447099685669\n",
      "train r2:  0.8323349299914512\n",
      "test loss:  7.2391157150268555\n",
      "test r2:  -0.2765692855266224\n",
      "train loss:  2.405982255935669\n",
      "train r2:  0.8325439239512709\n",
      "test loss:  7.239404201507568\n",
      "test r2:  -0.2765875412220975\n",
      "train loss:  2.4045169353485107\n",
      "train r2:  0.8327596685229849\n",
      "test loss:  7.239717483520508\n",
      "test r2:  -0.2766166494106228\n",
      "train loss:  2.4030516147613525\n",
      "train r2:  0.8329682910893474\n",
      "test loss:  7.240014553070068\n",
      "test r2:  -0.27663821322421045\n",
      "train loss:  2.4015865325927734\n",
      "train r2:  0.8331808326830947\n",
      "test loss:  7.240318775177002\n",
      "test r2:  -0.2766631294292621\n",
      "train loss:  2.4001221656799316\n",
      "train r2:  0.8333907802679003\n",
      "test loss:  7.240627765655518\n",
      "test r2:  -0.2766894795084083\n",
      "train loss:  2.3986589908599854\n",
      "train r2:  0.8335994202334265\n",
      "test loss:  7.240922927856445\n",
      "test r2:  -0.27671044221948793\n",
      "train loss:  2.3971962928771973\n",
      "train r2:  0.8338103405023555\n",
      "test loss:  7.241238117218018\n",
      "test r2:  -0.27673910506102484\n",
      "train loss:  2.395733118057251\n",
      "train r2:  0.8340162350481605\n",
      "test loss:  7.241531848907471\n",
      "test r2:  -0.2767590675171483\n",
      "train loss:  2.3942699432373047\n",
      "train r2:  0.8342266962343148\n",
      "test loss:  7.241847515106201\n",
      "test r2:  -0.2767878382196791\n",
      "train loss:  2.3928070068359375\n",
      "train r2:  0.8344313711805883\n",
      "test loss:  7.2421464920043945\n",
      "test r2:  -0.27680918201420734\n",
      "train loss:  2.3913440704345703\n",
      "train r2:  0.8346398447607386\n",
      "test loss:  7.242457866668701\n",
      "test r2:  -0.27683568250313595\n",
      "train loss:  2.3898813724517822\n",
      "train r2:  0.8348445332819392\n",
      "test loss:  7.242763996124268\n",
      "test r2:  -0.27685968663126315\n",
      "train loss:  2.3884191513061523\n",
      "train r2:  0.8350502477698565\n",
      "test loss:  7.243069171905518\n",
      "test r2:  -0.27688357135078534\n",
      "train loss:  2.3869574069976807\n",
      "train r2:  0.8352553049093376\n",
      "test loss:  7.243381977081299\n",
      "test r2:  -0.27691023413300786\n",
      "train loss:  2.3854963779449463\n",
      "train r2:  0.8354583060782422\n",
      "test loss:  7.2436842918396\n",
      "test r2:  -0.2769323307383691\n",
      "train loss:  2.384035348892212\n",
      "train r2:  0.8356631738274624\n",
      "test loss:  7.24399995803833\n",
      "test r2:  -0.2769600349971191\n",
      "train loss:  2.3825743198394775\n",
      "train r2:  0.835864255821339\n",
      "test loss:  7.244300842285156\n",
      "test r2:  -0.27698138139692596\n",
      "train loss:  2.3811135292053223\n",
      "train r2:  0.8360683507523536\n",
      "test loss:  7.244616985321045\n",
      "test r2:  -0.2770092341565591\n",
      "train loss:  2.379652976989746\n",
      "train r2:  0.8362681180186032\n",
      "test loss:  7.244922161102295\n",
      "test r2:  -0.27703157132827183\n",
      "train loss:  2.378192663192749\n",
      "train r2:  0.8364706114490066\n",
      "test loss:  7.245238780975342\n",
      "test r2:  -0.2770586810222886\n",
      "train loss:  2.376732110977173\n",
      "train r2:  0.8366696542836314\n",
      "test loss:  7.245544910430908\n",
      "test r2:  -0.27708163458818413\n",
      "train loss:  2.375272512435913\n",
      "train r2:  0.8368703785497348\n",
      "test loss:  7.2458577156066895\n",
      "test r2:  -0.27710735690577604\n",
      "train loss:  2.373812675476074\n",
      "train r2:  0.8370689324835983\n",
      "test loss:  7.246169567108154\n",
      "test r2:  -0.2771318694851648\n",
      "train loss:  2.3723535537719727\n",
      "train r2:  0.8372676103788375\n",
      "test loss:  7.246481418609619\n",
      "test r2:  -0.2771566823638818\n",
      "train loss:  2.37089467048645\n",
      "train r2:  0.8374655965562782\n",
      "test loss:  7.246796131134033\n",
      "test r2:  -0.27718242021073713\n",
      "train loss:  2.3694357872009277\n",
      "train r2:  0.8376624731810461\n",
      "test loss:  7.247106552124023\n",
      "test r2:  -0.27720617843906514\n",
      "train loss:  2.3679773807525635\n",
      "train r2:  0.8378598005456993\n",
      "test loss:  7.247421741485596\n",
      "test r2:  -0.2772324285344985\n",
      "train loss:  2.3665192127227783\n",
      "train r2:  0.8380550451934106\n",
      "test loss:  7.247732639312744\n",
      "test r2:  -0.27725561764052364\n",
      "train loss:  2.3650612831115723\n",
      "train r2:  0.8382514609797901\n",
      "test loss:  7.248053073883057\n",
      "test r2:  -0.2772831652220755\n",
      "train loss:  2.3636038303375244\n",
      "train r2:  0.8384450485588324\n",
      "test loss:  7.2483625411987305\n",
      "test r2:  -0.2773055867171548\n",
      "train loss:  2.3621463775634766\n",
      "train r2:  0.8386405873531597\n",
      "test loss:  7.248682975769043\n",
      "test r2:  -0.27733308091916853\n",
      "train loss:  2.360689163208008\n",
      "train r2:  0.8388328310132597\n",
      "test loss:  7.248992443084717\n",
      "test r2:  -0.2773550373392373\n",
      "train loss:  2.359232187271118\n",
      "train r2:  0.8390273742484972\n",
      "test loss:  7.24931526184082\n",
      "test r2:  -0.2773834878833348\n",
      "train loss:  2.357775926589966\n",
      "train r2:  0.8392181120201876\n",
      "test loss:  7.249626159667969\n",
      "test r2:  -0.27740566207766304\n",
      "train loss:  2.3563196659088135\n",
      "train r2:  0.8394115483829752\n",
      "test loss:  7.249950885772705\n",
      "test r2:  -0.2774341850083628\n",
      "train loss:  2.3548636436462402\n",
      "train r2:  0.8396008484195697\n",
      "test loss:  7.250259876251221\n",
      "test r2:  -0.27745523919503623\n",
      "train loss:  2.3534083366394043\n",
      "train r2:  0.8397934895405715\n",
      "test loss:  7.250587463378906\n",
      "test r2:  -0.2774846342919215\n",
      "train loss:  2.3519530296325684\n",
      "train r2:  0.8399811346422178\n",
      "test loss:  7.25089693069458\n",
      "test r2:  -0.27750530445806354\n",
      "train loss:  2.3504979610443115\n",
      "train r2:  0.8401730152479479\n",
      "test loss:  7.251229763031006\n",
      "test r2:  -0.27753615667173404\n",
      "train loss:  2.349043846130371\n",
      "train r2:  0.8403586544083751\n",
      "test loss:  7.251534938812256\n",
      "test r2:  -0.2775548601474296\n",
      "train loss:  2.3475899696350098\n",
      "train r2:  0.8405503406551652\n",
      "test loss:  7.251871109008789\n",
      "test r2:  -0.2775874478617404\n",
      "train loss:  2.346137046813965\n",
      "train r2:  0.8407336345423397\n",
      "test loss:  7.252172946929932\n",
      "test r2:  -0.2776034793947808\n",
      "train loss:  2.3446853160858154\n",
      "train r2:  0.840925602210121\n",
      "test loss:  7.252521991729736\n",
      "test r2:  -0.2776408007037807\n",
      "train loss:  2.343235969543457\n",
      "train r2:  0.8411053954877256\n",
      "test loss:  7.252811908721924\n",
      "test r2:  -0.2776515813591396\n",
      "train loss:  2.3417890071868896\n",
      "train r2:  0.8412989300882476\n",
      "test loss:  7.253175258636475\n",
      "test r2:  -0.2776952526825722\n",
      "train loss:  2.3403475284576416\n",
      "train r2:  0.8414738629477695\n",
      "test loss:  7.253448009490967\n",
      "test r2:  -0.27769695877961187\n",
      "train loss:  2.338913917541504\n",
      "train r2:  0.8416708171655686\n",
      "test loss:  7.253839015960693\n",
      "test r2:  -0.2777527731757672\n",
      "train loss:  2.3374953269958496\n",
      "train r2:  0.8418378439641668\n",
      "test loss:  7.254079818725586\n",
      "test r2:  -0.2777391550442463\n",
      "train loss:  2.33609938621521\n",
      "train r2:  0.8420413618252758\n",
      "test loss:  7.254517078399658\n",
      "test r2:  -0.2778159161716196\n",
      "train loss:  2.3347434997558594\n",
      "train r2:  0.8421954175980948\n",
      "test loss:  7.254699230194092\n",
      "test r2:  -0.2777750069064475\n",
      "train loss:  2.333439350128174\n",
      "train r2:  0.8424105624082058\n",
      "test loss:  7.255209445953369\n",
      "test r2:  -0.27788422765526444\n",
      "train loss:  2.3322088718414307\n",
      "train r2:  0.8425448437276044\n",
      "test loss:  7.255314826965332\n",
      "test r2:  -0.27780717297115487\n",
      "train loss:  2.3309977054595947\n",
      "train r2:  0.8427762072447897\n",
      "test loss:  7.255904674530029\n",
      "test r2:  -0.27795164498351643\n",
      "train loss:  2.329739570617676\n",
      "train r2:  0.8428923559243044\n",
      "test loss:  7.255965709686279\n",
      "test r2:  -0.2778529798488736\n",
      "train loss:  2.3281986713409424\n",
      "train r2:  0.8431368050522726\n",
      "test loss:  7.256542682647705\n",
      "test r2:  -0.2779899111238562\n",
      "train loss:  2.326397657394409\n",
      "train r2:  0.8432647253929924\n",
      "test loss:  7.256714344024658\n",
      "test r2:  -0.27794134526013936\n",
      "train loss:  2.324518918991089\n",
      "train r2:  0.8434863533156239\n",
      "test loss:  7.257101535797119\n",
      "test r2:  -0.2779911672163571\n",
      "train loss:  2.3229148387908936\n",
      "train r2:  0.8436543971246829\n",
      "test loss:  7.2574968338012695\n",
      "test r2:  -0.27804591921182875\n",
      "train loss:  2.3216376304626465\n",
      "train r2:  0.8438148085588844\n",
      "test loss:  7.2576799392700195\n",
      "test r2:  -0.27800310684385265\n",
      "train loss:  2.3204360008239746\n",
      "train r2:  0.8440216473181842\n",
      "test loss:  7.258195877075195\n",
      "test r2:  -0.27811371178213395\n",
      "train loss:  2.3190391063690186\n",
      "train r2:  0.8441546540967944\n",
      "test loss:  7.258362293243408\n",
      "test r2:  -0.27806257014167657\n",
      "train loss:  2.317380905151367\n",
      "train r2:  0.844370291241409\n",
      "test loss:  7.258796691894531\n",
      "test r2:  -0.2781346357499346\n",
      "train loss:  2.315718173980713\n",
      "train r2:  0.8445254916696664\n",
      "test loss:  7.259126663208008\n",
      "test r2:  -0.27815891521423275\n",
      "train loss:  2.314265727996826\n",
      "train r2:  0.8447001085667942\n",
      "test loss:  7.259373664855957\n",
      "test r2:  -0.2781457087699917\n",
      "train loss:  2.312971830368042\n",
      "train r2:  0.8448898107505672\n",
      "test loss:  7.259834289550781\n",
      "test r2:  -0.27823160024387605\n",
      "train loss:  2.311622142791748\n",
      "train r2:  0.8450315884029483\n",
      "test loss:  7.260036945343018\n",
      "test r2:  -0.278195654739112\n",
      "train loss:  2.3100943565368652\n",
      "train r2:  0.8452345455197225\n",
      "test loss:  7.260464191436768\n",
      "test r2:  -0.27826449362373373\n",
      "train loss:  2.3085074424743652\n",
      "train r2:  0.8453874671507812\n",
      "test loss:  7.260777473449707\n",
      "test r2:  -0.2782804491530948\n",
      "train loss:  2.307025671005249\n",
      "train r2:  0.8455633003648603\n",
      "test loss:  7.26106071472168\n",
      "test r2:  -0.27828185741680866\n",
      "train loss:  2.305662155151367\n",
      "train r2:  0.8457437722901954\n",
      "test loss:  7.261491775512695\n",
      "test r2:  -0.2783521005384324\n",
      "train loss:  2.3042922019958496\n",
      "train r2:  0.8458910861289793\n",
      "test loss:  7.2617292404174805\n",
      "test r2:  -0.2783298680407533\n",
      "train loss:  2.3028180599212646\n",
      "train r2:  0.8460836511879096\n",
      "test loss:  7.262146472930908\n",
      "test r2:  -0.2783921112077681\n",
      "train loss:  2.3012900352478027\n",
      "train r2:  0.8462362091325183\n",
      "test loss:  7.262462139129639\n",
      "test r2:  -0.2784055073621743\n",
      "train loss:  2.2998099327087402\n",
      "train r2:  0.846410433108949\n",
      "test loss:  7.26277494430542\n",
      "test r2:  -0.2784173189910186\n",
      "train loss:  2.2984073162078857\n",
      "train r2:  0.8465838323130683\n",
      "test loss:  7.263189792633057\n",
      "test r2:  -0.278475867975311\n",
      "train loss:  2.2970163822174072\n",
      "train r2:  0.8467347132849525\n",
      "test loss:  7.263458728790283\n",
      "test r2:  -0.2784644935703928\n",
      "train loss:  2.2955706119537354\n",
      "train r2:  0.8469188062587264\n",
      "test loss:  7.263874530792236\n",
      "test r2:  -0.2785215473459406\n",
      "train loss:  2.294081211090088\n",
      "train r2:  0.8470706033222464\n",
      "test loss:  7.264194011688232\n",
      "test r2:  -0.27853294160177144\n",
      "train loss:  2.2926065921783447\n",
      "train r2:  0.8472429733096006\n",
      "test loss:  7.264538764953613\n",
      "test r2:  -0.278554366643307\n",
      "train loss:  2.2911791801452637\n",
      "train r2:  0.8474096760708256\n",
      "test loss:  7.264941692352295\n",
      "test r2:  -0.2786026347023727\n",
      "train loss:  2.289771795272827\n",
      "train r2:  0.8475630946171595\n",
      "test loss:  7.26524019241333\n",
      "test r2:  -0.2786003177043561\n",
      "train loss:  2.288342237472534\n",
      "train r2:  0.8477396877608263\n",
      "test loss:  7.26565408706665\n",
      "test r2:  -0.278652939458508\n",
      "train loss:  2.2868809700012207\n",
      "train r2:  0.8478903157358376\n",
      "test loss:  7.265983581542969\n",
      "test r2:  -0.27866319093507363\n",
      "train loss:  2.285414934158325\n",
      "train r2:  0.8480604695269363\n",
      "test loss:  7.266355991363525\n",
      "test r2:  -0.2786932727358946\n",
      "train loss:  2.2839715480804443\n",
      "train r2:  0.84822062669599\n",
      "test loss:  7.266745090484619\n",
      "test r2:  -0.27873099125157696\n",
      "train loss:  2.2825496196746826\n",
      "train r2:  0.8483762273224855\n",
      "test loss:  7.267070293426514\n",
      "test r2:  -0.27873733422848024\n",
      "train loss:  2.2811264991760254\n",
      "train r2:  0.8485455099711907\n",
      "test loss:  7.267486095428467\n",
      "test r2:  -0.2787862326625714\n",
      "train loss:  2.2796852588653564\n",
      "train r2:  0.8486950311974967\n",
      "test loss:  7.267822742462158\n",
      "test r2:  -0.27879598294251173\n",
      "train loss:  2.2782323360443115\n",
      "train r2:  0.8488623891052696\n",
      "test loss:  7.268215656280518\n",
      "test r2:  -0.2788324135329565\n",
      "train loss:  2.2767832279205322\n",
      "train r2:  0.8490166419652343\n",
      "test loss:  7.268591403961182\n",
      "test r2:  -0.2788600913006105\n",
      "train loss:  2.2753472328186035\n",
      "train r2:  0.8491740554820818\n",
      "test loss:  7.268944263458252\n",
      "test r2:  -0.2788765619828617\n",
      "train loss:  2.2739205360412598\n",
      "train r2:  0.8493358470083101\n",
      "test loss:  7.269355773925781\n",
      "test r2:  -0.2789198487204667\n",
      "train loss:  2.272491216659546\n",
      "train r2:  0.8494851153090524\n",
      "test loss:  7.269701957702637\n",
      "test r2:  -0.27893087160939145\n",
      "train loss:  2.271052360534668\n",
      "train r2:  0.8496486318979183\n",
      "test loss:  7.270106315612793\n",
      "test r2:  -0.2789706446125917\n",
      "train loss:  2.2696077823638916\n",
      "train r2:  0.8497983020416632\n",
      "test loss:  7.270472526550293\n",
      "test r2:  -0.2789905715287817\n",
      "train loss:  2.2681655883789062\n",
      "train r2:  0.84995648109987\n",
      "test loss:  7.270854473114014\n",
      "test r2:  -0.2790177395834983\n",
      "train loss:  2.266730546951294\n",
      "train r2:  0.8501107956038063\n",
      "test loss:  7.271255016326904\n",
      "test r2:  -0.27905234091194564\n",
      "train loss:  2.265300750732422\n",
      "train r2:  0.8502612323283048\n",
      "test loss:  7.271615505218506\n",
      "test r2:  -0.27906809166476587\n",
      "train loss:  2.2638704776763916\n",
      "train r2:  0.850419350252603\n",
      "test loss:  7.272024631500244\n",
      "test r2:  -0.2791073252073344\n",
      "train loss:  2.2624356746673584\n",
      "train r2:  0.8505664519992102\n",
      "test loss:  7.272392272949219\n",
      "test r2:  -0.27912385193994393\n",
      "train loss:  2.2609972953796387\n",
      "train r2:  0.8507233058427155\n",
      "test loss:  7.272797107696533\n",
      "test r2:  -0.27915911384990233\n",
      "train loss:  2.259558916091919\n",
      "train r2:  0.8508714041098868\n",
      "test loss:  7.2731828689575195\n",
      "test r2:  -0.279183818724253\n",
      "train loss:  2.2581238746643066\n",
      "train r2:  0.8510233176942552\n",
      "test loss:  7.273568630218506\n",
      "test r2:  -0.2792081653195362\n",
      "train loss:  2.2566921710968018\n",
      "train r2:  0.851174747504236\n",
      "test loss:  7.2739763259887695\n",
      "test r2:  -0.27924213865293757\n",
      "train loss:  2.2552614212036133\n",
      "train r2:  0.8513215432132653\n",
      "test loss:  7.274356365203857\n",
      "test r2:  -0.27926149709404835\n",
      "train loss:  2.2538301944732666\n",
      "train r2:  0.8514743367683264\n",
      "test loss:  7.274772644042969\n",
      "test r2:  -0.2792979670299358\n",
      "train loss:  2.252396821975708\n",
      "train r2:  0.851618893095899\n",
      "test loss:  7.2751569747924805\n",
      "test r2:  -0.2793174600771102\n",
      "train loss:  2.250962257385254\n",
      "train r2:  0.851770329336355\n",
      "test loss:  7.275570869445801\n",
      "test r2:  -0.2793502429128645\n",
      "train loss:  2.249527931213379\n",
      "train r2:  0.8519154280619552\n",
      "test loss:  7.275973320007324\n",
      "test r2:  -0.2793762653167746\n",
      "train loss:  2.2480955123901367\n",
      "train r2:  0.8520629990539057\n",
      "test loss:  7.276379108428955\n",
      "test r2:  -0.2794027697750665\n",
      "train loss:  2.246664047241211\n",
      "train r2:  0.8522097646798774\n",
      "test loss:  7.276794910430908\n",
      "test r2:  -0.27943424613731027\n",
      "train loss:  2.2452337741851807\n",
      "train r2:  0.8523537125135435\n",
      "test loss:  7.277198314666748\n",
      "test r2:  -0.2794565357299168\n",
      "train loss:  2.2438039779663086\n",
      "train r2:  0.8525011945046872\n",
      "test loss:  7.2776265144348145\n",
      "test r2:  -0.2794909723564163\n",
      "train loss:  2.24237322807312\n",
      "train r2:  0.8526428002216752\n",
      "test loss:  7.27803373336792\n",
      "test r2:  -0.27951291981776727\n",
      "train loss:  2.2409417629241943\n",
      "train r2:  0.8527893398221243\n",
      "test loss:  7.2784647941589355\n",
      "test r2:  -0.2795457731762847\n",
      "train loss:  2.2395102977752686\n",
      "train r2:  0.852930543546081\n",
      "test loss:  7.278883457183838\n",
      "test r2:  -0.27957077125098917\n",
      "train loss:  2.2380788326263428\n",
      "train r2:  0.8530746226970145\n",
      "test loss:  7.279313564300537\n",
      "test r2:  -0.27959994862686743\n",
      "train loss:  2.2366487979888916\n",
      "train r2:  0.8532162996183578\n",
      "test loss:  7.279747009277344\n",
      "test r2:  -0.279629305766973\n",
      "train loss:  2.2352187633514404\n",
      "train r2:  0.853357491963656\n",
      "test loss:  7.280177116394043\n",
      "test r2:  -0.27965550013975604\n",
      "train loss:  2.2337899208068848\n",
      "train r2:  0.8534994224086402\n",
      "test loss:  7.28062105178833\n",
      "test r2:  -0.27968718214287036\n",
      "train loss:  2.232360601425171\n",
      "train r2:  0.8536383490131775\n",
      "test loss:  7.281052112579346\n",
      "test r2:  -0.2797111391424898\n",
      "train loss:  2.230931282043457\n",
      "train r2:  0.8537800616950685\n",
      "test loss:  7.28150749206543\n",
      "test r2:  -0.2797445174605595\n",
      "train loss:  2.2295026779174805\n",
      "train r2:  0.8539173457626854\n",
      "test loss:  7.281949996948242\n",
      "test r2:  -0.2797694306998537\n",
      "train loss:  2.2280731201171875\n",
      "train r2:  0.8540576978459753\n",
      "test loss:  7.282407760620117\n",
      "test r2:  -0.2798014681145904\n",
      "train loss:  2.2266440391540527\n",
      "train r2:  0.8541943949034853\n",
      "test loss:  7.28285551071167\n",
      "test r2:  -0.2798270528480722\n",
      "train loss:  2.225215196609497\n",
      "train r2:  0.8543331169918188\n",
      "test loss:  7.283318996429443\n",
      "test r2:  -0.2798579622713677\n",
      "train loss:  2.2237868309020996\n",
      "train r2:  0.854469378905742\n",
      "test loss:  7.283783435821533\n",
      "test r2:  -0.27988712430231866\n",
      "train loss:  2.222358465194702\n",
      "train r2:  0.8546058166340961\n",
      "test loss:  7.284248352050781\n",
      "test r2:  -0.27991513785598165\n",
      "train loss:  2.220930576324463\n",
      "train r2:  0.8547420032947957\n",
      "test loss:  7.284721374511719\n",
      "test r2:  -0.2799455865341087\n",
      "train loss:  2.2195024490356445\n",
      "train r2:  0.8548766933796109\n",
      "test loss:  7.285192966461182\n",
      "test r2:  -0.27997266713584734\n",
      "train loss:  2.2180750370025635\n",
      "train r2:  0.8550122671009213\n",
      "test loss:  7.285679817199707\n",
      "test r2:  -0.280005139324893\n",
      "train loss:  2.2166473865509033\n",
      "train r2:  0.8551451721623993\n",
      "test loss:  7.286157131195068\n",
      "test r2:  -0.2800315846605641\n",
      "train loss:  2.2152202129364014\n",
      "train r2:  0.8552799335665959\n",
      "test loss:  7.286651134490967\n",
      "test r2:  -0.2800636545306825\n",
      "train loss:  2.2137928009033203\n",
      "train r2:  0.8554117855748119\n",
      "test loss:  7.287139415740967\n",
      "test r2:  -0.2800905932962994\n",
      "train loss:  2.21236515045166\n",
      "train r2:  0.8555453272276681\n",
      "test loss:  7.287643909454346\n",
      "test r2:  -0.28012343690959995\n",
      "train loss:  2.210937976837158\n",
      "train r2:  0.8556759971338943\n",
      "test loss:  7.288142204284668\n",
      "test r2:  -0.28015091216599464\n",
      "train loss:  2.209510564804077\n",
      "train r2:  0.8558082205983815\n",
      "test loss:  7.288652420043945\n",
      "test r2:  -0.2801823879752312\n",
      "train loss:  2.208083152770996\n",
      "train r2:  0.8559382223345302\n",
      "test loss:  7.289163589477539\n",
      "test r2:  -0.2802108732768589\n",
      "train loss:  2.206655979156494\n",
      "train r2:  0.8560690137150934\n",
      "test loss:  7.289687633514404\n",
      "test r2:  -0.280242760244946\n",
      "train loss:  2.205228567123413\n",
      "train r2:  0.8561979664100399\n",
      "test loss:  7.290209770202637\n",
      "test r2:  -0.2802721916764568\n",
      "train loss:  2.2038016319274902\n",
      "train r2:  0.8563273110181584\n",
      "test loss:  7.290740489959717\n",
      "test r2:  -0.2803028539259882\n",
      "train loss:  2.202374219894409\n",
      "train r2:  0.8564555586064444\n",
      "test loss:  7.291275501251221\n",
      "test r2:  -0.2803328598665018\n",
      "train loss:  2.200946807861328\n",
      "train r2:  0.8565835784601001\n",
      "test loss:  7.29182243347168\n",
      "test r2:  -0.28036435805819515\n",
      "train loss:  2.199519395828247\n",
      "train r2:  0.8567107062659669\n",
      "test loss:  7.292372226715088\n",
      "test r2:  -0.2803955991916316\n",
      "train loss:  2.198091506958008\n",
      "train r2:  0.8568372811753157\n",
      "test loss:  7.292924880981445\n",
      "test r2:  -0.2804254638899941\n",
      "train loss:  2.1966636180877686\n",
      "train r2:  0.856963764944058\n",
      "test loss:  7.293489456176758\n",
      "test r2:  -0.2804572681118096\n",
      "train loss:  2.1952357292175293\n",
      "train r2:  0.8570890270987926\n",
      "test loss:  7.294060230255127\n",
      "test r2:  -0.2804882164135638\n",
      "train loss:  2.193807363510132\n",
      "train r2:  0.8572142866160177\n",
      "test loss:  7.294641017913818\n",
      "test r2:  -0.28052117125915466\n",
      "train loss:  2.192378520965576\n",
      "train r2:  0.8573381584417024\n",
      "test loss:  7.295222282409668\n",
      "test r2:  -0.28055094086075005\n",
      "train loss:  2.1909494400024414\n",
      "train r2:  0.857462626737768\n",
      "test loss:  7.295817852020264\n",
      "test r2:  -0.28058422291868923\n",
      "train loss:  2.1895198822021484\n",
      "train r2:  0.8575852909884877\n",
      "test loss:  7.296417713165283\n",
      "test r2:  -0.28061487153147135\n",
      "train loss:  2.188089609146118\n",
      "train r2:  0.8577085746793432\n",
      "test loss:  7.297033786773682\n",
      "test r2:  -0.28064960659755633\n",
      "train loss:  2.1866588592529297\n",
      "train r2:  0.8578297427187511\n",
      "test loss:  7.297646999359131\n",
      "test r2:  -0.280679218518348\n",
      "train loss:  2.185227394104004\n",
      "train r2:  0.8579522657849267\n",
      "test loss:  7.298280239105225\n",
      "test r2:  -0.28071471031137674\n",
      "train loss:  2.1837944984436035\n",
      "train r2:  0.8580720354814179\n",
      "test loss:  7.298913478851318\n",
      "test r2:  -0.28074426203630387\n",
      "train loss:  2.182361364364624\n",
      "train r2:  0.8581936592043626\n",
      "test loss:  7.299569606781006\n",
      "test r2:  -0.2807824615454131\n",
      "train loss:  2.180927038192749\n",
      "train r2:  0.8583114862534309\n",
      "test loss:  7.30021333694458\n",
      "test r2:  -0.28080984883269\n",
      "train loss:  2.1794915199279785\n",
      "train r2:  0.8584327482147764\n",
      "test loss:  7.300887584686279\n",
      "test r2:  -0.2808505393527674\n",
      "train loss:  2.1780545711517334\n",
      "train r2:  0.8585486056285289\n",
      "test loss:  7.301544189453125\n",
      "test r2:  -0.2808760821150462\n",
      "train loss:  2.176616907119751\n",
      "train r2:  0.8586695270977898\n",
      "test loss:  7.30224609375\n",
      "test r2:  -0.2809222320211211\n",
      "train loss:  2.1751787662506104\n",
      "train r2:  0.8587823788879311\n",
      "test loss:  7.3029069900512695\n",
      "test r2:  -0.28094188219609206\n",
      "train loss:  2.1737406253814697\n",
      "train r2:  0.8589041007039754\n",
      "test loss:  7.303640842437744\n",
      "test r2:  -0.2809959001461104\n",
      "train loss:  2.172304391860962\n",
      "train r2:  0.8590129896064161\n",
      "test loss:  7.304304122924805\n",
      "test r2:  -0.28100706069287984\n",
      "train loss:  2.170872449874878\n",
      "train r2:  0.8591363744865033\n",
      "test loss:  7.305086135864258\n",
      "test r2:  -0.2810756235162768\n",
      "train loss:  2.1694509983062744\n",
      "train r2:  0.8592388038628228\n",
      "test loss:  7.3057332038879395\n",
      "test r2:  -0.28106884258220055\n",
      "train loss:  2.1680471897125244\n",
      "train r2:  0.8593663564102716\n",
      "test loss:  7.306582927703857\n",
      "test r2:  -0.2811613550645575\n",
      "train loss:  2.166680335998535\n",
      "train r2:  0.8594583559516755\n",
      "test loss:  7.307194709777832\n",
      "test r2:  -0.2811251788328748\n",
      "train loss:  2.165356397628784\n",
      "train r2:  0.859593088531718\n",
      "test loss:  7.308151721954346\n",
      "test r2:  -0.2812583138850542\n",
      "train loss:  2.1641151905059814\n",
      "train r2:  0.8596682176501192\n",
      "test loss:  7.308688163757324\n",
      "test r2:  -0.28117490329186423\n",
      "train loss:  2.1628808975219727\n",
      "train r2:  0.859814682451601\n",
      "test loss:  7.309777736663818\n",
      "test r2:  -0.2813575485393456\n",
      "train loss:  2.1616485118865967\n",
      "train r2:  0.8598719331730654\n",
      "test loss:  7.310250759124756\n",
      "test r2:  -0.28123510352716474\n",
      "train loss:  2.1600873470306396\n",
      "train r2:  0.8600312925210181\n",
      "test loss:  7.311408519744873\n",
      "test r2:  -0.2814279929842869\n",
      "train loss:  2.1582729816436768\n",
      "train r2:  0.8600919022104353\n",
      "test loss:  7.311984062194824\n",
      "test r2:  -0.28134761486581206\n",
      "train loss:  2.156259536743164\n",
      "train r2:  0.8602387883028588\n",
      "test loss:  7.312951564788818\n",
      "test r2:  -0.2814369908917034\n",
      "train loss:  2.154496669769287\n",
      "train r2:  0.8603279216266084\n",
      "test loss:  7.313854694366455\n",
      "test r2:  -0.2814950379215453\n",
      "train loss:  2.1531107425689697\n",
      "train r2:  0.860418959051842\n",
      "test loss:  7.314483165740967\n",
      "test r2:  -0.28142988139348324\n",
      "train loss:  2.1518824100494385\n",
      "train r2:  0.8605434425200289\n",
      "test loss:  7.315664291381836\n",
      "test r2:  -0.28159473244438615\n",
      "train loss:  2.1505212783813477\n",
      "train r2:  0.8606003001491689\n",
      "test loss:  7.316168308258057\n",
      "test r2:  -0.28147749799360944\n",
      "train loss:  2.1488356590270996\n",
      "train r2:  0.8607461399084607\n",
      "test loss:  7.317312717437744\n",
      "test r2:  -0.28161261678114813\n",
      "train loss:  2.147085189819336\n",
      "train r2:  0.8608232318517424\n",
      "test loss:  7.318143844604492\n",
      "test r2:  -0.281623143901111\n",
      "train loss:  2.1454999446868896\n",
      "train r2:  0.8609394159560793\n",
      "test loss:  7.318917751312256\n",
      "test r2:  -0.28160750256180167\n",
      "train loss:  2.144089698791504\n",
      "train r2:  0.8610675966800984\n",
      "test loss:  7.320199489593506\n",
      "test r2:  -0.281784601478255\n",
      "train loss:  2.1426429748535156\n",
      "train r2:  0.8611465046044056\n",
      "test loss:  7.320847034454346\n",
      "test r2:  -0.2817160781477692\n",
      "train loss:  2.1409835815429688\n",
      "train r2:  0.8613034852319363\n",
      "test loss:  7.3221116065979\n",
      "test r2:  -0.2818809179664803\n",
      "train loss:  2.1392340660095215\n",
      "train r2:  0.8613945320876776\n",
      "test loss:  7.323029041290283\n",
      "test r2:  -0.28191352203342057\n",
      "train loss:  2.137579917907715\n",
      "train r2:  0.8615190018572884\n",
      "test loss:  7.323883056640625\n",
      "test r2:  -0.28192203988957076\n",
      "train loss:  2.136061191558838\n",
      "train r2:  0.8616425966085807\n",
      "test loss:  7.325078010559082\n",
      "test r2:  -0.2820602108020158\n",
      "train loss:  2.1345646381378174\n",
      "train r2:  0.8617212925139397\n",
      "test loss:  7.325686931610107\n",
      "test r2:  -0.28197988651367734\n",
      "train loss:  2.132967472076416\n",
      "train r2:  0.8618709865980833\n",
      "test loss:  7.326968193054199\n",
      "test r2:  -0.28214384938166615\n",
      "train loss:  2.131288528442383\n",
      "train r2:  0.8619487997409134\n",
      "test loss:  7.3278045654296875\n",
      "test r2:  -0.282147029918955\n",
      "train loss:  2.1296215057373047\n",
      "train r2:  0.8620779983096782\n",
      "test loss:  7.328752517700195\n",
      "test r2:  -0.2821934893042788\n",
      "train loss:  2.128028154373169\n",
      "train r2:  0.8621910682685089\n",
      "test loss:  7.3298659324646\n",
      "test r2:  -0.2823021564027073\n",
      "train loss:  2.126481533050537\n",
      "train r2:  0.8622819989093898\n",
      "test loss:  7.330542087554932\n",
      "test r2:  -0.28225512656376717\n",
      "train loss:  2.124908924102783\n",
      "train r2:  0.8624191486321869\n",
      "test loss:  7.331769943237305\n",
      "test r2:  -0.2824083282668306\n",
      "train loss:  2.1232759952545166\n",
      "train r2:  0.8624950910196039\n",
      "test loss:  7.332441329956055\n",
      "test r2:  -0.2823678836793231\n",
      "train loss:  2.1216073036193848\n",
      "train r2:  0.86262789155727\n",
      "test loss:  7.33345365524292\n",
      "test r2:  -0.2824523572139148\n",
      "train loss:  2.1199560165405273\n",
      "train r2:  0.8627232114683091\n",
      "test loss:  7.3343706130981445\n",
      "test r2:  -0.2825075123434875\n",
      "train loss:  2.118347406387329\n",
      "train r2:  0.8628270922375951\n",
      "test loss:  7.335107803344727\n",
      "test r2:  -0.28250410558526506\n",
      "train loss:  2.1167638301849365\n",
      "train r2:  0.8629481720002093\n",
      "test loss:  7.3362135887146\n",
      "test r2:  -0.28263546704894105\n",
      "train loss:  2.1151723861694336\n",
      "train r2:  0.8630304496972272\n",
      "test loss:  7.336805820465088\n",
      "test r2:  -0.28259280450496904\n",
      "train loss:  2.113551378250122\n",
      "train r2:  0.8631620037919087\n",
      "test loss:  7.33787202835083\n",
      "test r2:  -0.28272006751303635\n",
      "train loss:  2.111908435821533\n",
      "train r2:  0.8632455951402196\n",
      "test loss:  7.338566780090332\n",
      "test r2:  -0.2827242137320871\n",
      "train loss:  2.1102685928344727\n",
      "train r2:  0.863362250245892\n",
      "test loss:  7.339378833770752\n",
      "test r2:  -0.28277466349901514\n",
      "train loss:  2.1086504459381104\n",
      "train r2:  0.8634648998769321\n",
      "test loss:  7.34025239944458\n",
      "test r2:  -0.28285256391146674\n",
      "train loss:  2.107050895690918\n",
      "train r2:  0.8635593756009522\n",
      "test loss:  7.3408403396606445\n",
      "test r2:  -0.2828379126968399\n",
      "train loss:  2.10545015335083\n",
      "train r2:  0.8636794716653569\n",
      "test loss:  7.341834545135498\n",
      "test r2:  -0.28296831382039467\n",
      "train loss:  2.103835105895996\n",
      "train r2:  0.8637607227160791\n",
      "test loss:  7.342370510101318\n",
      "test r2:  -0.2829483344135746\n",
      "train loss:  2.1022043228149414\n",
      "train r2:  0.8638825124594881\n",
      "test loss:  7.343262195587158\n",
      "test r2:  -0.2830560507532449\n",
      "train loss:  2.1005682945251465\n",
      "train r2:  0.8639693723691413\n",
      "test loss:  7.3438920974731445\n",
      "test r2:  -0.28308060965416026\n",
      "train loss:  2.0989387035369873\n",
      "train r2:  0.8640772538633495\n",
      "test loss:  7.344566345214844\n",
      "test r2:  -0.28312644599692516\n",
      "train loss:  2.097321033477783\n",
      "train r2:  0.8641779845747725\n",
      "test loss:  7.345320224761963\n",
      "test r2:  -0.2832060113954469\n",
      "train loss:  2.0957114696502686\n",
      "train r2:  0.8642685666062297\n",
      "test loss:  7.345798015594482\n",
      "test r2:  -0.2831986245169771\n",
      "train loss:  2.094101905822754\n",
      "train r2:  0.8643814668840722\n",
      "test loss:  7.346612930297852\n",
      "test r2:  -0.283312120294573\n",
      "train loss:  2.0924863815307617\n",
      "train r2:  0.8644622885167668\n",
      "test loss:  7.347036838531494\n",
      "test r2:  -0.2833007669612797\n",
      "train loss:  2.0908632278442383\n",
      "train r2:  0.8645755403058227\n",
      "test loss:  7.347781658172607\n",
      "test r2:  -0.2834044777751392\n",
      "train loss:  2.089235305786133\n",
      "train r2:  0.8646580354514901\n",
      "test loss:  7.348237991333008\n",
      "test r2:  -0.2834188196211187\n",
      "train loss:  2.087608575820923\n",
      "train r2:  0.864762371028664\n",
      "test loss:  7.348797798156738\n",
      "test r2:  -0.28347511277819004\n",
      "train loss:  2.085986614227295\n",
      "train r2:  0.8648546755047162\n",
      "test loss:  7.349340915679932\n",
      "test r2:  -0.2835331116267623\n",
      "train loss:  2.084369421005249\n",
      "train r2:  0.8649453289352791\n",
      "test loss:  7.3497209548950195\n",
      "test r2:  -0.2835441311730653\n",
      "train loss:  2.082754373550415\n",
      "train r2:  0.8650470555569558\n",
      "test loss:  7.350308418273926\n",
      "test r2:  -0.28363225407221315\n",
      "train loss:  2.0811376571655273\n",
      "train r2:  0.8651287186749175\n",
      "test loss:  7.350598335266113\n",
      "test r2:  -0.2836293003457322\n",
      "train loss:  2.079517364501953\n",
      "train r2:  0.8652328797280221\n",
      "test loss:  7.351147174835205\n",
      "test r2:  -0.28371987269428023\n",
      "train loss:  2.0778937339782715\n",
      "train r2:  0.8653131470208705\n",
      "test loss:  7.3514509201049805\n",
      "test r2:  -0.28373729232470324\n",
      "train loss:  2.076270341873169\n",
      "train r2:  0.8654108421376958\n",
      "test loss:  7.3518476486206055\n",
      "test r2:  -0.28379299604567176\n",
      "train loss:  2.074648857116699\n",
      "train r2:  0.8654980345322447\n",
      "test loss:  7.352206707000732\n",
      "test r2:  -0.2838435884434136\n",
      "train loss:  2.0730299949645996\n",
      "train r2:  0.8655855136375805\n",
      "test loss:  7.352450847625732\n",
      "test r2:  -0.2838632980605207\n",
      "train loss:  2.0714120864868164\n",
      "train r2:  0.8656796779825291\n",
      "test loss:  7.352842330932617\n",
      "test r2:  -0.2839392590806027\n",
      "train loss:  2.0697929859161377\n",
      "train r2:  0.8657594940793838\n",
      "test loss:  7.353004455566406\n",
      "test r2:  -0.2839469922358342\n",
      "train loss:  2.068171739578247\n",
      "train r2:  0.8658552716647091\n",
      "test loss:  7.353350639343262\n",
      "test r2:  -0.28402192537107873\n",
      "train loss:  2.066549062728882\n",
      "train r2:  0.8659342137805779\n",
      "test loss:  7.353529453277588\n",
      "test r2:  -0.28404835906492276\n",
      "train loss:  2.0649263858795166\n",
      "train r2:  0.8660240790743008\n",
      "test loss:  7.353759288787842\n",
      "test r2:  -0.28409773844738107\n",
      "train loss:  2.0633046627044678\n",
      "train r2:  0.8661075592756774\n",
      "test loss:  7.353973865509033\n",
      "test r2:  -0.28414880278561605\n",
      "train loss:  2.0616838932037354\n",
      "train r2:  0.8661896432706823\n",
      "test loss:  7.3540802001953125\n",
      "test r2:  -0.28416957255860686\n",
      "train loss:  2.0600638389587402\n",
      "train r2:  0.8662780200021378\n",
      "test loss:  7.354312419891357\n",
      "test r2:  -0.2842370024831353\n",
      "train loss:  2.0584425926208496\n",
      "train r2:  0.8663544845897578\n",
      "test loss:  7.354368209838867\n",
      "test r2:  -0.28425199675479274\n",
      "train loss:  2.0568203926086426\n",
      "train r2:  0.8664426349631796\n",
      "test loss:  7.354551315307617\n",
      "test r2:  -0.2843136332892271\n",
      "train loss:  2.05519700050354\n",
      "train r2:  0.8665190775095092\n",
      "test loss:  7.354625225067139\n",
      "test r2:  -0.2843442067626596\n",
      "train loss:  2.0535738468170166\n",
      "train r2:  0.8666020796129442\n",
      "test loss:  7.3547210693359375\n",
      "test r2:  -0.2843861188757777\n",
      "train loss:  2.0519511699676514\n",
      "train r2:  0.8666815938815133\n",
      "test loss:  7.354833602905273\n",
      "test r2:  -0.2844370875765272\n",
      "train loss:  2.0503287315368652\n",
      "train r2:  0.8667581790054609\n",
      "test loss:  7.354849338531494\n",
      "test r2:  -0.28446020145717954\n",
      "train loss:  2.048706293106079\n",
      "train r2:  0.8668404145993608\n",
      "test loss:  7.354964733123779\n",
      "test r2:  -0.2845187070160644\n",
      "train loss:  2.0470831394195557\n",
      "train r2:  0.86691359149817\n",
      "test loss:  7.354960918426514\n",
      "test r2:  -0.28454148080134734\n",
      "train loss:  2.045459032058716\n",
      "train r2:  0.8669943542135099\n",
      "test loss:  7.355040073394775\n",
      "test r2:  -0.2845939526127006\n",
      "train loss:  2.043834924697876\n",
      "train r2:  0.8670675838593493\n",
      "test loss:  7.355067729949951\n",
      "test r2:  -0.2846320636693225\n",
      "train loss:  2.042210340499878\n",
      "train r2:  0.867143409435852\n",
      "test loss:  7.35508394241333\n",
      "test r2:  -0.2846680632049443\n",
      "train loss:  2.040585994720459\n",
      "train r2:  0.8672189463984818\n",
      "test loss:  7.35514497756958\n",
      "test r2:  -0.28472098396397794\n",
      "train loss:  2.0389621257781982\n",
      "train r2:  0.8672898235236571\n",
      "test loss:  7.3551225662231445\n",
      "test r2:  -0.2847482412740665\n",
      "train loss:  2.037337064743042\n",
      "train r2:  0.8673658203709051\n",
      "test loss:  7.355175971984863\n",
      "test r2:  -0.28480133665231144\n",
      "train loss:  2.0357112884521484\n",
      "train r2:  0.8674350897609806\n",
      "test loss:  7.355159282684326\n",
      "test r2:  -0.28483298351283826\n",
      "train loss:  2.034085750579834\n",
      "train r2:  0.8675085076019095\n",
      "test loss:  7.3551788330078125\n",
      "test r2:  -0.2848769614931348\n",
      "train loss:  2.0324597358703613\n",
      "train r2:  0.8675783998255163\n",
      "test loss:  7.355198860168457\n",
      "test r2:  -0.28492197661192376\n",
      "train loss:  2.0308334827423096\n",
      "train r2:  0.8676472812009297\n",
      "test loss:  7.3551788330078125\n",
      "test r2:  -0.2849549172554686\n",
      "train loss:  2.029207706451416\n",
      "train r2:  0.8677181699089329\n",
      "test loss:  7.355217456817627\n",
      "test r2:  -0.28500710241243565\n",
      "train loss:  2.027580738067627\n",
      "train r2:  0.8677839869657574\n",
      "test loss:  7.355193614959717\n",
      "test r2:  -0.28503893375208866\n",
      "train loss:  2.025954008102417\n",
      "train r2:  0.8678535572399545\n",
      "test loss:  7.355215549468994\n",
      "test r2:  -0.2850859737090137\n",
      "train loss:  2.0243265628814697\n",
      "train r2:  0.8679189224209093\n",
      "test loss:  7.355212688446045\n",
      "test r2:  -0.2851250550230202\n",
      "train loss:  2.0226988792419434\n",
      "train r2:  0.8679854113867929\n",
      "test loss:  7.355208873748779\n",
      "test r2:  -0.28516312858984616\n",
      "train loss:  2.021071434020996\n",
      "train r2:  0.8680512872662967\n",
      "test loss:  7.355240345001221\n",
      "test r2:  -0.285212475672584\n",
      "train loss:  2.0194437503814697\n",
      "train r2:  0.8681140039622863\n",
      "test loss:  7.355225086212158\n",
      "test r2:  -0.28524626005774145\n",
      "train loss:  2.017815113067627\n",
      "train r2:  0.8681793541247611\n",
      "test loss:  7.355258464813232\n",
      "test r2:  -0.2852949505365241\n",
      "train loss:  2.0161867141723633\n",
      "train r2:  0.8682407183687602\n",
      "test loss:  7.355264186859131\n",
      "test r2:  -0.28533346723421316\n",
      "train loss:  2.0145576000213623\n",
      "train r2:  0.8683035403325634\n",
      "test loss:  7.355285167694092\n",
      "test r2:  -0.28537592249058163\n",
      "train loss:  2.0129287242889404\n",
      "train r2:  0.8683647446088179\n",
      "test loss:  7.355318069458008\n",
      "test r2:  -0.28542145493742277\n",
      "train loss:  2.0112993717193604\n",
      "train r2:  0.8684245199378688\n",
      "test loss:  7.3553242683410645\n",
      "test r2:  -0.2854573991764149\n",
      "train loss:  2.0096700191497803\n",
      "train r2:  0.8684856218252226\n",
      "test loss:  7.355376720428467\n",
      "test r2:  -0.28550652992680847\n",
      "train loss:  2.008040428161621\n",
      "train r2:  0.8685430979167592\n",
      "test loss:  7.355401515960693\n",
      "test r2:  -0.28554566622202593\n",
      "train loss:  2.0064098834991455\n",
      "train r2:  0.8686020002929529\n",
      "test loss:  7.3554463386535645\n",
      "test r2:  -0.2855899188544029\n",
      "train loss:  2.004779815673828\n",
      "train r2:  0.8686590521653952\n",
      "test loss:  7.355495929718018\n",
      "test r2:  -0.28563430413888447\n",
      "train loss:  2.0031495094299316\n",
      "train r2:  0.86871531783938\n",
      "test loss:  7.355534076690674\n",
      "test r2:  -0.28567303677566835\n",
      "train loss:  2.0015225410461426\n",
      "train r2:  0.8687720212740951\n",
      "test loss:  7.355621814727783\n",
      "test r2:  -0.2857268185260444\n",
      "train loss:  1.9999139308929443\n",
      "train r2:  0.8688246963745339\n",
      "test loss:  7.355664253234863\n",
      "test r2:  -0.28576506249693745\n",
      "train loss:  1.9983274936676025\n",
      "train r2:  0.8688797021955135\n",
      "test loss:  7.355712890625\n",
      "test r2:  -0.2858049178900268\n",
      "train loss:  1.9967644214630127\n",
      "train r2:  0.8689334458246638\n",
      "test loss:  7.35576057434082\n",
      "test r2:  -0.2858436984008541\n",
      "train loss:  1.9952260255813599\n",
      "train r2:  0.8689864958719611\n",
      "test loss:  7.3558125495910645\n",
      "test r2:  -0.28588357991227165\n",
      "train loss:  1.9937132596969604\n",
      "train r2:  0.8690382608347872\n",
      "test loss:  7.355900764465332\n",
      "test r2:  -0.2859349690091413\n",
      "train loss:  1.992226243019104\n",
      "train r2:  0.8690866111798042\n",
      "test loss:  7.355941295623779\n",
      "test r2:  -0.28597173542246246\n",
      "train loss:  1.9907664060592651\n",
      "train r2:  0.8691369250284486\n",
      "test loss:  7.355993747711182\n",
      "test r2:  -0.28601257111309075\n",
      "train loss:  1.9893337488174438\n",
      "train r2:  0.8691852921083147\n",
      "test loss:  7.3560380935668945\n",
      "test r2:  -0.2860507395268066\n",
      "train loss:  1.987928867340088\n",
      "train r2:  0.8692330404703795\n",
      "test loss:  7.356064319610596\n",
      "test r2:  -0.28608391043028614\n",
      "train loss:  1.9865517616271973\n",
      "train r2:  0.8692806499386578\n",
      "test loss:  7.356111526489258\n",
      "test r2:  -0.28612390168701873\n",
      "train loss:  1.985202431678772\n",
      "train r2:  0.8693257365300473\n",
      "test loss:  7.356139659881592\n",
      "test r2:  -0.28615784436333613\n",
      "train loss:  1.983880877494812\n",
      "train r2:  0.8693709998983988\n",
      "test loss:  7.356192111968994\n",
      "test r2:  -0.28619932685535354\n",
      "train loss:  1.9825866222381592\n",
      "train r2:  0.8694134776223296\n",
      "test loss:  7.356228351593018\n",
      "test r2:  -0.28623534294432607\n",
      "train loss:  1.9813206195831299\n",
      "train r2:  0.8694559180854898\n",
      "test loss:  7.356242656707764\n",
      "test r2:  -0.28626422881164326\n",
      "train loss:  1.9800806045532227\n",
      "train r2:  0.8694987196739544\n",
      "test loss:  7.356274127960205\n",
      "test r2:  -0.2862981262929303\n",
      "train loss:  1.978867769241333\n",
      "train r2:  0.8695392937056746\n",
      "test loss:  7.356297492980957\n",
      "test r2:  -0.2863285768267039\n",
      "train loss:  1.9776813983917236\n",
      "train r2:  0.8695795085423027\n",
      "test loss:  7.356338024139404\n",
      "test r2:  -0.28636422958171304\n",
      "train loss:  1.9765212535858154\n",
      "train r2:  0.869617535148655\n",
      "test loss:  7.356369495391846\n",
      "test r2:  -0.28639629705137026\n",
      "train loss:  1.9753865003585815\n",
      "train r2:  0.8696551877964642\n",
      "test loss:  7.356396198272705\n",
      "test r2:  -0.2864255345288971\n",
      "train loss:  1.9742769002914429\n",
      "train r2:  0.8696923479953348\n",
      "test loss:  7.356433391571045\n",
      "test r2:  -0.2864575180520519\n",
      "train loss:  1.973191499710083\n",
      "train r2:  0.8697277870885101\n",
      "test loss:  7.356451511383057\n",
      "test r2:  -0.2864829557839146\n",
      "train loss:  1.972130537033081\n",
      "train r2:  0.8697635972172744\n",
      "test loss:  7.356482028961182\n",
      "test r2:  -0.2865116639925287\n",
      "train loss:  1.9710932970046997\n",
      "train r2:  0.869797693871546\n",
      "test loss:  7.356518268585205\n",
      "test r2:  -0.2865413054357153\n",
      "train loss:  1.9700785875320435\n",
      "train r2:  0.8698305870693811\n",
      "test loss:  7.356549263000488\n",
      "test r2:  -0.2865691153598158\n",
      "train loss:  1.9690862894058228\n",
      "train r2:  0.8698628783352241\n",
      "test loss:  7.35658597946167\n",
      "test r2:  -0.28659817455599423\n",
      "train loss:  1.968116283416748\n",
      "train r2:  0.8698939273106275\n",
      "test loss:  7.356601238250732\n",
      "test r2:  -0.28662022599909576\n",
      "train loss:  1.9671673774719238\n",
      "train r2:  0.8699255202264917\n",
      "test loss:  7.356626987457275\n",
      "test r2:  -0.2866450936746878\n",
      "train loss:  1.9662394523620605\n",
      "train r2:  0.8699555646368802\n",
      "test loss:  7.3566575050354\n",
      "test r2:  -0.28667139843181677\n",
      "train loss:  1.9653315544128418\n",
      "train r2:  0.8699844686913141\n",
      "test loss:  7.356677532196045\n",
      "test r2:  -0.28669476876856237\n",
      "train loss:  1.964443325996399\n",
      "train r2:  0.8700131222726702\n",
      "test loss:  7.356703281402588\n",
      "test r2:  -0.28671959929025936\n",
      "train loss:  1.9635746479034424\n",
      "train r2:  0.8700405637013391\n",
      "test loss:  7.356716632843018\n",
      "test r2:  -0.28674088251205876\n",
      "train loss:  1.9627243280410767\n",
      "train r2:  0.8700679747485092\n",
      "test loss:  7.356729507446289\n",
      "test r2:  -0.2867626149478011\n",
      "train loss:  1.9618921279907227\n",
      "train r2:  0.8700944985606689\n",
      "test loss:  7.356738567352295\n",
      "test r2:  -0.2867830487586398\n",
      "train loss:  1.9610772132873535\n",
      "train r2:  0.8701205092200293\n",
      "test loss:  7.356741428375244\n",
      "test r2:  -0.28680218219543296\n",
      "train loss:  1.9602797031402588\n",
      "train r2:  0.8701460430721049\n",
      "test loss:  7.356755256652832\n",
      "test r2:  -0.2868248598434757\n",
      "train loss:  1.9594987630844116\n",
      "train r2:  0.8701701009203324\n",
      "test loss:  7.356753349304199\n",
      "test r2:  -0.28684318528340746\n",
      "train loss:  1.9587335586547852\n",
      "train r2:  0.87019440406995\n",
      "test loss:  7.356745719909668\n",
      "test r2:  -0.28685996704658034\n",
      "train loss:  1.9579839706420898\n",
      "train r2:  0.8702183006035416\n",
      "test loss:  7.356739521026611\n",
      "test r2:  -0.28687768377298584\n",
      "train loss:  1.9572497606277466\n",
      "train r2:  0.8702413532821\n",
      "test loss:  7.3567280769348145\n",
      "test r2:  -0.28689407453544713\n",
      "train loss:  1.956529974937439\n",
      "train r2:  0.8702640816072154\n",
      "test loss:  7.356719493865967\n",
      "test r2:  -0.2869116428920524\n",
      "train loss:  1.955824375152588\n",
      "train r2:  0.8702859084226588\n",
      "test loss:  7.356704235076904\n",
      "test r2:  -0.28692738398977546\n",
      "train loss:  1.9551324844360352\n",
      "train r2:  0.8703075619496689\n",
      "test loss:  7.356685161590576\n",
      "test r2:  -0.2869417931797502\n",
      "train loss:  1.954453706741333\n",
      "train r2:  0.8703288149851495\n",
      "test loss:  7.3566670417785645\n",
      "test r2:  -0.2869567748674202\n",
      "train loss:  1.9537875652313232\n",
      "train r2:  0.8703494838627284\n",
      "test loss:  7.35664176940918\n",
      "test r2:  -0.2869694662079272\n",
      "train loss:  1.9531338214874268\n",
      "train r2:  0.8703700313277587\n",
      "test loss:  7.356620788574219\n",
      "test r2:  -0.28698346204340774\n",
      "train loss:  1.9524918794631958\n",
      "train r2:  0.8703898406876458\n",
      "test loss:  7.356599807739258\n",
      "test r2:  -0.2869975917435126\n",
      "train loss:  1.9518613815307617\n",
      "train r2:  0.8704090496881869\n",
      "test loss:  7.356573581695557\n",
      "test r2:  -0.28700981713239004\n",
      "train loss:  1.9512417316436768\n",
      "train r2:  0.8704281923007368\n",
      "test loss:  7.356546401977539\n",
      "test r2:  -0.28702148095673086\n",
      "train loss:  1.9506324529647827\n",
      "train r2:  0.8704469797766452\n",
      "test loss:  7.356517314910889\n",
      "test r2:  -0.2870323762730247\n",
      "train loss:  1.9500333070755005\n",
      "train r2:  0.8704654794616566\n",
      "test loss:  7.35649299621582\n",
      "test r2:  -0.28704424024093433\n",
      "train loss:  1.9494428634643555\n",
      "train r2:  0.8704833806359402\n",
      "test loss:  7.356471061706543\n",
      "test r2:  -0.2870563514686313\n",
      "train loss:  1.9488617181777954\n",
      "train r2:  0.8705007292466174\n",
      "test loss:  7.356441020965576\n",
      "test r2:  -0.2870659460053413\n",
      "train loss:  1.9482883214950562\n",
      "train r2:  0.8705182250354818\n",
      "test loss:  7.356414318084717\n",
      "test r2:  -0.2870756485341286\n",
      "train loss:  1.947722315788269\n",
      "train r2:  0.8705353693830578\n",
      "test loss:  7.356390476226807\n",
      "test r2:  -0.28708601105455256\n",
      "train loss:  1.9471626281738281\n",
      "train r2:  0.8705519486483835\n",
      "test loss:  7.35636568069458\n",
      "test r2:  -0.2870950436457653\n",
      "train loss:  1.9466087818145752\n",
      "train r2:  0.8705685022487893\n",
      "test loss:  7.356344699859619\n",
      "test r2:  -0.2871050153661985\n",
      "train loss:  1.9460595846176147\n",
      "train r2:  0.8705845083713445\n",
      "test loss:  7.356321811676025\n",
      "test r2:  -0.2871135711545503\n",
      "train loss:  1.9455136060714722\n",
      "train r2:  0.8706005431182473\n",
      "test loss:  7.3563008308410645\n",
      "test r2:  -0.28712168337372956\n",
      "train loss:  1.9449703693389893\n",
      "train r2:  0.8706163957832102\n",
      "test loss:  7.356285095214844\n",
      "test r2:  -0.28713056274506377\n",
      "train loss:  1.9444286823272705\n",
      "train r2:  0.8706318217467349\n",
      "test loss:  7.356269836425781\n",
      "test r2:  -0.2871385782412248\n",
      "train loss:  1.9438875913619995\n",
      "train r2:  0.8706472121609335\n",
      "test loss:  7.356258869171143\n",
      "test r2:  -0.28714676704576547\n",
      "train loss:  1.9433467388153076\n",
      "train r2:  0.8706623773750679\n",
      "test loss:  7.356252670288086\n",
      "test r2:  -0.28715520016891394\n",
      "train loss:  1.942805528640747\n",
      "train r2:  0.8706772667845035\n",
      "test loss:  7.356247425079346\n",
      "test r2:  -0.2871629031832015\n",
      "train loss:  1.942264437675476\n",
      "train r2:  0.8706921152365211\n",
      "test loss:  7.35624885559082\n",
      "test r2:  -0.28717143890763075\n",
      "train loss:  1.9417235851287842\n",
      "train r2:  0.8707066836896737\n",
      "test loss:  7.356256484985352\n",
      "test r2:  -0.2871806113728135\n",
      "train loss:  1.941184401512146\n",
      "train r2:  0.8707208933545509\n",
      "test loss:  7.356269836425781\n",
      "test r2:  -0.2871901290128398\n",
      "train loss:  1.9406476020812988\n",
      "train r2:  0.8707349031962075\n",
      "test loss:  7.356287956237793\n",
      "test r2:  -0.2872000535187418\n",
      "train loss:  1.9401136636734009\n",
      "train r2:  0.870748699604243\n",
      "test loss:  7.356307506561279\n",
      "test r2:  -0.2872090807560248\n",
      "train loss:  1.9395831823349\n",
      "train r2:  0.8707624906869236\n",
      "test loss:  7.356335163116455\n",
      "test r2:  -0.2872194318189576\n",
      "train loss:  1.9390554428100586\n",
      "train r2:  0.8707759513531059\n",
      "test loss:  7.356368541717529\n",
      "test r2:  -0.28723004094784943\n",
      "train loss:  1.9385310411453247\n",
      "train r2:  0.8707891636815344\n",
      "test loss:  7.356401443481445\n",
      "test r2:  -0.2872393672719413\n",
      "train loss:  1.9380087852478027\n",
      "train r2:  0.8708025623247131\n",
      "test loss:  7.356440544128418\n",
      "test r2:  -0.28724888838157603\n",
      "train loss:  1.9374878406524658\n",
      "train r2:  0.8708158507659924\n",
      "test loss:  7.3564863204956055\n",
      "test r2:  -0.2872591890102465\n",
      "train loss:  1.936967372894287\n",
      "train r2:  0.8708288557325777\n",
      "test loss:  7.3565354347229\n",
      "test r2:  -0.2872690858780744\n",
      "train loss:  1.9364464282989502\n",
      "train r2:  0.870841904764651\n",
      "test loss:  7.356588840484619\n",
      "test r2:  -0.2872786340686797\n",
      "train loss:  1.9359238147735596\n",
      "train r2:  0.8708549393507056\n",
      "test loss:  7.35664701461792\n",
      "test r2:  -0.28728791559508693\n",
      "train loss:  1.9353985786437988\n",
      "train r2:  0.870868019472225\n",
      "test loss:  7.356713771820068\n",
      "test r2:  -0.2872982653226097\n",
      "train loss:  1.9348698854446411\n",
      "train r2:  0.870880819443695\n",
      "test loss:  7.356787204742432\n",
      "test r2:  -0.2873084503809551\n",
      "train loss:  1.9343359470367432\n",
      "train r2:  0.870893696333838\n",
      "test loss:  7.3568644523620605\n",
      "test r2:  -0.2873178861840995\n",
      "train loss:  1.9337964057922363\n",
      "train r2:  0.8709067142757732\n",
      "test loss:  7.35695219039917\n",
      "test r2:  -0.2873285024775074\n",
      "train loss:  1.933249831199646\n",
      "train r2:  0.8709195356438274\n",
      "test loss:  7.357048034667969\n",
      "test r2:  -0.287339334673143\n",
      "train loss:  1.9326945543289185\n",
      "train r2:  0.8709323133113864\n",
      "test loss:  7.357151508331299\n",
      "test r2:  -0.2873500039200685\n",
      "train loss:  1.9321296215057373\n",
      "train r2:  0.8709452483539992\n",
      "test loss:  7.357264518737793\n",
      "test r2:  -0.28736077938535187\n",
      "train loss:  1.931553840637207\n",
      "train r2:  0.870958213834644\n",
      "test loss:  7.357390880584717\n",
      "test r2:  -0.28737295267275265\n",
      "train loss:  1.9309660196304321\n",
      "train r2:  0.8709710215916203\n",
      "test loss:  7.35752534866333\n",
      "test r2:  -0.28738500079617646\n",
      "train loss:  1.930364727973938\n",
      "train r2:  0.8709839210664613\n",
      "test loss:  7.357672214508057\n",
      "test r2:  -0.2873972341852258\n",
      "train loss:  1.9297491312026978\n",
      "train r2:  0.8709969524672061\n",
      "test loss:  7.357834339141846\n",
      "test r2:  -0.2874107690215639\n",
      "train loss:  1.9291186332702637\n",
      "train r2:  0.8710098248174596\n",
      "test loss:  7.358010768890381\n",
      "test r2:  -0.28742486149403934\n",
      "train loss:  1.9284723997116089\n",
      "train r2:  0.8710227760480819\n",
      "test loss:  7.358203411102295\n",
      "test r2:  -0.28743998176532903\n",
      "train loss:  1.9278111457824707\n",
      "train r2:  0.8710356599192723\n",
      "test loss:  7.35841178894043\n",
      "test r2:  -0.28745593567253525\n",
      "train loss:  1.9271355867385864\n",
      "train r2:  0.8710485389526739\n",
      "test loss:  7.358638286590576\n",
      "test r2:  -0.2874728978758332\n",
      "train loss:  1.926446795463562\n",
      "train r2:  0.8710612818694681\n",
      "test loss:  7.358888626098633\n",
      "test r2:  -0.28749222793743057\n",
      "train loss:  1.9257487058639526\n",
      "train r2:  0.8710736638793105\n",
      "test loss:  7.359157085418701\n",
      "test r2:  -0.2875118744789391\n",
      "train loss:  1.925044298171997\n",
      "train r2:  0.871086024598225\n",
      "test loss:  7.359454154968262\n",
      "test r2:  -0.28753472637342536\n",
      "train loss:  1.924338698387146\n",
      "train r2:  0.8710976790903782\n",
      "test loss:  7.359769821166992\n",
      "test r2:  -0.28755740124004636\n",
      "train loss:  1.9236385822296143\n",
      "train r2:  0.8711092974556522\n",
      "test loss:  7.360125541687012\n",
      "test r2:  -0.28758586873893677\n",
      "train loss:  1.922950267791748\n",
      "train r2:  0.8711194515685148\n",
      "test loss:  7.3604888916015625\n",
      "test r2:  -0.28761027576767284\n",
      "train loss:  1.9222800731658936\n",
      "train r2:  0.8711302576458653\n",
      "test loss:  7.360925197601318\n",
      "test r2:  -0.28765015949521566\n",
      "train loss:  1.9216326475143433\n",
      "train r2:  0.8711374605569618\n",
      "test loss:  7.361291408538818\n",
      "test r2:  -0.28766201205069386\n",
      "train loss:  1.9210110902786255\n",
      "train r2:  0.8711502758809997\n",
      "test loss:  7.361930847167969\n",
      "test r2:  -0.2877494967016314\n",
      "train loss:  1.9204201698303223\n",
      "train r2:  0.8711464853092359\n",
      "test loss:  7.3619585037231445\n",
      "test r2:  -0.2876477891094684\n",
      "train loss:  1.9199142456054688\n",
      "train r2:  0.8711821600464114\n",
      "test loss:  7.363732814788818\n",
      "test r2:  -0.28806184693074144\n",
      "train loss:  1.919688105583191\n",
      "train r2:  0.8711036800491274\n",
      "test loss:  7.361538410186768\n",
      "test r2:  -0.2872825568113515\n",
      "train loss:  1.9195576906204224\n",
      "train r2:  0.8712786458054886\n",
      "test loss:  7.365806579589844\n",
      "test r2:  -0.2884354933285571\n",
      "train loss:  1.918113112449646\n",
      "train r2:  0.8710595540546007\n",
      "test loss:  7.364935398101807\n",
      "test r2:  -0.2880586843518511\n",
      "train loss:  1.9179250001907349\n",
      "train r2:  0.8711497528360426\n",
      "test loss:  7.3615264892578125\n",
      "test r2:  -0.2868997155085473\n",
      "train loss:  1.917145848274231\n",
      "train r2:  0.8714134816448253\n",
      "test loss:  7.367189407348633\n",
      "test r2:  -0.2884457504171225\n",
      "train loss:  1.916232943534851\n",
      "train r2:  0.8711034009872316\n",
      "test loss:  7.36943244934082\n",
      "test r2:  -0.28899355893512557\n",
      "train loss:  1.9158920049667358\n",
      "train r2:  0.8709986320167487\n",
      "test loss:  7.362943649291992\n",
      "test r2:  -0.28694165220386214\n",
      "train loss:  1.9147727489471436\n",
      "train r2:  0.8714580037246651\n",
      "test loss:  7.364779949188232\n",
      "test r2:  -0.2873529638443273\n",
      "train loss:  1.9144505262374878\n",
      "train r2:  0.8713816451327621\n",
      "test loss:  7.372497081756592\n",
      "test r2:  -0.2895247134469219\n",
      "train loss:  1.9134552478790283\n",
      "train r2:  0.870939063810284\n",
      "test loss:  7.36876106262207\n",
      "test r2:  -0.288321412768312\n",
      "train loss:  1.91302490234375\n",
      "train r2:  0.8712097747066669\n",
      "test loss:  7.363103866577148\n",
      "test r2:  -0.2865157734120183\n",
      "train loss:  1.912192702293396\n",
      "train r2:  0.8716117852251586\n",
      "test loss:  7.36961030960083\n",
      "test r2:  -0.28833183413280494\n",
      "train loss:  1.911643624305725\n",
      "train r2:  0.8712395684674583\n",
      "test loss:  7.37507438659668\n",
      "test r2:  -0.2898417642090796\n",
      "train loss:  1.910923719406128\n",
      "train r2:  0.8709339072746833\n",
      "test loss:  7.367860794067383\n",
      "test r2:  -0.2876056555763391\n",
      "train loss:  1.9102997779846191\n",
      "train r2:  0.871426787276339\n",
      "test loss:  7.365095138549805\n",
      "test r2:  -0.2866591800599869\n",
      "train loss:  1.909645676612854\n",
      "train r2:  0.871642987764432\n",
      "test loss:  7.373653888702393\n",
      "test r2:  -0.2890902183656836\n",
      "train loss:  1.9089646339416504\n",
      "train r2:  0.8711408154471256\n",
      "test loss:  7.376337051391602\n",
      "test r2:  -0.28977767516117514\n",
      "train loss:  1.9083349704742432\n",
      "train r2:  0.8710090286982226\n",
      "test loss:  7.368347644805908\n",
      "test r2:  -0.2872953588024669\n",
      "train loss:  1.9076220989227295\n",
      "train r2:  0.871554443567677\n",
      "test loss:  7.367837905883789\n",
      "test r2:  -0.2870133925373455\n",
      "train loss:  1.9069970846176147\n",
      "train r2:  0.8716282971504394\n",
      "test loss:  7.376623153686523\n",
      "test r2:  -0.2894961255685915\n",
      "train loss:  1.906275749206543\n",
      "train r2:  0.8711145115741821\n",
      "test loss:  7.377600193023682\n",
      "test r2:  -0.2896547338597961\n",
      "train loss:  1.9056472778320312\n",
      "train r2:  0.8710946597585767\n",
      "test loss:  7.370288372039795\n",
      "test r2:  -0.2873363480488744\n",
      "train loss:  1.904931664466858\n",
      "train r2:  0.8716036430376582\n",
      "test loss:  7.371026992797852\n",
      "test r2:  -0.2873983428869542\n",
      "train loss:  1.9042974710464478\n",
      "train r2:  0.8716034932477776\n",
      "test loss:  7.379144191741943\n",
      "test r2:  -0.2896534721430064\n",
      "train loss:  1.9036022424697876\n",
      "train r2:  0.8711365702669918\n",
      "test loss:  7.379434108734131\n",
      "test r2:  -0.2895754968492754\n",
      "train loss:  1.9029709100723267\n",
      "train r2:  0.8711662315535846\n",
      "test loss:  7.373252868652344\n",
      "test r2:  -0.28756009268132776\n",
      "train loss:  1.9023089408874512\n",
      "train r2:  0.871608887119947\n",
      "test loss:  7.374612331390381\n",
      "test r2:  -0.28778758292208284\n",
      "train loss:  1.9016793966293335\n",
      "train r2:  0.8715729298769347\n",
      "test loss:  7.381659030914307\n",
      "test r2:  -0.28970920439095704\n",
      "train loss:  1.9010504484176636\n",
      "train r2:  0.8711756110337985\n",
      "test loss:  7.381654739379883\n",
      "test r2:  -0.2895281091818662\n",
      "train loss:  1.9004229307174683\n",
      "train r2:  0.8712266166164203\n",
      "test loss:  7.376747131347656\n",
      "test r2:  -0.28787996856095943\n",
      "train loss:  1.8998202085494995\n",
      "train r2:  0.871589814830546\n",
      "test loss:  7.378271102905273\n",
      "test r2:  -0.2881554627117413\n",
      "train loss:  1.8991990089416504\n",
      "train r2:  0.8715432751401769\n",
      "test loss:  7.3839826583862305\n",
      "test r2:  -0.28968344657439515\n",
      "train loss:  1.898618221282959\n",
      "train r2:  0.8712290042849113\n",
      "test loss:  7.383918285369873\n",
      "test r2:  -0.28948965350340794\n",
      "train loss:  1.8980140686035156\n",
      "train r2:  0.8712821356207898\n",
      "test loss:  7.380285739898682\n",
      "test r2:  -0.2882337247827491\n",
      "train loss:  1.8974528312683105\n",
      "train r2:  0.8715611823581056\n",
      "test loss:  7.381603717803955\n",
      "test r2:  -0.2884676345816721\n",
      "train loss:  1.8968758583068848\n",
      "train r2:  0.871522996106585\n",
      "test loss:  7.3858962059021\n",
      "test r2:  -0.28959522782884806\n",
      "train loss:  1.896330714225769\n",
      "train r2:  0.8712935968001304\n",
      "test loss:  7.3859758377075195\n",
      "test r2:  -0.2894689889574582\n",
      "train loss:  1.8957839012145996\n",
      "train r2:  0.871331611947759\n",
      "test loss:  7.383481979370117\n",
      "test r2:  -0.2885802355812299\n",
      "train loss:  1.8952521085739136\n",
      "train r2:  0.8715321435880345\n",
      "test loss:  7.384352207183838\n",
      "test r2:  -0.2887036154501381\n",
      "train loss:  1.8947330713272095\n",
      "train r2:  0.8715167813402255\n",
      "test loss:  7.387434005737305\n",
      "test r2:  -0.2894890324311936\n",
      "train loss:  1.8942136764526367\n",
      "train r2:  0.8713600148442369\n",
      "test loss:  7.387878894805908\n",
      "test r2:  -0.28948722351576683\n",
      "train loss:  1.8937171697616577\n",
      "train r2:  0.8713707526557521\n",
      "test loss:  7.386314392089844\n",
      "test r2:  -0.28888694661915215\n",
      "train loss:  1.8932130336761475\n",
      "train r2:  0.8715093947326786\n",
      "test loss:  7.386697769165039\n",
      "test r2:  -0.288868417213757\n",
      "train loss:  1.8927351236343384\n",
      "train r2:  0.8715235365951689\n",
      "test loss:  7.3889851570129395\n",
      "test r2:  -0.2894158369553661\n",
      "train loss:  1.8922507762908936\n",
      "train r2:  0.8714167789180821\n",
      "test loss:  7.389921188354492\n",
      "test r2:  -0.2895560682499767\n",
      "train loss:  1.891789197921753\n",
      "train r2:  0.8713965377065052\n",
      "test loss:  7.3889851570129395\n",
      "test r2:  -0.28913422019493007\n",
      "train loss:  1.8913272619247437\n",
      "train r2:  0.8714962617758555\n",
      "test loss:  7.388988971710205\n",
      "test r2:  -0.2889865641592857\n",
      "train loss:  1.8908798694610596\n",
      "train r2:  0.8715371260980652\n",
      "test loss:  7.390933513641357\n",
      "test r2:  -0.289414924837478\n",
      "train loss:  1.890439510345459\n",
      "train r2:  0.8714548559735888\n",
      "test loss:  7.3922834396362305\n",
      "test r2:  -0.28966058257109806\n",
      "train loss:  1.890006422996521\n",
      "train r2:  0.8714114239902369\n",
      "test loss:  7.391663074493408\n",
      "test r2:  -0.28931114479530207\n",
      "train loss:  1.8895831108093262\n",
      "train r2:  0.8714948370832554\n",
      "test loss:  7.391511917114258\n",
      "test r2:  -0.2890950235563796\n",
      "train loss:  1.8891651630401611\n",
      "train r2:  0.8715495210302735\n",
      "test loss:  7.393405437469482\n",
      "test r2:  -0.2894876157289985\n",
      "train loss:  1.888755440711975\n",
      "train r2:  0.8714742691946827\n",
      "test loss:  7.3949079513549805\n",
      "test r2:  -0.28975989205341635\n",
      "train loss:  1.8883538246154785\n",
      "train r2:  0.8714246090160535\n",
      "test loss:  7.394402980804443\n",
      "test r2:  -0.2894267069644092\n",
      "train loss:  1.887956976890564\n",
      "train r2:  0.8715040524395045\n",
      "test loss:  7.394346714019775\n",
      "test r2:  -0.28922458353131164\n",
      "train loss:  1.8875714540481567\n",
      "train r2:  0.871555282114939\n",
      "test loss:  7.3962202072143555\n",
      "test r2:  -0.28960025623375674\n",
      "train loss:  1.8871883153915405\n",
      "train r2:  0.8714834167601302\n",
      "test loss:  7.397587776184082\n",
      "test r2:  -0.2898225018396674\n",
      "train loss:  1.8868168592453003\n",
      "train r2:  0.8714441421509589\n",
      "test loss:  7.397199630737305\n",
      "test r2:  -0.2895164410194906\n",
      "train loss:  1.8864474296569824\n",
      "train r2:  0.8715176400441639\n",
      "test loss:  7.397387981414795\n",
      "test r2:  -0.2893816303512129\n",
      "train loss:  1.8860881328582764\n",
      "train r2:  0.8715545507287016\n",
      "test loss:  7.399112224578857\n",
      "test r2:  -0.289706938486715\n",
      "train loss:  1.8857325315475464\n",
      "train r2:  0.8714934011825088\n",
      "test loss:  7.4002532958984375\n",
      "test r2:  -0.289854065314892\n",
      "train loss:  1.8853836059570312\n",
      "train r2:  0.8714701975054334\n",
      "test loss:  7.400117874145508\n",
      "test r2:  -0.28961574696256265\n",
      "train loss:  1.885040283203125\n",
      "train r2:  0.8715293458593353\n",
      "test loss:  7.400546550750732\n",
      "test r2:  -0.28954316621779963\n",
      "train loss:  1.8847028017044067\n",
      "train r2:  0.8715532088502597\n",
      "test loss:  7.402037143707275\n",
      "test r2:  -0.28978500684952024\n",
      "train loss:  1.8843706846237183\n",
      "train r2:  0.8715100251096791\n",
      "test loss:  7.403081893920898\n",
      "test r2:  -0.28988738843874073\n",
      "train loss:  1.8840445280075073\n",
      "train r2:  0.8714965560350342\n",
      "test loss:  7.403295993804932\n",
      "test r2:  -0.2897343612483836\n",
      "train loss:  1.8837226629257202\n",
      "train r2:  0.8715377960398314\n",
      "test loss:  7.403874397277832\n",
      "test r2:  -0.28968355937558754\n",
      "train loss:  1.8834072351455688\n",
      "train r2:  0.8715572784941865\n",
      "test loss:  7.40519905090332\n",
      "test r2:  -0.2898480387523583\n",
      "train loss:  1.883095383644104\n",
      "train r2:  0.871530852277205\n",
      "test loss:  7.406349182128906\n",
      "test r2:  -0.2899503871857212\n",
      "train loss:  1.882789969444275\n",
      "train r2:  0.8715177765893095\n",
      "test loss:  7.406886100769043\n",
      "test r2:  -0.2898588435188336\n",
      "train loss:  1.8824877738952637\n",
      "train r2:  0.8715462850816028\n",
      "test loss:  7.407565593719482\n",
      "test r2:  -0.289798546081242\n",
      "train loss:  1.8821907043457031\n",
      "train r2:  0.871568170407341\n",
      "test loss:  7.4089155197143555\n",
      "test r2:  -0.2899279014352947\n",
      "train loss:  1.8818979263305664\n",
      "train r2:  0.8715497360511153\n",
      "test loss:  7.410270690917969\n",
      "test r2:  -0.29004621585600043\n",
      "train loss:  1.8816090822219849\n",
      "train r2:  0.8715338635899044\n",
      "test loss:  7.411037921905518\n",
      "test r2:  -0.28997491187392077\n",
      "train loss:  1.8813248872756958\n",
      "train r2:  0.8715586753769302\n",
      "test loss:  7.4118852615356445\n",
      "test r2:  -0.2899130681420028\n",
      "train loss:  1.8810451030731201\n",
      "train r2:  0.8715816311874751\n",
      "test loss:  7.41342306137085\n",
      "test r2:  -0.2900446573381654\n",
      "train loss:  1.8807687759399414\n",
      "train r2:  0.8715635553219341\n",
      "test loss:  7.414961338043213\n",
      "test r2:  -0.2901611869217904\n",
      "train loss:  1.880496859550476\n",
      "train r2:  0.8715490581002812\n",
      "test loss:  7.41593599319458\n",
      "test r2:  -0.2900917824418232\n",
      "train loss:  1.8802282810211182\n",
      "train r2:  0.8715745018838654\n",
      "test loss:  7.417081832885742\n",
      "test r2:  -0.290056770597652\n",
      "train loss:  1.8799638748168945\n",
      "train r2:  0.8715929631178719\n",
      "test loss:  7.418847560882568\n",
      "test r2:  -0.2901933536910699\n",
      "train loss:  1.879702091217041\n",
      "train r2:  0.8715747944265156\n",
      "test loss:  7.42051362991333\n",
      "test r2:  -0.2902831192225055\n",
      "train loss:  1.8794448375701904\n",
      "train r2:  0.8715666937511767\n",
      "test loss:  7.421752452850342\n",
      "test r2:  -0.29022548238067936\n",
      "train loss:  1.8791903257369995\n",
      "train r2:  0.8715902333821555\n",
      "test loss:  7.423243999481201\n",
      "test r2:  -0.29022437421557257\n",
      "train loss:  1.8789395093917847\n",
      "train r2:  0.8716019912001737\n",
      "test loss:  7.425210475921631\n",
      "test r2:  -0.29034479232915333\n",
      "train loss:  1.8786919116973877\n",
      "train r2:  0.8715880882041949\n",
      "test loss:  7.427080154418945\n",
      "test r2:  -0.29041274996188515\n",
      "train loss:  1.8784472942352295\n",
      "train r2:  0.8715857415985154\n",
      "test loss:  7.428723335266113\n",
      "test r2:  -0.2903870186773827\n",
      "train loss:  1.8782060146331787\n",
      "train r2:  0.8716039770984505\n",
      "test loss:  7.4306182861328125\n",
      "test r2:  -0.2904100337131075\n",
      "train loss:  1.8779674768447876\n",
      "train r2:  0.8716124626709196\n",
      "test loss:  7.4328765869140625\n",
      "test r2:  -0.2905130041526527\n",
      "train loss:  1.8777320384979248\n",
      "train r2:  0.8716044392743807\n",
      "test loss:  7.435141086578369\n",
      "test r2:  -0.2905857851024298\n",
      "train loss:  1.8774992227554321\n",
      "train r2:  0.8716037408532578\n",
      "test loss:  7.437312126159668\n",
      "test r2:  -0.2905953285494616\n",
      "train loss:  1.8772696256637573\n",
      "train r2:  0.8716175145452683\n",
      "test loss:  7.439700603485107\n",
      "test r2:  -0.2906327565274178\n",
      "train loss:  1.8770424127578735\n",
      "train r2:  0.8716264108601721\n",
      "test loss:  7.44245719909668\n",
      "test r2:  -0.29074037609081715\n",
      "train loss:  1.8768179416656494\n",
      "train r2:  0.8716215466727038\n",
      "test loss:  7.445327281951904\n",
      "test r2:  -0.29083751737093944\n",
      "train loss:  1.8765960931777954\n",
      "train r2:  0.8716202887965756\n",
      "test loss:  7.4481658935546875\n",
      "test r2:  -0.29087708204196683\n",
      "train loss:  1.8763766288757324\n",
      "train r2:  0.8716330401470271\n",
      "test loss:  7.451262950897217\n",
      "test r2:  -0.2909417338669278\n",
      "train loss:  1.87615966796875\n",
      "train r2:  0.8716421874212357\n",
      "test loss:  7.454797267913818\n",
      "test r2:  -0.2910811173276724\n",
      "train loss:  1.8759450912475586\n",
      "train r2:  0.871637395520521\n",
      "test loss:  7.458503723144531\n",
      "test r2:  -0.2912104660005781\n",
      "train loss:  1.8757330179214478\n",
      "train r2:  0.87163715434157\n",
      "test loss:  7.462268352508545\n",
      "test r2:  -0.2912897906811833\n",
      "train loss:  1.8755232095718384\n",
      "train r2:  0.8716502462921987\n",
      "test loss:  7.466418743133545\n",
      "test r2:  -0.2914116015415038\n",
      "train loss:  1.8753156661987305\n",
      "train r2:  0.8716573635810442\n",
      "test loss:  7.471065998077393\n",
      "test r2:  -0.29160402815612607\n",
      "train loss:  1.875110149383545\n",
      "train r2:  0.8716528353572349\n",
      "test loss:  7.475952625274658\n",
      "test r2:  -0.29178243992410735\n",
      "train loss:  1.8749068975448608\n",
      "train r2:  0.8716553221792992\n",
      "test loss:  7.481074333190918\n",
      "test r2:  -0.29193821230805184\n",
      "train loss:  1.8747057914733887\n",
      "train r2:  0.8716671994275267\n",
      "test loss:  7.486719131469727\n",
      "test r2:  -0.2921516814716172\n",
      "train loss:  1.8745063543319702\n",
      "train r2:  0.871671967374392\n",
      "test loss:  7.492924690246582\n",
      "test r2:  -0.29242640869554326\n",
      "train loss:  1.8743090629577637\n",
      "train r2:  0.8716695848786568\n",
      "test loss:  7.499511241912842\n",
      "test r2:  -0.29270152971798846\n",
      "train loss:  1.8741137981414795\n",
      "train r2:  0.8716738438836482\n",
      "test loss:  7.506530284881592\n",
      "test r2:  -0.2929872537207041\n",
      "train loss:  1.8739197254180908\n",
      "train r2:  0.8716834962045346\n",
      "test loss:  7.514178276062012\n",
      "test r2:  -0.29333870400462225\n",
      "train loss:  1.8737276792526245\n",
      "train r2:  0.8716876791538548\n",
      "test loss:  7.522451877593994\n",
      "test r2:  -0.2937544674846253\n",
      "train loss:  1.8735368251800537\n",
      "train r2:  0.8716875603755765\n",
      "test loss:  7.531206130981445\n",
      "test r2:  -0.2941969338992745\n",
      "train loss:  1.873347520828247\n",
      "train r2:  0.8716919898011994\n",
      "test loss:  7.540399074554443\n",
      "test r2:  -0.2946697467512489\n",
      "train loss:  1.8731589317321777\n",
      "train r2:  0.8717004074917291\n",
      "test loss:  7.550031661987305\n",
      "test r2:  -0.29520510869795147\n",
      "train loss:  1.8729709386825562\n",
      "train r2:  0.8717053105350504\n",
      "test loss:  7.559872627258301\n",
      "test r2:  -0.2957940705416646\n",
      "train loss:  1.8727818727493286\n",
      "train r2:  0.8717062906785833\n",
      "test loss:  7.569369792938232\n",
      "test r2:  -0.2963750816770896\n",
      "train loss:  1.8725917339324951\n",
      "train r2:  0.8717110998990921\n",
      "test loss:  7.577770709991455\n",
      "test r2:  -0.29689640596457734\n",
      "train loss:  1.872401475906372\n",
      "train r2:  0.8717200165110748\n",
      "test loss:  7.583940505981445\n",
      "test r2:  -0.29730449640738255\n",
      "train loss:  1.8722270727157593\n",
      "train r2:  0.8717249766112679\n",
      "test loss:  7.585508346557617\n",
      "test r2:  -0.297431329040621\n",
      "train loss:  1.8720612525939941\n",
      "train r2:  0.8717258096395475\n",
      "test loss:  7.581417560577393\n",
      "test r2:  -0.2971581516174968\n",
      "train loss:  1.8718643188476562\n",
      "train r2:  0.8717348609698066\n",
      "test loss:  7.575867176055908\n",
      "test r2:  -0.29675407743293936\n",
      "train loss:  1.8716926574707031\n",
      "train r2:  0.8717548294464923\n",
      "test loss:  7.572064399719238\n",
      "test r2:  -0.2964995468616636\n",
      "train loss:  1.871526837348938\n",
      "train r2:  0.8717655970012478\n",
      "test loss:  7.571413993835449\n",
      "test r2:  -0.2964858981263112\n",
      "train loss:  1.8713569641113281\n",
      "train r2:  0.8717651914596475\n",
      "test loss:  7.573617458343506\n",
      "test r2:  -0.2966261883673995\n",
      "train loss:  1.8711824417114258\n",
      "train r2:  0.8717717042501979\n",
      "test loss:  7.5775861740112305\n",
      "test r2:  -0.2968565610745295\n",
      "train loss:  1.8710039854049683\n",
      "train r2:  0.8717848177621565\n",
      "test loss:  7.581630229949951\n",
      "test r2:  -0.29712722363773536\n",
      "train loss:  1.870836615562439\n",
      "train r2:  0.8717888724377826\n",
      "test loss:  7.583004474639893\n",
      "test r2:  -0.29725133595042386\n",
      "train loss:  1.8706797361373901\n",
      "train r2:  0.8717850952267561\n",
      "test loss:  7.580178737640381\n",
      "test r2:  -0.2970642714826406\n",
      "train loss:  1.8705012798309326\n",
      "train r2:  0.8717906783920268\n",
      "test loss:  7.5764994621276855\n",
      "test r2:  -0.2967780176784869\n",
      "train loss:  1.870341181755066\n",
      "train r2:  0.8718082384198824\n",
      "test loss:  7.574766635894775\n",
      "test r2:  -0.2966574267972448\n",
      "train loss:  1.8701823949813843\n",
      "train r2:  0.8718150897121038\n",
      "test loss:  7.575753688812256\n",
      "test r2:  -0.2967583495246353\n",
      "train loss:  1.8700178861618042\n",
      "train r2:  0.8718090590796937\n",
      "test loss:  7.57835578918457\n",
      "test r2:  -0.2969353543438309\n",
      "train loss:  1.8698508739471436\n",
      "train r2:  0.8718108889508196\n",
      "test loss:  7.580732822418213\n",
      "test r2:  -0.29706592336858306\n",
      "train loss:  1.8696943521499634\n",
      "train r2:  0.8718216950121468\n",
      "test loss:  7.5809102058410645\n",
      "test r2:  -0.297085437917499\n",
      "train loss:  1.869537353515625\n",
      "train r2:  0.8718234657293339\n",
      "test loss:  7.578799724578857\n",
      "test r2:  -0.29697211595213346\n",
      "train loss:  1.8693742752075195\n",
      "train r2:  0.8718205150013296\n",
      "test loss:  7.5764875411987305\n",
      "test r2:  -0.29680128740887457\n",
      "train loss:  1.8692212104797363\n",
      "train r2:  0.8718300550088307\n",
      "test loss:  7.5757341384887695\n",
      "test r2:  -0.2967235062124993\n",
      "train loss:  1.8690671920776367\n",
      "train r2:  0.8718421483287446\n",
      "test loss:  7.576970100402832\n",
      "test r2:  -0.29682298500925586\n",
      "train loss:  1.8689097166061401\n",
      "train r2:  0.8718412798381169\n",
      "test loss:  7.578985214233398\n",
      "test r2:  -0.2969835135587786\n",
      "train loss:  1.8687554597854614\n",
      "train r2:  0.8718379212885139\n",
      "test loss:  7.579851150512695\n",
      "test r2:  -0.297029997206784\n",
      "train loss:  1.868606448173523\n",
      "train r2:  0.8718456130732037\n",
      "test loss:  7.578670024871826\n",
      "test r2:  -0.29693348618289317\n",
      "train loss:  1.868451714515686\n",
      "train r2:  0.8718558574727613\n",
      "test loss:  7.576895236968994\n",
      "test r2:  -0.2968219967975687\n",
      "train loss:  1.8683017492294312\n",
      "train r2:  0.8718597896737015\n",
      "test loss:  7.576046466827393\n",
      "test r2:  -0.29677412359388033\n",
      "train loss:  1.8681541681289673\n",
      "train r2:  0.8718631475160007\n",
      "test loss:  7.576553821563721\n",
      "test r2:  -0.29679808671344676\n",
      "train loss:  1.8680038452148438\n",
      "train r2:  0.87187123439738\n",
      "test loss:  7.577826023101807\n",
      "test r2:  -0.29687672909778917\n",
      "train loss:  1.867855191230774\n",
      "train r2:  0.8718781874021873\n",
      "test loss:  7.578515529632568\n",
      "test r2:  -0.29693661837505836\n",
      "train loss:  1.8677102327346802\n",
      "train r2:  0.8718798844489758\n",
      "test loss:  7.577670574188232\n",
      "test r2:  -0.29688754774679493\n",
      "train loss:  1.8675627708435059\n",
      "train r2:  0.8718839572424737\n",
      "test loss:  7.576255798339844\n",
      "test r2:  -0.29677479865598877\n",
      "train loss:  1.8674184083938599\n",
      "train r2:  0.8718952396278491\n",
      "test loss:  7.575716018676758\n",
      "test r2:  -0.29672761968942374\n",
      "train loss:  1.8672748804092407\n",
      "train r2:  0.8719042659018235\n",
      "test loss:  7.576392650604248\n",
      "test r2:  -0.29678793019437233\n",
      "train loss:  1.867130160331726\n",
      "train r2:  0.8719055377871235\n",
      "test loss:  7.577300548553467\n",
      "test r2:  -0.29685885000025913\n",
      "train loss:  1.866988182067871\n",
      "train r2:  0.8719080322769188\n",
      "test loss:  7.577182292938232\n",
      "test r2:  -0.2968407393606367\n",
      "train loss:  1.8668467998504639\n",
      "train r2:  0.8719164042975751\n",
      "test loss:  7.57615327835083\n",
      "test r2:  -0.29676358733086383\n",
      "train loss:  1.8667051792144775\n",
      "train r2:  0.8719244448158249\n",
      "test loss:  7.575438976287842\n",
      "test r2:  -0.29672018665328115\n",
      "train loss:  1.8665658235549927\n",
      "train r2:  0.8719287916593983\n",
      "test loss:  7.575642108917236\n",
      "test r2:  -0.296737563607929\n",
      "train loss:  1.8664259910583496\n",
      "train r2:  0.8719328905407231\n",
      "test loss:  7.5763092041015625\n",
      "test r2:  -0.2967789971239849\n",
      "train loss:  1.866287112236023\n",
      "train r2:  0.8719386600861704\n",
      "test loss:  7.576465129852295\n",
      "test r2:  -0.2967901514361093\n",
      "train loss:  1.86614990234375\n",
      "train r2:  0.8719433983193932\n",
      "test loss:  7.5757951736450195\n",
      "test r2:  -0.2967498783504907\n",
      "train loss:  1.8660118579864502\n",
      "train r2:  0.8719473259884556\n",
      "test loss:  7.575130939483643\n",
      "test r2:  -0.2967004745619788\n",
      "train loss:  1.8658761978149414\n",
      "train r2:  0.8719538420321005\n",
      "test loss:  7.57517671585083\n",
      "test r2:  -0.2966967725019751\n",
      "train loss:  1.865740180015564\n",
      "train r2:  0.8719606251400823\n",
      "test loss:  7.575718879699707\n",
      "test r2:  -0.2967390055723149\n",
      "train loss:  1.8656049966812134\n",
      "train r2:  0.8719636679212996\n",
      "test loss:  7.575871467590332\n",
      "test r2:  -0.29675850287150074\n",
      "train loss:  1.8654708862304688\n",
      "train r2:  0.8719659937935723\n",
      "test loss:  7.575301647186279\n",
      "test r2:  -0.2967149782014975\n",
      "train loss:  1.8653366565704346\n",
      "train r2:  0.8719726380582314\n",
      "test loss:  7.5747785568237305\n",
      "test r2:  -0.2966689579694808\n",
      "train loss:  1.8652037382125854\n",
      "train r2:  0.8719808246826789\n",
      "test loss:  7.574905872344971\n",
      "test r2:  -0.2966810828789872\n",
      "train loss:  1.8650710582733154\n",
      "train r2:  0.8719848277840418\n",
      "test loss:  7.5753374099731445\n",
      "test r2:  -0.29671989905263807\n",
      "train loss:  1.8649392127990723\n",
      "train r2:  0.8719870283984665\n",
      "test loss:  7.5752973556518555\n",
      "test r2:  -0.2967152237285289\n",
      "train loss:  1.8648080825805664\n",
      "train r2:  0.8719927339631995\n",
      "test loss:  7.57478141784668\n",
      "test r2:  -0.2966717473708784\n",
      "train loss:  1.86467707157135\n",
      "train r2:  0.8720005833256896\n",
      "test loss:  7.574505805969238\n",
      "test r2:  -0.2966523886512158\n",
      "train loss:  1.8645472526550293\n",
      "train r2:  0.8720061869634665\n",
      "test loss:  7.574734210968018\n",
      "test r2:  -0.296673320967378\n",
      "train loss:  1.864417552947998\n",
      "train r2:  0.8720097978905653\n",
      "test loss:  7.574978828430176\n",
      "test r2:  -0.296690310354055\n",
      "train loss:  1.8642888069152832\n",
      "train r2:  0.8720147978402656\n",
      "test loss:  7.5747599601745605\n",
      "test r2:  -0.29667145682495955\n",
      "train loss:  1.864160180091858\n",
      "train r2:  0.8720213570198289\n",
      "test loss:  7.574383735656738\n",
      "test r2:  -0.29664341348673506\n",
      "train loss:  1.86403226852417\n",
      "train r2:  0.8720275563729091\n",
      "test loss:  7.574365139007568\n",
      "test r2:  -0.29664249601901393\n",
      "train loss:  1.8639048337936401\n",
      "train r2:  0.8720328061678665\n",
      "test loss:  7.574623107910156\n",
      "test r2:  -0.2966605732569976\n",
      "train loss:  1.863777756690979\n",
      "train r2:  0.8720377598055906\n",
      "test loss:  7.574652194976807\n",
      "test r2:  -0.29666257045705935\n",
      "train loss:  1.8636516332626343\n",
      "train r2:  0.8720430060347172\n",
      "test loss:  7.57436990737915\n",
      "test r2:  -0.29664157678576575\n",
      "train loss:  1.863525390625\n",
      "train r2:  0.8720488676819503\n",
      "test loss:  7.574233531951904\n",
      "test r2:  -0.2966283758756938\n",
      "train loss:  1.8634002208709717\n",
      "train r2:  0.8720551969067661\n",
      "test loss:  7.574425220489502\n",
      "test r2:  -0.2966405320444474\n",
      "train loss:  1.8632748126983643\n",
      "train r2:  0.8720604347957344\n",
      "test loss:  7.574585437774658\n",
      "test r2:  -0.29665411863407276\n",
      "train loss:  1.8631503582000732\n",
      "train r2:  0.8720646319435674\n",
      "test loss:  7.574435710906982\n",
      "test r2:  -0.2966429912841244\n",
      "train loss:  1.8630261421203613\n",
      "train r2:  0.8720700106407733\n",
      "test loss:  7.574291706085205\n",
      "test r2:  -0.2966266523159138\n",
      "train loss:  1.8629025220870972\n",
      "train r2:  0.8720768642568849\n",
      "test loss:  7.574448108673096\n",
      "test r2:  -0.29663512845073825\n",
      "train loss:  1.8627792596817017\n",
      "train r2:  0.8720822795056209\n",
      "test loss:  7.57466459274292\n",
      "test r2:  -0.2966536495569281\n",
      "train loss:  1.8626562356948853\n",
      "train r2:  0.8720859960948091\n",
      "test loss:  7.574623107910156\n",
      "test r2:  -0.2966501377191333\n",
      "train loss:  1.8625339269638062\n",
      "train r2:  0.8720910291075685\n",
      "test loss:  7.574532985687256\n",
      "test r2:  -0.29663615706062996\n",
      "train loss:  1.8624118566513062\n",
      "train r2:  0.8720980241813261\n",
      "test loss:  7.57469367980957\n",
      "test r2:  -0.2966434394330164\n",
      "train loss:  1.8622897863388062\n",
      "train r2:  0.8721037208671795\n",
      "test loss:  7.574944972991943\n",
      "test r2:  -0.2966644732567336\n",
      "train loss:  1.862168312072754\n",
      "train r2:  0.8721072008113379\n",
      "test loss:  7.574983596801758\n",
      "test r2:  -0.2966663920526549\n",
      "train loss:  1.8620474338531494\n",
      "train r2:  0.8721120662863941\n",
      "test loss:  7.5749711990356445\n",
      "test r2:  -0.29665616606767564\n",
      "train loss:  1.8619266748428345\n",
      "train r2:  0.8721193433840817\n",
      "test loss:  7.575178146362305\n",
      "test r2:  -0.29666542383525263\n",
      "train loss:  1.861806035041809\n",
      "train r2:  0.8721251926437088\n",
      "test loss:  7.575466632843018\n",
      "test r2:  -0.2966890612417348\n",
      "train loss:  1.861686110496521\n",
      "train r2:  0.8721284923978915\n",
      "test loss:  7.575573921203613\n",
      "test r2:  -0.29669450466425573\n",
      "train loss:  1.8615658283233643\n",
      "train r2:  0.8721335534507144\n",
      "test loss:  7.575659275054932\n",
      "test r2:  -0.29668918709799463\n",
      "train loss:  1.8614463806152344\n",
      "train r2:  0.8721411007425158\n",
      "test loss:  7.575949192047119\n",
      "test r2:  -0.2967038223163745\n",
      "train loss:  1.8613269329071045\n",
      "train r2:  0.8721467957256197\n",
      "test loss:  7.5762834548950195\n",
      "test r2:  -0.296730122248003\n",
      "train loss:  1.8612078428268433\n",
      "train r2:  0.8721500905912585\n",
      "test loss:  7.576470851898193\n",
      "test r2:  -0.2967386323087988\n",
      "train loss:  1.8610888719558716\n",
      "train r2:  0.8721555273729442\n",
      "test loss:  7.576690196990967\n",
      "test r2:  -0.2967408773871971\n",
      "train loss:  1.8609704971313477\n",
      "train r2:  0.8721631886796335\n",
      "test loss:  7.577090740203857\n",
      "test r2:  -0.29676323411078886\n",
      "train loss:  1.8608518838882446\n",
      "train r2:  0.8721685267110258\n",
      "test loss:  7.5774922370910645\n",
      "test r2:  -0.2967924977476073\n",
      "train loss:  1.8607336282730103\n",
      "train r2:  0.8721719152429622\n",
      "test loss:  7.577798366546631\n",
      "test r2:  -0.2968059548679918\n",
      "train loss:  1.8606154918670654\n",
      "train r2:  0.8721778501449762\n",
      "test loss:  7.578193187713623\n",
      "test r2:  -0.29681872157724376\n",
      "train loss:  1.8604974746704102\n",
      "train r2:  0.8721854679293883\n",
      "test loss:  7.578732013702393\n",
      "test r2:  -0.29685087790083076\n",
      "train loss:  1.860379695892334\n",
      "train r2:  0.8721902524201524\n",
      "test loss:  7.579241752624512\n",
      "test r2:  -0.296885403065841\n",
      "train loss:  1.8602617979049683\n",
      "train r2:  0.8721938013544298\n",
      "test loss:  7.57973051071167\n",
      "test r2:  -0.2969069561101241\n",
      "train loss:  1.8601443767547607\n",
      "train r2:  0.8722003746837216\n",
      "test loss:  7.580348014831543\n",
      "test r2:  -0.29693405080330715\n",
      "train loss:  1.8600265979766846\n",
      "train r2:  0.8722076627523716\n",
      "test loss:  7.581056594848633\n",
      "test r2:  -0.2969779250967901\n",
      "train loss:  1.8599090576171875\n",
      "train r2:  0.8722118559804304\n",
      "test loss:  7.581752300262451\n",
      "test r2:  -0.2970208062957367\n",
      "train loss:  1.859791874885559\n",
      "train r2:  0.8722159613891155\n",
      "test loss:  7.5825090408325195\n",
      "test r2:  -0.2970561301998573\n",
      "train loss:  1.8596742153167725\n",
      "train r2:  0.8722231257863938\n",
      "test loss:  7.583396911621094\n",
      "test r2:  -0.2971017790813535\n",
      "train loss:  1.8595569133758545\n",
      "train r2:  0.8722296783677966\n",
      "test loss:  7.584342956542969\n",
      "test r2:  -0.29716057198281143\n",
      "train loss:  1.8594392538070679\n",
      "train r2:  0.8722335408671824\n",
      "test loss:  7.585342884063721\n",
      "test r2:  -0.2972179914682058\n",
      "train loss:  1.8593217134475708\n",
      "train r2:  0.8722386361041641\n",
      "test loss:  7.586463928222656\n",
      "test r2:  -0.2972747959398876\n",
      "train loss:  1.8592042922973633\n",
      "train r2:  0.8722459646457328\n",
      "test loss:  7.587686061859131\n",
      "test r2:  -0.29734318442262486\n",
      "train loss:  1.8590861558914185\n",
      "train r2:  0.8722518285610127\n",
      "test loss:  7.589004039764404\n",
      "test r2:  -0.2974238352105467\n",
      "train loss:  1.8589683771133423\n",
      "train r2:  0.8722559007081737\n",
      "test loss:  7.590456962585449\n",
      "test r2:  -0.2975063277993937\n",
      "train loss:  1.858850121498108\n",
      "train r2:  0.8722619228140869\n",
      "test loss:  7.59202766418457\n",
      "test r2:  -0.2975917281331921\n",
      "train loss:  1.858731746673584\n",
      "train r2:  0.8722691640279041\n",
      "test loss:  7.593717575073242\n",
      "test r2:  -0.29769177812090786\n",
      "train loss:  1.8586130142211914\n",
      "train r2:  0.8722745092289418\n",
      "test loss:  7.595582962036133\n",
      "test r2:  -0.2978054339101308\n",
      "train loss:  1.8584941625595093\n",
      "train r2:  0.8722793667139671\n",
      "test loss:  7.597595691680908\n",
      "test r2:  -0.2979219652961498\n",
      "train loss:  1.858374834060669\n",
      "train r2:  0.8722861205229491\n",
      "test loss:  7.599715709686279\n",
      "test r2:  -0.2980455497162995\n",
      "train loss:  1.8582550287246704\n",
      "train r2:  0.872293016531148\n",
      "test loss:  7.602012634277344\n",
      "test r2:  -0.29818682202045355\n",
      "train loss:  1.8581351041793823\n",
      "train r2:  0.8722985070388433\n",
      "test loss:  7.604478359222412\n",
      "test r2:  -0.298339385479403\n",
      "train loss:  1.8580148220062256\n",
      "train r2:  0.8723042661144755\n",
      "test loss:  7.607005596160889\n",
      "test r2:  -0.29849262957149714\n",
      "train loss:  1.857893943786621\n",
      "train r2:  0.8723114069144274\n",
      "test loss:  7.609614849090576\n",
      "test r2:  -0.2986537829332021\n",
      "train loss:  1.857772946357727\n",
      "train r2:  0.8723183970073303\n",
      "test loss:  7.612308979034424\n",
      "test r2:  -0.29882627605289613\n",
      "train loss:  1.857651710510254\n",
      "train r2:  0.8723243821359759\n",
      "test loss:  7.614935398101807\n",
      "test r2:  -0.2989947305892344\n",
      "train loss:  1.857529878616333\n",
      "train r2:  0.87233099764665\n",
      "test loss:  7.617419242858887\n",
      "test r2:  -0.29915211026625443\n",
      "train loss:  1.8574081659317017\n",
      "train r2:  0.8723386750136378\n",
      "test loss:  7.61973237991333\n",
      "test r2:  -0.29930184591642806\n",
      "train loss:  1.857285976409912\n",
      "train r2:  0.8723460057754427\n",
      "test loss:  7.621731281280518\n",
      "test r2:  -0.2994349522531934\n",
      "train loss:  1.8571635484695435\n",
      "train r2:  0.8723526413366423\n",
      "test loss:  7.623336315155029\n",
      "test r2:  -0.2995399986451308\n",
      "train loss:  1.8570407629013062\n",
      "train r2:  0.8723601152593059\n",
      "test loss:  7.624536514282227\n",
      "test r2:  -0.2996162427762563\n",
      "train loss:  1.8569176197052002\n",
      "train r2:  0.8723682850535888\n",
      "test loss:  7.625311374664307\n",
      "test r2:  -0.29966714436240616\n",
      "train loss:  1.8567941188812256\n",
      "train r2:  0.87237551740933\n",
      "test loss:  7.625740051269531\n",
      "test r2:  -0.2996951955287557\n",
      "train loss:  1.8566696643829346\n",
      "train r2:  0.8723825633839618\n",
      "test loss:  7.62590217590332\n",
      "test r2:  -0.29970237150664136\n",
      "train loss:  1.8565443754196167\n",
      "train r2:  0.8723902169035269\n",
      "test loss:  7.625886917114258\n",
      "test r2:  -0.2996981300146806\n",
      "train loss:  1.8564181327819824\n",
      "train r2:  0.8723975132203071\n",
      "test loss:  7.62584114074707\n",
      "test r2:  -0.2996935274704231\n",
      "train loss:  1.8562909364700317\n",
      "train r2:  0.8724039903409351\n",
      "test loss:  7.625791549682617\n",
      "test r2:  -0.2996887914179238\n",
      "train loss:  1.856162428855896\n",
      "train r2:  0.8724101598071989\n",
      "test loss:  7.625740051269531\n",
      "test r2:  -0.29968203869131416\n",
      "train loss:  1.8560327291488647\n",
      "train r2:  0.872416482295121\n",
      "test loss:  7.625708103179932\n",
      "test r2:  -0.2996772644854102\n",
      "train loss:  1.8559014797210693\n",
      "train r2:  0.8724222921332777\n",
      "test loss:  7.625606060028076\n",
      "test r2:  -0.2996698713518138\n",
      "train loss:  1.8557690382003784\n",
      "train r2:  0.8724272566367185\n",
      "test loss:  7.6254072189331055\n",
      "test r2:  -0.29965525367400514\n",
      "train loss:  1.855635166168213\n",
      "train r2:  0.8724321790861227\n",
      "test loss:  7.625051975250244\n",
      "test r2:  -0.299628071560615\n",
      "train loss:  1.8554997444152832\n",
      "train r2:  0.872437371835898\n",
      "test loss:  7.624533176422119\n",
      "test r2:  -0.29959179332571884\n",
      "train loss:  1.8553625345230103\n",
      "train r2:  0.8724419202294595\n",
      "test loss:  7.623891830444336\n",
      "test r2:  -0.29954750772182015\n",
      "train loss:  1.8552241325378418\n",
      "train r2:  0.8724461826554388\n",
      "test loss:  7.623130798339844\n",
      "test r2:  -0.2994950395807965\n",
      "train loss:  1.8550838232040405\n",
      "train r2:  0.8724505359965418\n",
      "test loss:  7.622334003448486\n",
      "test r2:  -0.29943891874078776\n",
      "train loss:  1.854941725730896\n",
      "train r2:  0.8724552225942953\n",
      "test loss:  7.621570110321045\n",
      "test r2:  -0.29938640474931755\n",
      "train loss:  1.8547974824905396\n",
      "train r2:  0.8724594806522374\n",
      "test loss:  7.620886325836182\n",
      "test r2:  -0.299340171769263\n",
      "train loss:  1.8546512126922607\n",
      "train r2:  0.8724635901280928\n",
      "test loss:  7.620339870452881\n",
      "test r2:  -0.2993020299408593\n",
      "train loss:  1.8545030355453491\n",
      "train r2:  0.8724681202452865\n",
      "test loss:  7.619937419891357\n",
      "test r2:  -0.29927293973531066\n",
      "train loss:  1.8543530702590942\n",
      "train r2:  0.8724728561049178\n",
      "test loss:  7.619716167449951\n",
      "test r2:  -0.2992574093620286\n",
      "train loss:  1.8542004823684692\n",
      "train r2:  0.8724773447268614\n",
      "test loss:  7.619651794433594\n",
      "test r2:  -0.29925250083270893\n",
      "train loss:  1.8540459871292114\n",
      "train r2:  0.87248188550298\n",
      "test loss:  7.61970853805542\n",
      "test r2:  -0.2992542319010987\n",
      "train loss:  1.8538898229599\n",
      "train r2:  0.8724869590682399\n",
      "test loss:  7.619876384735107\n",
      "test r2:  -0.2992633330447301\n",
      "train loss:  1.853731393814087\n",
      "train r2:  0.8724921826987266\n",
      "test loss:  7.62009859085083\n",
      "test r2:  -0.29927722161318715\n",
      "train loss:  1.8535716533660889\n",
      "train r2:  0.8724972222014377\n",
      "test loss:  7.620348930358887\n",
      "test r2:  -0.2992923398363019\n",
      "train loss:  1.8534103631973267\n",
      "train r2:  0.8725026176158663\n",
      "test loss:  7.620585918426514\n",
      "test r2:  -0.29930612750346364\n",
      "train loss:  1.8532482385635376\n",
      "train r2:  0.8725082580714038\n",
      "test loss:  7.620790481567383\n",
      "test r2:  -0.2993177765031134\n",
      "train loss:  1.8530861139297485\n",
      "train r2:  0.872513966261695\n",
      "test loss:  7.620965480804443\n",
      "test r2:  -0.29932809250538583\n",
      "train loss:  1.8529237508773804\n",
      "train r2:  0.872519527267553\n",
      "test loss:  7.621091842651367\n",
      "test r2:  -0.29933510415818776\n",
      "train loss:  1.8527621030807495\n",
      "train r2:  0.8725250841183143\n",
      "test loss:  7.621194362640381\n",
      "test r2:  -0.2993396600654994\n",
      "train loss:  1.852602481842041\n",
      "train r2:  0.8725308276841893\n",
      "test loss:  7.621278285980225\n",
      "test r2:  -0.29934342515194556\n",
      "train loss:  1.8524448871612549\n",
      "train r2:  0.8725363139564467\n",
      "test loss:  7.621367931365967\n",
      "test r2:  -0.29934835539192073\n",
      "train loss:  1.8522905111312866\n",
      "train r2:  0.8725414011347846\n",
      "test loss:  7.621460437774658\n",
      "test r2:  -0.29935353523889185\n",
      "train loss:  1.8521397113800049\n",
      "train r2:  0.8725462658019982\n",
      "test loss:  7.621555805206299\n",
      "test r2:  -0.29935788456317236\n",
      "train loss:  1.851993441581726\n",
      "train r2:  0.872551151201445\n",
      "test loss:  7.621655464172363\n",
      "test r2:  -0.29936352207076045\n",
      "train loss:  1.8518519401550293\n",
      "train r2:  0.8725555386307798\n",
      "test loss:  7.621740818023682\n",
      "test r2:  -0.29936918276368996\n",
      "train loss:  1.8517154455184937\n",
      "train r2:  0.8725594129365868\n",
      "test loss:  7.621797561645508\n",
      "test r2:  -0.29937207914126995\n",
      "train loss:  1.8515832424163818\n",
      "train r2:  0.8725631877123439\n",
      "test loss:  7.621800422668457\n",
      "test r2:  -0.2993713990160727\n",
      "train loss:  1.8514553308486938\n",
      "train r2:  0.8725666991269347\n",
      "test loss:  7.621756076812744\n",
      "test r2:  -0.29936775259679216\n",
      "train loss:  1.8513307571411133\n",
      "train r2:  0.8725699652491601\n",
      "test loss:  7.621650695800781\n",
      "test r2:  -0.29936105755088827\n",
      "train loss:  1.8512083292007446\n",
      "train r2:  0.8725727531178793\n",
      "test loss:  7.621498107910156\n",
      "test r2:  -0.2993502392541685\n",
      "train loss:  1.8510863780975342\n",
      "train r2:  0.8725756179783863\n",
      "test loss:  7.621298313140869\n",
      "test r2:  -0.29933622997446707\n",
      "train loss:  1.850964069366455\n",
      "train r2:  0.8725784011027892\n",
      "test loss:  7.621093273162842\n",
      "test r2:  -0.29932287989171025\n",
      "train loss:  1.8508405685424805\n",
      "train r2:  0.8725807817437893\n",
      "test loss:  7.620872497558594\n",
      "test r2:  -0.29930838011914607\n",
      "train loss:  1.8507155179977417\n",
      "train r2:  0.8725831807262979\n",
      "test loss:  7.620674133300781\n",
      "test r2:  -0.2992946619506598\n",
      "train loss:  1.8505879640579224\n",
      "train r2:  0.8725857548490537\n",
      "test loss:  7.620488166809082\n",
      "test r2:  -0.29928274690536094\n",
      "train loss:  1.8504588603973389\n",
      "train r2:  0.8725880772758884\n",
      "test loss:  7.620345592498779\n",
      "test r2:  -0.2992737479042189\n",
      "train loss:  1.8503285646438599\n",
      "train r2:  0.8725903914308755\n",
      "test loss:  7.620211601257324\n",
      "test r2:  -0.2992651167635072\n",
      "train loss:  1.8501973152160645\n",
      "train r2:  0.8725927836662921\n",
      "test loss:  7.620115280151367\n",
      "test r2:  -0.29925911256704496\n",
      "train loss:  1.8500664234161377\n",
      "train r2:  0.8725952726379641\n",
      "test loss:  7.620019435882568\n",
      "test r2:  -0.2992533277014553\n",
      "train loss:  1.8499364852905273\n",
      "train r2:  0.8725977073172375\n",
      "test loss:  7.619949817657471\n",
      "test r2:  -0.2992489503212732\n",
      "train loss:  1.849807858467102\n",
      "train r2:  0.8726003217957938\n",
      "test loss:  7.619863510131836\n",
      "test r2:  -0.2992432978374291\n",
      "train loss:  1.8496813774108887\n",
      "train r2:  0.872603045009062\n",
      "test loss:  7.619806289672852\n",
      "test r2:  -0.2992396772620214\n",
      "train loss:  1.8495566844940186\n",
      "train r2:  0.8726058781650682\n",
      "test loss:  7.619726657867432\n",
      "test r2:  -0.2992345739758333\n",
      "train loss:  1.8494340181350708\n",
      "train r2:  0.872608739292093\n",
      "test loss:  7.61968994140625\n",
      "test r2:  -0.29923162162162953\n",
      "train loss:  1.8493132591247559\n",
      "train r2:  0.8726118704569312\n",
      "test loss:  7.619624137878418\n",
      "test r2:  -0.2992270547197142\n",
      "train loss:  1.849194049835205\n",
      "train r2:  0.8726150170108519\n",
      "test loss:  7.619628429412842\n",
      "test r2:  -0.29922682679060264\n",
      "train loss:  1.8490760326385498\n",
      "train r2:  0.8726182816182245\n",
      "test loss:  7.619585037231445\n",
      "test r2:  -0.29922413316596663\n",
      "train loss:  1.84895920753479\n",
      "train r2:  0.8726214705495734\n",
      "test loss:  7.6196370124816895\n",
      "test r2:  -0.29922612626967826\n",
      "train loss:  1.848842740058899\n",
      "train r2:  0.8726251008570823\n",
      "test loss:  7.619596481323242\n",
      "test r2:  -0.29922368442720026\n",
      "train loss:  1.8487271070480347\n",
      "train r2:  0.8726283039409067\n",
      "test loss:  7.619700908660889\n",
      "test r2:  -0.2992289896183875\n",
      "train loss:  1.8486117124557495\n",
      "train r2:  0.8726320455055591\n",
      "test loss:  7.6196088790893555\n",
      "test r2:  -0.2992241010260037\n",
      "train loss:  1.8484965562820435\n",
      "train r2:  0.872635130722543\n",
      "test loss:  7.619771957397461\n",
      "test r2:  -0.2992314762339723\n",
      "train loss:  1.8483814001083374\n",
      "train r2:  0.8726393656920708\n",
      "test loss:  7.619535446166992\n",
      "test r2:  -0.29921847185448813\n",
      "train loss:  1.8482664823532104\n",
      "train r2:  0.8726421593005571\n",
      "test loss:  7.619826793670654\n",
      "test r2:  -0.29923225916526763\n",
      "train loss:  1.8481522798538208\n",
      "train r2:  0.872646907336203\n",
      "test loss:  7.619297981262207\n",
      "test r2:  -0.299203764306855\n",
      "train loss:  1.848039150238037\n",
      "train r2:  0.8726487206027165\n",
      "test loss:  7.619869709014893\n",
      "test r2:  -0.29922909935141373\n",
      "train loss:  1.8479264974594116\n",
      "train r2:  0.8726552609914815\n",
      "test loss:  7.618842601776123\n",
      "test r2:  -0.2991758729882783\n",
      "train loss:  1.847816824913025\n",
      "train r2:  0.8726549498433012\n",
      "test loss:  7.619816303253174\n",
      "test r2:  -0.2992186890265842\n",
      "train loss:  1.8477035760879517\n",
      "train r2:  0.8726637719220044\n",
      "test loss:  7.618635177612305\n",
      "test r2:  -0.2991620455004973\n",
      "train loss:  1.8475937843322754\n",
      "train r2:  0.8726616549844963\n",
      "test loss:  7.619433879852295\n",
      "test r2:  -0.2991939491653075\n",
      "train loss:  1.8474793434143066\n",
      "train r2:  0.8726702829705153\n",
      "test loss:  7.619047164916992\n",
      "test r2:  -0.2991775834602197\n",
      "train loss:  1.8473681211471558\n",
      "train r2:  0.8726712336651832\n",
      "test loss:  7.618704319000244\n",
      "test r2:  -0.2991588398894496\n",
      "train loss:  1.8472601175308228\n",
      "train r2:  0.8726735870949582\n",
      "test loss:  7.619110584259033\n",
      "test r2:  -0.2991677346384818\n",
      "train loss:  1.8471531867980957\n",
      "train r2:  0.8726817119638028\n",
      "test loss:  7.618142604827881\n",
      "test r2:  -0.2991201993795791\n",
      "train loss:  1.8470468521118164\n",
      "train r2:  0.8726809983701425\n",
      "test loss:  7.618751049041748\n",
      "test r2:  -0.299144115780273\n",
      "train loss:  1.846936821937561\n",
      "train r2:  0.8726886344614568\n",
      "test loss:  7.618374347686768\n",
      "test r2:  -0.2991278743174832\n",
      "train loss:  1.846828579902649\n",
      "train r2:  0.8726899841894101\n",
      "test loss:  7.618072032928467\n",
      "test r2:  -0.2991075932267686\n",
      "train loss:  1.8467222452163696\n",
      "train r2:  0.8726937231575851\n",
      "test loss:  7.618406295776367\n",
      "test r2:  -0.29911378460594795\n",
      "train loss:  1.8466168642044067\n",
      "train r2:  0.8727015607807098\n",
      "test loss:  7.6176838874816895\n",
      "test r2:  -0.29908265226747344\n",
      "train loss:  1.846510887145996\n",
      "train r2:  0.8727010491049365\n",
      "test loss:  7.618125915527344\n",
      "test r2:  -0.29909784176298326\n",
      "train loss:  1.8464035987854004\n",
      "train r2:  0.8727084423279445\n",
      "test loss:  7.617878437042236\n",
      "test r2:  -0.2990831973892609\n",
      "train loss:  1.8462976217269897\n",
      "train r2:  0.8727119025059966\n",
      "test loss:  7.617602348327637\n",
      "test r2:  -0.29906775371113214\n",
      "train loss:  1.8461928367614746\n",
      "train r2:  0.8727150933169373\n",
      "test loss:  7.617930889129639\n",
      "test r2:  -0.29907743028134903\n",
      "train loss:  1.8460884094238281\n",
      "train r2:  0.8727221229325866\n",
      "test loss:  7.617364406585693\n",
      "test r2:  -0.29905075699608474\n",
      "train loss:  1.8459843397140503\n",
      "train r2:  0.872723381293239\n",
      "test loss:  7.617668151855469\n",
      "test r2:  -0.2990583881603919\n",
      "train loss:  1.8458795547485352\n",
      "train r2:  0.8727305730192245\n",
      "test loss:  7.61749267578125\n",
      "test r2:  -0.2990490144415294\n",
      "train loss:  1.8457754850387573\n",
      "train r2:  0.8727340189924896\n",
      "test loss:  7.617246627807617\n",
      "test r2:  -0.299035785340376\n",
      "train loss:  1.8456727266311646\n",
      "train r2:  0.8727372665178617\n",
      "test loss:  7.617485523223877\n",
      "test r2:  -0.2990386293625056\n",
      "train loss:  1.8455703258514404\n",
      "train r2:  0.8727446953747057\n",
      "test loss:  7.617016792297363\n",
      "test r2:  -0.299015881941332\n",
      "train loss:  1.8454675674438477\n",
      "train r2:  0.8727466411298725\n",
      "test loss:  7.617249965667725\n",
      "test r2:  -0.29902277368167796\n",
      "train loss:  1.8453646898269653\n",
      "train r2:  0.8727528909837629\n",
      "test loss:  7.617059707641602\n",
      "test r2:  -0.2990108873067334\n",
      "train loss:  1.8452624082565308\n",
      "train r2:  0.8727568127716804\n",
      "test loss:  7.616869926452637\n",
      "test r2:  -0.29899767813022704\n",
      "train loss:  1.845160961151123\n",
      "train r2:  0.8727611581951633\n",
      "test loss:  7.617012023925781\n",
      "test r2:  -0.2989983843614632\n",
      "train loss:  1.8450591564178467\n",
      "train r2:  0.8727675238044825\n",
      "test loss:  7.616607189178467\n",
      "test r2:  -0.29897876439297777\n",
      "train loss:  1.8449583053588867\n",
      "train r2:  0.8727698508051529\n",
      "test loss:  7.61677360534668\n",
      "test r2:  -0.29897942534725663\n",
      "train loss:  1.8448567390441895\n",
      "train r2:  0.8727766393965618\n",
      "test loss:  7.616504192352295\n",
      "test r2:  -0.2989632886568132\n",
      "train loss:  1.8447555303573608\n",
      "train r2:  0.8727804470853512\n",
      "test loss:  7.616395473480225\n",
      "test r2:  -0.29895415128096525\n",
      "train loss:  1.8446545600891113\n",
      "train r2:  0.8727851035114367\n",
      "test loss:  7.616384983062744\n",
      "test r2:  -0.2989477008690884\n",
      "train loss:  1.8445543050765991\n",
      "train r2:  0.8727907546416138\n",
      "test loss:  7.616029739379883\n",
      "test r2:  -0.29892677390685574\n",
      "train loss:  1.8444541692733765\n",
      "train r2:  0.8727943579411722\n",
      "test loss:  7.616132736206055\n",
      "test r2:  -0.29892494290800586\n",
      "train loss:  1.844354271888733\n",
      "train r2:  0.8728007607921295\n",
      "test loss:  7.615792751312256\n",
      "test r2:  -0.29890597479580583\n",
      "train loss:  1.8442542552947998\n",
      "train r2:  0.8728041387143828\n",
      "test loss:  7.615776062011719\n",
      "test r2:  -0.29889865828034146\n",
      "train loss:  1.8441544771194458\n",
      "train r2:  0.8728099900019666\n",
      "test loss:  7.615607738494873\n",
      "test r2:  -0.29888502135066997\n",
      "train loss:  1.8440550565719604\n",
      "train r2:  0.8728148855773982\n",
      "test loss:  7.615393161773682\n",
      "test r2:  -0.2988709414171222\n",
      "train loss:  1.843955636024475\n",
      "train r2:  0.8728191731198494\n",
      "test loss:  7.615391731262207\n",
      "test r2:  -0.29886481994625336\n",
      "train loss:  1.8438568115234375\n",
      "train r2:  0.8728250483494115\n",
      "test loss:  7.6150617599487305\n",
      "test r2:  -0.29884421261812166\n",
      "train loss:  1.8437579870224\n",
      "train r2:  0.8728291043599683\n",
      "test loss:  7.615098476409912\n",
      "test r2:  -0.29883942086345394\n",
      "train loss:  1.8436590433120728\n",
      "train r2:  0.8728352565705817\n",
      "test loss:  7.614805698394775\n",
      "test r2:  -0.298821730435616\n",
      "train loss:  1.8435606956481934\n",
      "train r2:  0.8728391692276766\n",
      "test loss:  7.61475944519043\n",
      "test r2:  -0.29881329353972896\n",
      "train loss:  1.8434618711471558\n",
      "train r2:  0.8728449358445202\n",
      "test loss:  7.614572048187256\n",
      "test r2:  -0.2987988290408352\n",
      "train loss:  1.843363642692566\n",
      "train r2:  0.8728498996888345\n",
      "test loss:  7.614402770996094\n",
      "test r2:  -0.29878566824631947\n",
      "train loss:  1.8432658910751343\n",
      "train r2:  0.8728548274695286\n",
      "test loss:  7.614330768585205\n",
      "test r2:  -0.29877660143829465\n",
      "train loss:  1.8431681394577026\n",
      "train r2:  0.8728603127574708\n",
      "test loss:  7.614068984985352\n",
      "test r2:  -0.2987589554435661\n",
      "train loss:  1.8430700302124023\n",
      "train r2:  0.8728648992722376\n",
      "test loss:  7.614056587219238\n",
      "test r2:  -0.2987516193557409\n",
      "train loss:  1.8429725170135498\n",
      "train r2:  0.8728710326927253\n",
      "test loss:  7.61376953125\n",
      "test r2:  -0.2987339371083142\n",
      "train loss:  1.8428750038146973\n",
      "train r2:  0.8728751900370869\n",
      "test loss:  7.613766193389893\n",
      "test r2:  -0.29872720684199217\n",
      "train loss:  1.8427776098251343\n",
      "train r2:  0.8728813044573293\n",
      "test loss:  7.613487720489502\n",
      "test r2:  -0.2987087714887948\n",
      "train loss:  1.8426802158355713\n",
      "train r2:  0.8728858868278504\n",
      "test loss:  7.6134538650512695\n",
      "test r2:  -0.2987009044197828\n",
      "train loss:  1.842583179473877\n",
      "train r2:  0.8728918393528526\n",
      "test loss:  7.613211154937744\n",
      "test r2:  -0.29868457364836853\n",
      "train loss:  1.8424861431121826\n",
      "train r2:  0.8728964479158727\n",
      "test loss:  7.613128185272217\n",
      "test r2:  -0.2986741284308292\n",
      "train loss:  1.8423895835876465\n",
      "train r2:  0.872902266616841\n",
      "test loss:  7.612916946411133\n",
      "test r2:  -0.29865805797427014\n",
      "train loss:  1.8422924280166626\n",
      "train r2:  0.8729073688257938\n",
      "test loss:  7.612791061401367\n",
      "test r2:  -0.2986461194405001\n",
      "train loss:  1.842195987701416\n",
      "train r2:  0.8729128494928616\n",
      "test loss:  7.612611293792725\n",
      "test r2:  -0.29863180483934504\n",
      "train loss:  1.8420994281768799\n",
      "train r2:  0.8729180077864174\n",
      "test loss:  7.612448215484619\n",
      "test r2:  -0.29861751099029954\n",
      "train loss:  1.8420032262802124\n",
      "train r2:  0.8729235223373464\n",
      "test loss:  7.612288951873779\n",
      "test r2:  -0.29860340470493174\n",
      "train loss:  1.8419065475463867\n",
      "train r2:  0.8729290088800166\n",
      "test loss:  7.61210298538208\n",
      "test r2:  -0.2985892119210356\n",
      "train loss:  1.8418104648590088\n",
      "train r2:  0.8729340965912806\n",
      "test loss:  7.611963272094727\n",
      "test r2:  -0.29857603225463514\n",
      "train loss:  1.8417145013809204\n",
      "train r2:  0.8729396814272046\n",
      "test loss:  7.61174201965332\n",
      "test r2:  -0.2985586113625365\n",
      "train loss:  1.8416186571121216\n",
      "train r2:  0.8729450156725003\n",
      "test loss:  7.611627578735352\n",
      "test r2:  -0.298546930890629\n",
      "train loss:  1.8415225744247437\n",
      "train r2:  0.8729506473694235\n",
      "test loss:  7.6113691329956055\n",
      "test r2:  -0.2985287503385998\n",
      "train loss:  1.8414268493652344\n",
      "train r2:  0.8729555447596554\n",
      "test loss:  7.611294269561768\n",
      "test r2:  -0.2985177067876852\n",
      "train loss:  1.8413314819335938\n",
      "train r2:  0.8729616707760505\n",
      "test loss:  7.6109619140625\n",
      "test r2:  -0.29849596293131886\n",
      "train loss:  1.8412359952926636\n",
      "train r2:  0.8729662681274952\n",
      "test loss:  7.610979080200195\n",
      "test r2:  -0.29848936561613515\n",
      "train loss:  1.8411402702331543\n",
      "train r2:  0.8729728172733231\n",
      "test loss:  7.610506057739258\n",
      "test r2:  -0.29846189446018667\n",
      "train loss:  1.8410453796386719\n",
      "train r2:  0.8729765478717784\n",
      "test loss:  7.61069917678833\n",
      "test r2:  -0.2984610997641739\n",
      "train loss:  1.8409507274627686\n",
      "train r2:  0.8729844982303195\n",
      "test loss:  7.60995626449585\n",
      "test r2:  -0.298422531558979\n",
      "train loss:  1.8408572673797607\n",
      "train r2:  0.8729865156378762\n",
      "test loss:  7.6104583740234375\n",
      "test r2:  -0.2984339812261372\n",
      "train loss:  1.8407626152038574\n",
      "train r2:  0.8729965319152747\n",
      "test loss:  7.609344005584717\n",
      "test r2:  -0.2983811933649896\n",
      "train loss:  1.840671181678772\n",
      "train r2:  0.872995943598919\n",
      "test loss:  7.610091686248779\n",
      "test r2:  -0.2983979809204016\n",
      "train loss:  1.8405734300613403\n",
      "train r2:  0.873008677744781\n",
      "test loss:  7.6091508865356445\n",
      "test r2:  -0.2983610274062902\n",
      "train loss:  1.8404775857925415\n",
      "train r2:  0.873006781296238\n",
      "test loss:  7.609481334686279\n",
      "test r2:  -0.29836152921736847\n",
      "train loss:  1.8403801918029785\n",
      "train r2:  0.8730167448263862\n",
      "test loss:  7.609131336212158\n",
      "test r2:  -0.2983394156572141\n",
      "train loss:  1.8402847051620483\n",
      "train r2:  0.873021066546742\n",
      "test loss:  7.608659744262695\n",
      "test r2:  -0.2983132279696743\n",
      "train loss:  1.8401908874511719\n",
      "train r2:  0.8730244899719359\n",
      "test loss:  7.608899116516113\n",
      "test r2:  -0.29830880380917413\n",
      "train loss:  1.8400976657867432\n",
      "train r2:  0.8730342687216504\n",
      "test loss:  7.608037948608398\n",
      "test r2:  -0.29826923811405903\n",
      "train loss:  1.840004563331604\n",
      "train r2:  0.8730346506257042\n",
      "test loss:  7.608451843261719\n",
      "test r2:  -0.29827173030887244\n",
      "train loss:  1.8399081230163574\n",
      "train r2:  0.8730456764398998\n",
      "test loss:  7.607962131500244\n",
      "test r2:  -0.29825191793072703\n",
      "train loss:  1.8398122787475586\n",
      "train r2:  0.8730471929293537\n",
      "test loss:  7.607863903045654\n",
      "test r2:  -0.2982390081318702\n",
      "train loss:  1.839717984199524\n",
      "train r2:  0.873053561776123\n",
      "test loss:  7.60786771774292\n",
      "test r2:  -0.2982257096180647\n",
      "train loss:  1.8396245241165161\n",
      "train r2:  0.8730619190909407\n",
      "test loss:  7.607265949249268\n",
      "test r2:  -0.29819823426335734\n",
      "train loss:  1.8395313024520874\n",
      "train r2:  0.8730636542016211\n",
      "test loss:  7.6075544357299805\n",
      "test r2:  -0.2981977597831271\n",
      "train loss:  1.8394370079040527\n",
      "train r2:  0.8730733411787529\n",
      "test loss:  7.606966018676758\n",
      "test r2:  -0.2981692499812294\n",
      "train loss:  1.8393423557281494\n",
      "train r2:  0.8730755687175271\n",
      "test loss:  7.606996059417725\n",
      "test r2:  -0.29815794023310094\n",
      "train loss:  1.839247465133667\n",
      "train r2:  0.8730837724959903\n",
      "test loss:  7.606786727905273\n",
      "test r2:  -0.298142877433603\n",
      "train loss:  1.8391536474227905\n",
      "train r2:  0.8730888761453769\n",
      "test loss:  7.606387615203857\n",
      "test r2:  -0.29812017568673266\n",
      "train loss:  1.8390603065490723\n",
      "train r2:  0.8730927532975226\n",
      "test loss:  7.606489181518555\n",
      "test r2:  -0.29810946276861894\n",
      "train loss:  1.8389668464660645\n",
      "train r2:  0.8731019557936436\n",
      "test loss:  7.605939865112305\n",
      "test r2:  -0.2980835472057115\n",
      "train loss:  1.838873267173767\n",
      "train r2:  0.8731041117396392\n",
      "test loss:  7.606061935424805\n",
      "test r2:  -0.29807782964725016\n",
      "train loss:  1.838779091835022\n",
      "train r2:  0.873112257141554\n",
      "test loss:  7.605688571929932\n",
      "test r2:  -0.2980561992556847\n",
      "train loss:  1.838685154914856\n",
      "train r2:  0.8731162694450533\n",
      "test loss:  7.605497360229492\n",
      "test r2:  -0.2980379051692166\n",
      "train loss:  1.8385915756225586\n",
      "train r2:  0.8731224624175462\n",
      "test loss:  7.60539436340332\n",
      "test r2:  -0.298023988921722\n",
      "train loss:  1.8384982347488403\n",
      "train r2:  0.8731289205039044\n",
      "test loss:  7.60493803024292\n",
      "test r2:  -0.2979991707259424\n",
      "train loss:  1.8384051322937012\n",
      "train r2:  0.8731323371944952\n",
      "test loss:  7.604965686798096\n",
      "test r2:  -0.29798621696505645\n",
      "train loss:  1.838311791419983\n",
      "train r2:  0.8731407584033068\n",
      "test loss:  7.604488849639893\n",
      "test r2:  -0.29796124375519706\n",
      "train loss:  1.8382185697555542\n",
      "train r2:  0.8731438726006551\n",
      "test loss:  7.604446887969971\n",
      "test r2:  -0.2979482158421818\n",
      "train loss:  1.8381249904632568\n",
      "train r2:  0.8731511116862533\n",
      "test loss:  7.604140758514404\n",
      "test r2:  -0.29792748092913013\n",
      "train loss:  1.8380316495895386\n",
      "train r2:  0.8731559613289352\n",
      "test loss:  7.603893756866455\n",
      "test r2:  -0.2979079686045323\n",
      "train loss:  1.8379384279251099\n",
      "train r2:  0.8731615170780382\n",
      "test loss:  7.6037797927856445\n",
      "test r2:  -0.29789276090484273\n",
      "train loss:  1.8378454446792603\n",
      "train r2:  0.873168162831854\n",
      "test loss:  7.60338020324707\n",
      "test r2:  -0.2978698494453298\n",
      "train loss:  1.8377526998519897\n",
      "train r2:  0.8731720348821368\n",
      "test loss:  7.603347301483154\n",
      "test r2:  -0.2978557531550563\n",
      "train loss:  1.8376597166061401\n",
      "train r2:  0.8731797799068589\n",
      "test loss:  7.602928161621094\n",
      "test r2:  -0.2978318298274345\n",
      "train loss:  1.8375664949417114\n",
      "train r2:  0.8731836843961692\n",
      "test loss:  7.602847576141357\n",
      "test r2:  -0.29781769202884556\n",
      "train loss:  1.837473750114441\n",
      "train r2:  0.873190612307617\n",
      "test loss:  7.602525234222412\n",
      "test r2:  -0.29779600783172167\n",
      "train loss:  1.8373805284500122\n",
      "train r2:  0.8731954931389043\n",
      "test loss:  7.6023149490356445\n",
      "test r2:  -0.2977772159485985\n",
      "train loss:  1.8372877836227417\n",
      "train r2:  0.8732015350130766\n",
      "test loss:  7.602123737335205\n",
      "test r2:  -0.29775951285484625\n",
      "train loss:  1.8371949195861816\n",
      "train r2:  0.873207569877265\n",
      "test loss:  7.601806640625\n",
      "test r2:  -0.2977387803873157\n",
      "train loss:  1.8371025323867798\n",
      "train r2:  0.8732123234797828\n",
      "test loss:  7.6017045974731445\n",
      "test r2:  -0.29772327285937816\n",
      "train loss:  1.8370097875595093\n",
      "train r2:  0.8732192883111003\n",
      "test loss:  7.601333141326904\n",
      "test r2:  -0.29770046314500864\n",
      "train loss:  1.8369174003601074\n",
      "train r2:  0.8732236963535616\n",
      "test loss:  7.601253032684326\n",
      "test r2:  -0.29768632232331327\n",
      "train loss:  1.8368247747421265\n",
      "train r2:  0.8732306871757203\n",
      "test loss:  7.600887775421143\n",
      "test r2:  -0.2976632914592918\n",
      "train loss:  1.8367321491241455\n",
      "train r2:  0.8732351762301159\n",
      "test loss:  7.600764274597168\n",
      "test r2:  -0.2976471736448294\n",
      "train loss:  1.8366397619247437\n",
      "train r2:  0.8732419705925756\n",
      "test loss:  7.600446701049805\n",
      "test r2:  -0.2976260029292852\n",
      "train loss:  1.8365472555160522\n",
      "train r2:  0.8732467924653287\n",
      "test loss:  7.600255012512207\n",
      "test r2:  -0.2976077021821517\n",
      "train loss:  1.8364546298980713\n",
      "train r2:  0.8732530046004493\n",
      "test loss:  7.5999956130981445\n",
      "test r2:  -0.29758723491232564\n",
      "train loss:  1.8363624811172485\n",
      "train r2:  0.8732586401382828\n",
      "test loss:  7.59974479675293\n",
      "test r2:  -0.2975679325502478\n",
      "train loss:  1.8362703323364258\n",
      "train r2:  0.873264098856634\n",
      "test loss:  7.599545001983643\n",
      "test r2:  -0.2975493534888969\n",
      "train loss:  1.8361778259277344\n",
      "train r2:  0.8732701727146099\n",
      "test loss:  7.599242687225342\n",
      "test r2:  -0.2975279506495787\n",
      "train loss:  1.8360857963562012\n",
      "train r2:  0.8732753520441882\n",
      "test loss:  7.599082946777344\n",
      "test r2:  -0.29751077495680334\n",
      "train loss:  1.8359935283660889\n",
      "train r2:  0.8732817935460042\n",
      "test loss:  7.5987443923950195\n",
      "test r2:  -0.297488477069088\n",
      "train loss:  1.835901141166687\n",
      "train r2:  0.8732865620044998\n",
      "test loss:  7.598606586456299\n",
      "test r2:  -0.2974713817712793\n",
      "train loss:  1.8358092308044434\n",
      "train r2:  0.8732933184252037\n",
      "test loss:  7.598239421844482\n",
      "test r2:  -0.2974479485473671\n",
      "train loss:  1.8357172012329102\n",
      "train r2:  0.8732979382572388\n",
      "test loss:  7.598118782043457\n",
      "test r2:  -0.2974316298560895\n",
      "train loss:  1.8356252908706665\n",
      "train r2:  0.8733047653794508\n",
      "test loss:  7.597729206085205\n",
      "test r2:  -0.2974075638648832\n",
      "train loss:  1.8355331420898438\n",
      "train r2:  0.8733091539276145\n",
      "test loss:  7.597626209259033\n",
      "test r2:  -0.2973907956196655\n",
      "train loss:  1.8354412317276\n",
      "train r2:  0.8733164109764664\n",
      "test loss:  7.59721565246582\n",
      "test r2:  -0.29736659151182354\n",
      "train loss:  1.835349440574646\n",
      "train r2:  0.8733205151947864\n",
      "test loss:  7.597145080566406\n",
      "test r2:  -0.29735202734053967\n",
      "train loss:  1.8352575302124023\n",
      "train r2:  0.8733277321122512\n",
      "test loss:  7.596696376800537\n",
      "test r2:  -0.29732523265174793\n",
      "train loss:  1.8351659774780273\n",
      "train r2:  0.8733317888193053\n",
      "test loss:  7.59666109085083\n",
      "test r2:  -0.2973109856731402\n",
      "train loss:  1.8350739479064941\n",
      "train r2:  0.8733395663219626\n",
      "test loss:  7.596168518066406\n",
      "test r2:  -0.29728487635287393\n",
      "train loss:  1.8349823951721191\n",
      "train r2:  0.8733427559792762\n",
      "test loss:  7.596182346343994\n",
      "test r2:  -0.2972709553331314\n",
      "train loss:  1.8348908424377441\n",
      "train r2:  0.8733512046006324\n",
      "test loss:  7.595618724822998\n",
      "test r2:  -0.29724180452617954\n",
      "train loss:  1.8347996473312378\n",
      "train r2:  0.8733540395874725\n",
      "test loss:  7.595702648162842\n",
      "test r2:  -0.29723073891641993\n",
      "train loss:  1.8347079753875732\n",
      "train r2:  0.8733628513204589\n",
      "test loss:  7.595071792602539\n",
      "test r2:  -0.2972002757495025\n",
      "train loss:  1.8346166610717773\n",
      "train r2:  0.8733649204313318\n",
      "test loss:  7.595205783843994\n",
      "test r2:  -0.29718865957390594\n",
      "train loss:  1.8345251083374023\n",
      "train r2:  0.8733747102652183\n",
      "test loss:  7.594541549682617\n",
      "test r2:  -0.29715825158072784\n",
      "train loss:  1.8344337940216064\n",
      "train r2:  0.8733761778354344\n",
      "test loss:  7.594686508178711\n",
      "test r2:  -0.2971479228633849\n",
      "train loss:  1.8343417644500732\n",
      "train r2:  0.8733858481127964\n",
      "test loss:  7.594058513641357\n",
      "test r2:  -0.29711819598262434\n",
      "train loss:  1.8342502117156982\n",
      "train r2:  0.8733877472158321\n",
      "test loss:  7.594116687774658\n",
      "test r2:  -0.29710418183236276\n",
      "train loss:  1.834158182144165\n",
      "train r2:  0.8733969573025129\n",
      "test loss:  7.5936126708984375\n",
      "test r2:  -0.2970788985206092\n",
      "train loss:  1.8340665102005005\n",
      "train r2:  0.8733997292522192\n",
      "test loss:  7.593525409698486\n",
      "test r2:  -0.2970618730737624\n",
      "train loss:  1.8339749574661255\n",
      "train r2:  0.8734073182497781\n",
      "test loss:  7.593168258666992\n",
      "test r2:  -0.29703767700295924\n",
      "train loss:  1.8338834047317505\n",
      "train r2:  0.8734122859761881\n",
      "test loss:  7.592929363250732\n",
      "test r2:  -0.29701808887130654\n",
      "train loss:  1.8337920904159546\n",
      "train r2:  0.8734180818695909\n",
      "test loss:  7.592729091644287\n",
      "test r2:  -0.29699938907413337\n",
      "train loss:  1.8337005376815796\n",
      "train r2:  0.873424277661781\n",
      "test loss:  7.592358112335205\n",
      "test r2:  -0.2969752008478408\n",
      "train loss:  1.8336094617843628\n",
      "train r2:  0.8734290749438904\n",
      "test loss:  7.592269420623779\n",
      "test r2:  -0.29695840709055465\n",
      "train loss:  1.833518385887146\n",
      "train r2:  0.8734366135303533\n",
      "test loss:  7.591812610626221\n",
      "test r2:  -0.2969340340901987\n",
      "train loss:  1.8334274291992188\n",
      "train r2:  0.8734400311201488\n",
      "test loss:  7.591792106628418\n",
      "test r2:  -0.29691816183553854\n",
      "train loss:  1.8333364725112915\n",
      "train r2:  0.8734484254665662\n",
      "test loss:  7.591272354125977\n",
      "test r2:  -0.2968914301731893\n",
      "train loss:  1.8332452774047852\n",
      "train r2:  0.873451423424211\n",
      "test loss:  7.591277599334717\n",
      "test r2:  -0.2968760209125938\n",
      "train loss:  1.833154320716858\n",
      "train r2:  0.8734601438226877\n",
      "test loss:  7.59074592590332\n",
      "test r2:  -0.29684993649813607\n",
      "train loss:  1.833063006401062\n",
      "train r2:  0.8734627069949297\n",
      "test loss:  7.590734481811523\n",
      "test r2:  -0.2968333641649574\n",
      "train loss:  1.8329719305038452\n",
      "train r2:  0.8734714083010823\n",
      "test loss:  7.590229511260986\n",
      "test r2:  -0.2968068495149465\n",
      "train loss:  1.8328808546066284\n",
      "train r2:  0.8734745681517081\n",
      "test loss:  7.590174674987793\n",
      "test r2:  -0.2967906866242478\n",
      "train loss:  1.8327897787094116\n",
      "train r2:  0.8734824186205776\n",
      "test loss:  7.5897321701049805\n",
      "test r2:  -0.29676573977440124\n",
      "train loss:  1.8326984643936157\n",
      "train r2:  0.8734861378539097\n",
      "test loss:  7.589600086212158\n",
      "test r2:  -0.29674643536414824\n",
      "train loss:  1.8326072692871094\n",
      "train r2:  0.8734935565509934\n",
      "test loss:  7.589231491088867\n",
      "test r2:  -0.2967234373405654\n",
      "train loss:  1.8325164318084717\n",
      "train r2:  0.8734979908362722\n",
      "test loss:  7.589028835296631\n",
      "test r2:  -0.29670383496999997\n",
      "train loss:  1.832425594329834\n",
      "train r2:  0.8735043485602982\n",
      "test loss:  7.588721752166748\n",
      "test r2:  -0.29668068944094683\n",
      "train loss:  1.832334280014038\n",
      "train r2:  0.8735098465394717\n",
      "test loss:  7.5884504318237305\n",
      "test r2:  -0.2966589602699954\n",
      "train loss:  1.8322436809539795\n",
      "train r2:  0.8735156102994047\n",
      "test loss:  7.588208198547363\n",
      "test r2:  -0.2966388648176739\n",
      "train loss:  1.8321528434753418\n",
      "train r2:  0.8735214226191464\n",
      "test loss:  7.587886333465576\n",
      "test r2:  -0.2966159288947583\n",
      "train loss:  1.8320621252059937\n",
      "train r2:  0.8735266572511263\n",
      "test loss:  7.587686061859131\n",
      "test r2:  -0.2965949211443095\n",
      "train loss:  1.831971287727356\n",
      "train r2:  0.8735333992796993\n",
      "test loss:  7.587325572967529\n",
      "test r2:  -0.2965725680336986\n",
      "train loss:  1.8318804502487183\n",
      "train r2:  0.8735378516913364\n",
      "test loss:  7.587172031402588\n",
      "test r2:  -0.2965535149304268\n",
      "train loss:  1.8317899703979492\n",
      "train r2:  0.8735448687187981\n",
      "test loss:  7.586758613586426\n",
      "test r2:  -0.29652792115630033\n",
      "train loss:  1.8316993713378906\n",
      "train r2:  0.8735492868262031\n",
      "test loss:  7.586648941040039\n",
      "test r2:  -0.2965104816954469\n",
      "train loss:  1.831608772277832\n",
      "train r2:  0.8735566058675249\n",
      "test loss:  7.586187839508057\n",
      "test r2:  -0.29648491764443663\n",
      "train loss:  1.8315180540084839\n",
      "train r2:  0.8735602641964432\n",
      "test loss:  7.586121082305908\n",
      "test r2:  -0.29646661902740523\n",
      "train loss:  1.8314274549484253\n",
      "train r2:  0.8735684694635867\n",
      "test loss:  7.585602283477783\n",
      "test r2:  -0.29643998933549853\n",
      "train loss:  1.8313374519348145\n",
      "train r2:  0.8735714199596116\n",
      "test loss:  7.585599899291992\n",
      "test r2:  -0.29642379464483426\n",
      "train loss:  1.8312466144561768\n",
      "train r2:  0.8735801638604217\n",
      "test loss:  7.585014820098877\n",
      "test r2:  -0.296395872402911\n",
      "train loss:  1.831156611442566\n",
      "train r2:  0.8735823531778344\n",
      "test loss:  7.585068225860596\n",
      "test r2:  -0.2963792793340081\n",
      "train loss:  1.8310660123825073\n",
      "train r2:  0.87359204184517\n",
      "test loss:  7.584433078765869\n",
      "test r2:  -0.2963512962326116\n",
      "train loss:  1.830976128578186\n",
      "train r2:  0.8735934240629539\n",
      "test loss:  7.584517955780029\n",
      "test r2:  -0.29633544856424465\n",
      "train loss:  1.8308850526809692\n",
      "train r2:  0.873603441139339\n",
      "test loss:  7.583878040313721\n",
      "test r2:  -0.29630739680802076\n",
      "train loss:  1.8307949304580688\n",
      "train r2:  0.8736047666831158\n",
      "test loss:  7.583924770355225\n",
      "test r2:  -0.2962898759526911\n",
      "train loss:  1.830703854560852\n",
      "train r2:  0.8736145688641059\n",
      "test loss:  7.583362102508545\n",
      "test r2:  -0.2962642759152452\n",
      "train loss:  1.8306132555007935\n",
      "train r2:  0.873616559635016\n",
      "test loss:  7.5833024978637695\n",
      "test r2:  -0.29624484752895697\n",
      "train loss:  1.8305226564407349\n",
      "train r2:  0.8736251484936449\n",
      "test loss:  7.582869052886963\n",
      "test r2:  -0.2962207337456344\n",
      "train loss:  1.8304318189620972\n",
      "train r2:  0.8736289033760827\n",
      "test loss:  7.582672595977783\n",
      "test r2:  -0.2962000359659964\n",
      "train loss:  1.8303413391113281\n",
      "train r2:  0.873635622850524\n",
      "test loss:  7.582382678985596\n",
      "test r2:  -0.2961779199808028\n",
      "train loss:  1.8302509784698486\n",
      "train r2:  0.8736411783248179\n",
      "test loss:  7.582057476043701\n",
      "test r2:  -0.2961550822883623\n",
      "train loss:  1.8301608562469482\n",
      "train r2:  0.8736464135035311\n",
      "test loss:  7.581886291503906\n",
      "test r2:  -0.29613486814020074\n",
      "train loss:  1.8300708532333374\n",
      "train r2:  0.8736534474913287\n",
      "test loss:  7.581463813781738\n",
      "test r2:  -0.2961110675474201\n",
      "train loss:  1.829980731010437\n",
      "train r2:  0.8736573171677181\n",
      "test loss:  7.5813703536987305\n",
      "test r2:  -0.29609151466076367\n",
      "train loss:  1.8298906087875366\n",
      "train r2:  0.8736654614509104\n",
      "test loss:  7.580885410308838\n",
      "test r2:  -0.29606660768888515\n",
      "train loss:  1.8298002481460571\n",
      "train r2:  0.8736686041953973\n",
      "test loss:  7.580827713012695\n",
      "test r2:  -0.2960479483923253\n",
      "train loss:  1.8297103643417358\n",
      "train r2:  0.8736770690956538\n",
      "test loss:  7.580325603485107\n",
      "test r2:  -0.29602275942770695\n",
      "train loss:  1.8296200037002563\n",
      "train r2:  0.8736799736089872\n",
      "test loss:  7.580256462097168\n",
      "test r2:  -0.29600277874692194\n",
      "train loss:  1.8295300006866455\n",
      "train r2:  0.873688566448787\n",
      "test loss:  7.579780578613281\n",
      "test r2:  -0.2959787543172838\n",
      "train loss:  1.8294398784637451\n",
      "train r2:  0.8736915912863856\n",
      "test loss:  7.57966947555542\n",
      "test r2:  -0.29595860981526645\n",
      "train loss:  1.8293495178222656\n",
      "train r2:  0.8736995584530937\n",
      "test loss:  7.579240798950195\n",
      "test r2:  -0.29593418460692855\n",
      "train loss:  1.8292593955993652\n",
      "train r2:  0.8737034503563847\n",
      "test loss:  7.579067707061768\n",
      "test r2:  -0.29591326716051736\n",
      "train loss:  1.8291691541671753\n",
      "train r2:  0.8737105627259055\n",
      "test loss:  7.578704357147217\n",
      "test r2:  -0.2958903955994543\n",
      "train loss:  1.829079031944275\n",
      "train r2:  0.8737151343178717\n",
      "test loss:  7.578461170196533\n",
      "test r2:  -0.29586791492850173\n",
      "train loss:  1.8289889097213745\n",
      "train r2:  0.8737215356076428\n",
      "test loss:  7.578157424926758\n",
      "test r2:  -0.29584528394607923\n",
      "train loss:  1.8288987874984741\n",
      "train r2:  0.8737269876467055\n",
      "test loss:  7.577859401702881\n",
      "test r2:  -0.2958227841246901\n",
      "train loss:  1.8288089036941528\n",
      "train r2:  0.8737324668212317\n",
      "test loss:  7.577605724334717\n",
      "test r2:  -0.29580046297789875\n",
      "train loss:  1.828718900680542\n",
      "train r2:  0.8737386868293189\n",
      "test loss:  7.5772600173950195\n",
      "test r2:  -0.29577698174476375\n",
      "train loss:  1.8286292552947998\n",
      "train r2:  0.8737436836964958\n",
      "test loss:  7.577049255371094\n",
      "test r2:  -0.2957556837597186\n",
      "train loss:  1.8285391330718994\n",
      "train r2:  0.8737503318515859\n",
      "test loss:  7.576669692993164\n",
      "test r2:  -0.2957321349245179\n",
      "train loss:  1.8284493684768677\n",
      "train r2:  0.8737547613682006\n",
      "test loss:  7.576488971710205\n",
      "test r2:  -0.29571057761183805\n",
      "train loss:  1.8283594846725464\n",
      "train r2:  0.8737619684489488\n",
      "test loss:  7.576077461242676\n",
      "test r2:  -0.2956864170891609\n",
      "train loss:  1.828269600868225\n",
      "train r2:  0.8737660925086608\n",
      "test loss:  7.575925827026367\n",
      "test r2:  -0.29566583031651383\n",
      "train loss:  1.8281800746917725\n",
      "train r2:  0.8737735334034059\n",
      "test loss:  7.5754923820495605\n",
      "test r2:  -0.2956417106426399\n",
      "train loss:  1.8280906677246094\n",
      "train r2:  0.8737772651218244\n",
      "test loss:  7.5753679275512695\n",
      "test r2:  -0.2956210336151115\n",
      "train loss:  1.8280013799667358\n",
      "train r2:  0.8737851194894752\n",
      "test loss:  7.5749101638793945\n",
      "test r2:  -0.2955969018242339\n",
      "train loss:  1.8279123306274414\n",
      "train r2:  0.8737884965846134\n",
      "test loss:  7.574807643890381\n",
      "test r2:  -0.2955764769598239\n",
      "train loss:  1.827823281288147\n",
      "train r2:  0.87379665035185\n",
      "test loss:  7.574321269989014\n",
      "test r2:  -0.2955519535455893\n",
      "train loss:  1.8277348279953003\n",
      "train r2:  0.8737996052548582\n",
      "test loss:  7.57423210144043\n",
      "test r2:  -0.2955306194962779\n",
      "train loss:  1.8276461362838745\n",
      "train r2:  0.8738081723566165\n",
      "test loss:  7.573721408843994\n",
      "test r2:  -0.2955060123485511\n",
      "train loss:  1.8275578022003174\n",
      "train r2:  0.8738107705339647\n",
      "test loss:  7.5736494064331055\n",
      "test r2:  -0.29548487548524394\n",
      "train loss:  1.8274694681167603\n",
      "train r2:  0.8738195422571284\n",
      "test loss:  7.573129177093506\n",
      "test r2:  -0.29546044407093586\n",
      "train loss:  1.8273816108703613\n",
      "train r2:  0.8738219440989953\n",
      "test loss:  7.573062419891357\n",
      "test r2:  -0.2954390495840753\n",
      "train loss:  1.8272937536239624\n",
      "train r2:  0.8738308943101385\n",
      "test loss:  7.57255220413208\n",
      "test r2:  -0.2954152090436888\n",
      "train loss:  1.8272061347961426\n",
      "train r2:  0.8738332488147316\n",
      "test loss:  7.572473526000977\n",
      "test r2:  -0.2953939935632308\n",
      "train loss:  1.8271185159683228\n",
      "train r2:  0.8738419875631057\n",
      "test loss:  7.571984767913818\n",
      "test r2:  -0.2953701120019945\n",
      "train loss:  1.8270312547683716\n",
      "train r2:  0.8738447620040336\n",
      "test loss:  7.571873188018799\n",
      "test r2:  -0.2953484463326621\n",
      "train loss:  1.8269442319869995\n",
      "train r2:  0.8738530354198301\n",
      "test loss:  7.5714263916015625\n",
      "test r2:  -0.2953253994560081\n",
      "train loss:  1.8268574476242065\n",
      "train r2:  0.8738563313361236\n",
      "test loss:  7.57127046585083\n",
      "test r2:  -0.2953028273381364\n",
      "train loss:  1.8267706632614136\n",
      "train r2:  0.8738641311755526\n",
      "test loss:  7.57088041305542\n",
      "test r2:  -0.2952806331904869\n",
      "train loss:  1.8266844749450684\n",
      "train r2:  0.8738680844304472\n",
      "test loss:  7.570682048797607\n",
      "test r2:  -0.29525918354627256\n",
      "train loss:  1.8265984058380127\n",
      "train r2:  0.8738749922995747\n",
      "test loss:  7.57034158706665\n",
      "test r2:  -0.2952362690022081\n",
      "train loss:  1.826512098312378\n",
      "train r2:  0.8738799592616909\n",
      "test loss:  7.570098400115967\n",
      "test r2:  -0.29521466204586155\n",
      "train loss:  1.826426386833191\n",
      "train r2:  0.8738861908782916\n",
      "test loss:  7.569807052612305\n",
      "test r2:  -0.295193312115001\n",
      "train loss:  1.826340675354004\n",
      "train r2:  0.8738915721677324\n",
      "test loss:  7.569522380828857\n",
      "test r2:  -0.2951706502993514\n",
      "train loss:  1.8262556791305542\n",
      "train r2:  0.8738973873114785\n",
      "test loss:  7.56926155090332\n",
      "test r2:  -0.29514844038485033\n",
      "train loss:  1.8261704444885254\n",
      "train r2:  0.8739034935831085\n",
      "test loss:  7.568953037261963\n",
      "test r2:  -0.2951274769323313\n",
      "train loss:  1.8260855674743652\n",
      "train r2:  0.8739084794095119\n",
      "test loss:  7.568723678588867\n",
      "test r2:  -0.295105556404482\n",
      "train loss:  1.8260008096694946\n",
      "train r2:  0.873915047869379\n",
      "test loss:  7.568380832672119\n",
      "test r2:  -0.29508226825280803\n",
      "train loss:  1.8259162902832031\n",
      "train r2:  0.8739200816867015\n",
      "test loss:  7.568185806274414\n",
      "test r2:  -0.2950626717932756\n",
      "train loss:  1.8258320093154907\n",
      "train r2:  0.8739265614654067\n",
      "test loss:  7.567817687988281\n",
      "test r2:  -0.2950398715128004\n",
      "train loss:  1.8257477283477783\n",
      "train r2:  0.8739310528924974\n",
      "test loss:  7.567637920379639\n",
      "test r2:  -0.2950174060188251\n",
      "train loss:  1.8256640434265137\n",
      "train r2:  0.8739385288312413\n",
      "test loss:  7.56724214553833\n",
      "test r2:  -0.2949957295965737\n",
      "train loss:  1.8255802392959595\n",
      "train r2:  0.8739423062269294\n",
      "test loss:  7.567101955413818\n",
      "test r2:  -0.2949751422053777\n",
      "train loss:  1.8254966735839844\n",
      "train r2:  0.8739499037227316\n",
      "test loss:  7.5666608810424805\n",
      "test r2:  -0.2949511780494347\n",
      "train loss:  1.825413465499878\n",
      "train r2:  0.8739535589959683\n",
      "test loss:  7.566560745239258\n",
      "test r2:  -0.2949300303512814\n",
      "train loss:  1.825330376625061\n",
      "train r2:  0.8739619297139618\n",
      "test loss:  7.56608247756958\n",
      "test r2:  -0.2949087388056988\n",
      "train loss:  1.8252476453781128\n",
      "train r2:  0.8739642579765625\n",
      "test loss:  7.566030979156494\n",
      "test r2:  -0.2948867095771037\n",
      "train loss:  1.8251649141311646\n",
      "train r2:  0.8739736897603881\n",
      "test loss:  7.565491199493408\n",
      "test r2:  -0.29486328943283735\n",
      "train loss:  1.8250824213027954\n",
      "train r2:  0.8739755922222612\n",
      "test loss:  7.565498352050781\n",
      "test r2:  -0.29484313651282035\n",
      "train loss:  1.8250000476837158\n",
      "train r2:  0.8739854204872425\n",
      "test loss:  7.564916610717773\n",
      "test r2:  -0.2948208406077384\n",
      "train loss:  1.824918270111084\n",
      "train r2:  0.8739863396833107\n",
      "test loss:  7.564947605133057\n",
      "test r2:  -0.29479777387197914\n",
      "train loss:  1.8248356580734253\n",
      "train r2:  0.8739974081747488\n",
      "test loss:  7.5643630027771\n",
      "test r2:  -0.29477733259349437\n",
      "train loss:  1.824754238128662\n",
      "train r2:  0.8739977934615899\n",
      "test loss:  7.564384460449219\n",
      "test r2:  -0.29475532380158986\n",
      "train loss:  1.824671983718872\n",
      "train r2:  0.8740083726065212\n",
      "test loss:  7.563848972320557\n",
      "test r2:  -0.29473434982554747\n",
      "train loss:  1.8245899677276611\n",
      "train r2:  0.874009784405143\n",
      "test loss:  7.5637922286987305\n",
      "test r2:  -0.2947116975584898\n",
      "train loss:  1.8245080709457397\n",
      "train r2:  0.8740193334427924\n",
      "test loss:  7.56336784362793\n",
      "test r2:  -0.2946923940289521\n",
      "train loss:  1.824426531791687\n",
      "train r2:  0.8740220688869622\n",
      "test loss:  7.563199996948242\n",
      "test r2:  -0.2946699378500768\n",
      "train loss:  1.8243449926376343\n",
      "train r2:  0.8740298037220905\n",
      "test loss:  7.562890529632568\n",
      "test r2:  -0.29464843321645895\n",
      "train loss:  1.8242640495300293\n",
      "train r2:  0.8740350232358903\n",
      "test loss:  7.562620162963867\n",
      "test r2:  -0.29462860548109715\n",
      "train loss:  1.8241832256317139\n",
      "train r2:  0.8740404541135722\n",
      "test loss:  7.56242036819458\n",
      "test r2:  -0.294607541774506\n",
      "train loss:  1.8241026401519775\n",
      "train r2:  0.8740473596492264\n",
      "test loss:  7.562055587768555\n",
      "test r2:  -0.29458621853136635\n",
      "train loss:  1.8240220546722412\n",
      "train r2:  0.8740516570457859\n",
      "test loss:  7.561933517456055\n",
      "test r2:  -0.2945647838838896\n",
      "train loss:  1.823941946029663\n",
      "train r2:  0.8740598820128512\n",
      "test loss:  7.561516284942627\n",
      "test r2:  -0.29454639865772836\n",
      "train loss:  1.8238619565963745\n",
      "train r2:  0.8740626394972177\n",
      "test loss:  7.561428546905518\n",
      "test r2:  -0.29452295964567354\n",
      "train loss:  1.8237818479537964\n",
      "train r2:  0.8740719067117411\n",
      "test loss:  7.560978412628174\n",
      "test r2:  -0.29450271132166317\n",
      "train loss:  1.8237019777297974\n",
      "train r2:  0.8740746074692156\n",
      "test loss:  7.560906887054443\n",
      "test r2:  -0.2944822186175995\n",
      "train loss:  1.8236221075057983\n",
      "train r2:  0.8740833657827805\n",
      "test loss:  7.560464382171631\n",
      "test r2:  -0.29446191345673167\n",
      "train loss:  1.8235424757003784\n",
      "train r2:  0.8740861604725729\n",
      "test loss:  7.560360431671143\n",
      "test r2:  -0.2944382072602425\n",
      "train loss:  1.8234628438949585\n",
      "train r2:  0.874095238601819\n",
      "test loss:  7.5599589347839355\n",
      "test r2:  -0.29442028638403794\n",
      "train loss:  1.8233833312988281\n",
      "train r2:  0.8740980523158342\n",
      "test loss:  7.559815883636475\n",
      "test r2:  -0.2943981851416084\n",
      "train loss:  1.8233041763305664\n",
      "train r2:  0.8741060789986963\n",
      "test loss:  7.559447765350342\n",
      "test r2:  -0.2943763865006559\n",
      "train loss:  1.8232247829437256\n",
      "train r2:  0.874110462160061\n",
      "test loss:  7.5592570304870605\n",
      "test r2:  -0.29435542154477634\n",
      "train loss:  1.823146104812622\n",
      "train r2:  0.8741173968987128\n",
      "test loss:  7.55894660949707\n",
      "test r2:  -0.2943353063152765\n",
      "train loss:  1.82306706905365\n",
      "train r2:  0.8741222814554537\n",
      "test loss:  7.558704853057861\n",
      "test r2:  -0.2943132941725577\n",
      "train loss:  1.8229882717132568\n",
      "train r2:  0.8741287531820262\n",
      "test loss:  7.558440685272217\n",
      "test r2:  -0.29429237723409374\n",
      "train loss:  1.8229097127914429\n",
      "train r2:  0.8741345736130196\n",
      "test loss:  7.558166027069092\n",
      "test r2:  -0.29427230555289174\n",
      "train loss:  1.822831153869629\n",
      "train r2:  0.8741400104377661\n",
      "test loss:  7.557938098907471\n",
      "test r2:  -0.2942509066952257\n",
      "train loss:  1.8227529525756836\n",
      "train r2:  0.8741465464271978\n",
      "test loss:  7.5576276779174805\n",
      "test r2:  -0.29422999343528433\n",
      "train loss:  1.8226748704910278\n",
      "train r2:  0.8741516849926678\n",
      "test loss:  7.557434558868408\n",
      "test r2:  -0.2942093658629903\n",
      "train loss:  1.8225969076156616\n",
      "train r2:  0.874158604405435\n",
      "test loss:  7.557098865509033\n",
      "test r2:  -0.29418918043843556\n",
      "train loss:  1.8225189447402954\n",
      "train r2:  0.8741631472188444\n",
      "test loss:  7.556929111480713\n",
      "test r2:  -0.2941671535037964\n",
      "train loss:  1.8224411010742188\n",
      "train r2:  0.8741707943526764\n",
      "test loss:  7.5565714836120605\n",
      "test r2:  -0.29414787242635354\n",
      "train loss:  1.822363257408142\n",
      "train r2:  0.8741747300746622\n",
      "test loss:  7.556430339813232\n",
      "test r2:  -0.2941260730562507\n",
      "train loss:  1.8222858905792236\n",
      "train r2:  0.874182793898127\n",
      "test loss:  7.556041240692139\n",
      "test r2:  -0.2941063395287482\n",
      "train loss:  1.8222084045410156\n",
      "train r2:  0.8741863850118247\n",
      "test loss:  7.555932521820068\n",
      "test r2:  -0.2940844326990937\n",
      "train loss:  1.8221310377120972\n",
      "train r2:  0.8741949856463194\n",
      "test loss:  7.555509567260742\n",
      "test r2:  -0.29406527262373583\n",
      "train loss:  1.822054147720337\n",
      "train r2:  0.8741979054242734\n",
      "test loss:  7.555435657501221\n",
      "test r2:  -0.294042742407429\n",
      "train loss:  1.821977138519287\n",
      "train r2:  0.8742072240923584\n",
      "test loss:  7.5549726486206055\n",
      "test r2:  -0.29402404248736524\n",
      "train loss:  1.8219000101089478\n",
      "train r2:  0.8742093659394181\n",
      "test loss:  7.554940700531006\n",
      "test r2:  -0.2940008195700663\n",
      "train loss:  1.8218234777450562\n",
      "train r2:  0.8742195296791662\n",
      "test loss:  7.554434299468994\n",
      "test r2:  -0.29398299472869316\n",
      "train loss:  1.8217469453811646\n",
      "train r2:  0.8742207545299361\n",
      "test loss:  7.554440498352051\n",
      "test r2:  -0.2939586278769588\n",
      "train loss:  1.8216701745986938\n",
      "train r2:  0.8742318185244939\n",
      "test loss:  7.553906440734863\n",
      "test r2:  -0.293941971752939\n",
      "train loss:  1.8215938806533813\n",
      "train r2:  0.8742323122535416\n",
      "test loss:  7.553927898406982\n",
      "test r2:  -0.2939168717938154\n",
      "train loss:  1.821516990661621\n",
      "train r2:  0.8742438213905518\n",
      "test loss:  7.553399562835693\n",
      "test r2:  -0.2939009724622812\n",
      "train loss:  1.8214406967163086\n",
      "train r2:  0.874244200918834\n",
      "test loss:  7.553393840789795\n",
      "test r2:  -0.2938752214128897\n",
      "train loss:  1.821364402770996\n",
      "train r2:  0.8742554458368108\n",
      "test loss:  7.552917003631592\n",
      "test r2:  -0.2938593918831609\n",
      "train loss:  1.8212878704071045\n",
      "train r2:  0.8742566415782711\n",
      "test loss:  7.552844524383545\n",
      "test r2:  -0.29383493355992907\n",
      "train loss:  1.8212112188339233\n",
      "train r2:  0.874266564790996\n",
      "test loss:  7.552453994750977\n",
      "test r2:  -0.29381746043527035\n",
      "train loss:  1.8211350440979004\n",
      "train r2:  0.8742695719431987\n",
      "test loss:  7.55229377746582\n",
      "test r2:  -0.2937947947076065\n",
      "train loss:  1.8210591077804565\n",
      "train r2:  0.8742776620449829\n",
      "test loss:  7.552003383636475\n",
      "test r2:  -0.2937761825313616\n",
      "train loss:  1.8209832906723022\n",
      "train r2:  0.8742825959566455\n",
      "test loss:  7.551758289337158\n",
      "test r2:  -0.29375574169118623\n",
      "train loss:  1.820907473564148\n",
      "train r2:  0.8742887650723735\n",
      "test loss:  7.551547527313232\n",
      "test r2:  -0.2937344176861254\n",
      "train loss:  1.8208317756652832\n",
      "train r2:  0.8742956982423672\n",
      "test loss:  7.551232814788818\n",
      "test r2:  -0.29371624301235855\n",
      "train loss:  1.820756196975708\n",
      "train r2:  0.874300182357902\n",
      "test loss:  7.551085948944092\n",
      "test r2:  -0.2936940243521502\n",
      "train loss:  1.8206809759140015\n",
      "train r2:  0.8743084372727404\n",
      "test loss:  7.5507121086120605\n",
      "test r2:  -0.29367563584890877\n",
      "train loss:  1.820605754852295\n",
      "train r2:  0.874312017128662\n",
      "test loss:  7.55061149597168\n",
      "test r2:  -0.29365318442179955\n",
      "train loss:  1.820530652999878\n",
      "train r2:  0.8743210085911277\n",
      "test loss:  7.550203323364258\n",
      "test r2:  -0.29363635230629126\n",
      "train loss:  1.8204556703567505\n",
      "train r2:  0.8743236785366973\n",
      "test loss:  7.550124645233154\n",
      "test r2:  -0.2936116460473741\n",
      "train loss:  1.820380449295044\n",
      "train r2:  0.8743335792982766\n",
      "test loss:  7.549698352813721\n",
      "test r2:  -0.2935957367166495\n",
      "train loss:  1.8203054666519165\n",
      "train r2:  0.8743356910133582\n",
      "test loss:  7.549631118774414\n",
      "test r2:  -0.2935718128360205\n",
      "train loss:  1.8202303647994995\n",
      "train r2:  0.8743455281524133\n",
      "test loss:  7.549192428588867\n",
      "test r2:  -0.29355421595243314\n",
      "train loss:  1.8201557397842407\n",
      "train r2:  0.8743479192680906\n",
      "test loss:  7.549116134643555\n",
      "test r2:  -0.29352985309463997\n",
      "train loss:  1.8200808763504028\n",
      "train r2:  0.8743577401502114\n",
      "test loss:  7.548699855804443\n",
      "test r2:  -0.2935144652743409\n",
      "train loss:  1.8200061321258545\n",
      "train r2:  0.8743598464299406\n",
      "test loss:  7.548598766326904\n",
      "test r2:  -0.29348910534855177\n",
      "train loss:  1.8199316263198853\n",
      "train r2:  0.8743695577088086\n",
      "test loss:  7.54820442199707\n",
      "test r2:  -0.2934719364393321\n",
      "train loss:  1.8198570013046265\n",
      "train r2:  0.8743725374732142\n",
      "test loss:  7.5480804443359375\n",
      "test r2:  -0.29344901648808563\n",
      "train loss:  1.8197826147079468\n",
      "train r2:  0.874381235960125\n",
      "test loss:  7.547723293304443\n",
      "test r2:  -0.2934317603634764\n",
      "train loss:  1.8197081089019775\n",
      "train r2:  0.8743848351725363\n",
      "test loss:  7.547561168670654\n",
      "test r2:  -0.29340791004510214\n",
      "train loss:  1.8196336030960083\n",
      "train r2:  0.8743932247409882\n",
      "test loss:  7.547237873077393\n",
      "test r2:  -0.2933900138412142\n",
      "train loss:  1.8195594549179077\n",
      "train r2:  0.8743975370476135\n",
      "test loss:  7.547053337097168\n",
      "test r2:  -0.2933688567091668\n",
      "train loss:  1.8194851875305176\n",
      "train r2:  0.8744049100299349\n",
      "test loss:  7.546757698059082\n",
      "test r2:  -0.29334917721661813\n",
      "train loss:  1.8194111585617065\n",
      "train r2:  0.874410141223592\n",
      "test loss:  7.546546936035156\n",
      "test r2:  -0.293327822845314\n",
      "train loss:  1.8193371295928955\n",
      "train r2:  0.8744171489652384\n",
      "test loss:  7.546281337738037\n",
      "test r2:  -0.29330920725271326\n",
      "train loss:  1.8192633390426636\n",
      "train r2:  0.8744225911612019\n",
      "test loss:  7.546051502227783\n",
      "test r2:  -0.2932885645730803\n",
      "train loss:  1.819189429283142\n",
      "train r2:  0.8744291671948278\n",
      "test loss:  7.545797348022461\n",
      "test r2:  -0.29326788606267296\n",
      "train loss:  1.819115400314331\n",
      "train r2:  0.8744353298435273\n",
      "test loss:  7.545556545257568\n",
      "test r2:  -0.29324828164802885\n",
      "train loss:  1.8190420866012573\n",
      "train r2:  0.8744414356286958\n",
      "test loss:  7.545319080352783\n",
      "test r2:  -0.29322854353261407\n",
      "train loss:  1.8189681768417358\n",
      "train r2:  0.8744476139748123\n",
      "test loss:  7.545061111450195\n",
      "test r2:  -0.2932077711830192\n",
      "train loss:  1.818894624710083\n",
      "train r2:  0.8744537973297032\n",
      "test loss:  7.544833183288574\n",
      "test r2:  -0.29318749913294906\n",
      "train loss:  1.8188209533691406\n",
      "train r2:  0.8744602513257336\n",
      "test loss:  7.54456901550293\n",
      "test r2:  -0.2931685820571748\n",
      "train loss:  1.8187475204467773\n",
      "train r2:  0.8744658129912646\n",
      "test loss:  7.544346809387207\n",
      "test r2:  -0.2931470369843887\n",
      "train loss:  1.8186743259429932\n",
      "train r2:  0.8744727083536347\n",
      "test loss:  7.544064044952393\n",
      "test r2:  -0.29312705352218216\n",
      "train loss:  1.818601131439209\n",
      "train r2:  0.874478272051166\n",
      "test loss:  7.54386568069458\n",
      "test r2:  -0.2931069711699883\n",
      "train loss:  1.8185275793075562\n",
      "train r2:  0.8744851350674367\n",
      "test loss:  7.543561935424805\n",
      "test r2:  -0.2930874939060506\n",
      "train loss:  1.818454623222351\n",
      "train r2:  0.8744902064129464\n",
      "test loss:  7.54338264465332\n",
      "test r2:  -0.2930649133537939\n",
      "train loss:  1.8183815479278564\n",
      "train r2:  0.8744980615530618\n",
      "test loss:  7.543045520782471\n",
      "test r2:  -0.29304728633745536\n",
      "train loss:  1.8183083534240723\n",
      "train r2:  0.8745022200243064\n",
      "test loss:  7.542915344238281\n",
      "test r2:  -0.2930248255993424\n",
      "train loss:  1.8182355165481567\n",
      "train r2:  0.8745107532685306\n",
      "test loss:  7.542511463165283\n",
      "test r2:  -0.2930067150047799\n",
      "train loss:  1.8181627988815308\n",
      "train r2:  0.8745139402947957\n",
      "test loss:  7.542453289031982\n",
      "test r2:  -0.2929815861827736\n",
      "train loss:  1.818090558052063\n",
      "train r2:  0.8745243512267277\n",
      "test loss:  7.541956901550293\n",
      "test r2:  -0.29296824731582327\n",
      "train loss:  1.8180181980133057\n",
      "train r2:  0.8745248456587177\n",
      "test loss:  7.542011737823486\n",
      "test r2:  -0.2929382231752262\n",
      "train loss:  1.817945957183838\n",
      "train r2:  0.8745382218682838\n",
      "test loss:  7.541370868682861\n",
      "test r2:  -0.29292808773596923\n",
      "train loss:  1.8178752660751343\n",
      "train r2:  0.8745356372215717\n",
      "test loss:  7.541550159454346\n",
      "test r2:  -0.29289243172436197\n",
      "train loss:  1.8178024291992188\n",
      "train r2:  0.8745524560427971\n",
      "test loss:  7.540838718414307\n",
      "test r2:  -0.29289203521405915\n",
      "train loss:  1.8177316188812256\n",
      "train r2:  0.8745461601247234\n",
      "test loss:  7.54100227355957\n",
      "test r2:  -0.2928459555276175\n",
      "train loss:  1.8176568746566772\n",
      "train r2:  0.8745654313314097\n",
      "test loss:  7.540451526641846\n",
      "test r2:  -0.29285339897258567\n",
      "train loss:  1.8175829648971558\n",
      "train r2:  0.8745596027469349\n",
      "test loss:  7.540383815765381\n",
      "test r2:  -0.29281249594615466\n",
      "train loss:  1.8175086975097656\n",
      "train r2:  0.8745739603196697\n",
      "test loss:  7.540069103240967\n",
      "test r2:  -0.2928014754249202\n",
      "train loss:  1.817435622215271\n",
      "train r2:  0.8745767298717673\n",
      "test loss:  7.539739608764648\n",
      "test r2:  -0.2927798466759912\n",
      "train loss:  1.8173638582229614\n",
      "train r2:  0.8745820552729842\n",
      "test loss:  7.539680480957031\n",
      "test r2:  -0.29275394890353224\n",
      "train loss:  1.8172922134399414\n",
      "train r2:  0.8745927553969546\n",
      "test loss:  7.5391950607299805\n",
      "test r2:  -0.2927457042698365\n",
      "train loss:  1.8172210454940796\n",
      "train r2:  0.8745922349559352\n",
      "test loss:  7.539246082305908\n",
      "test r2:  -0.29270805823906887\n",
      "train loss:  1.8171484470367432\n",
      "train r2:  0.8746077677541777\n",
      "test loss:  7.538808822631836\n",
      "test r2:  -0.2927158870850384\n",
      "train loss:  1.8170760869979858\n",
      "train r2:  0.8746037736160794\n",
      "test loss:  7.53871488571167\n",
      "test r2:  -0.2926682946615704\n",
      "train loss:  1.8170030117034912\n",
      "train r2:  0.8746197152319417\n",
      "test loss:  7.538410663604736\n",
      "test r2:  -0.292668845518248\n",
      "train loss:  1.8169302940368652\n",
      "train r2:  0.8746197453885314\n",
      "test loss:  7.538149833679199\n",
      "test r2:  -0.2926396780063807\n",
      "train loss:  1.8168580532073975\n",
      "train r2:  0.8746282198201502\n",
      "test loss:  7.537988185882568\n",
      "test r2:  -0.29261762077104003\n",
      "train loss:  1.816786527633667\n",
      "train r2:  0.8746364115013997\n",
      "test loss:  7.537623405456543\n",
      "test r2:  -0.292605870988889\n",
      "train loss:  1.8167147636413574\n",
      "train r2:  0.874638701831625\n",
      "test loss:  7.5375776290893555\n",
      "test r2:  -0.2925755100300027\n",
      "train loss:  1.816643238067627\n",
      "train r2:  0.8746507999649797\n",
      "test loss:  7.537191867828369\n",
      "test r2:  -0.2925742765411614\n",
      "train loss:  1.8165713548660278\n",
      "train r2:  0.8746500373580272\n",
      "test loss:  7.53706693649292\n",
      "test r2:  -0.2925301590186995\n",
      "train loss:  1.8164993524551392\n",
      "train r2:  0.8746644275103844\n",
      "test loss:  7.536750793457031\n",
      "test r2:  -0.2925340678051065\n",
      "train loss:  1.8164271116256714\n",
      "train r2:  0.8746633697947208\n",
      "test loss:  7.536509990692139\n",
      "test r2:  -0.2924957092715905\n",
      "train loss:  1.8163554668426514\n",
      "train r2:  0.8746744714712099\n",
      "test loss:  7.536263942718506\n",
      "test r2:  -0.2924808921097255\n",
      "train loss:  1.8162834644317627\n",
      "train r2:  0.8746793891936335\n",
      "test loss:  7.535979747772217\n",
      "test r2:  -0.292463525887515\n",
      "train loss:  1.8162120580673218\n",
      "train r2:  0.8746843009502181\n",
      "test loss:  7.535820484161377\n",
      "test r2:  -0.29243638399209004\n",
      "train loss:  1.8161404132843018\n",
      "train r2:  0.8746937527359258\n",
      "test loss:  7.535491466522217\n",
      "test r2:  -0.2924278710187893\n",
      "train loss:  1.8160690069198608\n",
      "train r2:  0.8746957007168669\n",
      "test loss:  7.535338878631592\n",
      "test r2:  -0.2923918403877739\n",
      "train loss:  1.81599760055542\n",
      "train r2:  0.8747075483007395\n",
      "test loss:  7.535012722015381\n",
      "test r2:  -0.2923909398953275\n",
      "train loss:  1.8159259557724\n",
      "train r2:  0.8747076356649534\n",
      "test loss:  7.534804821014404\n",
      "test r2:  -0.2923506194845764\n",
      "train loss:  1.8158543109893799\n",
      "train r2:  0.8747197255828402\n",
      "test loss:  7.534510612487793\n",
      "test r2:  -0.2923429574337897\n",
      "train loss:  1.815782904624939\n",
      "train r2:  0.8747220514375283\n",
      "test loss:  7.534295558929443\n",
      "test r2:  -0.2923173009896034\n",
      "train loss:  1.815711259841919\n",
      "train r2:  0.8747302368463182\n",
      "test loss:  7.534049987792969\n",
      "test r2:  -0.2922971579213085\n",
      "train loss:  1.8156399726867676\n",
      "train r2:  0.8747366095632263\n",
      "test loss:  7.533805847167969\n",
      "test r2:  -0.292281870174842\n",
      "train loss:  1.8155686855316162\n",
      "train r2:  0.8747417028665083\n",
      "test loss:  7.533599376678467\n",
      "test r2:  -0.29225434696247676\n",
      "train loss:  1.815497636795044\n",
      "train r2:  0.8747505526966283\n",
      "test loss:  7.533315658569336\n",
      "test r2:  -0.2922454884087937\n",
      "train loss:  1.815426230430603\n",
      "train r2:  0.874753439688392\n",
      "test loss:  7.533111095428467\n",
      "test r2:  -0.2922108782650008\n",
      "train loss:  1.8153551816940308\n",
      "train r2:  0.8747642062176098\n",
      "test loss:  7.532812118530273\n",
      "test r2:  -0.2922039182958478\n",
      "train loss:  1.8152841329574585\n",
      "train r2:  0.8747663005183267\n",
      "test loss:  7.532630920410156\n",
      "test r2:  -0.2921734724810694\n",
      "train loss:  1.8152127265930176\n",
      "train r2:  0.8747763710336158\n",
      "test loss:  7.532331466674805\n",
      "test r2:  -0.29216012671586555\n",
      "train loss:  1.8151415586471558\n",
      "train r2:  0.8747801581563193\n",
      "test loss:  7.532159805297852\n",
      "test r2:  -0.29213718686864665\n",
      "train loss:  1.815070629119873\n",
      "train r2:  0.8747884276282916\n",
      "test loss:  7.53187370300293\n",
      "test r2:  -0.29211895847534475\n",
      "train loss:  1.8149993419647217\n",
      "train r2:  0.874793672021791\n",
      "test loss:  7.531668186187744\n",
      "test r2:  -0.2920987939503681\n",
      "train loss:  1.814928412437439\n",
      "train r2:  0.8748006642885263\n",
      "test loss:  7.531396389007568\n",
      "test r2:  -0.2920759700175677\n",
      "train loss:  1.8148574829101562\n",
      "train r2:  0.8748073309355167\n",
      "test loss:  7.531161785125732\n",
      "test r2:  -0.29205978466658156\n",
      "train loss:  1.814786434173584\n",
      "train r2:  0.874812871101416\n",
      "test loss:  7.530920505523682\n",
      "test r2:  -0.2920348240857693\n",
      "train loss:  1.8147156238555908\n",
      "train r2:  0.8748205706402923\n",
      "test loss:  7.53065824508667\n",
      "test r2:  -0.29201834324866627\n",
      "train loss:  1.8146449327468872\n",
      "train r2:  0.8748257731272537\n",
      "test loss:  7.530462265014648\n",
      "test r2:  -0.2919963007601858\n",
      "train loss:  1.8145740032196045\n",
      "train r2:  0.874833392009547\n",
      "test loss:  7.530172824859619\n",
      "test r2:  -0.2919785500914236\n",
      "train loss:  1.8145031929016113\n",
      "train r2:  0.8748384857528343\n",
      "test loss:  7.52998161315918\n",
      "test r2:  -0.2919546873733978\n",
      "train loss:  1.8144322633743286\n",
      "train r2:  0.8748466885642232\n",
      "test loss:  7.529676914215088\n",
      "test r2:  -0.2919385265144887\n",
      "train loss:  1.8143614530563354\n",
      "train r2:  0.8748511765453946\n",
      "test loss:  7.529491901397705\n",
      "test r2:  -0.2919144898818238\n",
      "train loss:  1.8142907619476318\n",
      "train r2:  0.8748594879541775\n",
      "test loss:  7.529176712036133\n",
      "test r2:  -0.2918964974137086\n",
      "train loss:  1.8142200708389282\n",
      "train r2:  0.8748642601837432\n",
      "test loss:  7.529006481170654\n",
      "test r2:  -0.29187335829953986\n",
      "train loss:  1.8141494989395142\n",
      "train r2:  0.8748725659745028\n",
      "test loss:  7.528702259063721\n",
      "test r2:  -0.2918583429193904\n",
      "train loss:  1.814078688621521\n",
      "train r2:  0.8748768082105701\n",
      "test loss:  7.528522968292236\n",
      "test r2:  -0.2918315276382468\n",
      "train loss:  1.8140079975128174\n",
      "train r2:  0.8748859245848623\n",
      "test loss:  7.52821683883667\n",
      "test r2:  -0.2918185719766544\n",
      "train loss:  1.8139374256134033\n",
      "train r2:  0.8748895792097416\n",
      "test loss:  7.5280351638793945\n",
      "test r2:  -0.2917909370486296\n",
      "train loss:  1.8138667345046997\n",
      "train r2:  0.8748989067115558\n",
      "test loss:  7.527719020843506\n",
      "test r2:  -0.2917776775402696\n",
      "train loss:  1.8137964010238647\n",
      "train r2:  0.8749024592188468\n",
      "test loss:  7.5275492668151855\n",
      "test r2:  -0.291749041824763\n",
      "train loss:  1.8137255907058716\n",
      "train r2:  0.8749122506022129\n",
      "test loss:  7.527233600616455\n",
      "test r2:  -0.2917387757119383\n",
      "train loss:  1.8136553764343262\n",
      "train r2:  0.8749150555789578\n",
      "test loss:  7.527080059051514\n",
      "test r2:  -0.29170847689058643\n",
      "train loss:  1.8135849237442017\n",
      "train r2:  0.8749255339365143\n",
      "test loss:  7.526736736297607\n",
      "test r2:  -0.2916979416885246\n",
      "train loss:  1.8135143518447876\n",
      "train r2:  0.8749279877289453\n",
      "test loss:  7.526611804962158\n",
      "test r2:  -0.29166828794809496\n",
      "train loss:  1.8134442567825317\n",
      "train r2:  0.874938732123994\n",
      "test loss:  7.5262298583984375\n",
      "test r2:  -0.29165805455691474\n",
      "train loss:  1.8133739233016968\n",
      "train r2:  0.874940560395658\n",
      "test loss:  7.5261335372924805\n",
      "test r2:  -0.2916251034471953\n",
      "train loss:  1.8133034706115723\n",
      "train r2:  0.8749526051424994\n",
      "test loss:  7.525722980499268\n",
      "test r2:  -0.2916200700037761\n",
      "train loss:  1.813233494758606\n",
      "train r2:  0.874952627150535\n",
      "test loss:  7.525662422180176\n",
      "test r2:  -0.2915818043222276\n",
      "train loss:  1.8131632804870605\n",
      "train r2:  0.8749665848766885\n",
      "test loss:  7.525217056274414\n",
      "test r2:  -0.2915817460762258\n",
      "train loss:  1.8130935430526733\n",
      "train r2:  0.874964809661547\n",
      "test loss:  7.5251874923706055\n",
      "test r2:  -0.29153876058010963\n",
      "train loss:  1.8130232095718384\n",
      "train r2:  0.8749804162607854\n",
      "test loss:  7.52471923828125\n",
      "test r2:  -0.2915436632598414\n",
      "train loss:  1.8129534721374512\n",
      "train r2:  0.8749769639254594\n",
      "test loss:  7.524682521820068\n",
      "test r2:  -0.2914939958712013\n",
      "train loss:  1.812882661819458\n",
      "train r2:  0.8749942094632922\n",
      "test loss:  7.524243354797363\n",
      "test r2:  -0.2915051347400859\n",
      "train loss:  1.8128124475479126\n",
      "train r2:  0.8749896394357555\n",
      "test loss:  7.524160385131836\n",
      "test r2:  -0.2914529085417874\n",
      "train loss:  1.8127415180206299\n",
      "train r2:  0.8750068496395078\n",
      "test loss:  7.523791790008545\n",
      "test r2:  -0.29146307295862495\n",
      "train loss:  1.8126710653305054\n",
      "train r2:  0.8750036016726739\n",
      "test loss:  7.523636341094971\n",
      "test r2:  -0.2914154555842883\n",
      "train loss:  1.8126002550125122\n",
      "train r2:  0.8750185625026994\n",
      "test loss:  7.523355484008789\n",
      "test r2:  -0.29141946927002826\n",
      "train loss:  1.8125295639038086\n",
      "train r2:  0.8750182776678604\n",
      "test loss:  7.523116588592529\n",
      "test r2:  -0.29137936358994865\n",
      "train loss:  1.8124592304229736\n",
      "train r2:  0.8750300977665648\n",
      "test loss:  7.522911071777344\n",
      "test r2:  -0.2913740144080579\n",
      "train loss:  1.8123888969421387\n",
      "train r2:  0.8750333942557483\n",
      "test loss:  7.522619247436523\n",
      "test r2:  -0.2913456680054687\n",
      "train loss:  1.8123189210891724\n",
      "train r2:  0.8750414025552019\n",
      "test loss:  7.522454738616943\n",
      "test r2:  -0.29132728105474404\n",
      "train loss:  1.812248706817627\n",
      "train r2:  0.8750487314969391\n",
      "test loss:  7.5221405029296875\n",
      "test r2:  -0.2913118909118144\n",
      "train loss:  1.8121788501739502\n",
      "train r2:  0.8750530083147072\n",
      "test loss:  7.521989822387695\n",
      "test r2:  -0.2912820525161155\n",
      "train loss:  1.8121087551116943\n",
      "train r2:  0.8750635314391493\n",
      "test loss:  7.521667003631592\n",
      "test r2:  -0.2912771727022101\n",
      "train loss:  1.812038779258728\n",
      "train r2:  0.8750649877172277\n",
      "test loss:  7.521507740020752\n",
      "test r2:  -0.291236527610655\n",
      "train loss:  1.8119686841964722\n",
      "train r2:  0.8750781484338702\n",
      "test loss:  7.521191596984863\n",
      "test r2:  -0.2912411199754823\n",
      "train loss:  1.811898946762085\n",
      "train r2:  0.8750772231051203\n",
      "test loss:  7.521020412445068\n",
      "test r2:  -0.2911929085730347\n",
      "train loss:  1.8118289709091187\n",
      "train r2:  0.875092135425352\n",
      "test loss:  7.520711898803711\n",
      "test r2:  -0.291202830051734\n",
      "train loss:  1.8117588758468628\n",
      "train r2:  0.8750899477222498\n",
      "test loss:  7.520529270172119\n",
      "test r2:  -0.2911510435802316\n",
      "train loss:  1.8116888999938965\n",
      "train r2:  0.8751055861865135\n",
      "test loss:  7.520222187042236\n",
      "test r2:  -0.29116224128908885\n",
      "train loss:  1.8116188049316406\n",
      "train r2:  0.8751030710830671\n",
      "test loss:  7.520034313201904\n",
      "test r2:  -0.29111033616680637\n",
      "train loss:  1.8115489482879639\n",
      "train r2:  0.8751186350614719\n",
      "test loss:  7.519728183746338\n",
      "test r2:  -0.29112021410540057\n",
      "train loss:  1.8114787340164185\n",
      "train r2:  0.8751164750445937\n",
      "test loss:  7.519537448883057\n",
      "test r2:  -0.2910706004936445\n",
      "train loss:  1.811408519744873\n",
      "train r2:  0.8751314194915403\n",
      "test loss:  7.519233703613281\n",
      "test r2:  -0.2910772510327049\n",
      "train loss:  1.8113385438919067\n",
      "train r2:  0.875130132576581\n",
      "test loss:  7.519045829772949\n",
      "test r2:  -0.29103182473458333\n",
      "train loss:  1.8112684488296509\n",
      "train r2:  0.8751440497204213\n",
      "test loss:  7.518743991851807\n",
      "test r2:  -0.2910344992989027\n",
      "train loss:  1.8111984729766846\n",
      "train r2:  0.8751438680170559\n",
      "test loss:  7.518552780151367\n",
      "test r2:  -0.29099265706951694\n",
      "train loss:  1.8111284971237183\n",
      "train r2:  0.8751568241288316\n",
      "test loss:  7.518258571624756\n",
      "test r2:  -0.2909918525996129\n",
      "train loss:  1.811058521270752\n",
      "train r2:  0.8751576598990616\n",
      "test loss:  7.51806640625\n",
      "test r2:  -0.2909543129141898\n",
      "train loss:  1.810988426208496\n",
      "train r2:  0.8751695437816335\n",
      "test loss:  7.517773151397705\n",
      "test r2:  -0.29094863215733757\n",
      "train loss:  1.8109186887741089\n",
      "train r2:  0.8751716131534726\n",
      "test loss:  7.517584323883057\n",
      "test r2:  -0.2909155191885373\n",
      "train loss:  1.8108487129211426\n",
      "train r2:  0.8751824178003548\n",
      "test loss:  7.517295837402344\n",
      "test r2:  -0.29090788392788003\n",
      "train loss:  1.8107786178588867\n",
      "train r2:  0.8751851802790762\n",
      "test loss:  7.517097473144531\n",
      "test r2:  -0.2908747569290808\n",
      "train loss:  1.8107088804244995\n",
      "train r2:  0.8751958096657247\n",
      "test loss:  7.516818523406982\n",
      "test r2:  -0.29086740383320997\n",
      "train loss:  1.8106390237808228\n",
      "train r2:  0.8751986278339177\n",
      "test loss:  7.516617298126221\n",
      "test r2:  -0.2908348383743693\n",
      "train loss:  1.8105690479278564\n",
      "train r2:  0.8752091155103997\n",
      "test loss:  7.516334533691406\n",
      "test r2:  -0.2908262796735126\n",
      "train loss:  1.810498833656311\n",
      "train r2:  0.875212172970965\n",
      "test loss:  7.516138076782227\n",
      "test r2:  -0.2907942086973796\n",
      "train loss:  1.8104292154312134\n",
      "train r2:  0.8752225827518678\n",
      "test loss:  7.5158491134643555\n",
      "test r2:  -0.2907868209381945\n",
      "train loss:  1.8103593587875366\n",
      "train r2:  0.8752252803297589\n",
      "test loss:  7.515653610229492\n",
      "test r2:  -0.2907516736441116\n",
      "train loss:  1.8102896213531494\n",
      "train r2:  0.8752364725140035\n",
      "test loss:  7.5153584480285645\n",
      "test r2:  -0.29074799249187855\n",
      "train loss:  1.8102198839187622\n",
      "train r2:  0.8752380887522277\n",
      "test loss:  7.515172004699707\n",
      "test r2:  -0.2907088284234076\n",
      "train loss:  1.8101502656936646\n",
      "train r2:  0.8752504562218621\n",
      "test loss:  7.514860153198242\n",
      "test r2:  -0.2907094272483448\n",
      "train loss:  1.8100807666778564\n",
      "train r2:  0.8752507239666866\n",
      "test loss:  7.514691352844238\n",
      "test r2:  -0.2906645298955244\n",
      "train loss:  1.8100107908248901\n",
      "train r2:  0.87526480091584\n",
      "test loss:  7.514352321624756\n",
      "test r2:  -0.29067211392313097\n",
      "train loss:  1.8099414110183716\n",
      "train r2:  0.875262886658437\n",
      "test loss:  7.514209270477295\n",
      "test r2:  -0.2906188012130324\n",
      "train loss:  1.809872031211853\n",
      "train r2:  0.875279520364638\n",
      "test loss:  7.513837814331055\n",
      "test r2:  -0.29063603521735115\n",
      "train loss:  1.8098030090332031\n",
      "train r2:  0.8752745644813829\n",
      "test loss:  7.5137176513671875\n",
      "test r2:  -0.29056991125428944\n",
      "train loss:  1.809733271598816\n",
      "train r2:  0.875294910092139\n",
      "test loss:  7.51333475112915\n",
      "test r2:  -0.29060356734585846\n",
      "train loss:  1.8096647262573242\n",
      "train r2:  0.8752855221349982\n",
      "test loss:  7.513208389282227\n",
      "test r2:  -0.29051868846104045\n",
      "train loss:  1.809594988822937\n",
      "train r2:  0.8753105753616373\n",
      "test loss:  7.512852668762207\n",
      "test r2:  -0.2905711173958976\n",
      "train loss:  1.8095265626907349\n",
      "train r2:  0.8752967538434868\n",
      "test loss:  7.512671947479248\n",
      "test r2:  -0.2904688833613034\n",
      "train loss:  1.809456467628479\n",
      "train r2:  0.8753254794648982\n",
      "test loss:  7.51240873336792\n",
      "test r2:  -0.290537628025777\n",
      "train loss:  1.8093873262405396\n",
      "train r2:  0.87530885853049\n",
      "test loss:  7.512110710144043\n",
      "test r2:  -0.29042141537675814\n",
      "train loss:  1.809317946434021\n",
      "train r2:  0.8753394416601916\n",
      "test loss:  7.511987209320068\n",
      "test r2:  -0.2905018668895374\n",
      "train loss:  1.8092488050460815\n",
      "train r2:  0.8753219189951024\n",
      "test loss:  7.5115556716918945\n",
      "test r2:  -0.2903759781577673\n",
      "train loss:  1.8091800212860107\n",
      "train r2:  0.8753530813935738\n",
      "test loss:  7.511569499969482\n",
      "test r2:  -0.29046686458166926\n",
      "train loss:  1.8091109991073608\n",
      "train r2:  0.8753350067425463\n",
      "test loss:  7.51103401184082\n",
      "test r2:  -0.29033046435341525\n",
      "train loss:  1.8090423345565796\n",
      "train r2:  0.8753673404383624\n",
      "test loss:  7.51112699508667\n",
      "test r2:  -0.2904309188966656\n",
      "train loss:  1.8089730739593506\n",
      "train r2:  0.8753480434206149\n",
      "test loss:  7.510559558868408\n",
      "test r2:  -0.2902880026575845\n",
      "train loss:  1.8089033365249634\n",
      "train r2:  0.8753816367246217\n",
      "test loss:  7.5106401443481445\n",
      "test r2:  -0.2903915586621817\n",
      "train loss:  1.808833360671997\n",
      "train r2:  0.8753613504635679\n",
      "test loss:  7.510120868682861\n",
      "test r2:  -0.29024869248459506\n",
      "train loss:  1.8087626695632935\n",
      "train r2:  0.875395657686717\n",
      "test loss:  7.510114669799805\n",
      "test r2:  -0.29034791944594085\n",
      "train loss:  1.8086918592453003\n",
      "train r2:  0.8753752377260161\n",
      "test loss:  7.509707927703857\n",
      "test r2:  -0.2902148025323996\n",
      "train loss:  1.808620810508728\n",
      "train r2:  0.8754087081443818\n",
      "test loss:  7.509558200836182\n",
      "test r2:  -0.2902972585449366\n",
      "train loss:  1.808550238609314\n",
      "train r2:  0.8753903652785098\n",
      "test loss:  7.509289741516113\n",
      "test r2:  -0.29018565816491027\n",
      "train loss:  1.8084793090820312\n",
      "train r2:  0.8754203272757727\n",
      "test loss:  7.509006023406982\n",
      "test r2:  -0.2902435553625553\n",
      "train loss:  1.8084090948104858\n",
      "train r2:  0.8754062332205164\n",
      "test loss:  7.508821487426758\n",
      "test r2:  -0.290156359274903\n",
      "train loss:  1.8083380460739136\n",
      "train r2:  0.8754311022903681\n",
      "test loss:  7.508491516113281\n",
      "test r2:  -0.29018827548683346\n",
      "train loss:  1.8082674741744995\n",
      "train r2:  0.8754230147196791\n",
      "test loss:  7.5083160400390625\n",
      "test r2:  -0.2901312495705626\n",
      "train loss:  1.8081966638565063\n",
      "train r2:  0.8754401958210147\n",
      "test loss:  7.507998943328857\n",
      "test r2:  -0.2901291255515983\n",
      "train loss:  1.8081265687942505\n",
      "train r2:  0.8754410997661816\n",
      "test loss:  7.507789134979248\n",
      "test r2:  -0.29010625168019377\n",
      "train loss:  1.8080564737319946\n",
      "train r2:  0.8754489981903782\n",
      "test loss:  7.50752592086792\n",
      "test r2:  -0.2900737358527308\n",
      "train loss:  1.8079867362976074\n",
      "train r2:  0.8754585649153782\n",
      "test loss:  7.507261276245117\n",
      "test r2:  -0.29007578460535854\n",
      "train loss:  1.807917594909668\n",
      "train r2:  0.8754592301596149\n",
      "test loss:  7.507055759429932\n",
      "test r2:  -0.2900231911651785\n",
      "train loss:  1.8078482151031494\n",
      "train r2:  0.8754748700623064\n",
      "test loss:  7.506765365600586\n",
      "test r2:  -0.29004356295318034\n",
      "train loss:  1.8077791929244995\n",
      "train r2:  0.8754704979973127\n",
      "test loss:  7.506555080413818\n",
      "test r2:  -0.2899740266485713\n",
      "train loss:  1.8077093362808228\n",
      "train r2:  0.8754904762902116\n",
      "test loss:  7.506298542022705\n",
      "test r2:  -0.2900086691043735\n",
      "train loss:  1.8076399564743042\n",
      "train r2:  0.8754828994112402\n",
      "test loss:  7.506041049957275\n",
      "test r2:  -0.28993017673246757\n",
      "train loss:  1.8075698614120483\n",
      "train r2:  0.8755045197316823\n",
      "test loss:  7.505844593048096\n",
      "test r2:  -0.28996842870762873\n",
      "train loss:  1.8075003623962402\n",
      "train r2:  0.8754969521218481\n",
      "test loss:  7.505529403686523\n",
      "test r2:  -0.2898903453767603\n",
      "train loss:  1.807430624961853\n",
      "train r2:  0.8755175343854378\n",
      "test loss:  7.505395412445068\n",
      "test r2:  -0.289927281776321\n",
      "train loss:  1.8073606491088867\n",
      "train r2:  0.8755112894916387\n",
      "test loss:  7.5050153732299805\n",
      "test r2:  -0.2898493440993726\n",
      "train loss:  1.8072909116744995\n",
      "train r2:  0.8755309097692736\n",
      "test loss:  7.504931449890137\n",
      "test r2:  -0.28988655090719506\n",
      "train loss:  1.8072214126586914\n",
      "train r2:  0.8755253041332902\n",
      "test loss:  7.504519939422607\n",
      "test r2:  -0.2898093606175125\n",
      "train loss:  1.807151436805725\n",
      "train r2:  0.8755443242455535\n",
      "test loss:  7.50444221496582\n",
      "test r2:  -0.28984424123510855\n",
      "train loss:  1.8070815801620483\n",
      "train r2:  0.8755393891852756\n",
      "test loss:  7.504045009613037\n",
      "test r2:  -0.28976993415733676\n",
      "train loss:  1.8070117235183716\n",
      "train r2:  0.8755578399907793\n",
      "test loss:  7.50393533706665\n",
      "test r2:  -0.28980214479852573\n",
      "train loss:  1.8069419860839844\n",
      "train r2:  0.8755531035425191\n",
      "test loss:  7.503573894500732\n",
      "test r2:  -0.28972945402170325\n",
      "train loss:  1.8068718910217285\n",
      "train r2:  0.8755716582407786\n",
      "test loss:  7.503417491912842\n",
      "test r2:  -0.28976017181774183\n",
      "train loss:  1.8068020343780518\n",
      "train r2:  0.8755666101442838\n",
      "test loss:  7.50309944152832\n",
      "test r2:  -0.28968842858404265\n",
      "train loss:  1.806732177734375\n",
      "train r2:  0.8755855867438482\n",
      "test loss:  7.502897262573242\n",
      "test r2:  -0.2897189213266078\n",
      "train loss:  1.8066624402999878\n",
      "train r2:  0.8755799060365825\n",
      "test loss:  7.502618312835693\n",
      "test r2:  -0.2896460304062163\n",
      "train loss:  1.8065927028656006\n",
      "train r2:  0.8755996917294723\n",
      "test loss:  7.502383708953857\n",
      "test r2:  -0.2896783730399979\n",
      "train loss:  1.806523084640503\n",
      "train r2:  0.8755931090258946\n",
      "test loss:  7.502127170562744\n",
      "test r2:  -0.2896034361606894\n",
      "train loss:  1.8064533472061157\n",
      "train r2:  0.8756137300636258\n",
      "test loss:  7.501880168914795\n",
      "test r2:  -0.2896385324715993\n",
      "train loss:  1.806383490562439\n",
      "train r2:  0.8756062559632312\n",
      "test loss:  7.50161600112915\n",
      "test r2:  -0.2895590969519535\n",
      "train loss:  1.8063137531280518\n",
      "train r2:  0.8756279782911242\n",
      "test loss:  7.50139045715332\n",
      "test r2:  -0.28959997737062837\n",
      "train loss:  1.8062443733215332\n",
      "train r2:  0.8756192668293246\n",
      "test loss:  7.501099109649658\n",
      "test r2:  -0.28951438546692176\n",
      "train loss:  1.8061742782592773\n",
      "train r2:  0.8756421743964694\n",
      "test loss:  7.500913619995117\n",
      "test r2:  -0.28956234485781596\n",
      "train loss:  1.8061048984527588\n",
      "train r2:  0.875632297573711\n",
      "test loss:  7.500577926635742\n",
      "test r2:  -0.28946831354715985\n",
      "train loss:  1.8060356378555298\n",
      "train r2:  0.8756567327470224\n",
      "test loss:  7.500443935394287\n",
      "test r2:  -0.2895263725997894\n",
      "train loss:  1.8059660196304321\n",
      "train r2:  0.8756450071525996\n",
      "test loss:  7.500059604644775\n",
      "test r2:  -0.28942127933741424\n",
      "train loss:  1.8058966398239136\n",
      "train r2:  0.8756715795641309\n",
      "test loss:  7.499971389770508\n",
      "test r2:  -0.2894913790335323\n",
      "train loss:  1.8058276176452637\n",
      "train r2:  0.8756575087195324\n",
      "test loss:  7.499548435211182\n",
      "test r2:  -0.2893728078822777\n",
      "train loss:  1.8057583570480347\n",
      "train r2:  0.8756870072564946\n",
      "test loss:  7.499499797821045\n",
      "test r2:  -0.2894593832540979\n",
      "train loss:  1.8056895732879639\n",
      "train r2:  0.8756692478890088\n",
      "test loss:  7.49904203414917\n",
      "test r2:  -0.28932129445299015\n",
      "train loss:  1.8056210279464722\n",
      "train r2:  0.8757032608753305\n",
      "test loss:  7.499021530151367\n",
      "test r2:  -0.289429461616469\n",
      "train loss:  1.805552363395691\n",
      "train r2:  0.8756803441792311\n",
      "test loss:  7.498535633087158\n",
      "test r2:  -0.28926796906878427\n",
      "train loss:  1.8054836988449097\n",
      "train r2:  0.8757199645323889\n",
      "test loss:  7.498531818389893\n",
      "test r2:  -0.28939985531177337\n",
      "train loss:  1.8054157495498657\n",
      "train r2:  0.8756911763792725\n",
      "test loss:  7.498029708862305\n",
      "test r2:  -0.28921460188951853\n",
      "train loss:  1.8053473234176636\n",
      "train r2:  0.8757366841886071\n",
      "test loss:  7.498039245605469\n",
      "test r2:  -0.28936935615022774\n",
      "train loss:  1.8052788972854614\n",
      "train r2:  0.8757022052659741\n",
      "test loss:  7.497513294219971\n",
      "test r2:  -0.28916375162244257\n",
      "train loss:  1.8052090406417847\n",
      "train r2:  0.8757525663880892\n",
      "test loss:  7.497547626495361\n",
      "test r2:  -0.2893324069741512\n",
      "train loss:  1.8051396608352661\n",
      "train r2:  0.8757148579195181\n",
      "test loss:  7.49699592590332\n",
      "test r2:  -0.28912319955080523\n",
      "train loss:  1.8050682544708252\n",
      "train r2:  0.8757657567424565\n",
      "test loss:  7.497045993804932\n",
      "test r2:  -0.2892823698489524\n",
      "train loss:  1.8049968481063843\n",
      "train r2:  0.8757307518215899\n",
      "test loss:  7.496495246887207\n",
      "test r2:  -0.28909689201225475\n",
      "train loss:  1.8049241304397583\n",
      "train r2:  0.8757756233301587\n",
      "test loss:  7.496527194976807\n",
      "test r2:  -0.2892194339973311\n",
      "train loss:  1.8048511743545532\n",
      "train r2:  0.8757498107742029\n",
      "test loss:  7.496029376983643\n",
      "test r2:  -0.28908191134047967\n",
      "train loss:  1.8047785758972168\n",
      "train r2:  0.8757831547711636\n",
      "test loss:  7.495986461639404\n",
      "test r2:  -0.2891486429151493\n",
      "train loss:  1.8047064542770386\n",
      "train r2:  0.8757706398084993\n",
      "test loss:  7.495593547821045\n",
      "test r2:  -0.28907088460508223\n",
      "train loss:  1.8046350479125977\n",
      "train r2:  0.8757901540677072\n",
      "test loss:  7.495437145233154\n",
      "test r2:  -0.2890783980935403\n",
      "train loss:  1.8045639991760254\n",
      "train r2:  0.8757912448708719\n",
      "test loss:  7.495169162750244\n",
      "test r2:  -0.2890571388640635\n",
      "train loss:  1.8044936656951904\n",
      "train r2:  0.8757981166770707\n",
      "test loss:  7.4948930740356445\n",
      "test r2:  -0.2890130666267514\n",
      "train loss:  1.8044244050979614\n",
      "train r2:  0.8758106938779381\n",
      "test loss:  7.49473762512207\n",
      "test r2:  -0.2890377970623268\n",
      "train loss:  1.8043551445007324\n",
      "train r2:  0.8758073960996879\n",
      "test loss:  7.494363307952881\n",
      "test r2:  -0.2889540275633278\n",
      "train loss:  1.804286003112793\n",
      "train r2:  0.8758287573794825\n",
      "test loss:  7.4942827224731445\n",
      "test r2:  -0.28901106027134715\n",
      "train loss:  1.8042166233062744\n",
      "train r2:  0.8758181831327774\n",
      "test loss:  7.493854999542236\n",
      "test r2:  -0.2889031600465217\n",
      "train loss:  1.8041470050811768\n",
      "train r2:  0.8758449590032932\n",
      "test loss:  7.493791580200195\n",
      "test r2:  -0.2889753298372515\n",
      "train loss:  1.8040775060653687\n",
      "train r2:  0.875830734517053\n",
      "test loss:  7.493361949920654\n",
      "test r2:  -0.2888586833356024\n",
      "train loss:  1.8040072917938232\n",
      "train r2:  0.8758597047688014\n",
      "test loss:  7.493278503417969\n",
      "test r2:  -0.2889342553007388\n",
      "train loss:  1.8039370775222778\n",
      "train r2:  0.8758443229168145\n",
      "test loss:  7.492874622344971\n",
      "test r2:  -0.28881901330645077\n",
      "train loss:  1.8038666248321533\n",
      "train r2:  0.8758732677829707\n",
      "test loss:  7.492748737335205\n",
      "test r2:  -0.28888716002670245\n",
      "train loss:  1.8037959337234497\n",
      "train r2:  0.875859153905271\n",
      "test loss:  7.4923906326293945\n",
      "test r2:  -0.288784937199722\n",
      "train loss:  1.8037251234054565\n",
      "train r2:  0.8758854174659104\n",
      "test loss:  7.492211818695068\n",
      "test r2:  -0.2888353395759762\n",
      "train loss:  1.8036547899246216\n",
      "train r2:  0.8758750989348877\n",
      "test loss:  7.4919023513793945\n",
      "test r2:  -0.2887535563889405\n",
      "train loss:  1.8035838603973389\n",
      "train r2:  0.8758968225492001\n",
      "test loss:  7.491687297821045\n",
      "test r2:  -0.288782627427667\n",
      "train loss:  1.8035129308700562\n",
      "train r2:  0.8758914355241868\n",
      "test loss:  7.491403102874756\n",
      "test r2:  -0.288722232202006\n",
      "train loss:  1.8034427165985107\n",
      "train r2:  0.8759080836043043\n",
      "test loss:  7.491172790527344\n",
      "test r2:  -0.2887300970016402\n",
      "train loss:  1.8033720254898071\n",
      "train r2:  0.87590792906071\n",
      "test loss:  7.490906238555908\n",
      "test r2:  -0.288691596845013\n",
      "train loss:  1.8033018112182617\n",
      "train r2:  0.8759192547229203\n",
      "test loss:  7.490663528442383\n",
      "test r2:  -0.28867755088249636\n",
      "train loss:  1.8032317161560059\n",
      "train r2:  0.8759245701778001\n",
      "test loss:  7.490415573120117\n",
      "test r2:  -0.2886601028848492\n",
      "train loss:  1.8031611442565918\n",
      "train r2:  0.8759307490781769\n",
      "test loss:  7.490161418914795\n",
      "test r2:  -0.28862808709064836\n",
      "train loss:  1.8030911684036255\n",
      "train r2:  0.8759406011435442\n",
      "test loss:  7.489920139312744\n",
      "test r2:  -0.28862489140096037\n",
      "train loss:  1.8030210733413696\n",
      "train r2:  0.8759432220129639\n",
      "test loss:  7.489663600921631\n",
      "test r2:  -0.28858108178065245\n",
      "train loss:  1.8029507398605347\n",
      "train r2:  0.8759560047986265\n",
      "test loss:  7.4894328117370605\n",
      "test r2:  -0.2885892551132787\n",
      "train loss:  1.8028805255889893\n",
      "train r2:  0.8759558995301868\n",
      "test loss:  7.4891557693481445\n",
      "test r2:  -0.28853375661125646\n",
      "train loss:  1.802810549736023\n",
      "train r2:  0.8759714152630851\n",
      "test loss:  7.488945484161377\n",
      "test r2:  -0.2885531344158141\n",
      "train loss:  1.802740216255188\n",
      "train r2:  0.8759687031972627\n",
      "test loss:  7.488646984100342\n",
      "test r2:  -0.28848769020518183\n",
      "train loss:  1.8026701211929321\n",
      "train r2:  0.8759864850603616\n",
      "test loss:  7.488454818725586\n",
      "test r2:  -0.28851541408954495\n",
      "train loss:  1.8025999069213867\n",
      "train r2:  0.8759818421783956\n",
      "test loss:  7.4881367683410645\n",
      "test r2:  -0.2884422577338608\n",
      "train loss:  1.8025298118591309\n",
      "train r2:  0.8760013298640412\n",
      "test loss:  7.487960338592529\n",
      "test r2:  -0.28847829394000857\n",
      "train loss:  1.802459716796875\n",
      "train r2:  0.8759948211406352\n",
      "test loss:  7.487618923187256\n",
      "test r2:  -0.2883951103132878\n",
      "train loss:  1.8023896217346191\n",
      "train r2:  0.8760164786395087\n",
      "test loss:  7.487462997436523\n",
      "test r2:  -0.2884418603428427\n",
      "train loss:  1.8023195266723633\n",
      "train r2:  0.8760074826993207\n",
      "test loss:  7.487102031707764\n",
      "test r2:  -0.28834736752509715\n",
      "train loss:  1.8022494316101074\n",
      "train r2:  0.8760317896947122\n",
      "test loss:  7.486963272094727\n",
      "test r2:  -0.2884065096403998\n",
      "train loss:  1.8021794557571411\n",
      "train r2:  0.8760198600016246\n",
      "test loss:  7.486579895019531\n",
      "test r2:  -0.28829728934627785\n",
      "train loss:  1.8021094799041748\n",
      "train r2:  0.8760476153657231\n",
      "test loss:  7.486466884613037\n",
      "test r2:  -0.2883739056799648\n",
      "train loss:  1.8020399808883667\n",
      "train r2:  0.8760316113380225\n",
      "test loss:  7.486052989959717\n",
      "test r2:  -0.2882448699763982\n",
      "train loss:  1.8019702434539795\n",
      "train r2:  0.8760639936406439\n",
      "test loss:  7.4859724044799805\n",
      "test r2:  -0.2883427172706503\n",
      "train loss:  1.8019009828567505\n",
      "train r2:  0.8760429917883606\n",
      "test loss:  7.485523700714111\n",
      "test r2:  -0.28819098043876235\n",
      "train loss:  1.8018313646316528\n",
      "train r2:  0.876080717385874\n",
      "test loss:  7.485485553741455\n",
      "test r2:  -0.2883139489480986\n",
      "train loss:  1.8017627000808716\n",
      "train r2:  0.8760538587951568\n",
      "test loss:  7.484979152679443\n",
      "test r2:  -0.28813397545484043\n",
      "train loss:  1.8016934394836426\n",
      "train r2:  0.8760979581570397\n",
      "test loss:  7.485011100769043\n",
      "test r2:  -0.2882872351867991\n",
      "train loss:  1.8016250133514404\n",
      "train r2:  0.876064393393234\n",
      "test loss:  7.484426498413086\n",
      "test r2:  -0.2880769260296163\n",
      "train loss:  1.8015559911727905\n",
      "train r2:  0.8761151727134863\n",
      "test loss:  7.48454475402832\n",
      "test r2:  -0.2882587238938301\n",
      "train loss:  1.8014875650405884\n",
      "train r2:  0.8760755016001385\n",
      "test loss:  7.483877658843994\n",
      "test r2:  -0.28802446395528714\n",
      "train loss:  1.8014183044433594\n",
      "train r2:  0.8761312566370812\n",
      "test loss:  7.484069347381592\n",
      "test r2:  -0.2882238488882334\n",
      "train loss:  1.8013489246368408\n",
      "train r2:  0.8760881481252598\n",
      "test loss:  7.4833478927612305\n",
      "test r2:  -0.28797936704877247\n",
      "train loss:  1.8012782335281372\n",
      "train r2:  0.8761458202326486\n",
      "test loss:  7.483578205108643\n",
      "test r2:  -0.28818135998854166\n",
      "train loss:  1.8012069463729858\n",
      "train r2:  0.8761026319511628\n",
      "test loss:  7.482852458953857\n",
      "test r2:  -0.2879444843010741\n",
      "train loss:  1.8011339902877808\n",
      "train r2:  0.8761583457969759\n",
      "test loss:  7.4830474853515625\n",
      "test r2:  -0.28812602278849697\n",
      "train loss:  1.801060676574707\n",
      "train r2:  0.8761199371932669\n",
      "test loss:  7.482404708862305\n",
      "test r2:  -0.2879241163800268\n",
      "train loss:  1.800986647605896\n",
      "train r2:  0.8761679201326724\n",
      "test loss:  7.482473850250244\n",
      "test r2:  -0.2880564480191603\n",
      "train loss:  1.800912618637085\n",
      "train r2:  0.8761403154039404\n",
      "test loss:  7.481991291046143\n",
      "test r2:  -0.287915339724671\n",
      "train loss:  1.8008391857147217\n",
      "train r2:  0.8761749794885986\n",
      "test loss:  7.481887340545654\n",
      "test r2:  -0.28797992915812376\n",
      "train loss:  1.8007664680480957\n",
      "train r2:  0.8761623257748512\n",
      "test loss:  7.481574535369873\n",
      "test r2:  -0.287908893302639\n",
      "train loss:  1.8006945848464966\n",
      "train r2:  0.8761813910135037\n",
      "test loss:  7.481314182281494\n",
      "test r2:  -0.28790444746015775\n",
      "train loss:  1.8006236553192139\n",
      "train r2:  0.8761841440140374\n",
      "test loss:  7.481136798858643\n",
      "test r2:  -0.2878995961814268\n",
      "train loss:  1.800553321838379\n",
      "train r2:  0.8761882627102642\n",
      "test loss:  7.480759143829346\n",
      "test r2:  -0.2878336084916435\n",
      "train loss:  1.8004831075668335\n",
      "train r2:  0.8762050783619514\n",
      "test loss:  7.48067045211792\n",
      "test r2:  -0.2878826798613463\n",
      "train loss:  1.8004133701324463\n",
      "train r2:  0.8761965454193821\n",
      "test loss:  7.480228900909424\n",
      "test r2:  -0.287772042254673\n",
      "train loss:  1.8003432750701904\n",
      "train r2:  0.8762239274115728\n",
      "test loss:  7.480171203613281\n",
      "test r2:  -0.28785515631308023\n",
      "train loss:  1.8002732992172241\n",
      "train r2:  0.8762071178737701\n",
      "test loss:  7.479713439941406\n",
      "test r2:  -0.2877200988806732\n",
      "train loss:  1.8002026081085205\n",
      "train r2:  0.8762405073576504\n",
      "test loss:  7.479655742645264\n",
      "test r2:  -0.28781881412187027\n",
      "train loss:  1.8001322746276855\n",
      "train r2:  0.8762196542853419\n",
      "test loss:  7.4791975021362305\n",
      "test r2:  -0.2876754243447195\n",
      "train loss:  1.8000612258911133\n",
      "train r2:  0.8762551689671315\n",
      "test loss:  7.479136943817139\n",
      "test r2:  -0.28777465029426685\n",
      "train loss:  1.7999900579452515\n",
      "train r2:  0.8762341818565665\n",
      "test loss:  7.478687763214111\n",
      "test r2:  -0.2876400607346774\n",
      "train loss:  1.7999184131622314\n",
      "train r2:  0.8762675423765424\n",
      "test loss:  7.478606700897217\n",
      "test r2:  -0.2877210685399909\n",
      "train loss:  1.7998467683792114\n",
      "train r2:  0.8762509079539739\n",
      "test loss:  7.478186130523682\n",
      "test r2:  -0.2876117471356596\n",
      "train loss:  1.7997751235961914\n",
      "train r2:  0.8762782389390115\n",
      "test loss:  7.478073596954346\n",
      "test r2:  -0.28766375816088097\n",
      "train loss:  1.7997033596038818\n",
      "train r2:  0.8762686502117335\n",
      "test loss:  7.477691650390625\n",
      "test r2:  -0.2875847800273965\n",
      "train loss:  1.7996318340301514\n",
      "train r2:  0.8762887843953862\n",
      "test loss:  7.477545261383057\n",
      "test r2:  -0.2876076370423204\n",
      "train loss:  1.799560546875\n",
      "train r2:  0.8762861748707522\n",
      "test loss:  7.477203845977783\n",
      "test r2:  -0.28755609665904935\n",
      "train loss:  1.799489140510559\n",
      "train r2:  0.8762998632981571\n",
      "test loss:  7.477014541625977\n",
      "test r2:  -0.2875533452103354\n",
      "train loss:  1.7994182109832764\n",
      "train r2:  0.8763032393198247\n",
      "test loss:  7.4767255783081055\n",
      "test r2:  -0.2875262751771801\n",
      "train loss:  1.7993468046188354\n",
      "train r2:  0.876311455622916\n",
      "test loss:  7.4764790534973145\n",
      "test r2:  -0.2875001619080322\n",
      "train loss:  1.7992756366729736\n",
      "train r2:  0.876320015101161\n",
      "test loss:  7.476251125335693\n",
      "test r2:  -0.28749504331378395\n",
      "train loss:  1.799204707145691\n",
      "train r2:  0.8763234790550224\n",
      "test loss:  7.475950241088867\n",
      "test r2:  -0.2874500077050519\n",
      "train loss:  1.7991336584091187\n",
      "train r2:  0.8763361107945695\n",
      "test loss:  7.475761413574219\n",
      "test r2:  -0.2874594237719814\n",
      "train loss:  1.7990626096725464\n",
      "train r2:  0.8763363764466757\n",
      "test loss:  7.475430011749268\n",
      "test r2:  -0.2874033911673535\n",
      "train loss:  1.7989916801452637\n",
      "train r2:  0.8763513864891279\n",
      "test loss:  7.475263595581055\n",
      "test r2:  -0.2874222190901645\n",
      "train loss:  1.7989206314086914\n",
      "train r2:  0.8763495569831683\n",
      "test loss:  7.4749064445495605\n",
      "test r2:  -0.28735538359109314\n",
      "train loss:  1.7988498210906982\n",
      "train r2:  0.8763669655010602\n",
      "test loss:  7.474766731262207\n",
      "test r2:  -0.28738760712759226\n",
      "train loss:  1.7987785339355469\n",
      "train r2:  0.8763620890856839\n",
      "test loss:  7.474379062652588\n",
      "test r2:  -0.28730620126765216\n",
      "train loss:  1.7987077236175537\n",
      "train r2:  0.8763827762612462\n",
      "test loss:  7.474255084991455\n",
      "test r2:  -0.2873509542978663\n",
      "train loss:  1.7986364364624023\n",
      "train r2:  0.8763748995607288\n",
      "test loss:  7.473861217498779\n",
      "test r2:  -0.28725928824023095\n",
      "train loss:  1.79856538772583\n",
      "train r2:  0.8763980831231457\n",
      "test loss:  7.473735332489014\n",
      "test r2:  -0.28731322540612925\n",
      "train loss:  1.7984942197799683\n",
      "train r2:  0.8763878533233307\n",
      "test loss:  7.4733381271362305\n",
      "test r2:  -0.28721072633358835\n",
      "train loss:  1.798423409461975\n",
      "train r2:  0.8764137876424581\n",
      "test loss:  7.473227024078369\n",
      "test r2:  -0.2872793646527172\n",
      "train loss:  1.7983527183532715\n",
      "train r2:  0.8763999588975598\n",
      "test loss:  7.472797870635986\n",
      "test r2:  -0.28715774912275416\n",
      "train loss:  1.7982816696166992\n",
      "train r2:  0.8764303489953778\n",
      "test loss:  7.472728252410889\n",
      "test r2:  -0.28724839937568825\n",
      "train loss:  1.7982112169265747\n",
      "train r2:  0.8764114831660815\n",
      "test loss:  7.472254753112793\n",
      "test r2:  -0.2871039891403824\n",
      "train loss:  1.798140525817871\n",
      "train r2:  0.8764470964872223\n",
      "test loss:  7.472230911254883\n",
      "test r2:  -0.2872172475017203\n",
      "train loss:  1.7980701923370361\n",
      "train r2:  0.8764231008875317\n",
      "test loss:  7.471708297729492\n",
      "test r2:  -0.28704946391885144\n",
      "train loss:  1.7979998588562012\n",
      "train r2:  0.8764639852253113\n",
      "test loss:  7.471746921539307\n",
      "test r2:  -0.28718951572778684\n",
      "train loss:  1.7979304790496826\n",
      "train r2:  0.8764340003052057\n",
      "test loss:  7.471142292022705\n",
      "test r2:  -0.28698966307358775\n",
      "train loss:  1.7978603839874268\n",
      "train r2:  0.8764819034176137\n",
      "test loss:  7.471280097961426\n",
      "test r2:  -0.2871659402581179\n",
      "train loss:  1.7977912425994873\n",
      "train r2:  0.8764440974005441\n",
      "test loss:  7.470571994781494\n",
      "test r2:  -0.28692860115875796\n",
      "train loss:  1.7977222204208374\n",
      "train r2:  0.8765001631215241\n",
      "test loss:  7.470814228057861\n",
      "test r2:  -0.28714214137761185\n",
      "train loss:  1.7976536750793457\n",
      "train r2:  0.876454236947625\n",
      "test loss:  7.470006942749023\n",
      "test r2:  -0.28686842679600466\n",
      "train loss:  1.7975845336914062\n",
      "train r2:  0.8765182321454461\n",
      "test loss:  7.470342636108398\n",
      "test r2:  -0.28711700085233316\n",
      "train loss:  1.7975157499313354\n",
      "train r2:  0.8764647274630628\n",
      "test loss:  7.469448566436768\n",
      "test r2:  -0.2868112316349336\n",
      "train loss:  1.7974454164505005\n",
      "train r2:  0.8765357149844597\n",
      "test loss:  7.469854831695557\n",
      "test r2:  -0.287085513966566\n",
      "train loss:  1.7973747253417969\n",
      "train r2:  0.876476598238903\n",
      "test loss:  7.468921184539795\n",
      "test r2:  -0.28676533292114215\n",
      "train loss:  1.7973017692565918\n",
      "train r2:  0.8765508442953125\n",
      "test loss:  7.469326496124268\n",
      "test r2:  -0.28703728026358855\n",
      "train loss:  1.7972279787063599\n",
      "train r2:  0.8764923231809019\n",
      "test loss:  7.468451023101807\n",
      "test r2:  -0.28674175713605443\n",
      "train loss:  1.7971516847610474\n",
      "train r2:  0.876561085317696\n",
      "test loss:  7.468735218048096\n",
      "test r2:  -0.2869642684844842\n",
      "train loss:  1.7970751523971558\n",
      "train r2:  0.8765135725620824\n",
      "test loss:  7.46803092956543\n",
      "test r2:  -0.2867405965048959\n",
      "train loss:  1.7969982624053955\n",
      "train r2:  0.8765663754112236\n",
      "test loss:  7.468107223510742\n",
      "test r2:  -0.2868738979917791\n",
      "train loss:  1.7969229221343994\n",
      "train r2:  0.8765387617525577\n",
      "test loss:  7.467636585235596\n",
      "test r2:  -0.2867512640026799\n",
      "train loss:  1.7968482971191406\n",
      "train r2:  0.8765689939206047\n",
      "test loss:  7.467475414276123\n",
      "test r2:  -0.28677804249859973\n",
      "train loss:  1.7967753410339355\n",
      "train r2:  0.8765652493809858\n",
      "test loss:  7.467241287231445\n",
      "test r2:  -0.28676151089543\n",
      "train loss:  1.796703815460205\n",
      "train r2:  0.876571628647436\n",
      "test loss:  7.466861248016357\n",
      "test r2:  -0.2866892476096059\n",
      "train loss:  1.796633005142212\n",
      "train r2:  0.8765902455315682\n",
      "test loss:  7.466810703277588\n",
      "test r2:  -0.28675852135456004\n",
      "train loss:  1.7965627908706665\n",
      "train r2:  0.87657718408806\n",
      "test loss:  7.46628999710083\n",
      "test r2:  -0.2866169952815183\n",
      "train loss:  1.796492338180542\n",
      "train r2:  0.8766114754617298\n",
      "test loss:  7.466339111328125\n",
      "test r2:  -0.28673869210354885\n",
      "train loss:  1.796422004699707\n",
      "train r2:  0.8765864303097929\n",
      "test loss:  7.465742111206055\n",
      "test r2:  -0.2865593931357773\n",
      "train loss:  1.7963507175445557\n",
      "train r2:  0.8766293332583703\n",
      "test loss:  7.46583890914917\n",
      "test r2:  -0.28670475284358754\n",
      "train loss:  1.7962791919708252\n",
      "train r2:  0.8765988730805833\n",
      "test loss:  7.465216159820557\n",
      "test r2:  -0.28651658482318765\n",
      "train loss:  1.7962067127227783\n",
      "train r2:  0.876643676221464\n",
      "test loss:  7.465301990509033\n",
      "test r2:  -0.28665453893630444\n",
      "train loss:  1.7961337566375732\n",
      "train r2:  0.8766149638215665\n",
      "test loss:  7.464722156524658\n",
      "test r2:  -0.28648947947949455\n",
      "train loss:  1.7960606813430786\n",
      "train r2:  0.8766544637248757\n",
      "test loss:  7.46473503112793\n",
      "test r2:  -0.28659178696574217\n",
      "train loss:  1.7959872484207153\n",
      "train r2:  0.8766338693410445\n",
      "test loss:  7.464245319366455\n",
      "test r2:  -0.2864695719472332\n",
      "train loss:  1.7959141731262207\n",
      "train r2:  0.8766636539238825\n",
      "test loss:  7.464163303375244\n",
      "test r2:  -0.28652642180237753\n",
      "train loss:  1.7958413362503052\n",
      "train r2:  0.8766533597421596\n",
      "test loss:  7.463769435882568\n",
      "test r2:  -0.2864500460268493\n",
      "train loss:  1.7957686185836792\n",
      "train r2:  0.8766727809485092\n",
      "test loss:  7.463588237762451\n",
      "test r2:  -0.28646117815314165\n",
      "train loss:  1.7956957817077637\n",
      "train r2:  0.8766727771363851\n",
      "test loss:  7.46329927444458\n",
      "test r2:  -0.2864298392971776\n",
      "train loss:  1.795623779296875\n",
      "train r2:  0.8766822024102218\n",
      "test loss:  7.463018894195557\n",
      "test r2:  -0.28639857954583015\n",
      "train loss:  1.7955517768859863\n",
      "train r2:  0.8766916906714038\n",
      "test loss:  7.462823867797852\n",
      "test r2:  -0.2864054982975086\n",
      "train loss:  1.7954797744750977\n",
      "train r2:  0.8766925911306628\n",
      "test loss:  7.462465286254883\n",
      "test r2:  -0.28634152306259475\n",
      "train loss:  1.7954078912734985\n",
      "train r2:  0.8767093405533648\n",
      "test loss:  7.4623308181762695\n",
      "test r2:  -0.28637500231882695\n",
      "train loss:  1.7953358888626099\n",
      "train r2:  0.8767043575939372\n",
      "test loss:  7.461925983428955\n",
      "test r2:  -0.2862897381313201\n",
      "train loss:  1.7952640056610107\n",
      "train r2:  0.8767258754242324\n",
      "test loss:  7.461828708648682\n",
      "test r2:  -0.2863413834876585\n",
      "train loss:  1.795192003250122\n",
      "train r2:  0.8767167880807972\n",
      "test loss:  7.461388111114502\n",
      "test r2:  -0.2862394462172424\n",
      "train loss:  1.7951198816299438\n",
      "train r2:  0.8767421220055305\n",
      "test loss:  7.4613237380981445\n",
      "test r2:  -0.28630630993197315\n",
      "train loss:  1.7950478792190552\n",
      "train r2:  0.8767295283130816\n",
      "test loss:  7.4608564376831055\n",
      "test r2:  -0.2861918952406446\n",
      "train loss:  1.7949758768081665\n",
      "train r2:  0.8767576866733354\n",
      "test loss:  7.460801601409912\n",
      "test r2:  -0.2862667393048526\n",
      "train loss:  1.7949033975601196\n",
      "train r2:  0.8767432057561064\n",
      "test loss:  7.460330486297607\n",
      "test r2:  -0.28614756625639837\n",
      "train loss:  1.7948310375213623\n",
      "train r2:  0.8767724929119498\n",
      "test loss:  7.460278511047363\n",
      "test r2:  -0.286226404646996\n",
      "train loss:  1.794758915901184\n",
      "train r2:  0.8767570363359366\n",
      "test loss:  7.4597978591918945\n",
      "test r2:  -0.2861022013871428\n",
      "train loss:  1.7946864366531372\n",
      "train r2:  0.876787522279214\n",
      "test loss:  7.459762096405029\n",
      "test r2:  -0.286187383786924\n",
      "train loss:  1.794614315032959\n",
      "train r2:  0.8767706411903752\n",
      "test loss:  7.459261894226074\n",
      "test r2:  -0.2860567683177546\n",
      "train loss:  1.794541597366333\n",
      "train r2:  0.8768024631473212\n",
      "test loss:  7.4592390060424805\n",
      "test r2:  -0.2861467851070152\n",
      "train loss:  1.7944693565368652\n",
      "train r2:  0.8767845516738032\n",
      "test loss:  7.4587297439575195\n",
      "test r2:  -0.28601250496522956\n",
      "train loss:  1.794396996498108\n",
      "train r2:  0.8768172079734345\n",
      "test loss:  7.458718776702881\n",
      "test r2:  -0.2861068957838582\n",
      "train loss:  1.7943247556686401\n",
      "train r2:  0.876798333972284\n",
      "test loss:  7.458191394805908\n",
      "test r2:  -0.2859658313039293\n",
      "train loss:  1.794252634048462\n",
      "train r2:  0.8768324643294217\n",
      "test loss:  7.4582061767578125\n",
      "test r2:  -0.286070086567775\n",
      "train loss:  1.7941802740097046\n",
      "train r2:  0.8768114442251598\n",
      "test loss:  7.457647800445557\n",
      "test r2:  -0.2859162432533977\n",
      "train loss:  1.7941081523895264\n",
      "train r2:  0.8768484221547399\n",
      "test loss:  7.457700729370117\n",
      "test r2:  -0.28603631071531477\n",
      "train loss:  1.7940362691879272\n",
      "train r2:  0.8768239287389646\n",
      "test loss:  7.457099914550781\n",
      "test r2:  -0.2858642544262975\n",
      "train loss:  1.7939640283584595\n",
      "train r2:  0.8768649351547686\n",
      "test loss:  7.45719575881958\n",
      "test r2:  -0.28600397153066015\n",
      "train loss:  1.7938923835754395\n",
      "train r2:  0.8768360090723019\n",
      "test loss:  7.456549167633057\n",
      "test r2:  -0.28581028294117816\n",
      "train loss:  1.7938206195831299\n",
      "train r2:  0.8768819215350043\n",
      "test loss:  7.456698894500732\n",
      "test r2:  -0.2859751461951081\n",
      "train loss:  1.793749213218689\n",
      "train r2:  0.8768473405218915\n",
      "test loss:  7.455986022949219\n",
      "test r2:  -0.28575184881034943\n",
      "train loss:  1.7936779260635376\n",
      "train r2:  0.8768999049749429\n",
      "test loss:  7.4562153816223145\n",
      "test r2:  -0.28595144395978944\n",
      "train loss:  1.793607234954834\n",
      "train r2:  0.8768575315260659\n",
      "test loss:  7.455404758453369\n",
      "test r2:  -0.28568883670107503\n",
      "train loss:  1.7935364246368408\n",
      "train r2:  0.8769187374728211\n",
      "test loss:  7.4557342529296875\n",
      "test r2:  -0.285928747697932\n",
      "train loss:  1.7934662103652954\n",
      "train r2:  0.8768674365135436\n",
      "test loss:  7.454826354980469\n",
      "test r2:  -0.28562752703899186\n",
      "train loss:  1.7933954000473022\n",
      "train r2:  0.8769371646116481\n",
      "test loss:  7.455247402191162\n",
      "test r2:  -0.2859032797718728\n",
      "train loss:  1.7933251857757568\n",
      "train r2:  0.8768779934619642\n",
      "test loss:  7.454251289367676\n",
      "test r2:  -0.28556882311845033\n",
      "train loss:  1.7932538986206055\n",
      "train r2:  0.8769549843180555\n",
      "test loss:  7.454757213592529\n",
      "test r2:  -0.28587482207964454\n",
      "train loss:  1.7931828498840332\n",
      "train r2:  0.876889233919971\n",
      "test loss:  7.453683376312256\n",
      "test r2:  -0.2855163036296784\n",
      "train loss:  1.7931100130081177\n",
      "train r2:  0.876971382821198\n",
      "test loss:  7.454237461090088\n",
      "test r2:  -0.28583463826987976\n",
      "train loss:  1.7930368185043335\n",
      "train r2:  0.8769031823941004\n",
      "test loss:  7.453166484832764\n",
      "test r2:  -0.28548090801894954\n",
      "train loss:  1.7929612398147583\n",
      "train r2:  0.8769841661316351\n",
      "test loss:  7.453668117523193\n",
      "test r2:  -0.2857747399806403\n",
      "train loss:  1.7928853034973145\n",
      "train r2:  0.8769215754041052\n",
      "test loss:  7.452705383300781\n",
      "test r2:  -0.28546584089780236\n",
      "train loss:  1.7928078174591064\n",
      "train r2:  0.8769926876811774\n",
      "test loss:  7.453052043914795\n",
      "test r2:  -0.28569662547245156\n",
      "train loss:  1.792730450630188\n",
      "train r2:  0.8769440366131772\n",
      "test loss:  7.452285289764404\n",
      "test r2:  -0.2854663249634919\n",
      "train loss:  1.7926530838012695\n",
      "train r2:  0.8769978215383294\n",
      "test loss:  7.4524078369140625\n",
      "test r2:  -0.2856065988519507\n",
      "train loss:  1.792576551437378\n",
      "train r2:  0.8769692148329052\n",
      "test loss:  7.451888561248779\n",
      "test r2:  -0.28547485713228915\n",
      "train loss:  1.7925010919570923\n",
      "train r2:  0.877001236160764\n",
      "test loss:  7.45176362991333\n",
      "test r2:  -0.28551349311159635\n",
      "train loss:  1.7924267053604126\n",
      "train r2:  0.8769950979501492\n",
      "test loss:  7.451486110687256\n",
      "test r2:  -0.28548192202944955\n",
      "train loss:  1.7923533916473389\n",
      "train r2:  0.8770048717918532\n",
      "test loss:  7.451132297515869\n",
      "test r2:  -0.28542572042170633\n",
      "train loss:  1.792280673980713\n",
      "train r2:  0.8770198198783874\n",
      "test loss:  7.451056003570557\n",
      "test r2:  -0.2854798824813205\n",
      "train loss:  1.7922086715698242\n",
      "train r2:  0.8770104210025609\n",
      "test loss:  7.450532913208008\n",
      "test r2:  -0.2853500826691875\n",
      "train loss:  1.792136549949646\n",
      "train r2:  0.877041849695178\n",
      "test loss:  7.450588703155518\n",
      "test r2:  -0.2854641663754294\n",
      "train loss:  1.7920646667480469\n",
      "train r2:  0.8770189584136301\n",
      "test loss:  7.4499592781066895\n",
      "test r2:  -0.2852875473791592\n",
      "train loss:  1.7919921875\n",
      "train r2:  0.8770608450579428\n",
      "test loss:  7.450087070465088\n",
      "test r2:  -0.285435811079664\n",
      "train loss:  1.7919198274612427\n",
      "train r2:  0.8770301597833218\n",
      "test loss:  7.449400424957275\n",
      "test r2:  -0.28523533292919256\n",
      "train loss:  1.791846752166748\n",
      "train r2:  0.8770773687132676\n",
      "test loss:  7.449566841125488\n",
      "test r2:  -0.2853981481063925\n",
      "train loss:  1.7917736768722534\n",
      "train r2:  0.877043525790531\n",
      "test loss:  7.448860168457031\n",
      "test r2:  -0.28519282150776815\n",
      "train loss:  1.791700005531311\n",
      "train r2:  0.8770916646100119\n",
      "test loss:  7.449018478393555\n",
      "test r2:  -0.28534982812199305\n",
      "train loss:  1.7916259765625\n",
      "train r2:  0.8770591984013107\n",
      "test loss:  7.448340892791748\n",
      "test r2:  -0.2851598459141642\n",
      "train loss:  1.7915518283843994\n",
      "train r2:  0.8771037920072527\n",
      "test loss:  7.448449611663818\n",
      "test r2:  -0.2852942268876073\n",
      "train loss:  1.7914775609970093\n",
      "train r2:  0.877076479914461\n",
      "test loss:  7.4478349685668945\n",
      "test r2:  -0.28513051973017634\n",
      "train loss:  1.79140305519104\n",
      "train r2:  0.8771152854120828\n",
      "test loss:  7.447885513305664\n",
      "test r2:  -0.28523934632818815\n",
      "train loss:  1.791329026222229\n",
      "train r2:  0.8770936912365114\n",
      "test loss:  7.447327136993408\n",
      "test r2:  -0.28509970746001567\n",
      "train loss:  1.7912544012069702\n",
      "train r2:  0.8771271099529071\n",
      "test loss:  7.447319507598877\n",
      "test r2:  -0.285184015350499\n",
      "train loss:  1.7911803722381592\n",
      "train r2:  0.8771109453805223\n",
      "test loss:  7.446830749511719\n",
      "test r2:  -0.2850709395348101\n",
      "train loss:  1.791106104850769\n",
      "train r2:  0.8771386254478427\n",
      "test loss:  7.446750164031982\n",
      "test r2:  -0.2851275168679759\n",
      "train loss:  1.791032314300537\n",
      "train r2:  0.8771286116386438\n",
      "test loss:  7.44633674621582\n",
      "test r2:  -0.28504216364629986\n",
      "train loss:  1.790958046913147\n",
      "train r2:  0.8771501990885064\n",
      "test loss:  7.446189880371094\n",
      "test r2:  -0.2850732436457093\n",
      "train loss:  1.790884256362915\n",
      "train r2:  0.877145783160892\n",
      "test loss:  7.445830821990967\n",
      "test r2:  -0.2850098318104972\n",
      "train loss:  1.790809988975525\n",
      "train r2:  0.8771625423683506\n",
      "test loss:  7.445641040802002\n",
      "test r2:  -0.2850220322771808\n",
      "train loss:  1.790736198425293\n",
      "train r2:  0.8771623279448044\n",
      "test loss:  7.445319652557373\n",
      "test r2:  -0.2849761271485052\n",
      "train loss:  1.790662407875061\n",
      "train r2:  0.8771751571811297\n",
      "test loss:  7.445091247558594\n",
      "test r2:  -0.2849710193481394\n",
      "train loss:  1.7905884981155396\n",
      "train r2:  0.8771788183134388\n",
      "test loss:  7.44480562210083\n",
      "test r2:  -0.2849419344350752\n",
      "train loss:  1.7905144691467285\n",
      "train r2:  0.8771878362510646\n",
      "test loss:  7.4445390701293945\n",
      "test r2:  -0.2849213903955521\n",
      "train loss:  1.7904406785964966\n",
      "train r2:  0.87719495787299\n",
      "test loss:  7.444280624389648\n",
      "test r2:  -0.2849048447910578\n",
      "train loss:  1.7903670072555542\n",
      "train r2:  0.8772010963644493\n",
      "test loss:  7.443994045257568\n",
      "test r2:  -0.2848744154804739\n",
      "train loss:  1.7902929782867432\n",
      "train r2:  0.8772104209188212\n",
      "test loss:  7.443752765655518\n",
      "test r2:  -0.2848661008688296\n",
      "train loss:  1.7902188301086426\n",
      "train r2:  0.8772147468741239\n",
      "test loss:  7.443446636199951\n",
      "test r2:  -0.2848278649595535\n",
      "train loss:  1.7901448011398315\n",
      "train r2:  0.8772258015224462\n",
      "test loss:  7.44322395324707\n",
      "test r2:  -0.2848277393040146\n",
      "train loss:  1.7900711297988892\n",
      "train r2:  0.8772282389158281\n",
      "test loss:  7.4428911209106445\n",
      "test r2:  -0.28477981691135446\n",
      "train loss:  1.7899969816207886\n",
      "train r2:  0.8772414010820637\n",
      "test loss:  7.4426984786987305\n",
      "test r2:  -0.28479038463433937\n",
      "train loss:  1.789923071861267\n",
      "train r2:  0.8772415476301787\n",
      "test loss:  7.44234037399292\n",
      "test r2:  -0.28473206052737776\n",
      "train loss:  1.7898489236831665\n",
      "train r2:  0.877257024877102\n",
      "test loss:  7.442172527313232\n",
      "test r2:  -0.2847536033307858\n",
      "train loss:  1.789774775505066\n",
      "train r2:  0.8772547546287002\n",
      "test loss:  7.4417829513549805\n",
      "test r2:  -0.2846817898733571\n",
      "train loss:  1.7897011041641235\n",
      "train r2:  0.8772732204072865\n",
      "test loss:  7.441656589508057\n",
      "test r2:  -0.28472102539855904\n",
      "train loss:  1.7896270751953125\n",
      "train r2:  0.8772670064659498\n",
      "test loss:  7.441212177276611\n",
      "test r2:  -0.28462609747060363\n",
      "train loss:  1.7895534038543701\n",
      "train r2:  0.8772906105115295\n",
      "test loss:  7.441157341003418\n",
      "test r2:  -0.28469424421543343\n",
      "train loss:  1.7894798517227173\n",
      "train r2:  0.8772779870377825\n",
      "test loss:  7.440629959106445\n",
      "test r2:  -0.284564698311464\n",
      "train loss:  1.789406418800354\n",
      "train r2:  0.8773093140719624\n",
      "test loss:  7.440669059753418\n",
      "test r2:  -0.28467397334920874\n",
      "train loss:  1.789333462715149\n",
      "train r2:  0.8772874909056276\n",
      "test loss:  7.440028190612793\n",
      "test r2:  -0.2844944040796804\n",
      "train loss:  1.7892614603042603\n",
      "train r2:  0.8773299922443473\n",
      "test loss:  7.440211296081543\n",
      "test r2:  -0.2846667248044812\n",
      "train loss:  1.789190411567688\n",
      "train r2:  0.8772940982490522\n",
      "test loss:  7.439379692077637\n",
      "test r2:  -0.2844063564386763\n",
      "train loss:  1.789121150970459\n",
      "train r2:  0.8773544522316409\n",
      "test loss:  7.439804553985596\n",
      "test r2:  -0.28468095196494736\n",
      "train loss:  1.7890547513961792\n",
      "train r2:  0.8772957774635961\n",
      "test loss:  7.438659191131592\n",
      "test r2:  -0.2842925632414861\n",
      "train loss:  1.7889907360076904\n",
      "train r2:  0.877384386569546\n",
      "test loss:  7.439469814300537\n",
      "test r2:  -0.2847228851947501\n",
      "train loss:  1.7889338731765747\n",
      "train r2:  0.8772911164118101\n",
      "test loss:  7.437854290008545\n",
      "test r2:  -0.2841509721470794\n",
      "train loss:  1.7888795137405396\n",
      "train r2:  0.8774200276195254\n",
      "test loss:  7.439199924468994\n",
      "test r2:  -0.28478768600396354\n",
      "train loss:  1.788834810256958\n",
      "train r2:  0.8772811697193007\n",
      "test loss:  7.436993598937988\n",
      "test r2:  -0.2839978204071978\n",
      "train loss:  1.7887835502624512\n",
      "train r2:  0.8774575598217543\n",
      "test loss:  7.4389262199401855\n",
      "test r2:  -0.2848395440182201\n",
      "train loss:  1.7887324094772339\n",
      "train r2:  0.8772743283179935\n",
      "test loss:  7.436252117156982\n",
      "test r2:  -0.28389978693793094\n",
      "train loss:  1.7886494398117065\n",
      "train r2:  0.8774832257989413\n",
      "test loss:  7.43837308883667\n",
      "test r2:  -0.2847803346244635\n",
      "train loss:  1.7885501384735107\n",
      "train r2:  0.8772930637407526\n",
      "test loss:  7.435977458953857\n",
      "test r2:  -0.2839713072646437\n",
      "train loss:  1.7884249687194824\n",
      "train r2:  0.8774732706662791\n",
      "test loss:  7.437240123748779\n",
      "test r2:  -0.2845183369927613\n",
      "train loss:  1.788307547569275\n",
      "train r2:  0.8773566033788395\n",
      "test loss:  7.436248302459717\n",
      "test r2:  -0.28422564848623333\n",
      "train loss:  1.7882122993469238\n",
      "train r2:  0.8774238275125624\n",
      "test loss:  7.435800075531006\n",
      "test r2:  -0.2841510707749004\n",
      "train loss:  1.7881447076797485\n",
      "train r2:  0.877442215690124\n",
      "test loss:  7.436506271362305\n",
      "test r2:  -0.2844735524288442\n",
      "train loss:  1.7880935668945312\n",
      "train r2:  0.8773747379990373\n",
      "test loss:  7.434760570526123\n",
      "test r2:  -0.28390629796759637\n",
      "train loss:  1.7880390882492065\n",
      "train r2:  0.877501323044117\n",
      "test loss:  7.4361982345581055\n",
      "test r2:  -0.2845263033695886\n",
      "train loss:  1.787971019744873\n",
      "train r2:  0.8773681368936366\n",
      "test loss:  7.434349536895752\n",
      "test r2:  -0.2838826265982757\n",
      "train loss:  1.7878811359405518\n",
      "train r2:  0.8775132811098016\n",
      "test loss:  7.435369968414307\n",
      "test r2:  -0.28437193938044114\n",
      "train loss:  1.7877846956253052\n",
      "train r2:  0.8774080447615131\n",
      "test loss:  7.434272289276123\n",
      "test r2:  -0.28402251444670257\n",
      "train loss:  1.7876919507980347\n",
      "train r2:  0.8774882233099871\n",
      "test loss:  7.434247970581055\n",
      "test r2:  -0.28410000669883173\n",
      "train loss:  1.7876136302947998\n",
      "train r2:  0.877473521946369\n",
      "test loss:  7.43431282043457\n",
      "test r2:  -0.284217950449011\n",
      "train loss:  1.7875477075576782\n",
      "train r2:  0.8774498556470676\n",
      "test loss:  7.433178424835205\n",
      "test r2:  -0.28385285508368474\n",
      "train loss:  1.7874850034713745\n",
      "train r2:  0.8775330266838407\n",
      "test loss:  7.434154987335205\n",
      "test r2:  -0.2843104469310247\n",
      "train loss:  1.7874163389205933\n",
      "train r2:  0.8774347993506632\n",
      "test loss:  7.432551383972168\n",
      "test r2:  -0.2837824304937524\n",
      "train loss:  1.7873364686965942\n",
      "train r2:  0.8775536613102077\n",
      "test loss:  7.433407306671143\n",
      "test r2:  -0.2841856547839796\n",
      "train loss:  1.7872511148452759\n",
      "train r2:  0.8774677384240522\n",
      "test loss:  7.432404041290283\n",
      "test r2:  -0.28390330054125257\n",
      "train loss:  1.7871662378311157\n",
      "train r2:  0.8775319345239043\n",
      "test loss:  7.432283401489258\n",
      "test r2:  -0.2839344834532651\n",
      "train loss:  1.7870879173278809\n",
      "train r2:  0.8775279383624153\n",
      "test loss:  7.432382106781006\n",
      "test r2:  -0.2840510328099719\n",
      "train loss:  1.7870160341262817\n",
      "train r2:  0.8775048162666529\n",
      "test loss:  7.431404113769531\n",
      "test r2:  -0.28376409334645203\n",
      "train loss:  1.7869465351104736\n",
      "train r2:  0.8775704390549938\n",
      "test loss:  7.431980609893799\n",
      "test r2:  -0.2840633286765526\n",
      "train loss:  1.786875605583191\n",
      "train r2:  0.8775072074266903\n",
      "test loss:  7.43088960647583\n",
      "test r2:  -0.2837368593077283\n",
      "train loss:  1.786799430847168\n",
      "train r2:  0.8775812922526239\n",
      "test loss:  7.4312543869018555\n",
      "test r2:  -0.28395730718124823\n",
      "train loss:  1.7867201566696167\n",
      "train r2:  0.8775356707396258\n",
      "test loss:  7.430569171905518\n",
      "test r2:  -0.28377641667496367\n",
      "train loss:  1.78663969039917\n",
      "train r2:  0.8775781101120887\n",
      "test loss:  7.430501937866211\n",
      "test r2:  -0.2838277367155637\n",
      "train loss:  1.7865612506866455\n",
      "train r2:  0.8775697821171227\n",
      "test loss:  7.430247783660889\n",
      "test r2:  -0.2838169864141591\n",
      "train loss:  1.7864863872528076\n",
      "train r2:  0.8775747094894688\n",
      "test loss:  7.429755687713623\n",
      "test r2:  -0.2837104176219052\n",
      "train loss:  1.786413550376892\n",
      "train r2:  0.877600698570209\n",
      "test loss:  7.429879665374756\n",
      "test r2:  -0.2838391957551709\n",
      "train loss:  1.7863404750823975\n",
      "train r2:  0.877575125758006\n",
      "test loss:  7.42909049987793\n",
      "test r2:  -0.28362404395436314\n",
      "train loss:  1.7862662076950073\n",
      "train r2:  0.8776248716945614\n",
      "test loss:  7.429388523101807\n",
      "test r2:  -0.2838122152272651\n",
      "train loss:  1.7861895561218262\n",
      "train r2:  0.8775864936516667\n",
      "test loss:  7.4285993576049805\n",
      "test r2:  -0.2836008192018995\n",
      "train loss:  1.7861117124557495\n",
      "train r2:  0.8776353943074909\n",
      "test loss:  7.428683280944824\n",
      "test r2:  -0.2837161123677929\n",
      "train loss:  1.786034107208252\n",
      "train r2:  0.8776126527993954\n",
      "test loss:  7.428256034851074\n",
      "test r2:  -0.2836315202069992\n",
      "train loss:  1.7859574556350708\n",
      "train r2:  0.877634114407943\n",
      "test loss:  7.427933216094971\n",
      "test r2:  -0.2835965969463987\n",
      "train loss:  1.7858821153640747\n",
      "train r2:  0.8776442087948271\n",
      "test loss:  7.427888870239258\n",
      "test r2:  -0.28365617693285095\n",
      "train loss:  1.7858078479766846\n",
      "train r2:  0.8776339090330859\n",
      "test loss:  7.427270412445068\n",
      "test r2:  -0.28350745811146627\n",
      "train loss:  1.7857329845428467\n",
      "train r2:  0.8776690226221541\n",
      "test loss:  7.427370071411133\n",
      "test r2:  -0.28363495942879613\n",
      "train loss:  1.7856580018997192\n",
      "train r2:  0.8776433766220477\n",
      "test loss:  7.42671537399292\n",
      "test r2:  -0.2834638621526824\n",
      "train loss:  1.7855814695358276\n",
      "train r2:  0.8776837444324359\n",
      "test loss:  7.426775932312012\n",
      "test r2:  -0.2835742940242689\n",
      "train loss:  1.785504937171936\n",
      "train r2:  0.8776619672873434\n",
      "test loss:  7.426252365112305\n",
      "test r2:  -0.28345498527602553\n",
      "train loss:  1.7854282855987549\n",
      "train r2:  0.8776908907744989\n",
      "test loss:  7.426123142242432\n",
      "test r2:  -0.2834881449800839\n",
      "train loss:  1.7853519916534424\n",
      "train r2:  0.8776862523594199\n",
      "test loss:  7.425815105438232\n",
      "test r2:  -0.2834600338759399\n",
      "train loss:  1.7852760553359985\n",
      "train r2:  0.8776948381012566\n",
      "test loss:  7.425443649291992\n",
      "test r2:  -0.2833984322506009\n",
      "train loss:  1.7852004766464233\n",
      "train r2:  0.8777111205245924\n",
      "test loss:  7.425368785858154\n",
      "test r2:  -0.2834540685374545\n",
      "train loss:  1.7851251363754272\n",
      "train r2:  0.8777014456158116\n",
      "test loss:  7.424837112426758\n",
      "test r2:  -0.28333508690324694\n",
      "train loss:  1.785049319267273\n",
      "train r2:  0.8777302268625751\n",
      "test loss:  7.424833297729492\n",
      "test r2:  -0.2834156773478358\n",
      "train loss:  1.7849737405776978\n",
      "train r2:  0.8777152167361819\n",
      "test loss:  7.424314498901367\n",
      "test r2:  -0.28330305456798444\n",
      "train loss:  1.7848974466323853\n",
      "train r2:  0.8777424961664552\n",
      "test loss:  7.424232006072998\n",
      "test r2:  -0.2833544469460305\n",
      "train loss:  1.7848211526870728\n",
      "train r2:  0.8777339116282699\n",
      "test loss:  7.423823356628418\n",
      "test r2:  -0.28328109889345154\n",
      "train loss:  1.7847446203231812\n",
      "train r2:  0.8777526742583431\n",
      "test loss:  7.4236345291137695\n",
      "test r2:  -0.28329266896872407\n",
      "train loss:  1.7846683263778687\n",
      "train r2:  0.8777528211775733\n",
      "test loss:  7.423315525054932\n",
      "test r2:  -0.2832549299753877\n",
      "train loss:  1.7845920324325562\n",
      "train r2:  0.8777637237183595\n",
      "test loss:  7.423042297363281\n",
      "test r2:  -0.2832343232985757\n",
      "train loss:  1.7845159769058228\n",
      "train r2:  0.877770881140705\n",
      "test loss:  7.422807216644287\n",
      "test r2:  -0.2832290161370439\n",
      "train loss:  1.7844396829605103\n",
      "train r2:  0.8777746867324353\n",
      "test loss:  7.422447204589844\n",
      "test r2:  -0.2831748139536805\n",
      "train loss:  1.7843637466430664\n",
      "train r2:  0.877789220272697\n",
      "test loss:  7.422301769256592\n",
      "test r2:  -0.28320232773215137\n",
      "train loss:  1.784287452697754\n",
      "train r2:  0.8777858403720981\n",
      "test loss:  7.421861171722412\n",
      "test r2:  -0.2831204712696056\n",
      "train loss:  1.7842113971710205\n",
      "train r2:  0.8778063931428381\n",
      "test loss:  7.421754360198975\n",
      "test r2:  -0.28316385597961546\n",
      "train loss:  1.784135103225708\n",
      "train r2:  0.8777994797659385\n",
      "test loss:  7.421318054199219\n",
      "test r2:  -0.2830805750236167\n",
      "train loss:  1.7840585708618164\n",
      "train r2:  0.8778204528276574\n",
      "test loss:  7.421179294586182\n",
      "test r2:  -0.2831127132208544\n",
      "train loss:  1.7839819192886353\n",
      "train r2:  0.8778159778996388\n",
      "test loss:  7.420799732208252\n",
      "test r2:  -0.28305012789390993\n",
      "train loss:  1.7839055061340332\n",
      "train r2:  0.8778324198284924\n",
      "test loss:  7.420589923858643\n",
      "test r2:  -0.2830572689995674\n",
      "train loss:  1.783828854560852\n",
      "train r2:  0.877833400280422\n",
      "test loss:  7.42026948928833\n",
      "test r2:  -0.28301887357432265\n",
      "train loss:  1.7837523221969604\n",
      "train r2:  0.8778444405108989\n",
      "test loss:  7.420011520385742\n",
      "test r2:  -0.2830037248825561\n",
      "train loss:  1.783676028251648\n",
      "train r2:  0.877850451177921\n",
      "test loss:  7.419742107391357\n",
      "test r2:  -0.2829870326205359\n",
      "train loss:  1.7835992574691772\n",
      "train r2:  0.8778567253084715\n",
      "test loss:  7.419431686401367\n",
      "test r2:  -0.2829511428179401\n",
      "train loss:  1.7835224866867065\n",
      "train r2:  0.8778672929661767\n",
      "test loss:  7.4192118644714355\n",
      "test r2:  -0.28295258374594967\n",
      "train loss:  1.7834457159042358\n",
      "train r2:  0.8778695702962579\n",
      "test loss:  7.418861389160156\n",
      "test r2:  -0.2829029082219583\n",
      "train loss:  1.7833689451217651\n",
      "train r2:  0.8778831492076942\n",
      "test loss:  7.418667316436768\n",
      "test r2:  -0.282912636299681\n",
      "train loss:  1.7832924127578735\n",
      "train r2:  0.8778836824917247\n",
      "test loss:  7.418307781219482\n",
      "test r2:  -0.2828598400819793\n",
      "train loss:  1.7832155227661133\n",
      "train r2:  0.8778979490476143\n",
      "test loss:  7.418111801147461\n",
      "test r2:  -0.2828699039129403\n",
      "train loss:  1.783138632774353\n",
      "train r2:  0.8778984227125879\n",
      "test loss:  7.417753219604492\n",
      "test r2:  -0.28281701809986926\n",
      "train loss:  1.7830616235733032\n",
      "train r2:  0.8779126660371115\n",
      "test loss:  7.4175615310668945\n",
      "test r2:  -0.282828354400539\n",
      "train loss:  1.7829844951629639\n",
      "train r2:  0.8779128738043411\n",
      "test loss:  7.417199611663818\n",
      "test r2:  -0.2827734764750729\n",
      "train loss:  1.782907247543335\n",
      "train r2:  0.87792763647243\n",
      "test loss:  7.417011737823486\n",
      "test r2:  -0.2827864521760102\n",
      "train loss:  1.782829761505127\n",
      "train r2:  0.877927490909738\n",
      "test loss:  7.4166483879089355\n",
      "test r2:  -0.2827314552638631\n",
      "train loss:  1.782752275466919\n",
      "train r2:  0.8779423273063213\n",
      "test loss:  7.416454792022705\n",
      "test r2:  -0.2827426161956894\n",
      "train loss:  1.7826745510101318\n",
      "train r2:  0.8779425401423171\n",
      "test loss:  7.416103839874268\n",
      "test r2:  -0.2826913828010864\n",
      "train loss:  1.7825965881347656\n",
      "train r2:  0.877956589380923\n",
      "test loss:  7.415896892547607\n",
      "test r2:  -0.28269741243178625\n",
      "train loss:  1.7825181484222412\n",
      "train r2:  0.8779580436939785\n",
      "test loss:  7.415564060211182\n",
      "test r2:  -0.28265265519871696\n",
      "train loss:  1.7824389934539795\n",
      "train r2:  0.8779706777462583\n",
      "test loss:  7.415342330932617\n",
      "test r2:  -0.2826522844872268\n",
      "train loss:  1.782359004020691\n",
      "train r2:  0.8779736327603418\n",
      "test loss:  7.415021896362305\n",
      "test r2:  -0.2826124893268691\n",
      "train loss:  1.7822777032852173\n",
      "train r2:  0.877985295656673\n",
      "test loss:  7.414797782897949\n",
      "test r2:  -0.28261022349226494\n",
      "train loss:  1.782193660736084\n",
      "train r2:  0.8779888629110217\n",
      "test loss:  7.414474964141846\n",
      "test r2:  -0.2825698399526628\n",
      "train loss:  1.7821048498153687\n",
      "train r2:  0.8780009367527967\n",
      "test loss:  7.414261341094971\n",
      "test r2:  -0.28257125186212817\n",
      "train loss:  1.7820053100585938\n",
      "train r2:  0.878004177875062\n",
      "test loss:  7.413918972015381\n",
      "test r2:  -0.2825286380565297\n",
      "train loss:  1.7818844318389893\n",
      "train r2:  0.8780175229873249\n",
      "test loss:  7.413652420043945\n",
      "test r2:  -0.28253544983202583\n",
      "train loss:  1.7817718982696533\n",
      "train r2:  0.8780199972423913\n",
      "test loss:  7.413094997406006\n",
      "test r2:  -0.2825115100002096\n",
      "train loss:  1.7818353176116943\n",
      "train r2:  0.8780260863072055\n",
      "test loss:  7.412565231323242\n",
      "test r2:  -0.28251244738028847\n",
      "train loss:  1.7816681861877441\n",
      "train r2:  0.8780333134298648\n",
      "test loss:  7.413791179656982\n",
      "test r2:  -0.2823336950130868\n",
      "train loss:  1.7816592454910278\n",
      "train r2:  0.878109920618575\n",
      "test loss:  7.417224407196045\n",
      "test r2:  -0.28282590013383113\n",
      "train loss:  1.7816082239151\n",
      "train r2:  0.8780420107771663\n",
      "test loss:  7.414922714233398\n",
      "test r2:  -0.28241453009989526\n",
      "train loss:  1.7815414667129517\n",
      "train r2:  0.8781225820486347\n",
      "test loss:  7.412753582000732\n",
      "test r2:  -0.2824663593004255\n",
      "train loss:  1.781471848487854\n",
      "train r2:  0.878082855209312\n",
      "test loss:  7.41279411315918\n",
      "test r2:  -0.28234445560042665\n",
      "train loss:  1.7813998460769653\n",
      "train r2:  0.8781160843227995\n",
      "test loss:  7.414147853851318\n",
      "test r2:  -0.2825951860737521\n",
      "train loss:  1.7813360691070557\n",
      "train r2:  0.8780737051775753\n",
      "test loss:  7.413049221038818\n",
      "test r2:  -0.2821901216088507\n",
      "train loss:  1.7812587022781372\n",
      "train r2:  0.878159980226647\n",
      "test loss:  7.4119343757629395\n",
      "test r2:  -0.2827048258955682\n",
      "train loss:  1.7811938524246216\n",
      "train r2:  0.8780097941760915\n",
      "test loss:  7.407575607299805\n",
      "test r2:  -0.2816884156635975\n",
      "train loss:  1.7811334133148193\n",
      "train r2:  0.8782083746492011\n",
      "test loss:  7.41093635559082\n",
      "test r2:  -0.2827087042010341\n",
      "train loss:  1.7810909748077393\n",
      "train r2:  0.8779913720268028\n",
      "test loss:  7.408761501312256\n",
      "test r2:  -0.281857466968505\n",
      "train loss:  1.7810479402542114\n",
      "train r2:  0.8781799426365559\n",
      "test loss:  7.409750461578369\n",
      "test r2:  -0.28247057559164057\n",
      "train loss:  1.7810090780258179\n",
      "train r2:  0.8780389516518539\n",
      "test loss:  7.406858444213867\n",
      "test r2:  -0.2818489353404261\n",
      "train loss:  1.780941128730774\n",
      "train r2:  0.8781583219481164\n",
      "test loss:  7.407055377960205\n",
      "test r2:  -0.282393623910254\n",
      "train loss:  1.7808631658554077\n",
      "train r2:  0.8780294735289427\n",
      "test loss:  7.4053120613098145\n",
      "test r2:  -0.2815134014821108\n",
      "train loss:  1.780730128288269\n",
      "train r2:  0.8782365766004632\n",
      "test loss:  7.409855365753174\n",
      "test r2:  -0.2827356447403706\n",
      "train loss:  1.780595302581787\n",
      "train r2:  0.8779936816429964\n",
      "test loss:  7.406219959259033\n",
      "test r2:  -0.2816085794103118\n",
      "train loss:  1.7804663181304932\n",
      "train r2:  0.8782443067006613\n",
      "test loss:  7.407548904418945\n",
      "test r2:  -0.28218326434338703\n",
      "train loss:  1.7803655862808228\n",
      "train r2:  0.8781228555737588\n",
      "test loss:  7.407330513000488\n",
      "test r2:  -0.28226534732180353\n",
      "train loss:  1.7802996635437012\n",
      "train r2:  0.878108395226679\n",
      "test loss:  7.40534782409668\n",
      "test r2:  -0.2814940038921825\n",
      "train loss:  1.7802523374557495\n",
      "train r2:  0.8782896923877073\n",
      "test loss:  7.4097819328308105\n",
      "test r2:  -0.28263726455603266\n",
      "train loss:  1.7802003622055054\n",
      "train r2:  0.8780654380731389\n",
      "test loss:  7.406831741333008\n",
      "test r2:  -0.2816588719060711\n",
      "train loss:  1.7801240682601929\n",
      "train r2:  0.8782852983530909\n",
      "test loss:  7.407226085662842\n",
      "test r2:  -0.28215757228962945\n",
      "train loss:  1.780032992362976\n",
      "train r2:  0.8781718926230198\n",
      "test loss:  7.406683444976807\n",
      "test r2:  -0.2819512896848222\n",
      "train loss:  1.7799277305603027\n",
      "train r2:  0.878222557816657\n",
      "test loss:  7.406526565551758\n",
      "test r2:  -0.2819478099009667\n",
      "train loss:  1.7798274755477905\n",
      "train r2:  0.8782300383728872\n",
      "test loss:  7.406918048858643\n",
      "test r2:  -0.28194961043116473\n",
      "train loss:  1.7797421216964722\n",
      "train r2:  0.878240107144224\n",
      "test loss:  7.406618118286133\n",
      "test r2:  -0.28199037196147114\n",
      "train loss:  1.7796730995178223\n",
      "train r2:  0.8782288254440002\n",
      "test loss:  7.404991626739502\n",
      "test r2:  -0.28188432118136\n",
      "train loss:  1.7796103954315186\n",
      "train r2:  0.8782391044812454\n",
      "test loss:  7.404356002807617\n",
      "test r2:  -0.28166077243636756\n",
      "train loss:  1.779539942741394\n",
      "train r2:  0.878289658682982\n",
      "test loss:  7.405823230743408\n",
      "test r2:  -0.2821816473173837\n",
      "train loss:  1.7794609069824219\n",
      "train r2:  0.8781805565546427\n",
      "test loss:  7.403428554534912\n",
      "test r2:  -0.28144224879052904\n",
      "train loss:  1.7793724536895752\n",
      "train r2:  0.8783417351177388\n",
      "test loss:  7.404696941375732\n",
      "test r2:  -0.2820554158931583\n",
      "train loss:  1.779281497001648\n",
      "train r2:  0.8782045941830676\n",
      "test loss:  7.402725696563721\n",
      "test r2:  -0.28166225243126775\n",
      "train loss:  1.7791945934295654\n",
      "train r2:  0.8782830782307844\n",
      "test loss:  7.402183532714844\n",
      "test r2:  -0.28154788364363803\n",
      "train loss:  1.7791165113449097\n",
      "train r2:  0.8783098700109231\n",
      "test loss:  7.403771877288818\n",
      "test r2:  -0.28199031208102543\n",
      "train loss:  1.7790441513061523\n",
      "train r2:  0.8782223468593224\n",
      "test loss:  7.401867866516113\n",
      "test r2:  -0.2814381740978471\n",
      "train loss:  1.7789720296859741\n",
      "train r2:  0.8783442291722856\n",
      "test loss:  7.4024658203125\n",
      "test r2:  -0.28180465196084525\n",
      "train loss:  1.778896689414978\n",
      "train r2:  0.878264204629476\n",
      "test loss:  7.40162467956543\n",
      "test r2:  -0.28159496072168744\n",
      "train loss:  1.7788163423538208\n",
      "train r2:  0.8783118284775081\n",
      "test loss:  7.401371955871582\n",
      "test r2:  -0.28159475254927235\n",
      "train loss:  1.7787330150604248\n",
      "train r2:  0.878316678048891\n",
      "test loss:  7.401798725128174\n",
      "test r2:  -0.2816133799147835\n",
      "train loss:  1.7786484956741333\n",
      "train r2:  0.8783238267333463\n",
      "test loss:  7.40181303024292\n",
      "test r2:  -0.28166758371210876\n",
      "train loss:  1.7785664796829224\n",
      "train r2:  0.8783173640803359\n",
      "test loss:  7.40077543258667\n",
      "test r2:  -0.281486398010548\n",
      "train loss:  1.7784886360168457\n",
      "train r2:  0.8783570726934057\n",
      "test loss:  7.4009480476379395\n",
      "test r2:  -0.2815808174094112\n",
      "train loss:  1.7784123420715332\n",
      "train r2:  0.8783409563669762\n",
      "test loss:  7.400863170623779\n",
      "test r2:  -0.2816010305580634\n",
      "train loss:  1.778336524963379\n",
      "train r2:  0.8783420757069951\n",
      "test loss:  7.400241374969482\n",
      "test r2:  -0.2813699182672147\n",
      "train loss:  1.7782596349716187\n",
      "train r2:  0.8783991436410672\n",
      "test loss:  7.401023864746094\n",
      "test r2:  -0.2817087322205112\n",
      "train loss:  1.7781805992126465\n",
      "train r2:  0.8783288284449684\n",
      "test loss:  7.399347305297852\n",
      "test r2:  -0.28130611642260717\n",
      "train loss:  1.778099775314331\n",
      "train r2:  0.8784152959289264\n",
      "test loss:  7.399679183959961\n",
      "test r2:  -0.2815193407309424\n",
      "train loss:  1.7780183553695679\n",
      "train r2:  0.87837073078199\n",
      "test loss:  7.3994669914245605\n",
      "test r2:  -0.2814524415500128\n",
      "train loss:  1.777937889099121\n",
      "train r2:  0.8783902767443256\n",
      "test loss:  7.398880481719971\n",
      "test r2:  -0.281341914958523\n",
      "train loss:  1.7778583765029907\n",
      "train r2:  0.8784165352105201\n",
      "test loss:  7.398947238922119\n",
      "test r2:  -0.2814651590088477\n",
      "train loss:  1.7777801752090454\n",
      "train r2:  0.8783905266917106\n",
      "test loss:  7.398050308227539\n",
      "test r2:  -0.28130178945210904\n",
      "train loss:  1.7777024507522583\n",
      "train r2:  0.8784252188961945\n",
      "test loss:  7.397850036621094\n",
      "test r2:  -0.28135201244509656\n",
      "train loss:  1.7776248455047607\n",
      "train r2:  0.8784151217085291\n",
      "test loss:  7.397696018218994\n",
      "test r2:  -0.28129661009260354\n",
      "train loss:  1.7775462865829468\n",
      "train r2:  0.8784319447294553\n",
      "test loss:  7.397522449493408\n",
      "test r2:  -0.2813389971652249\n",
      "train loss:  1.7774672508239746\n",
      "train r2:  0.8784245382796881\n",
      "test loss:  7.396798610687256\n",
      "test r2:  -0.28119816583725377\n",
      "train loss:  1.777387261390686\n",
      "train r2:  0.8784559585552525\n",
      "test loss:  7.396856784820557\n",
      "test r2:  -0.28132015709673563\n",
      "train loss:  1.7773072719573975\n",
      "train r2:  0.8784309807948508\n",
      "test loss:  7.396177291870117\n",
      "test r2:  -0.2811599971408898\n",
      "train loss:  1.777227520942688\n",
      "train r2:  0.8784687392970778\n",
      "test loss:  7.396306037902832\n",
      "test r2:  -0.2812319919273514\n",
      "train loss:  1.7771477699279785\n",
      "train r2:  0.8784578790847117\n",
      "test loss:  7.39607048034668\n",
      "test r2:  -0.28120913026716643\n",
      "train loss:  1.7770686149597168\n",
      "train r2:  0.8784664191039794\n",
      "test loss:  7.395471096038818\n",
      "test r2:  -0.28111891335481887\n",
      "train loss:  1.7769896984100342\n",
      "train r2:  0.8784875367220012\n",
      "test loss:  7.395466327667236\n",
      "test r2:  -0.28119097163061024\n",
      "train loss:  1.7769109010696411\n",
      "train r2:  0.8784749606663188\n",
      "test loss:  7.395034313201904\n",
      "test r2:  -0.2810859278070843\n",
      "train loss:  1.776832103729248\n",
      "train r2:  0.8785020992997429\n",
      "test loss:  7.395013332366943\n",
      "test r2:  -0.2811389739267194\n",
      "train loss:  1.7767530679702759\n",
      "train r2:  0.8784946254830002\n",
      "test loss:  7.394637584686279\n",
      "test r2:  -0.2810623465042128\n",
      "train loss:  1.7766739130020142\n",
      "train r2:  0.8785149266788955\n",
      "test loss:  7.394394397735596\n",
      "test r2:  -0.28109771148653206\n",
      "train loss:  1.7765945196151733\n",
      "train r2:  0.878508779181727\n",
      "test loss:  7.393893718719482\n",
      "test r2:  -0.28099696237065097\n",
      "train loss:  1.776515007019043\n",
      "train r2:  0.8785336048284547\n",
      "test loss:  7.393951892852783\n",
      "test r2:  -0.2810704024600237\n",
      "train loss:  1.7764352560043335\n",
      "train r2:  0.8785215088995497\n",
      "test loss:  7.393453598022461\n",
      "test r2:  -0.28096976564558007\n",
      "train loss:  1.7763553857803345\n",
      "train r2:  0.8785464158436298\n",
      "test loss:  7.393266677856445\n",
      "test r2:  -0.2809976100527556\n",
      "train loss:  1.7762757539749146\n",
      "train r2:  0.8785424391313694\n",
      "test loss:  7.39286994934082\n",
      "test r2:  -0.28095755799389854\n",
      "train loss:  1.7761962413787842\n",
      "train r2:  0.8785528643450015\n",
      "test loss:  7.3925018310546875\n",
      "test r2:  -0.2809209559589134\n",
      "train loss:  1.7761166095733643\n",
      "train r2:  0.8785630228813983\n",
      "test loss:  7.392364025115967\n",
      "test r2:  -0.2809280856439469\n",
      "train loss:  1.7760370969772339\n",
      "train r2:  0.8785648996404675\n",
      "test loss:  7.392016410827637\n",
      "test r2:  -0.2808884429907028\n",
      "train loss:  1.7759578227996826\n",
      "train r2:  0.8785759583004228\n",
      "test loss:  7.39166259765625\n",
      "test r2:  -0.2808706663879481\n",
      "train loss:  1.7758783102035522\n",
      "train r2:  0.8785813978320796\n",
      "test loss:  7.39134407043457\n",
      "test r2:  -0.2808408329447365\n",
      "train loss:  1.7757986783981323\n",
      "train r2:  0.8785901967197697\n",
      "test loss:  7.3911027908325195\n",
      "test r2:  -0.2808418912244919\n",
      "train loss:  1.775719165802002\n",
      "train r2:  0.878592495682398\n",
      "test loss:  7.3907470703125\n",
      "test r2:  -0.28077668545010903\n",
      "train loss:  1.775639533996582\n",
      "train r2:  0.8786100366106333\n",
      "test loss:  7.390653610229492\n",
      "test r2:  -0.2808256421670692\n",
      "train loss:  1.775559902191162\n",
      "train r2:  0.8786019831900543\n",
      "test loss:  7.39008903503418\n",
      "test r2:  -0.28072219832463374\n",
      "train loss:  1.775480031967163\n",
      "train r2:  0.878626600630251\n",
      "test loss:  7.390002727508545\n",
      "test r2:  -0.2807729460559707\n",
      "train loss:  1.7754005193710327\n",
      "train r2:  0.8786182852622342\n",
      "test loss:  7.389617919921875\n",
      "test r2:  -0.2806996106897879\n",
      "train loss:  1.7753204107284546\n",
      "train r2:  0.878637625717868\n",
      "test loss:  7.38944673538208\n",
      "test r2:  -0.2807186152062511\n",
      "train loss:  1.7752406597137451\n",
      "train r2:  0.8786365089824141\n",
      "test loss:  7.389092922210693\n",
      "test r2:  -0.28066344125394993\n",
      "train loss:  1.7751610279083252\n",
      "train r2:  0.8786515062231604\n",
      "test loss:  7.388870716094971\n",
      "test r2:  -0.2806843723453034\n",
      "train loss:  1.775080919265747\n",
      "train r2:  0.8786492547660135\n",
      "test loss:  7.388436794281006\n",
      "test r2:  -0.2806010871454858\n",
      "train loss:  1.775001049041748\n",
      "train r2:  0.8786704418704692\n",
      "test loss:  7.388408184051514\n",
      "test r2:  -0.2806631904590122\n",
      "train loss:  1.7749210596084595\n",
      "train r2:  0.8786601088585146\n",
      "test loss:  7.387876987457275\n",
      "test r2:  -0.2805521479568076\n",
      "train loss:  1.7748409509658813\n",
      "train r2:  0.8786871777085833\n",
      "test loss:  7.3878068923950195\n",
      "test r2:  -0.28061752642921367\n",
      "train loss:  1.7747611999511719\n",
      "train r2:  0.8786754103444376\n",
      "test loss:  7.387296676635742\n",
      "test r2:  -0.2805171857030506\n",
      "train loss:  1.7746812105178833\n",
      "train r2:  0.8786998456375622\n",
      "test loss:  7.387180805206299\n",
      "test r2:  -0.28056671221821117\n",
      "train loss:  1.7746014595031738\n",
      "train r2:  0.878691655979432\n",
      "test loss:  7.386747360229492\n",
      "test r2:  -0.28047407439983063\n",
      "train loss:  1.774521827697754\n",
      "train r2:  0.8787150093273388\n",
      "test loss:  7.386657238006592\n",
      "test r2:  -0.2805403364631427\n",
      "train loss:  1.7744419574737549\n",
      "train r2:  0.8787028195511091\n",
      "test loss:  7.386053085327148\n",
      "test r2:  -0.28040381427425776\n",
      "train loss:  1.7743624448776245\n",
      "train r2:  0.878735098726396\n",
      "test loss:  7.386123180389404\n",
      "test r2:  -0.28052527587977005\n",
      "train loss:  1.7742832899093628\n",
      "train r2:  0.8787109748190768\n",
      "test loss:  7.385396957397461\n",
      "test r2:  -0.28033396262442634\n",
      "train loss:  1.7742047309875488\n",
      "train r2:  0.878755585404323\n",
      "test loss:  7.385620594024658\n",
      "test r2:  -0.28050813222454885\n",
      "train loss:  1.7741267681121826\n",
      "train r2:  0.8787201191163357\n",
      "test loss:  7.384765148162842\n",
      "test r2:  -0.2802675733161917\n",
      "train loss:  1.7740496397018433\n",
      "train r2:  0.8787754169124102\n",
      "test loss:  7.385078430175781\n",
      "test r2:  -0.28049579518145706\n",
      "train loss:  1.7739744186401367\n",
      "train r2:  0.8787275595510764\n",
      "test loss:  7.384058952331543\n",
      "test r2:  -0.28017806893526664\n",
      "train loss:  1.773901343345642\n",
      "train r2:  0.8788000813017384\n",
      "test loss:  7.384683132171631\n",
      "test r2:  -0.28051985121033973\n",
      "train loss:  1.7738327980041504\n",
      "train r2:  0.8787275555428231\n",
      "test loss:  7.383279323577881\n",
      "test r2:  -0.28005171104852145\n",
      "train loss:  1.7737678289413452\n",
      "train r2:  0.8788330259317462\n",
      "test loss:  7.384368419647217\n",
      "test r2:  -0.2805809569397302\n",
      "train loss:  1.7737133502960205\n",
      "train r2:  0.8787189365064224\n",
      "test loss:  7.382379055023193\n",
      "test r2:  -0.2798896238214059\n",
      "train loss:  1.7736624479293823\n",
      "train r2:  0.8788730235227925\n",
      "test loss:  7.384122848510742\n",
      "test r2:  -0.28067039175234165\n",
      "train loss:  1.7736293077468872\n",
      "train r2:  0.8787036272129538\n",
      "test loss:  7.381471633911133\n",
      "test r2:  -0.2797098674592804\n",
      "train loss:  1.7735868692398071\n",
      "train r2:  0.8789170724126293\n",
      "test loss:  7.383895397186279\n",
      "test r2:  -0.2807629511338108\n",
      "train loss:  1.7735589742660522\n",
      "train r2:  0.8786875032266938\n",
      "test loss:  7.380594253540039\n",
      "test r2:  -0.27956076836962085\n",
      "train loss:  1.7734779119491577\n",
      "train r2:  0.8789542875552586\n",
      "test loss:  7.38343620300293\n",
      "test r2:  -0.28076172241312114\n",
      "train loss:  1.7733850479125977\n",
      "train r2:  0.878693210232713\n",
      "test loss:  7.380141735076904\n",
      "test r2:  -0.2795844161849286\n",
      "train loss:  1.7732242345809937\n",
      "train r2:  0.8789553290504324\n",
      "test loss:  7.382359504699707\n",
      "test r2:  -0.28051456213419357\n",
      "train loss:  1.7730653285980225\n",
      "train r2:  0.8787550563117751\n",
      "test loss:  7.380402088165283\n",
      "test r2:  -0.27988092742583737\n",
      "train loss:  1.7729240655899048\n",
      "train r2:  0.8788969110759287\n",
      "test loss:  7.38060188293457\n",
      "test r2:  -0.28003996199142445\n",
      "train loss:  1.7728304862976074\n",
      "train r2:  0.8788648122265741\n",
      "test loss:  7.380976676940918\n",
      "test r2:  -0.28027570203546914\n",
      "train loss:  1.7727769613265991\n",
      "train r2:  0.8788153820179786\n",
      "test loss:  7.379074573516846\n",
      "test r2:  -0.279641375388042\n",
      "train loss:  1.7727367877960205\n",
      "train r2:  0.8789566766110382\n",
      "test loss:  7.380978107452393\n",
      "test r2:  -0.280451665374041\n",
      "train loss:  1.7726871967315674\n",
      "train r2:  0.8787813803935178\n",
      "test loss:  7.378410339355469\n",
      "test r2:  -0.27955464437949673\n",
      "train loss:  1.7725988626480103\n",
      "train r2:  0.8789812498541384\n",
      "test loss:  7.380072116851807\n",
      "test r2:  -0.2802947074449367\n",
      "train loss:  1.7724897861480713\n",
      "train r2:  0.8788215662071015\n",
      "test loss:  7.3784260749816895\n",
      "test r2:  -0.2797399118890993\n",
      "train loss:  1.7723689079284668\n",
      "train r2:  0.8789469415371345\n",
      "test loss:  7.378744602203369\n",
      "test r2:  -0.27996202376146906\n",
      "train loss:  1.7722647190093994\n",
      "train r2:  0.8789010232225266\n",
      "test loss:  7.378590106964111\n",
      "test r2:  -0.27998983136293876\n",
      "train loss:  1.7721853256225586\n",
      "train r2:  0.8788976568078645\n",
      "test loss:  7.377546310424805\n",
      "test r2:  -0.2796753623581929\n",
      "train loss:  1.7721226215362549\n",
      "train r2:  0.8789692943830228\n",
      "test loss:  7.378448486328125\n",
      "test r2:  -0.28012160262547714\n",
      "train loss:  1.772062063217163\n",
      "train r2:  0.8788735433906267\n",
      "test loss:  7.376773357391357\n",
      "test r2:  -0.27955463446632955\n",
      "train loss:  1.7719861268997192\n",
      "train r2:  0.8790010389977064\n",
      "test loss:  7.377840042114258\n",
      "test r2:  -0.2800663374146888\n",
      "train loss:  1.7718960046768188\n",
      "train r2:  0.8788913227768034\n",
      "test loss:  7.376429557800293\n",
      "test r2:  -0.2796055349628501\n",
      "train loss:  1.771795630455017\n",
      "train r2:  0.8789956861860468\n",
      "test loss:  7.376858234405518\n",
      "test r2:  -0.27986657618283095\n",
      "train loss:  1.7716989517211914\n",
      "train r2:  0.8789411382563339\n",
      "test loss:  7.3763227462768555\n",
      "test r2:  -0.2797517289660896\n",
      "train loss:  1.7716130018234253\n",
      "train r2:  0.8789691650237726\n",
      "test loss:  7.375796794891357\n",
      "test r2:  -0.27963620581062054\n",
      "train loss:  1.77153742313385\n",
      "train r2:  0.8789972119935103\n",
      "test loss:  7.376147747039795\n",
      "test r2:  -0.2798715253970996\n",
      "train loss:  1.7714662551879883\n",
      "train r2:  0.8789478475871316\n",
      "test loss:  7.374921798706055\n",
      "test r2:  -0.27948604230896956\n",
      "train loss:  1.7713910341262817\n",
      "train r2:  0.8790351119540161\n",
      "test loss:  7.375654697418213\n",
      "test r2:  -0.2798690375034538\n",
      "train loss:  1.77130925655365\n",
      "train r2:  0.8789533903585928\n",
      "test loss:  7.374401569366455\n",
      "test r2:  -0.2794743362143923\n",
      "train loss:  1.7712202072143555\n",
      "train r2:  0.8790429329775977\n",
      "test loss:  7.37483024597168\n",
      "test r2:  -0.2797337191663172\n",
      "train loss:  1.7711303234100342\n",
      "train r2:  0.8789886252289989\n",
      "test loss:  7.374153137207031\n",
      "test r2:  -0.2795648914483899\n",
      "train loss:  1.771043062210083\n",
      "train r2:  0.8790284729107539\n",
      "test loss:  7.37385892868042\n",
      "test r2:  -0.27954555479986176\n",
      "train loss:  1.7709611654281616\n",
      "train r2:  0.8790352993094078\n",
      "test loss:  7.373895168304443\n",
      "test r2:  -0.27965173809280164\n",
      "train loss:  1.7708830833435059\n",
      "train r2:  0.8790145662675772\n",
      "test loss:  7.373032093048096\n",
      "test r2:  -0.2794111239287782\n",
      "train loss:  1.770805835723877\n",
      "train r2:  0.879070040687813\n",
      "test loss:  7.373416423797607\n",
      "test r2:  -0.27965493782968354\n",
      "train loss:  1.7707266807556152\n",
      "train r2:  0.879019014362787\n",
      "test loss:  7.3724517822265625\n",
      "test r2:  -0.27937080248574686\n",
      "train loss:  1.770643949508667\n",
      "train r2:  0.8790841890269216\n",
      "test loss:  7.372718811035156\n",
      "test r2:  -0.27957440351737994\n",
      "train loss:  1.7705590724945068\n",
      "train r2:  0.8790419910715032\n",
      "test loss:  7.3720293045043945\n",
      "test r2:  -0.27939119128589085\n",
      "train loss:  1.7704734802246094\n",
      "train r2:  0.8790851964629579\n",
      "test loss:  7.371952533721924\n",
      "test r2:  -0.2794605384538238\n",
      "train loss:  1.7703888416290283\n",
      "train r2:  0.8790725673968642\n",
      "test loss:  7.371614456176758\n",
      "test r2:  -0.27941962559615274\n",
      "train loss:  1.7703065872192383\n",
      "train r2:  0.8790843464947483\n",
      "test loss:  7.371212482452393\n",
      "test r2:  -0.2793539585645577\n",
      "train loss:  1.7702255249023438\n",
      "train r2:  0.87910148231287\n",
      "test loss:  7.371160984039307\n",
      "test r2:  -0.27943245810507644\n",
      "train loss:  1.7701455354690552\n",
      "train r2:  0.8790868222752064\n",
      "test loss:  7.370522975921631\n",
      "test r2:  -0.27927027161930207\n",
      "train loss:  1.770065188407898\n",
      "train r2:  0.8791252941580362\n",
      "test loss:  7.370643138885498\n",
      "test r2:  -0.27941684268747013\n",
      "train loss:  1.7699835300445557\n",
      "train r2:  0.8790955786972264\n",
      "test loss:  7.369906902313232\n",
      "test r2:  -0.2792217564110502\n",
      "train loss:  1.7699006795883179\n",
      "train r2:  0.8791411837601273\n",
      "test loss:  7.3700151443481445\n",
      "test r2:  -0.2793594423648016\n",
      "train loss:  1.7698172330856323\n",
      "train r2:  0.8791135674028049\n",
      "test loss:  7.369401931762695\n",
      "test r2:  -0.27921419975525485\n",
      "train loss:  1.7697334289550781\n",
      "train r2:  0.8791481809447852\n",
      "test loss:  7.3693037033081055\n",
      "test r2:  -0.27927002651419475\n",
      "train loss:  1.7696502208709717\n",
      "train r2:  0.8791385976023696\n",
      "test loss:  7.368946552276611\n",
      "test r2:  -0.27922454804086216\n",
      "train loss:  1.7695677280426025\n",
      "train r2:  0.8791512514137072\n",
      "test loss:  7.368578910827637\n",
      "test r2:  -0.27917855432451977\n",
      "train loss:  1.7694859504699707\n",
      "train r2:  0.879163929983767\n",
      "test loss:  7.3684492111206055\n",
      "test r2:  -0.279220922685014\n",
      "train loss:  1.7694038152694702\n",
      "train r2:  0.8791572543997028\n",
      "test loss:  7.367924213409424\n",
      "test r2:  -0.27911120238630405\n",
      "train loss:  1.769322395324707\n",
      "train r2:  0.8791840117407606\n",
      "test loss:  7.367877006530762\n",
      "test r2:  -0.279190860120653\n",
      "train loss:  1.769240379333496\n",
      "train r2:  0.8791690552469478\n",
      "test loss:  7.367327690124512\n",
      "test r2:  -0.2790670856954012\n",
      "train loss:  1.7691580057144165\n",
      "train r2:  0.8791989784711547\n",
      "test loss:  7.36726713180542\n",
      "test r2:  -0.27914507125048926\n",
      "train loss:  1.769075632095337\n",
      "train r2:  0.8791843236841028\n",
      "test loss:  7.3667497634887695\n",
      "test r2:  -0.2790319722412662\n",
      "train loss:  1.7689927816390991\n",
      "train r2:  0.8792120035385338\n",
      "test loss:  7.366652965545654\n",
      "test r2:  -0.27909337443989757\n",
      "train loss:  1.7689098119735718\n",
      "train r2:  0.879201039218211\n",
      "test loss:  7.366182327270508\n",
      "test r2:  -0.2790032820688815\n",
      "train loss:  1.768826961517334\n",
      "train r2:  0.8792235751188404\n",
      "test loss:  7.366015911102295\n",
      "test r2:  -0.2790332584378439\n",
      "train loss:  1.768743872642517\n",
      "train r2:  0.8792196262794905\n",
      "test loss:  7.365643501281738\n",
      "test r2:  -0.27898311490995176\n",
      "train loss:  1.7686611413955688\n",
      "train r2:  0.879233305667973\n",
      "test loss:  7.365362167358398\n",
      "test r2:  -0.27896786969588816\n",
      "train loss:  1.7685785293579102\n",
      "train r2:  0.8792393359172481\n",
      "test loss:  7.365108013153076\n",
      "test r2:  -0.27896359872659193\n",
      "train loss:  1.768495798110962\n",
      "train r2:  0.8792429238304112\n",
      "test loss:  7.364720344543457\n",
      "test r2:  -0.278907635624736\n",
      "train loss:  1.7684134244918823\n",
      "train r2:  0.8792578990444023\n",
      "test loss:  7.3645429611206055\n",
      "test r2:  -0.27893436695528084\n",
      "train loss:  1.7683308124542236\n",
      "train r2:  0.8792546482350931\n",
      "test loss:  7.364109992980957\n",
      "test r2:  -0.2788584840403059\n",
      "train loss:  1.7682480812072754\n",
      "train r2:  0.8792740436206058\n",
      "test loss:  7.363953113555908\n",
      "test r2:  -0.2788959816644061\n",
      "train loss:  1.7681655883789062\n",
      "train r2:  0.8792683762284205\n",
      "test loss:  7.36351203918457\n",
      "test r2:  -0.2788145203194041\n",
      "train loss:  1.768082857131958\n",
      "train r2:  0.8792890738364549\n",
      "test loss:  7.3633623123168945\n",
      "test r2:  -0.27885627428473425\n",
      "train loss:  1.7679998874664307\n",
      "train r2:  0.879282439399853\n",
      "test loss:  7.362905979156494\n",
      "test r2:  -0.2787697762028476\n",
      "train loss:  1.7679169178009033\n",
      "train r2:  0.8793041822898363\n",
      "test loss:  7.3627729415893555\n",
      "test r2:  -0.2788165007449124\n",
      "train loss:  1.767834186553955\n",
      "train r2:  0.8792964715532792\n",
      "test loss:  7.3623046875\n",
      "test r2:  -0.2787270645968909\n",
      "train loss:  1.7677509784698486\n",
      "train r2:  0.8793188436664962\n",
      "test loss:  7.362170219421387\n",
      "test r2:  -0.2787733434519699\n",
      "train loss:  1.7676681280136108\n",
      "train r2:  0.8793112393179598\n",
      "test loss:  7.361713886260986\n",
      "test r2:  -0.2786882389811529\n",
      "train loss:  1.7675848007202148\n",
      "train r2:  0.879332646814118\n",
      "test loss:  7.36155891418457\n",
      "test r2:  -0.27872745931708853\n",
      "train loss:  1.7675018310546875\n",
      "train r2:  0.8793265979830478\n",
      "test loss:  7.3611249923706055\n",
      "test r2:  -0.2786497630339544\n",
      "train loss:  1.767418622970581\n",
      "train r2:  0.8793464172847012\n",
      "test loss:  7.360954284667969\n",
      "test r2:  -0.27868326567215296\n",
      "train loss:  1.7673355340957642\n",
      "train r2:  0.8793416039066126\n",
      "test loss:  7.360525131225586\n",
      "test r2:  -0.27860827696991963\n",
      "train loss:  1.7672520875930786\n",
      "train r2:  0.879360786373409\n",
      "test loss:  7.360356330871582\n",
      "test r2:  -0.2786424429382801\n",
      "train loss:  1.7671688795089722\n",
      "train r2:  0.8793558338001546\n",
      "test loss:  7.359918594360352\n",
      "test r2:  -0.2785638081035109\n",
      "train loss:  1.7670859098434448\n",
      "train r2:  0.8793758520015507\n",
      "test loss:  7.359766006469727\n",
      "test r2:  -0.2786040832577861\n",
      "train loss:  1.7670025825500488\n",
      "train r2:  0.8793695436194309\n",
      "test loss:  7.359308242797852\n",
      "test r2:  -0.2785176561656464\n",
      "train loss:  1.7669193744659424\n",
      "train r2:  0.8793912812015743\n",
      "test loss:  7.359176158905029\n",
      "test r2:  -0.2785674426597613\n",
      "train loss:  1.766836404800415\n",
      "train r2:  0.8793828758378515\n",
      "test loss:  7.358694076538086\n",
      "test r2:  -0.2784693546312076\n",
      "train loss:  1.7667531967163086\n",
      "train r2:  0.8794071960949138\n",
      "test loss:  7.358595371246338\n",
      "test r2:  -0.2785337540513655\n",
      "train loss:  1.7666702270507812\n",
      "train r2:  0.879395572626066\n",
      "test loss:  7.358069896697998\n",
      "test r2:  -0.2784171383092091\n",
      "train loss:  1.766587257385254\n",
      "train r2:  0.8794240058802166\n",
      "test loss:  7.358026027679443\n",
      "test r2:  -0.2785057729817586\n",
      "train loss:  1.7665045261383057\n",
      "train r2:  0.8794069775121989\n",
      "test loss:  7.357423782348633\n",
      "test r2:  -0.27835672066012784\n",
      "train loss:  1.7664223909378052\n",
      "train r2:  0.879442580799884\n",
      "test loss:  7.357483386993408\n",
      "test r2:  -0.2784885452530481\n",
      "train loss:  1.766340732574463\n",
      "train r2:  0.8794160081635797\n",
      "test loss:  7.356748580932617\n",
      "test r2:  -0.27828342855549826\n",
      "train loss:  1.7662599086761475\n",
      "train r2:  0.8794640019046541\n",
      "test loss:  7.3569746017456055\n",
      "test r2:  -0.27848653702561177\n",
      "train loss:  1.7661807537078857\n",
      "train r2:  0.8794215568015518\n",
      "test loss:  7.356027126312256\n",
      "test r2:  -0.27819194244642587\n",
      "train loss:  1.7661038637161255\n",
      "train r2:  0.879489289462301\n",
      "test loss:  7.356517314910889\n",
      "test r2:  -0.2785059126181402\n",
      "train loss:  1.7660311460494995\n",
      "train r2:  0.8794222712867502\n",
      "test loss:  7.355246067047119\n",
      "test r2:  -0.278074402633232\n",
      "train loss:  1.7659624814987183\n",
      "train r2:  0.8795201557612735\n",
      "test loss:  7.356130599975586\n",
      "test r2:  -0.2785579906063964\n",
      "train loss:  1.7659050226211548\n",
      "train r2:  0.879415299813562\n",
      "test loss:  7.354366779327393\n",
      "test r2:  -0.2779159463944463\n",
      "train loss:  1.7658544778823853\n",
      "train r2:  0.8795596486641661\n",
      "test loss:  7.355862140655518\n",
      "test r2:  -0.2786577454029324\n",
      "train loss:  1.7658276557922363\n",
      "train r2:  0.8793972042873617\n",
      "test loss:  7.353367805480957\n",
      "test r2:  -0.27770961899195434\n",
      "train loss:  1.7657982110977173\n",
      "train r2:  0.8796090185064258\n",
      "test loss:  7.355685710906982\n",
      "test r2:  -0.27879338414837984\n",
      "train loss:  1.7657999992370605\n",
      "train r2:  0.879370430894482\n",
      "test loss:  7.352334976196289\n",
      "test r2:  -0.2775006453145372\n",
      "train loss:  1.7657427787780762\n",
      "train r2:  0.8796587562028353\n",
      "test loss:  7.355392932891846\n",
      "test r2:  -0.27886641400467727\n",
      "train loss:  1.7656832933425903\n",
      "train r2:  0.8793588517966869\n",
      "test loss:  7.351652145385742\n",
      "test r2:  -0.2774534665527897\n",
      "train loss:  1.7655022144317627\n",
      "train r2:  0.8796748115722408\n",
      "test loss:  7.354449272155762\n",
      "test r2:  -0.27866414955063146\n",
      "train loss:  1.7653099298477173\n",
      "train r2:  0.8794116681242132\n",
      "test loss:  7.3518290519714355\n",
      "test r2:  -0.27775747782974314\n",
      "train loss:  1.7651159763336182\n",
      "train r2:  0.8796148800722594\n",
      "test loss:  7.352563381195068\n",
      "test r2:  -0.27811882002080934\n",
      "train loss:  1.7649928331375122\n",
      "train r2:  0.8795388185566575\n",
      "test loss:  7.352652072906494\n",
      "test r2:  -0.2782726146213914\n",
      "train loss:  1.7649410963058472\n",
      "train r2:  0.8795066672325522\n",
      "test loss:  7.350675582885742\n",
      "test r2:  -0.27758734477709046\n",
      "train loss:  1.764919638633728\n",
      "train r2:  0.8796595900155548\n",
      "test loss:  7.3528947830200195\n",
      "test r2:  -0.27855315200177255\n",
      "train loss:  1.764887809753418\n",
      "train r2:  0.8794488976846933\n",
      "test loss:  7.3499040603637695\n",
      "test r2:  -0.27746396572745224\n",
      "train loss:  1.7647902965545654\n",
      "train r2:  0.8796922364905\n",
      "test loss:  7.351891040802002\n",
      "test r2:  -0.27836167938202516\n",
      "train loss:  1.7646598815917969\n",
      "train r2:  0.8794972393036073\n",
      "test loss:  7.350131511688232\n",
      "test r2:  -0.27774421511803715\n",
      "train loss:  1.7645149230957031\n",
      "train r2:  0.8796373952232218\n",
      "test loss:  7.3502516746521\n",
      "test r2:  -0.2779103805320211\n",
      "train loss:  1.7644037008285522\n",
      "train r2:  0.879603403197711\n",
      "test loss:  7.350493907928467\n",
      "test r2:  -0.27809090109692947\n",
      "train loss:  1.7643342018127441\n",
      "train r2:  0.8795664019646914\n",
      "test loss:  7.348973274230957\n",
      "test r2:  -0.27758106679697403\n",
      "train loss:  1.7642834186553955\n",
      "train r2:  0.8796813013850652\n",
      "test loss:  7.35026216506958\n",
      "test r2:  -0.27820749212580576\n",
      "train loss:  1.7642239332199097\n",
      "train r2:  0.8795450684560001\n",
      "test loss:  7.3483805656433105\n",
      "test r2:  -0.27753140249698194\n",
      "train loss:  1.764130711555481\n",
      "train r2:  0.879697707792368\n",
      "test loss:  7.349363327026367\n",
      "test r2:  -0.27805221262289614\n",
      "train loss:  1.7640193700790405\n",
      "train r2:  0.8795851243431725\n",
      "test loss:  7.348238945007324\n",
      "test r2:  -0.27768351176082673\n",
      "train loss:  1.7639062404632568\n",
      "train r2:  0.8796699928954373\n",
      "test loss:  7.348200798034668\n",
      "test r2:  -0.27777327392506246\n",
      "train loss:  1.7638119459152222\n",
      "train r2:  0.8796529441944647\n",
      "test loss:  7.3481855392456055\n",
      "test r2:  -0.27787490109768065\n",
      "train loss:  1.7637377977371216\n",
      "train r2:  0.8796328601248803\n",
      "test loss:  7.347150802612305\n",
      "test r2:  -0.27754260519928997\n",
      "train loss:  1.7636702060699463\n",
      "train r2:  0.8797090278547981\n",
      "test loss:  7.347874641418457\n",
      "test r2:  -0.2779558621513505\n",
      "train loss:  1.7635951042175293\n",
      "train r2:  0.8796197703272995\n",
      "test loss:  7.346435546875\n",
      "test r2:  -0.2774662276336568\n",
      "train loss:  1.7635035514831543\n",
      "train r2:  0.8797308649018794\n",
      "test loss:  7.347131252288818\n",
      "test r2:  -0.2778551028929066\n",
      "train loss:  1.7634044885635376\n",
      "train r2:  0.8796474602641478\n",
      "test loss:  7.346130847930908\n",
      "test r2:  -0.2775612314096303\n",
      "train loss:  1.7633070945739746\n",
      "train r2:  0.8797150006530139\n",
      "test loss:  7.34605598449707\n",
      "test r2:  -0.2776254358762946\n",
      "train loss:  1.763218879699707\n",
      "train r2:  0.8797036022611265\n",
      "test loss:  7.346015453338623\n",
      "test r2:  -0.2777171832587684\n",
      "train loss:  1.7631399631500244\n",
      "train r2:  0.8796856896074513\n",
      "test loss:  7.3450398445129395\n",
      "test r2:  -0.2774248754956916\n",
      "train loss:  1.7630633115768433\n",
      "train r2:  0.8797528112799883\n",
      "test loss:  7.345624923706055\n",
      "test r2:  -0.2777624092822377\n",
      "train loss:  1.762982964515686\n",
      "train r2:  0.879680741300607\n",
      "test loss:  7.344419479370117\n",
      "test r2:  -0.2773800007424345\n",
      "train loss:  1.762894630432129\n",
      "train r2:  0.8797678831192456\n",
      "test loss:  7.3448166847229\n",
      "test r2:  -0.27764635481377753\n",
      "train loss:  1.7628027200698853\n",
      "train r2:  0.8797116014155929\n",
      "test loss:  7.344125270843506\n",
      "test r2:  -0.27746169454301506\n",
      "train loss:  1.7627111673355103\n",
      "train r2:  0.8797552934256254\n",
      "test loss:  7.343865871429443\n",
      "test r2:  -0.27746980723327463\n",
      "train loss:  1.7626237869262695\n",
      "train r2:  0.8797559433517133\n",
      "test loss:  7.343801498413086\n",
      "test r2:  -0.2775384521639126\n",
      "train loss:  1.7625409364700317\n",
      "train r2:  0.8797435376454317\n",
      "test loss:  7.343072891235352\n",
      "test r2:  -0.27734758976924456\n",
      "train loss:  1.7624595165252686\n",
      "train r2:  0.8797882629912729\n",
      "test loss:  7.343263626098633\n",
      "test r2:  -0.27753603684530126\n",
      "train loss:  1.7623772621154785\n",
      "train r2:  0.8797490555301851\n",
      "test loss:  7.342474460601807\n",
      "test r2:  -0.27730344596460044\n",
      "train loss:  1.7622919082641602\n",
      "train r2:  0.879803505489827\n",
      "test loss:  7.3425984382629395\n",
      "test r2:  -0.27747136502195935\n",
      "train loss:  1.7622038125991821\n",
      "train r2:  0.8797687054344343\n",
      "test loss:  7.34196138381958\n",
      "test r2:  -0.2773046384284954\n",
      "train loss:  1.7621151208877563\n",
      "train r2:  0.879808546845612\n",
      "test loss:  7.341869831085205\n",
      "test r2:  -0.2773743528956589\n",
      "train loss:  1.762027621269226\n",
      "train r2:  0.8797956732339776\n",
      "test loss:  7.341486930847168\n",
      "test r2:  -0.27732679045747344\n",
      "train loss:  1.7619415521621704\n",
      "train r2:  0.8798087637706319\n",
      "test loss:  7.341104507446289\n",
      "test r2:  -0.2772663407995126\n",
      "train loss:  1.7618576288223267\n",
      "train r2:  0.8798248880150413\n",
      "test loss:  7.341024875640869\n",
      "test r2:  -0.2773470072027211\n",
      "train loss:  1.7617738246917725\n",
      "train r2:  0.879809467208019\n",
      "test loss:  7.3403706550598145\n",
      "test r2:  -0.2771797252465944\n",
      "train loss:  1.7616894245147705\n",
      "train r2:  0.8798491484002916\n",
      "test loss:  7.340469837188721\n",
      "test r2:  -0.27732742995507054\n",
      "train loss:  1.761603832244873\n",
      "train r2:  0.8798190226054734\n",
      "test loss:  7.3397674560546875\n",
      "test r2:  -0.27714512671185787\n",
      "train loss:  1.7615171670913696\n",
      "train r2:  0.8798619601184374\n",
      "test loss:  7.339771747589111\n",
      "test r2:  -0.2772526351740503\n",
      "train loss:  1.7614299058914185\n",
      "train r2:  0.8798407959669665\n",
      "test loss:  7.339278697967529\n",
      "test r2:  -0.27715381124030025\n",
      "train loss:  1.7613431215286255\n",
      "train r2:  0.8798652719669393\n",
      "test loss:  7.339012145996094\n",
      "test r2:  -0.27715559470100737\n",
      "train loss:  1.7612570524215698\n",
      "train r2:  0.8798673733654466\n",
      "test loss:  7.338781833648682\n",
      "test r2:  -0.2771616509661756\n",
      "train loss:  1.7611712217330933\n",
      "train r2:  0.8798687195782804\n",
      "test loss:  7.338317394256592\n",
      "test r2:  -0.2770792558090154\n",
      "train loss:  1.7610864639282227\n",
      "train r2:  0.8798894520672956\n",
      "test loss:  7.338200569152832\n",
      "test r2:  -0.27714010924420407\n",
      "train loss:  1.7610011100769043\n",
      "train r2:  0.8798784979102352\n",
      "test loss:  7.3376874923706055\n",
      "test r2:  -0.27702959757981405\n",
      "train loss:  1.7609155178070068\n",
      "train r2:  0.8799056665291188\n",
      "test loss:  7.337579250335693\n",
      "test r2:  -0.27709949370371834\n",
      "train loss:  1.7608299255371094\n",
      "train r2:  0.8798925985680045\n",
      "test loss:  7.337081432342529\n",
      "test r2:  -0.27699258058866194\n",
      "train loss:  1.7607436180114746\n",
      "train r2:  0.8799190603547541\n",
      "test loss:  7.336950302124023\n",
      "test r2:  -0.2770504469244053\n",
      "train loss:  1.7606570720672607\n",
      "train r2:  0.8799087600068979\n",
      "test loss:  7.336487293243408\n",
      "test r2:  -0.27696399860088294\n",
      "train loss:  1.7605706453323364\n",
      "train r2:  0.8799305385410819\n",
      "test loss:  7.3362956047058105\n",
      "test r2:  -0.27699099077471234\n",
      "train loss:  1.760484218597412\n",
      "train r2:  0.8799271868210005\n",
      "test loss:  7.335922718048096\n",
      "test r2:  -0.276945325040832\n",
      "train loss:  1.7603981494903564\n",
      "train r2:  0.879939857316337\n",
      "test loss:  7.335617542266846\n",
      "test r2:  -0.2769247256514267\n",
      "train loss:  1.7603118419647217\n",
      "train r2:  0.8799470495843926\n",
      "test loss:  7.335365295410156\n",
      "test r2:  -0.27692842462278233\n",
      "train loss:  1.760225772857666\n",
      "train r2:  0.8799487916113272\n",
      "test loss:  7.334951877593994\n",
      "test r2:  -0.27686390186562004\n",
      "train loss:  1.7601398229599\n",
      "train r2:  0.8799657504611796\n",
      "test loss:  7.334779262542725\n",
      "test r2:  -0.27690085705104206\n",
      "train loss:  1.7600539922714233\n",
      "train r2:  0.8799600869468044\n",
      "test loss:  7.3343186378479\n",
      "test r2:  -0.276816034282124\n",
      "train loss:  1.7599678039550781\n",
      "train r2:  0.8799815012997972\n",
      "test loss:  7.3341569900512695\n",
      "test r2:  -0.2768598236746551\n",
      "train loss:  1.759881615638733\n",
      "train r2:  0.8799743276412471\n",
      "test loss:  7.333713054656982\n",
      "test r2:  -0.27677915054114366\n",
      "train loss:  1.7597951889038086\n",
      "train r2:  0.879994913789375\n",
      "test loss:  7.333523273468018\n",
      "test r2:  -0.27681269393392904\n",
      "train loss:  1.7597087621688843\n",
      "train r2:  0.8799899874324602\n",
      "test loss:  7.333108425140381\n",
      "test r2:  -0.2767444575650557\n",
      "train loss:  1.7596222162246704\n",
      "train r2:  0.8800077730317681\n",
      "test loss:  7.332887649536133\n",
      "test r2:  -0.27676529557914265\n",
      "train loss:  1.759535551071167\n",
      "train r2:  0.8800056500865169\n",
      "test loss:  7.332498073577881\n",
      "test r2:  -0.2767090412308919\n",
      "train loss:  1.7594488859176636\n",
      "train r2:  0.8800207672634073\n",
      "test loss:  7.33225679397583\n",
      "test r2:  -0.27671818469801224\n",
      "train loss:  1.7593624591827393\n",
      "train r2:  0.880021288311274\n",
      "test loss:  7.331892013549805\n",
      "test r2:  -0.27667497316120215\n",
      "train loss:  1.7592757940292358\n",
      "train r2:  0.88003343292824\n",
      "test loss:  7.3316144943237305\n",
      "test r2:  -0.27666874758978866\n",
      "train loss:  1.7591891288757324\n",
      "train r2:  0.8800373803566313\n",
      "test loss:  7.331289768218994\n",
      "test r2:  -0.27664271602234325\n",
      "train loss:  1.759102463722229\n",
      "train r2:  0.8800456985894447\n",
      "test loss:  7.330972194671631\n",
      "test r2:  -0.2766189574048621\n",
      "train loss:  1.7590157985687256\n",
      "train r2:  0.8800535460319032\n",
      "test loss:  7.330687999725342\n",
      "test r2:  -0.27660921619833734\n",
      "train loss:  1.7589291334152222\n",
      "train r2:  0.8800583480194485\n",
      "test loss:  7.330337047576904\n",
      "test r2:  -0.2765721962741985\n",
      "train loss:  1.7588424682617188\n",
      "train r2:  0.8800691229902449\n",
      "test loss:  7.330071926116943\n",
      "test r2:  -0.2765722805074451\n",
      "train loss:  1.7587558031082153\n",
      "train r2:  0.8800716425586507\n",
      "test loss:  7.329708576202393\n",
      "test r2:  -0.27652813311849456\n",
      "train loss:  1.758669137954712\n",
      "train r2:  0.8800840210117492\n",
      "test loss:  7.32945442199707\n",
      "test r2:  -0.27653370628471197\n",
      "train loss:  1.758582353591919\n",
      "train r2:  0.8800853422013037\n",
      "test loss:  7.329080104827881\n",
      "test r2:  -0.27648438145744403\n",
      "train loss:  1.7584953308105469\n",
      "train r2:  0.8800989282004569\n",
      "test loss:  7.328837871551514\n",
      "test r2:  -0.27649628965774187\n",
      "train loss:  1.7584083080291748\n",
      "train r2:  0.8800987386465523\n",
      "test loss:  7.3284454345703125\n",
      "test r2:  -0.27643862072920533\n",
      "train loss:  1.7583215236663818\n",
      "train r2:  0.880114180166839\n",
      "test loss:  7.32822847366333\n",
      "test r2:  -0.2764608049145314\n",
      "train loss:  1.7582345008850098\n",
      "train r2:  0.8801117921987971\n",
      "test loss:  7.3278093338012695\n",
      "test r2:  -0.2763919092012448\n",
      "train loss:  1.7581478357315063\n",
      "train r2:  0.8801297373791581\n",
      "test loss:  7.3276166915893555\n",
      "test r2:  -0.27642593648357683\n",
      "train loss:  1.7580609321594238\n",
      "train r2:  0.8801246501872259\n",
      "test loss:  7.3271684646606445\n",
      "test r2:  -0.27634398732062837\n",
      "train loss:  1.7579739093780518\n",
      "train r2:  0.8801454690187023\n",
      "test loss:  7.327009201049805\n",
      "test r2:  -0.2763928238998332\n",
      "train loss:  1.7578872442245483\n",
      "train r2:  0.8801371441445305\n",
      "test loss:  7.326527118682861\n",
      "test r2:  -0.27629394451788847\n",
      "train loss:  1.757800579071045\n",
      "train r2:  0.880161785954843\n",
      "test loss:  7.326408386230469\n",
      "test r2:  -0.2763640358902233\n",
      "train loss:  1.757714033126831\n",
      "train r2:  0.8801485993451142\n",
      "test loss:  7.325864791870117\n",
      "test r2:  -0.2762367026215593\n",
      "train loss:  1.7576279640197754\n",
      "train r2:  0.8801795846642116\n",
      "test loss:  7.325828552246094\n",
      "test r2:  -0.27634419464100257\n",
      "train loss:  1.7575422525405884\n",
      "train r2:  0.8801580812628322\n",
      "test loss:  7.32518196105957\n",
      "test r2:  -0.2761693555211331\n",
      "train loss:  1.7574572563171387\n",
      "train r2:  0.8801996865782029\n",
      "test loss:  7.325273036956787\n",
      "test r2:  -0.2763363169829254\n",
      "train loss:  1.7573736906051636\n",
      "train r2:  0.8801647961504908\n",
      "test loss:  7.324464321136475\n",
      "test r2:  -0.2760869340776946\n",
      "train loss:  1.7572920322418213\n",
      "train r2:  0.8802230329401258\n",
      "test loss:  7.324759006500244\n",
      "test r2:  -0.2763479718895121\n",
      "train loss:  1.757214069366455\n",
      "train r2:  0.8801670645695076\n",
      "test loss:  7.323695182800293\n",
      "test r2:  -0.27597939717044717\n",
      "train loss:  1.7571401596069336\n",
      "train r2:  0.8802518437826856\n",
      "test loss:  7.324313163757324\n",
      "test r2:  -0.2763917490544383\n",
      "train loss:  1.7570762634277344\n",
      "train r2:  0.8801618406059833\n",
      "test loss:  7.3228349685668945\n",
      "test r2:  -0.2758321106706403\n",
      "train loss:  1.7570197582244873\n",
      "train r2:  0.8802890764929207\n",
      "test loss:  7.323968410491943\n",
      "test r2:  -0.276482423303791\n",
      "train loss:  1.756987452507019\n",
      "train r2:  0.8801454329134147\n",
      "test loss:  7.3218584060668945\n",
      "test r2:  -0.27563302459920336\n",
      "train loss:  1.7569595575332642\n",
      "train r2:  0.8803370418525106\n",
      "test loss:  7.323742389678955\n",
      "test r2:  -0.27662250758858997\n",
      "train loss:  1.7569717168807983\n",
      "train r2:  0.8801169979990656\n",
      "test loss:  7.320785045623779\n",
      "test r2:  -0.27540254405975384\n",
      "train loss:  1.7569388151168823\n",
      "train r2:  0.8803913161286905\n",
      "test loss:  7.323517322540283\n",
      "test r2:  -0.27674723702461157\n",
      "train loss:  1.7569221258163452\n",
      "train r2:  0.8800925456997686\n",
      "test loss:  7.319879055023193\n",
      "test r2:  -0.27527318031637615\n",
      "train loss:  1.7567557096481323\n",
      "train r2:  0.8804246384257243\n",
      "test loss:  7.322849750518799\n",
      "test r2:  -0.27664974126683495\n",
      "train loss:  1.7565646171569824\n",
      "train r2:  0.8801222057638015\n",
      "test loss:  7.31971549987793\n",
      "test r2:  -0.27548605370678514\n",
      "train loss:  1.7563188076019287\n",
      "train r2:  0.8803844683316804\n",
      "test loss:  7.3211669921875\n",
      "test r2:  -0.2761479995768308\n",
      "train loss:  1.7561440467834473\n",
      "train r2:  0.880242240534672\n",
      "test loss:  7.320490837097168\n",
      "test r2:  -0.2760339404978456\n",
      "train loss:  1.7560638189315796\n",
      "train r2:  0.8802687046676468\n",
      "test loss:  7.319025993347168\n",
      "test r2:  -0.27551303162531626\n",
      "train loss:  1.756047248840332\n",
      "train r2:  0.8803864376538619\n",
      "test loss:  7.321057319641113\n",
      "test r2:  -0.27645383097272824\n",
      "train loss:  1.7560380697250366\n",
      "train r2:  0.8801794500278741\n",
      "test loss:  7.317897319793701\n",
      "test r2:  -0.275265920387892\n",
      "train loss:  1.755955457687378\n",
      "train r2:  0.8804455526439583\n",
      "test loss:  7.320228576660156\n",
      "test r2:  -0.2763371624040414\n",
      "train loss:  1.7558249235153198\n",
      "train r2:  0.8802109690626293\n",
      "test loss:  7.318084716796875\n",
      "test r2:  -0.27554590483884245\n",
      "train loss:  1.7556562423706055\n",
      "train r2:  0.8803906764942538\n",
      "test loss:  7.31843900680542\n",
      "test r2:  -0.27582912076519506\n",
      "train loss:  1.7555233240127563\n",
      "train r2:  0.8803305247323425\n",
      "test loss:  7.318603992462158\n",
      "test r2:  -0.27597419640341614\n",
      "train loss:  1.7554446458816528\n",
      "train r2:  0.8803015611803245\n",
      "test loss:  7.31700325012207\n",
      "test r2:  -0.275432887031567\n",
      "train loss:  1.7553977966308594\n",
      "train r2:  0.880423607143388\n",
      "test loss:  7.3183794021606445\n",
      "test r2:  -0.2761218049091103\n",
      "train loss:  1.7553447484970093\n",
      "train r2:  0.880272608306716\n",
      "test loss:  7.31645393371582\n",
      "test r2:  -0.2753928221593269\n",
      "train loss:  1.7552480697631836\n",
      "train r2:  0.8804381924620059\n",
      "test loss:  7.317370891571045\n",
      "test r2:  -0.2759383449713315\n",
      "train loss:  1.7551275491714478\n",
      "train r2:  0.8803187969483964\n",
      "test loss:  7.316341876983643\n",
      "test r2:  -0.2755775259374236\n",
      "train loss:  1.7550028562545776\n",
      "train r2:  0.8804030254139799\n",
      "test loss:  7.316189765930176\n",
      "test r2:  -0.27564207704542487\n",
      "train loss:  1.754902958869934\n",
      "train r2:  0.8803910721751314\n",
      "test loss:  7.316215515136719\n",
      "test r2:  -0.2757744060547018\n",
      "train loss:  1.7548290491104126\n",
      "train r2:  0.8803639008779371\n",
      "test loss:  7.315181255340576\n",
      "test r2:  -0.2754172510707651\n",
      "train loss:  1.7547622919082642\n",
      "train r2:  0.8804463639087658\n",
      "test loss:  7.315842151641846\n",
      "test r2:  -0.2758494657507784\n",
      "train loss:  1.7546840906143188\n",
      "train r2:  0.8803517162418025\n",
      "test loss:  7.314447402954102\n",
      "test r2:  -0.27534726032527024\n",
      "train loss:  1.7545840740203857\n",
      "train r2:  0.8804667188756516\n",
      "test loss:  7.315093994140625\n",
      "test r2:  -0.2757412361015754\n",
      "train loss:  1.7544763088226318\n",
      "train r2:  0.8803816128482573\n",
      "test loss:  7.314116954803467\n",
      "test r2:  -0.2754590306382836\n",
      "train loss:  1.7543734312057495\n",
      "train r2:  0.8804467307121998\n",
      "test loss:  7.313973903656006\n",
      "test r2:  -0.2754909316978149\n",
      "train loss:  1.7542849779129028\n",
      "train r2:  0.8804425683684637\n",
      "test loss:  7.31401252746582\n",
      "test r2:  -0.27563834068258575\n",
      "train loss:  1.754206657409668\n",
      "train r2:  0.8804117697082416\n",
      "test loss:  7.312904357910156\n",
      "test r2:  -0.27527970228329646\n",
      "train loss:  1.7541276216506958\n",
      "train r2:  0.8804940462446582\n",
      "test loss:  7.31358528137207\n",
      "test r2:  -0.27567723374063147\n",
      "train loss:  1.7540407180786133\n",
      "train r2:  0.8804081419124077\n",
      "test loss:  7.312320232391357\n",
      "test r2:  -0.27526510035595386\n",
      "train loss:  1.7539442777633667\n",
      "train r2:  0.8805023196744552\n",
      "test loss:  7.312649250030518\n",
      "test r2:  -0.2755182512355576\n",
      "train loss:  1.7538455724716187\n",
      "train r2:  0.8804486201176247\n",
      "test loss:  7.312109470367432\n",
      "test r2:  -0.2753924311258442\n",
      "train loss:  1.7537510395050049\n",
      "train r2:  0.880479501682864\n",
      "test loss:  7.311613082885742\n",
      "test r2:  -0.27531195179065526\n",
      "train loss:  1.7536630630493164\n",
      "train r2:  0.8804996138540828\n",
      "test loss:  7.311758041381836\n",
      "test r2:  -0.27547672871810347\n",
      "train loss:  1.7535792589187622\n",
      "train r2:  0.880465617509712\n",
      "test loss:  7.310854911804199\n",
      "test r2:  -0.2752084463514035\n",
      "train loss:  1.7534947395324707\n",
      "train r2:  0.8805278573595181\n",
      "test loss:  7.311098098754883\n",
      "test r2:  -0.27544010380909945\n",
      "train loss:  1.7534066438674927\n",
      "train r2:  0.880478500862063\n",
      "test loss:  7.310338973999023\n",
      "test r2:  -0.27520780026277913\n",
      "train loss:  1.7533142566680908\n",
      "train r2:  0.8805333843097229\n",
      "test loss:  7.310324192047119\n",
      "test r2:  -0.2753388209838623\n",
      "train loss:  1.7532203197479248\n",
      "train r2:  0.8805063452126176\n",
      "test loss:  7.309845447540283\n",
      "test r2:  -0.2752373390145655\n",
      "train loss:  1.753127932548523\n",
      "train r2:  0.8805318542465768\n",
      "test loss:  7.309556484222412\n",
      "test r2:  -0.27522860616148126\n",
      "train loss:  1.7530382871627808\n",
      "train r2:  0.8805363828783676\n",
      "test loss:  7.309338092803955\n",
      "test r2:  -0.2752624334886764\n",
      "train loss:  1.7529511451721191\n",
      "train r2:  0.8805311376829319\n",
      "test loss:  7.308802604675293\n",
      "test r2:  -0.2751309784438829\n",
      "train loss:  1.7528644800186157\n",
      "train r2:  0.8805633489685301\n",
      "test loss:  7.308810234069824\n",
      "test r2:  -0.2752660639158062\n",
      "train loss:  1.7527763843536377\n",
      "train r2:  0.8805354322333317\n",
      "test loss:  7.308098316192627\n",
      "test r2:  -0.27507020963928697\n",
      "train loss:  1.7526865005493164\n",
      "train r2:  0.8805817703671491\n",
      "test loss:  7.308168411254883\n",
      "test r2:  -0.2752174413749895\n",
      "train loss:  1.752595067024231\n",
      "train r2:  0.8805515058982382\n",
      "test loss:  7.307540416717529\n",
      "test r2:  -0.2750679485851233\n",
      "train loss:  1.752503514289856\n",
      "train r2:  0.8805873303242915\n",
      "test loss:  7.30738639831543\n",
      "test r2:  -0.2751166572066408\n",
      "train loss:  1.752413034439087\n",
      "train r2:  0.8805790082009773\n",
      "test loss:  7.307065010070801\n",
      "test r2:  -0.2750968696237024\n",
      "train loss:  1.7523235082626343\n",
      "train r2:  0.8805859281171919\n",
      "test loss:  7.306595325469971\n",
      "test r2:  -0.2750143776615972\n",
      "train loss:  1.752234935760498\n",
      "train r2:  0.8806067663060128\n",
      "test loss:  7.306526184082031\n",
      "test r2:  -0.275100142722118\n",
      "train loss:  1.7521462440490723\n",
      "train r2:  0.8805902013466353\n",
      "test loss:  7.3059163093566895\n",
      "test r2:  -0.27495482692718065\n",
      "train loss:  1.7520575523376465\n",
      "train r2:  0.8806251084554945\n",
      "test loss:  7.305863857269287\n",
      "test r2:  -0.2750560431211875\n",
      "train loss:  1.751967430114746\n",
      "train r2:  0.8806049009271154\n",
      "test loss:  7.305327892303467\n",
      "test r2:  -0.2749338170630151\n",
      "train loss:  1.7518774271011353\n",
      "train r2:  0.8806348753775279\n",
      "test loss:  7.305158615112305\n",
      "test r2:  -0.27498922777615853\n",
      "train loss:  1.751786708831787\n",
      "train r2:  0.880624814766097\n",
      "test loss:  7.304749011993408\n",
      "test r2:  -0.2749224088509197\n",
      "train loss:  1.7516961097717285\n",
      "train r2:  0.8806424234948886\n",
      "test loss:  7.304464817047119\n",
      "test r2:  -0.27492262509314425\n",
      "train loss:  1.7516061067581177\n",
      "train r2:  0.8806448251244342\n",
      "test loss:  7.3041486740112305\n",
      "test r2:  -0.27490600024475764\n",
      "train loss:  1.7515164613723755\n",
      "train r2:  0.880650978573241\n",
      "test loss:  7.303783893585205\n",
      "test r2:  -0.2748610656520185\n",
      "train loss:  1.7514265775680542\n",
      "train r2:  0.8806636590008035\n",
      "test loss:  7.303549289703369\n",
      "test r2:  -0.27488564469878374\n",
      "train loss:  1.7513372898101807\n",
      "train r2:  0.8806605439911723\n",
      "test loss:  7.303105354309082\n",
      "test r2:  -0.2748043740388779\n",
      "train loss:  1.751247525215149\n",
      "train r2:  0.8806813404274361\n",
      "test loss:  7.302938938140869\n",
      "test r2:  -0.2748577504554133\n",
      "train loss:  1.7511576414108276\n",
      "train r2:  0.8806718136295979\n",
      "test loss:  7.302443981170654\n",
      "test r2:  -0.27475911064031044\n",
      "train loss:  1.7510675191879272\n",
      "train r2:  0.8806964102729042\n",
      "test loss:  7.302292346954346\n",
      "test r2:  -0.27481389085963426\n",
      "train loss:  1.7509771585464478\n",
      "train r2:  0.8806866846880205\n",
      "test loss:  7.301831245422363\n",
      "test r2:  -0.27473189183181623\n",
      "train loss:  1.7508866786956787\n",
      "train r2:  0.8807075622165392\n",
      "test loss:  7.301605701446533\n",
      "test r2:  -0.2747556875745183\n",
      "train loss:  1.7507961988449097\n",
      "train r2:  0.8807047335687117\n",
      "test loss:  7.3012375831604\n",
      "test r2:  -0.27471275447071974\n",
      "train loss:  1.7507060766220093\n",
      "train r2:  0.8807168368842497\n",
      "test loss:  7.300915241241455\n",
      "test r2:  -0.27469623547201927\n",
      "train loss:  1.7506155967712402\n",
      "train r2:  0.8807229992240283\n",
      "test loss:  7.300628662109375\n",
      "test r2:  -0.2746883878524773\n",
      "train loss:  1.7505253553390503\n",
      "train r2:  0.8807272952595236\n",
      "test loss:  7.3002519607543945\n",
      "test r2:  -0.2746456122861103\n",
      "train loss:  1.7504349946975708\n",
      "train r2:  0.880739366138244\n",
      "test loss:  7.299991130828857\n",
      "test r2:  -0.27465511790334896\n",
      "train loss:  1.7503448724746704\n",
      "train r2:  0.8807396762379647\n",
      "test loss:  7.29960298538208\n",
      "test r2:  -0.2746016051561866\n",
      "train loss:  1.7502546310424805\n",
      "train r2:  0.8807542178856717\n",
      "test loss:  7.299352645874023\n",
      "test r2:  -0.2746188115552022\n",
      "train loss:  1.7501641511917114\n",
      "train r2:  0.8807527657137756\n",
      "test loss:  7.298946857452393\n",
      "test r2:  -0.27455753492608626\n",
      "train loss:  1.7500739097595215\n",
      "train r2:  0.8807690366753472\n",
      "test loss:  7.2987165451049805\n",
      "test r2:  -0.27458291637000243\n",
      "train loss:  1.7499831914901733\n",
      "train r2:  0.880765783073556\n",
      "test loss:  7.29829216003418\n",
      "test r2:  -0.27451551113007944\n",
      "train loss:  1.7498927116394043\n",
      "train r2:  0.8807834165918963\n",
      "test loss:  7.298072338104248\n",
      "test r2:  -0.2745427180632547\n",
      "train loss:  1.7498022317886353\n",
      "train r2:  0.8807797974754662\n",
      "test loss:  7.297654628753662\n",
      "test r2:  -0.2744793976053239\n",
      "train loss:  1.749711275100708\n",
      "train r2:  0.880796425740276\n",
      "test loss:  7.2974090576171875\n",
      "test r2:  -0.27449679952722517\n",
      "train loss:  1.749620795249939\n",
      "train r2:  0.8807950159047713\n",
      "test loss:  7.297024250030518\n",
      "test r2:  -0.2744459748746264\n",
      "train loss:  1.7495298385620117\n",
      "train r2:  0.8808089359975066\n",
      "test loss:  7.296751022338867\n",
      "test r2:  -0.27445227963667973\n",
      "train loss:  1.7494391202926636\n",
      "train r2:  0.8808099643037277\n",
      "test loss:  7.296381950378418\n",
      "test r2:  -0.2744091733842595\n",
      "train loss:  1.7493481636047363\n",
      "train r2:  0.8808221313611965\n",
      "test loss:  7.296102523803711\n",
      "test r2:  -0.2744107609534092\n",
      "train loss:  1.7492575645446777\n",
      "train r2:  0.8808242397677514\n",
      "test loss:  7.295736312866211\n",
      "test r2:  -0.27437111192214814\n",
      "train loss:  1.7491663694381714\n",
      "train r2:  0.8808356181239426\n",
      "test loss:  7.2954511642456055\n",
      "test r2:  -0.27436890780315437\n",
      "train loss:  1.7490754127502441\n",
      "train r2:  0.8808386148944323\n",
      "test loss:  7.295094013214111\n",
      "test r2:  -0.2743344581092979\n",
      "train loss:  1.7489845752716064\n",
      "train r2:  0.8808487814570901\n",
      "test loss:  7.2947916984558105\n",
      "test r2:  -0.27432557342909414\n",
      "train loss:  1.7488936185836792\n",
      "train r2:  0.8808532359053398\n",
      "test loss:  7.294455051422119\n",
      "test r2:  -0.2742981205305781\n",
      "train loss:  1.7488025426864624\n",
      "train r2:  0.8808618948557155\n",
      "test loss:  7.2941389083862305\n",
      "test r2:  -0.27428394162921244\n",
      "train loss:  1.7487115859985352\n",
      "train r2:  0.8808675470441371\n",
      "test loss:  7.29380464553833\n",
      "test r2:  -0.27425895078456586\n",
      "train loss:  1.7486205101013184\n",
      "train r2:  0.8808756027562854\n",
      "test loss:  7.293491840362549\n",
      "test r2:  -0.274244942238111\n",
      "train loss:  1.7485291957855225\n",
      "train r2:  0.8808812460486926\n",
      "test loss:  7.29315185546875\n",
      "test r2:  -0.2742184076962242\n",
      "train loss:  1.7484381198883057\n",
      "train r2:  0.8808896541695632\n",
      "test loss:  7.292844772338867\n",
      "test r2:  -0.27420606155513894\n",
      "train loss:  1.7483468055725098\n",
      "train r2:  0.8808949025937932\n",
      "test loss:  7.2925004959106445\n",
      "test r2:  -0.2741785590744015\n",
      "train loss:  1.748255729675293\n",
      "train r2:  0.8809035243279356\n",
      "test loss:  7.292192459106445\n",
      "test r2:  -0.2741664663540142\n",
      "train loss:  1.748164176940918\n",
      "train r2:  0.8809087337850696\n",
      "test loss:  7.29185152053833\n",
      "test r2:  -0.2741393278544635\n",
      "train loss:  1.7480729818344116\n",
      "train r2:  0.880917272329134\n",
      "test loss:  7.291540145874023\n",
      "test r2:  -0.2741265698499553\n",
      "train loss:  1.7479815483093262\n",
      "train r2:  0.8809225659526639\n",
      "test loss:  7.291200637817383\n",
      "test r2:  -0.27409967160952986\n",
      "train loss:  1.7478899955749512\n",
      "train r2:  0.8809311058515585\n",
      "test loss:  7.290890216827393\n",
      "test r2:  -0.27408841635924297\n",
      "train loss:  1.7477988004684448\n",
      "train r2:  0.8809360640620263\n",
      "test loss:  7.2905426025390625\n",
      "test r2:  -0.27405741625504554\n",
      "train loss:  1.7477070093154907\n",
      "train r2:  0.8809455262197715\n",
      "test loss:  7.290246963500977\n",
      "test r2:  -0.27405266111765103\n",
      "train loss:  1.7476156949996948\n",
      "train r2:  0.8809490547031306\n",
      "test loss:  7.289883136749268\n",
      "test r2:  -0.27401428740715805\n",
      "train loss:  1.7475242614746094\n",
      "train r2:  0.8809600989237135\n",
      "test loss:  7.289599895477295\n",
      "test r2:  -0.27401693486183243\n",
      "train loss:  1.7474327087402344\n",
      "train r2:  0.8809619715939843\n",
      "test loss:  7.289222717285156\n",
      "test r2:  -0.27397005501484695\n",
      "train loss:  1.7473410367965698\n",
      "train r2:  0.8809750031845278\n",
      "test loss:  7.288961887359619\n",
      "test r2:  -0.27398484165480763\n",
      "train loss:  1.7472492456436157\n",
      "train r2:  0.8809740972703601\n",
      "test loss:  7.288547039031982\n",
      "test r2:  -0.273920474239433\n",
      "train loss:  1.7471580505371094\n",
      "train r2:  0.8809910477480728\n",
      "test loss:  7.288333415985107\n",
      "test r2:  -0.2739587625983757\n",
      "train loss:  1.7470669746398926\n",
      "train r2:  0.8809847861285302\n",
      "test loss:  7.287861347198486\n",
      "test r2:  -0.2738635592646115\n",
      "train loss:  1.7469761371612549\n",
      "train r2:  0.8810087845841512\n",
      "test loss:  7.287725925445557\n",
      "test r2:  -0.27394297866511974\n",
      "train loss:  1.7468856573104858\n",
      "train r2:  0.8809932130969016\n",
      "test loss:  7.287143230438232\n",
      "test r2:  -0.2737925787917799\n",
      "train loss:  1.746796727180481\n",
      "train r2:  0.8810295693477532\n",
      "test loss:  7.28715181350708\n",
      "test r2:  -0.27394615493810837\n",
      "train loss:  1.7467106580734253\n",
      "train r2:  0.8809971973490622\n",
      "test loss:  7.286380290985107\n",
      "test r2:  -0.2736956369916179\n",
      "train loss:  1.7466281652450562\n",
      "train r2:  0.8810562195976583\n",
      "test loss:  7.286648273468018\n",
      "test r2:  -0.2739857357979114\n",
      "train loss:  1.746554970741272\n",
      "train r2:  0.8809926961497468\n",
      "test loss:  7.285517692565918\n",
      "test r2:  -0.2735490630764863\n",
      "train loss:  1.7464948892593384\n",
      "train r2:  0.8810934942912668\n",
      "test loss:  7.286267280578613\n",
      "test r2:  -0.274091396961877\n",
      "train loss:  1.746466040611267\n",
      "train r2:  0.8809722532037249\n",
      "test loss:  7.284481525421143\n",
      "test r2:  -0.2733144609821099\n",
      "train loss:  1.7464683055877686\n",
      "train r2:  0.8811492641266538\n",
      "test loss:  7.286113262176514\n",
      "test r2:  -0.2743085243381145\n",
      "train loss:  1.7465600967407227\n",
      "train r2:  0.8809241826277592\n",
      "test loss:  7.2831621170043945\n",
      "test r2:  -0.27295637126433636\n",
      "train loss:  1.746644139289856\n",
      "train r2:  0.8812300329934679\n",
      "test loss:  7.286215305328369\n",
      "test r2:  -0.27462321573370674\n",
      "train loss:  1.746824026107788\n",
      "train r2:  0.8808519166371612\n",
      "test loss:  7.281712055206299\n",
      "test r2:  -0.2726073244564815\n",
      "train loss:  1.7466436624526978\n",
      "train r2:  0.8813098169390712\n",
      "test loss:  7.286046028137207\n",
      "test r2:  -0.27469611149188755\n",
      "train loss:  1.7463568449020386\n",
      "train r2:  0.8808454625059697\n",
      "test loss:  7.281261920928955\n",
      "test r2:  -0.2728376673257975\n",
      "train loss:  1.7458540201187134\n",
      "train r2:  0.8812670750258962\n",
      "test loss:  7.283946514129639\n",
      "test r2:  -0.2739035725556114\n",
      "train loss:  1.7455952167510986\n",
      "train r2:  0.881037975221542\n",
      "test loss:  7.283079147338867\n",
      "test r2:  -0.27389901888081036\n",
      "train loss:  1.7456388473510742\n",
      "train r2:  0.8810338318960762\n",
      "test loss:  7.28029203414917\n",
      "test r2:  -0.272720764904677\n",
      "train loss:  1.7457515001296997\n",
      "train r2:  0.8812991031249634\n",
      "test loss:  7.28462553024292\n",
      "test r2:  -0.2746253974661472\n",
      "train loss:  1.745732069015503\n",
      "train r2:  0.8808766321229777\n",
      "test loss:  7.279434680938721\n",
      "test r2:  -0.2726570388712206\n",
      "train loss:  1.7454235553741455\n",
      "train r2:  0.8813192651594403\n",
      "test loss:  7.282209873199463\n",
      "test r2:  -0.27385376562890196\n",
      "train loss:  1.7451488971710205\n",
      "train r2:  0.8810588556662245\n",
      "test loss:  7.2816267013549805\n",
      "test r2:  -0.2737930169005178\n",
      "train loss:  1.74507474899292\n",
      "train r2:  0.881073079359697\n",
      "test loss:  7.278682231903076\n",
      "test r2:  -0.2726862769345255\n",
      "train loss:  1.7451204061508179\n",
      "train r2:  0.881320907681994\n",
      "test loss:  7.282527446746826\n",
      "test r2:  -0.2743140416915619\n",
      "train loss:  1.745092749595642\n",
      "train r2:  0.880961994846363\n",
      "test loss:  7.2787861824035645\n",
      "test r2:  -0.27289706114952406\n",
      "train loss:  1.744881272315979\n",
      "train r2:  0.8812817223336498\n",
      "test loss:  7.279632091522217\n",
      "test r2:  -0.27345520681925484\n",
      "train loss:  1.7446777820587158\n",
      "train r2:  0.8811590490730276\n",
      "test loss:  7.280487537384033\n",
      "test r2:  -0.2738009901674059\n",
      "train loss:  1.7446011304855347\n",
      "train r2:  0.8810873661329669\n",
      "test loss:  7.277629375457764\n",
      "test r2:  -0.27278008451073266\n",
      "train loss:  1.7445933818817139\n",
      "train r2:  0.8813156200728248\n",
      "test loss:  7.279757976531982\n",
      "test r2:  -0.27383789892069976\n",
      "train loss:  1.744529128074646\n",
      "train r2:  0.8810804504105971\n",
      "test loss:  7.278194904327393\n",
      "test r2:  -0.2731527128303728\n",
      "train loss:  1.7443604469299316\n",
      "train r2:  0.8812405616429695\n",
      "test loss:  7.277724742889404\n",
      "test r2:  -0.2732331993751378\n",
      "train loss:  1.7442065477371216\n",
      "train r2:  0.8812222845725892\n",
      "test loss:  7.278481960296631\n",
      "test r2:  -0.27357503807743333\n",
      "train loss:  1.7441322803497314\n",
      "train r2:  0.8811505144931437\n",
      "test loss:  7.27686882019043\n",
      "test r2:  -0.2729761161837885\n",
      "train loss:  1.7440900802612305\n",
      "train r2:  0.8812869703535974\n",
      "test loss:  7.277356147766113\n",
      "test r2:  -0.27348037349563237\n",
      "train loss:  1.744004726409912\n",
      "train r2:  0.8811723331168332\n",
      "test loss:  7.276719570159912\n",
      "test r2:  -0.27313641523120147\n",
      "train loss:  1.7438617944717407\n",
      "train r2:  0.8812570876957095\n",
      "test loss:  7.27651834487915\n",
      "test r2:  -0.27323811644944374\n",
      "train loss:  1.743737816810608\n",
      "train r2:  0.8812357839892289\n",
      "test loss:  7.276220321655273\n",
      "test r2:  -0.2733004806922781\n",
      "train loss:  1.7436634302139282\n",
      "train r2:  0.8812222048020687\n",
      "test loss:  7.275521755218506\n",
      "test r2:  -0.2730064797397609\n",
      "train loss:  1.7435994148254395\n",
      "train r2:  0.8812926181458357\n",
      "test loss:  7.275787353515625\n",
      "test r2:  -0.27337077336335236\n",
      "train loss:  1.7435030937194824\n",
      "train r2:  0.8812105760989464\n",
      "test loss:  7.274726867675781\n",
      "test r2:  -0.27296761577399353\n",
      "train loss:  1.7433786392211914\n",
      "train r2:  0.8813054341358697\n",
      "test loss:  7.275093078613281\n",
      "test r2:  -0.2732124054213927\n",
      "train loss:  1.7432712316513062\n",
      "train r2:  0.8812539815180316\n",
      "test loss:  7.274498462677002\n",
      "test r2:  -0.2731830446764991\n",
      "train loss:  1.7431919574737549\n",
      "train r2:  0.8812603005913011\n",
      "test loss:  7.273689270019531\n",
      "test r2:  -0.2728792933539219\n",
      "train loss:  1.7431141138076782\n",
      "train r2:  0.8813323420033352\n",
      "test loss:  7.274362087249756\n",
      "test r2:  -0.27331661537551\n",
      "train loss:  1.743016004562378\n",
      "train r2:  0.8812363852501639\n",
      "test loss:  7.272976398468018\n",
      "test r2:  -0.27286546844684145\n",
      "train loss:  1.7429040670394897\n",
      "train r2:  0.8813396372862552\n",
      "test loss:  7.273251533508301\n",
      "test r2:  -0.27306544449949044\n",
      "train loss:  1.7428033351898193\n",
      "train r2:  0.8812983199135588\n",
      "test loss:  7.273087024688721\n",
      "test r2:  -0.2731464395200953\n",
      "train loss:  1.7427191734313965\n",
      "train r2:  0.8812819093237086\n",
      "test loss:  7.271928787231445\n",
      "test r2:  -0.2727642783383921\n",
      "train loss:  1.7426342964172363\n",
      "train r2:  0.8813700456967175\n",
      "test loss:  7.272628307342529\n",
      "test r2:  -0.27318262513241964\n",
      "train loss:  1.742537021636963\n",
      "train r2:  0.8812789164708983\n",
      "test loss:  7.271536350250244\n",
      "test r2:  -0.27284665074032755\n",
      "train loss:  1.7424323558807373\n",
      "train r2:  0.8813565397976895\n",
      "test loss:  7.271371841430664\n",
      "test r2:  -0.27289988462436154\n",
      "train loss:  1.7423344850540161\n",
      "train r2:  0.8813472011672263\n",
      "test loss:  7.271525859832764\n",
      "test r2:  -0.27306500998734795\n",
      "train loss:  1.742246150970459\n",
      "train r2:  0.8813132326117794\n",
      "test loss:  7.270403861999512\n",
      "test r2:  -0.27272239808668486\n",
      "train loss:  1.7421574592590332\n",
      "train r2:  0.8813920011619939\n",
      "test loss:  7.270726203918457\n",
      "test r2:  -0.2730010950097439\n",
      "train loss:  1.742061734199524\n",
      "train r2:  0.8813316129557965\n",
      "test loss:  7.270101547241211\n",
      "test r2:  -0.2728206720649544\n",
      "train loss:  1.7419612407684326\n",
      "train r2:  0.8813754249079704\n",
      "test loss:  7.269670009613037\n",
      "test r2:  -0.27279165092796465\n",
      "train loss:  1.7418643236160278\n",
      "train r2:  0.8813837924232814\n",
      "test loss:  7.269730091094971\n",
      "test r2:  -0.2729176266293434\n",
      "train loss:  1.7417731285095215\n",
      "train r2:  0.8813585133420944\n",
      "test loss:  7.268966197967529\n",
      "test r2:  -0.2727083804627184\n",
      "train loss:  1.7416824102401733\n",
      "train r2:  0.8814078325816821\n",
      "test loss:  7.268892288208008\n",
      "test r2:  -0.27284224513629307\n",
      "train loss:  1.7415878772735596\n",
      "train r2:  0.8813793326301775\n",
      "test loss:  7.268488883972168\n",
      "test r2:  -0.27273936749546257\n",
      "train loss:  1.7414900064468384\n",
      "train r2:  0.8814061491457944\n",
      "test loss:  7.268111705780029\n",
      "test r2:  -0.27273558489712\n",
      "train loss:  1.7413933277130127\n",
      "train r2:  0.8814086831343235\n",
      "test loss:  7.267859935760498\n",
      "test r2:  -0.2727533014228043\n",
      "train loss:  1.7412996292114258\n",
      "train r2:  0.8814070822387182\n",
      "test loss:  7.267451763153076\n",
      "test r2:  -0.272668751274177\n",
      "train loss:  1.7412078380584717\n",
      "train r2:  0.8814291824084491\n",
      "test loss:  7.267202377319336\n",
      "test r2:  -0.2727318100941316\n",
      "train loss:  1.7411139011383057\n",
      "train r2:  0.8814164594576251\n",
      "test loss:  7.266727924346924\n",
      "test r2:  -0.27261886589417084\n",
      "train loss:  1.741017460823059\n",
      "train r2:  0.8814449198703305\n",
      "test loss:  7.266563415527344\n",
      "test r2:  -0.2726839856738763\n",
      "train loss:  1.7409210205078125\n",
      "train r2:  0.8814325034502632\n",
      "test loss:  7.266086101531982\n",
      "test r2:  -0.2726186292111592\n",
      "train loss:  1.7408263683319092\n",
      "train r2:  0.8814492931442193\n",
      "test loss:  7.265799045562744\n",
      "test r2:  -0.27258714892051583\n",
      "train loss:  1.740733027458191\n",
      "train r2:  0.8814595202521003\n",
      "test loss:  7.26558256149292\n",
      "test r2:  -0.2726467923266602\n",
      "train loss:  1.740639328956604\n",
      "train r2:  0.8814479336917924\n",
      "test loss:  7.264970779418945\n",
      "test r2:  -0.2725028509677778\n",
      "train loss:  1.740544319152832\n",
      "train r2:  0.8814827009310137\n",
      "test loss:  7.264932632446289\n",
      "test r2:  -0.2726040614637617\n",
      "train loss:  1.7404484748840332\n",
      "train r2:  0.8814626762956702\n",
      "test loss:  7.264428615570068\n",
      "test r2:  -0.2725199201021984\n",
      "train loss:  1.740352749824524\n",
      "train r2:  0.8814838202257631\n",
      "test loss:  7.264074802398682\n",
      "test r2:  -0.2724879960990101\n",
      "train loss:  1.7402583360671997\n",
      "train r2:  0.8814934769249194\n",
      "test loss:  7.26392936706543\n",
      "test r2:  -0.27255152292286544\n",
      "train loss:  1.7401642799377441\n",
      "train r2:  0.8814816664661596\n",
      "test loss:  7.263320446014404\n",
      "test r2:  -0.27241760652877467\n",
      "train loss:  1.7400696277618408\n",
      "train r2:  0.8815140333706151\n",
      "test loss:  7.263209819793701\n",
      "test r2:  -0.27249559590166106\n",
      "train loss:  1.7399739027023315\n",
      "train r2:  0.8814990191366949\n",
      "test loss:  7.262789726257324\n",
      "test r2:  -0.2724309676839656\n",
      "train loss:  1.7398784160614014\n",
      "train r2:  0.8815161359095764\n",
      "test loss:  7.262397766113281\n",
      "test r2:  -0.2724017443388467\n",
      "train loss:  1.7397830486297607\n",
      "train r2:  0.8815248341316851\n",
      "test loss:  7.262201309204102\n",
      "test r2:  -0.27243262090941456\n",
      "train loss:  1.7396882772445679\n",
      "train r2:  0.8815205530121872\n",
      "test loss:  7.261727809906006\n",
      "test r2:  -0.2723517276052787\n",
      "train loss:  1.7395933866500854\n",
      "train r2:  0.8815411880407057\n",
      "test loss:  7.261471271514893\n",
      "test r2:  -0.27238277555074886\n",
      "train loss:  1.739498257637024\n",
      "train r2:  0.8815363028997721\n",
      "test loss:  7.261110305786133\n",
      "test r2:  -0.27233389131460695\n",
      "train loss:  1.7394027709960938\n",
      "train r2:  0.8815501232918623\n",
      "test loss:  7.260769367218018\n",
      "test r2:  -0.2723277194012832\n",
      "train loss:  1.7393072843551636\n",
      "train r2:  0.881553610094984\n",
      "test loss:  7.260447978973389\n",
      "test r2:  -0.27230883710352094\n",
      "train loss:  1.739211916923523\n",
      "train r2:  0.8815604266298154\n",
      "test loss:  7.260104656219482\n",
      "test r2:  -0.27228158926829016\n",
      "train loss:  1.7391165494918823\n",
      "train r2:  0.8815690729759337\n",
      "test loss:  7.259767532348633\n",
      "test r2:  -0.2722783213722393\n",
      "train loss:  1.7390213012695312\n",
      "train r2:  0.8815718651937011\n",
      "test loss:  7.259405612945557\n",
      "test r2:  -0.2722329910966603\n",
      "train loss:  1.738925814628601\n",
      "train r2:  0.8815848269172443\n",
      "test loss:  7.259132385253906\n",
      "test r2:  -0.2722500494494875\n",
      "train loss:  1.7388300895690918\n",
      "train r2:  0.8815832504662603\n",
      "test loss:  7.258716106414795\n",
      "test r2:  -0.2721953581742129\n",
      "train loss:  1.738734483718872\n",
      "train r2:  0.8815979887736124\n",
      "test loss:  7.25844144821167\n",
      "test r2:  -0.27220099461265357\n",
      "train loss:  1.7386387586593628\n",
      "train r2:  0.8815991536784946\n",
      "test loss:  7.258079528808594\n",
      "test r2:  -0.27217732838015585\n",
      "train loss:  1.738542914390564\n",
      "train r2:  0.8816067666311256\n",
      "test loss:  7.257711410522461\n",
      "test r2:  -0.27213995038586347\n",
      "train loss:  1.7384475469589233\n",
      "train r2:  0.8816177056729383\n",
      "test loss:  7.257449150085449\n",
      "test r2:  -0.27215724658506546\n",
      "train loss:  1.7383517026901245\n",
      "train r2:  0.8816161434579366\n",
      "test loss:  7.257019519805908\n",
      "test r2:  -0.27209743887022286\n",
      "train loss:  1.7382557392120361\n",
      "train r2:  0.8816320232652336\n",
      "test loss:  7.2567548751831055\n",
      "test r2:  -0.2721116439226876\n",
      "train loss:  1.7381597757339478\n",
      "train r2:  0.8816312118063582\n",
      "test loss:  7.256384372711182\n",
      "test r2:  -0.272076682774945\n",
      "train loss:  1.7380638122558594\n",
      "train r2:  0.8816415539837889\n",
      "test loss:  7.256030082702637\n",
      "test r2:  -0.27205406052184444\n",
      "train loss:  1.7379679679870605\n",
      "train r2:  0.8816489271310696\n",
      "test loss:  7.255739212036133\n",
      "test r2:  -0.27205386578545787\n",
      "train loss:  1.7378718852996826\n",
      "train r2:  0.8816514863962323\n",
      "test loss:  7.255347728729248\n",
      "test r2:  -0.2720109248453415\n",
      "train loss:  1.7377760410308838\n",
      "train r2:  0.8816635460022307\n",
      "test loss:  7.255050182342529\n",
      "test r2:  -0.272014443618257\n",
      "train loss:  1.7376799583435059\n",
      "train r2:  0.8816650967141012\n",
      "test loss:  7.254690647125244\n",
      "test r2:  -0.2719798816065777\n",
      "train loss:  1.737583875656128\n",
      "train r2:  0.8816754108313499\n",
      "test loss:  7.25435209274292\n",
      "test r2:  -0.2719694553756209\n",
      "train loss:  1.7374874353408813\n",
      "train r2:  0.8816799543352636\n",
      "test loss:  7.25401496887207\n",
      "test r2:  -0.271946655672731\n",
      "train loss:  1.7373913526535034\n",
      "train r2:  0.8816876169551766\n",
      "test loss:  7.253681659698486\n",
      "test r2:  -0.27193032309892295\n",
      "train loss:  1.7372949123382568\n",
      "train r2:  0.8816937100242737\n",
      "test loss:  7.253334045410156\n",
      "test r2:  -0.27191163467321755\n",
      "train loss:  1.7371985912322998\n",
      "train r2:  0.8817002355592507\n",
      "test loss:  7.252996921539307\n",
      "test r2:  -0.2718885931218187\n",
      "train loss:  1.7371023893356323\n",
      "train r2:  0.8817079342957579\n",
      "test loss:  7.252668380737305\n",
      "test r2:  -0.2718799214436265\n",
      "train loss:  1.7370060682296753\n",
      "train r2:  0.8817121940372535\n",
      "test loss:  7.25230073928833\n",
      "test r2:  -0.27184554715538267\n",
      "train loss:  1.7369093894958496\n",
      "train r2:  0.8817223930697433\n",
      "test loss:  7.25200080871582\n",
      "test r2:  -0.27184518065903696\n",
      "train loss:  1.736812949180603\n",
      "train r2:  0.8817248855097993\n",
      "test loss:  7.251623630523682\n",
      "test r2:  -0.2718108427709598\n",
      "train loss:  1.7367161512374878\n",
      "train r2:  0.8817349652771177\n",
      "test loss:  7.2513041496276855\n",
      "test r2:  -0.27180041540531397\n",
      "train loss:  1.7366197109222412\n",
      "train r2:  0.8817397377244964\n",
      "test loss:  7.2509660720825195\n",
      "test r2:  -0.27178319065874645\n",
      "train loss:  1.7365227937698364\n",
      "train r2:  0.8817460014260694\n",
      "test loss:  7.2505998611450195\n",
      "test r2:  -0.27175419082687347\n",
      "train loss:  1.7364262342453003\n",
      "train r2:  0.8817549116946903\n",
      "test loss:  7.250295639038086\n",
      "test r2:  -0.2717502756501602\n",
      "train loss:  1.7363296747207642\n",
      "train r2:  0.8817582054531437\n",
      "test loss:  7.24992561340332\n",
      "test r2:  -0.2717180988816901\n",
      "train loss:  1.7362326383590698\n",
      "train r2:  0.8817678589810386\n",
      "test loss:  7.249598503112793\n",
      "test r2:  -0.2717089213329369\n",
      "train loss:  1.7361358404159546\n",
      "train r2:  0.8817722553407411\n",
      "test loss:  7.249255180358887\n",
      "test r2:  -0.27168493552368744\n",
      "train loss:  1.7360389232635498\n",
      "train r2:  0.8817801496446127\n",
      "test loss:  7.2489118576049805\n",
      "test r2:  -0.2716690274259639\n",
      "train loss:  1.7359418869018555\n",
      "train r2:  0.8817860474633376\n",
      "test loss:  7.248570442199707\n",
      "test r2:  -0.2716489026478721\n",
      "train loss:  1.7358447313308716\n",
      "train r2:  0.8817930328323828\n",
      "test loss:  7.248231887817383\n",
      "test r2:  -0.27163148939546633\n",
      "train loss:  1.7357478141784668\n",
      "train r2:  0.8817993131105917\n",
      "test loss:  7.247885227203369\n",
      "test r2:  -0.2716124275956435\n",
      "train loss:  1.7356507778167725\n",
      "train r2:  0.8818059680664699\n",
      "test loss:  7.247546672821045\n",
      "test r2:  -0.2715925362890248\n",
      "train loss:  1.7355533838272095\n",
      "train r2:  0.881812911181616\n",
      "test loss:  7.247209072113037\n",
      "test r2:  -0.2715780767631\n",
      "train loss:  1.7354562282562256\n",
      "train r2:  0.8818185337791804\n",
      "test loss:  7.246853351593018\n",
      "test r2:  -0.2715524135845142\n",
      "train loss:  1.7353590726852417\n",
      "train r2:  0.8818267178699237\n",
      "test loss:  7.2465314865112305\n",
      "test r2:  -0.27154322369755457\n",
      "train loss:  1.7352616786956787\n",
      "train r2:  0.8818311494005411\n",
      "test loss:  7.246168613433838\n",
      "test r2:  -0.27151534662608356\n",
      "train loss:  1.7351641654968262\n",
      "train r2:  0.8818398498633411\n",
      "test loss:  7.245841979980469\n",
      "test r2:  -0.27150403485435826\n",
      "train loss:  1.7350668907165527\n",
      "train r2:  0.8818447826657596\n",
      "test loss:  7.245492458343506\n",
      "test r2:  -0.2714818032210091\n",
      "train loss:  1.734969139099121\n",
      "train r2:  0.8818521656806704\n",
      "test loss:  7.24514627456665\n",
      "test r2:  -0.2714630682648631\n",
      "train loss:  1.7348718643188477\n",
      "train r2:  0.881858788260853\n",
      "test loss:  7.244813919067383\n",
      "test r2:  -0.27144763842420483\n",
      "train loss:  1.734774112701416\n",
      "train r2:  0.8818646681479496\n",
      "test loss:  7.244460582733154\n",
      "test r2:  -0.27142564142569214\n",
      "train loss:  1.734676480293274\n",
      "train r2:  0.8818720031695411\n",
      "test loss:  7.244123458862305\n",
      "test r2:  -0.2714099826277385\n",
      "train loss:  1.7345788478851318\n",
      "train r2:  0.8818779205914529\n",
      "test loss:  7.243780136108398\n",
      "test r2:  -0.27138952695877605\n",
      "train loss:  1.7344810962677002\n",
      "train r2:  0.8818849419777015\n",
      "test loss:  7.243433952331543\n",
      "test r2:  -0.2713727975141862\n",
      "train loss:  1.734383225440979\n",
      "train r2:  0.881891051996311\n",
      "test loss:  7.243091106414795\n",
      "test r2:  -0.2713520705193795\n",
      "train loss:  1.734285593032837\n",
      "train r2:  0.8818981690685715\n",
      "test loss:  7.242753505706787\n",
      "test r2:  -0.2713374299798408\n",
      "train loss:  1.7341874837875366\n",
      "train r2:  0.8819038488597534\n",
      "test loss:  7.242400646209717\n",
      "test r2:  -0.27131431804495487\n",
      "train loss:  1.7340896129608154\n",
      "train r2:  0.8819114576015196\n",
      "test loss:  7.2420654296875\n",
      "test r2:  -0.27130048671070117\n",
      "train loss:  1.7339917421340942\n",
      "train r2:  0.8819169294878961\n",
      "test loss:  7.241713047027588\n",
      "test r2:  -0.2712783673828858\n",
      "train loss:  1.733893632888794\n",
      "train r2:  0.8819242953863037\n",
      "test loss:  7.2413740158081055\n",
      "test r2:  -0.27126200819918767\n",
      "train loss:  1.7337952852249146\n",
      "train r2:  0.8819304134507604\n",
      "test loss:  7.241031169891357\n",
      "test r2:  -0.2712439673286\n",
      "train loss:  1.7336971759796143\n",
      "train r2:  0.8819368817879981\n",
      "test loss:  7.240681171417236\n",
      "test r2:  -0.27122408695104316\n",
      "train loss:  1.7335989475250244\n",
      "train r2:  0.8819437360870813\n",
      "test loss:  7.240340709686279\n",
      "test r2:  -0.27120723330511876\n",
      "train loss:  1.7335004806518555\n",
      "train r2:  0.8819499038217269\n",
      "test loss:  7.239995002746582\n",
      "test r2:  -0.2711879127921135\n",
      "train loss:  1.7334022521972656\n",
      "train r2:  0.8819566601767664\n",
      "test loss:  7.239648342132568\n",
      "test r2:  -0.2711697469459813\n",
      "train loss:  1.7333036661148071\n",
      "train r2:  0.8819631153028737\n",
      "test loss:  7.239306926727295\n",
      "test r2:  -0.2711517970020765\n",
      "train loss:  1.7332054376602173\n",
      "train r2:  0.8819695969793077\n",
      "test loss:  7.238959789276123\n",
      "test r2:  -0.27113390521815006\n",
      "train loss:  1.7331068515777588\n",
      "train r2:  0.8819759940580622\n",
      "test loss:  7.238613605499268\n",
      "test r2:  -0.27111384348288614\n",
      "train loss:  1.7330081462860107\n",
      "train r2:  0.881982939355575\n",
      "test loss:  7.238273620605469\n",
      "test r2:  -0.27109884045732846\n",
      "train loss:  1.7329095602035522\n",
      "train r2:  0.8819886870021242\n",
      "test loss:  7.237918376922607\n",
      "test r2:  -0.27107619470346767\n",
      "train loss:  1.7328109741210938\n",
      "train r2:  0.8819961665667901\n",
      "test loss:  7.237584114074707\n",
      "test r2:  -0.27106268079947826\n",
      "train loss:  1.7327122688293457\n",
      "train r2:  0.8820016009328626\n",
      "test loss:  7.237227916717529\n",
      "test r2:  -0.2710399071657603\n",
      "train loss:  1.7326133251190186\n",
      "train r2:  0.8820091579673913\n",
      "test loss:  7.236889839172363\n",
      "test r2:  -0.2710258284897922\n",
      "train loss:  1.7325146198272705\n",
      "train r2:  0.8820146965528499\n",
      "test loss:  7.236538410186768\n",
      "test r2:  -0.27100409267046444\n",
      "train loss:  1.7324156761169434\n",
      "train r2:  0.8820220071978281\n",
      "test loss:  7.2361955642700195\n",
      "test r2:  -0.2709888641449312\n",
      "train loss:  1.7323166131973267\n",
      "train r2:  0.8820277934245068\n",
      "test loss:  7.235846042633057\n",
      "test r2:  -0.27096772053493523\n",
      "train loss:  1.73221755027771\n",
      "train r2:  0.8820349959572916\n",
      "test loss:  7.235504627227783\n",
      "test r2:  -0.2709531033773631\n",
      "train loss:  1.7321187257766724\n",
      "train r2:  0.8820406484014787\n",
      "test loss:  7.235151290893555\n",
      "test r2:  -0.27093086484985673\n",
      "train loss:  1.732019305229187\n",
      "train r2:  0.882048053925714\n",
      "test loss:  7.234811782836914\n",
      "test r2:  -0.27091676277963317\n",
      "train loss:  1.7319203615188599\n",
      "train r2:  0.8820536284618201\n",
      "test loss:  7.234458923339844\n",
      "test r2:  -0.27089504546761534\n",
      "train loss:  1.7318209409713745\n",
      "train r2:  0.8820609371017597\n",
      "test loss:  7.234115123748779\n",
      "test r2:  -0.2708800185931075\n",
      "train loss:  1.7317216396331787\n",
      "train r2:  0.8820666907600507\n",
      "test loss:  7.233767986297607\n",
      "test r2:  -0.2708589943589459\n",
      "train loss:  1.7316222190856934\n",
      "train r2:  0.8820738621141276\n",
      "test loss:  7.233421325683594\n",
      "test r2:  -0.27084418745843775\n",
      "train loss:  1.731522798538208\n",
      "train r2:  0.8820795424510868\n",
      "test loss:  7.233068466186523\n",
      "test r2:  -0.2708215459115284\n",
      "train loss:  1.7314233779907227\n",
      "train r2:  0.8820870737270514\n",
      "test loss:  7.232729911804199\n",
      "test r2:  -0.2708097592581302\n",
      "train loss:  1.7313237190246582\n",
      "train r2:  0.8820920911833515\n",
      "test loss:  7.2323713302612305\n",
      "test r2:  -0.27078353645258124\n",
      "train loss:  1.7312240600585938\n",
      "train r2:  0.8821004680673488\n",
      "test loss:  7.232038497924805\n",
      "test r2:  -0.2707757538625968\n",
      "train loss:  1.7311244010925293\n",
      "train r2:  0.8821045396600772\n",
      "test loss:  7.2316694259643555\n",
      "test r2:  -0.2707450866728671\n",
      "train loss:  1.7310246229171753\n",
      "train r2:  0.8821139284656725\n",
      "test loss:  7.231348991394043\n",
      "test r2:  -0.27074244184395324\n",
      "train loss:  1.7309247255325317\n",
      "train r2:  0.8821168589888533\n",
      "test loss:  7.230968952178955\n",
      "test r2:  -0.2707058555553379\n",
      "train loss:  1.7308249473571777\n",
      "train r2:  0.8821276017562787\n",
      "test loss:  7.230655193328857\n",
      "test r2:  -0.2707101959987315\n",
      "train loss:  1.7307249307632446\n",
      "train r2:  0.8821288688491546\n",
      "test loss:  7.2302656173706055\n",
      "test r2:  -0.27066527537044993\n",
      "train loss:  1.7306251525878906\n",
      "train r2:  0.8821415748087826\n",
      "test loss:  7.229966640472412\n",
      "test r2:  -0.27068017665086397\n",
      "train loss:  1.730525255203247\n",
      "train r2:  0.8821403712014505\n",
      "test loss:  7.229555130004883\n",
      "test r2:  -0.2706207903603255\n",
      "train loss:  1.7304253578186035\n",
      "train r2:  0.8821564261780037\n",
      "test loss:  7.229286193847656\n",
      "test r2:  -0.27065607910956957\n",
      "train loss:  1.7303258180618286\n",
      "train r2:  0.8821505445262443\n",
      "test loss:  7.2288312911987305\n",
      "test r2:  -0.27056895780488466\n",
      "train loss:  1.7302262783050537\n",
      "train r2:  0.882172995882288\n",
      "test loss:  7.2286224365234375\n",
      "test r2:  -0.2706412657655026\n",
      "train loss:  1.7301276922225952\n",
      "train r2:  0.8821585115924221\n",
      "test loss:  7.228090286254883\n",
      "test r2:  -0.2705059259839735\n",
      "train loss:  1.730029582977295\n",
      "train r2:  0.8821921229296368\n",
      "test loss:  7.2279744148254395\n",
      "test r2:  -0.27064053512001984\n",
      "train loss:  1.7299336194992065\n",
      "train r2:  0.8821631618069574\n",
      "test loss:  7.227322101593018\n",
      "test r2:  -0.27042389781881737\n",
      "train loss:  1.7298409938812256\n",
      "train r2:  0.8822155875406986\n",
      "test loss:  7.227367877960205\n",
      "test r2:  -0.2706667378985135\n",
      "train loss:  1.7297546863555908\n",
      "train r2:  0.882161368976705\n",
      "test loss:  7.226494312286377\n",
      "test r2:  -0.27030459711990185\n",
      "train loss:  1.7296780347824097\n",
      "train r2:  0.8822472677620679\n",
      "test loss:  7.226835250854492\n",
      "test r2:  -0.27074336034395463\n",
      "train loss:  1.7296222448349\n",
      "train r2:  0.8821471873818558\n",
      "test loss:  7.225555419921875\n",
      "test r2:  -0.27011805224135577\n",
      "train loss:  1.7295897006988525\n",
      "train r2:  0.8822934989258268\n",
      "test loss:  7.226442337036133\n",
      "test r2:  -0.2709046198584757\n",
      "train loss:  1.7296156883239746\n",
      "train r2:  0.8821117753809701\n",
      "test loss:  7.224426746368408\n",
      "test r2:  -0.26983356521757185\n",
      "train loss:  1.7296594381332397\n",
      "train r2:  0.8823599463273532\n",
      "test loss:  7.226240634918213\n",
      "test r2:  -0.27115886263248346\n",
      "train loss:  1.729785442352295\n",
      "train r2:  0.8820525995709041\n",
      "test loss:  7.223092555999756\n",
      "test r2:  -0.2695014061045031\n",
      "train loss:  1.7297357320785522\n",
      "train r2:  0.8824361399925608\n",
      "test loss:  7.22609281539917\n",
      "test r2:  -0.27133509298753933\n",
      "train loss:  1.7296142578125\n",
      "train r2:  0.8820172506663827\n",
      "test loss:  7.222050666809082\n",
      "test r2:  -0.2694705627962979\n",
      "train loss:  1.729177713394165\n",
      "train r2:  0.8824489357754977\n",
      "test loss:  7.225074768066406\n",
      "test r2:  -0.27093850970826217\n",
      "train loss:  1.7287945747375488\n",
      "train r2:  0.8821243541111953\n",
      "test loss:  7.2226057052612305\n",
      "test r2:  -0.2701834136442711\n",
      "train loss:  1.7286187410354614\n",
      "train r2:  0.8822931294951079\n",
      "test loss:  7.222198486328125\n",
      "test r2:  -0.26989734925944164\n",
      "train loss:  1.7286590337753296\n",
      "train r2:  0.8823639523163276\n",
      "test loss:  7.224249362945557\n",
      "test r2:  -0.27110439293697786\n",
      "train loss:  1.7287414073944092\n",
      "train r2:  0.8820879959967427\n",
      "test loss:  7.219932556152344\n",
      "test r2:  -0.26930144415149115\n",
      "train loss:  1.7286230325698853\n",
      "train r2:  0.8824974945251901\n",
      "test loss:  7.223618030548096\n",
      "test r2:  -0.2710123464349248\n",
      "train loss:  1.7283724546432495\n",
      "train r2:  0.8821178003425866\n",
      "test loss:  7.220787048339844\n",
      "test r2:  -0.2699523512100992\n",
      "train loss:  1.7281204462051392\n",
      "train r2:  0.8823602663128409\n",
      "test loss:  7.220495223999023\n",
      "test r2:  -0.26993439411806364\n",
      "train loss:  1.7280290126800537\n",
      "train r2:  0.8823672779216559\n",
      "test loss:  7.222314357757568\n",
      "test r2:  -0.2708659894420118\n",
      "train loss:  1.728042483329773\n",
      "train r2:  0.8821583502919874\n",
      "test loss:  7.218698501586914\n",
      "test r2:  -0.26942024158922084\n",
      "train loss:  1.7279870510101318\n",
      "train r2:  0.8824859979458043\n",
      "test loss:  7.2212748527526855\n",
      "test r2:  -0.27070474015198065\n",
      "train loss:  1.7278234958648682\n",
      "train r2:  0.8821997618449864\n",
      "test loss:  7.219628810882568\n",
      "test r2:  -0.2700147839439069\n",
      "train loss:  1.7276182174682617\n",
      "train r2:  0.8823617891146166\n",
      "test loss:  7.218681335449219\n",
      "test r2:  -0.26987191799981214\n",
      "train loss:  1.72749924659729\n",
      "train r2:  0.8823932783828667\n",
      "test loss:  7.220119953155518\n",
      "test r2:  -0.27057518512543965\n",
      "train loss:  1.7274600267410278\n",
      "train r2:  0.8822380636961594\n",
      "test loss:  7.217837333679199\n",
      "test r2:  -0.269634118532148\n",
      "train loss:  1.7273980379104614\n",
      "train r2:  0.8824541867108538\n",
      "test loss:  7.218839645385742\n",
      "test r2:  -0.2703785669369785\n",
      "train loss:  1.727268099784851\n",
      "train r2:  0.8822851757671664\n",
      "test loss:  7.218055725097656\n",
      "test r2:  -0.26999200188809325\n",
      "train loss:  1.7271023988723755\n",
      "train r2:  0.8823799974487138\n",
      "test loss:  7.217341423034668\n",
      "test r2:  -0.2699189935212485\n",
      "train loss:  1.7269822359085083\n",
      "train r2:  0.8823965902984535\n",
      "test loss:  7.217724323272705\n",
      "test r2:  -0.27025462153417035\n",
      "train loss:  1.7269145250320435\n",
      "train r2:  0.8823222297985854\n",
      "test loss:  7.216583728790283\n",
      "test r2:  -0.2697479241167009\n",
      "train loss:  1.7268400192260742\n",
      "train r2:  0.8824419847819676\n",
      "test loss:  7.216920375823975\n",
      "test r2:  -0.2702161495071791\n",
      "train loss:  1.7267237901687622\n",
      "train r2:  0.8823345147196865\n",
      "test loss:  7.216026782989502\n",
      "test r2:  -0.26983769804155777\n",
      "train loss:  1.7265830039978027\n",
      "train r2:  0.8824258587341963\n",
      "test loss:  7.216003894805908\n",
      "test r2:  -0.2699726627858514\n",
      "train loss:  1.7264667749404907\n",
      "train r2:  0.8823978255263378\n",
      "test loss:  7.2156081199646\n",
      "test r2:  -0.2700434647602279\n",
      "train loss:  1.726383090019226\n",
      "train r2:  0.8823813184926299\n",
      "test loss:  7.214822292327881\n",
      "test r2:  -0.2697046961125633\n",
      "train loss:  1.726298213005066\n",
      "train r2:  0.8824631594781875\n",
      "test loss:  7.215334892272949\n",
      "test r2:  -0.2701564362910365\n",
      "train loss:  1.7261890172958374\n",
      "train r2:  0.8823616745222161\n",
      "test loss:  7.214023113250732\n",
      "test r2:  -0.26969408047457133\n",
      "train loss:  1.7260633707046509\n",
      "train r2:  0.8824693248665425\n",
      "test loss:  7.214296340942383\n",
      "test r2:  -0.2699241033001516\n",
      "train loss:  1.725949764251709\n",
      "train r2:  0.882420643989618\n",
      "test loss:  7.213888645172119\n",
      "test r2:  -0.26995087554913755\n",
      "train loss:  1.725856065750122\n",
      "train r2:  0.8824152999809158\n",
      "test loss:  7.21293306350708\n",
      "test r2:  -0.26960813022215957\n",
      "train loss:  1.7257646322250366\n",
      "train r2:  0.8824965010941089\n",
      "test loss:  7.213615417480469\n",
      "test r2:  -0.2700686981415703\n",
      "train loss:  1.7256594896316528\n",
      "train r2:  0.8823946061665423\n",
      "test loss:  7.212287425994873\n",
      "test r2:  -0.2696290384763611\n",
      "train loss:  1.7255427837371826\n",
      "train r2:  0.882496315702251\n",
      "test loss:  7.212399005889893\n",
      "test r2:  -0.26980784417804093\n",
      "train loss:  1.7254307270050049\n",
      "train r2:  0.8824588125729427\n",
      "test loss:  7.212234020233154\n",
      "test r2:  -0.2698776380037946\n",
      "train loss:  1.7253309488296509\n",
      "train r2:  0.8824454580838786\n",
      "test loss:  7.2111711502075195\n",
      "test r2:  -0.26954854527502703\n",
      "train loss:  1.725234866142273\n",
      "train r2:  0.8825221103870727\n",
      "test loss:  7.211688041687012\n",
      "test r2:  -0.269922431579682\n",
      "train loss:  1.7251315116882324\n",
      "train r2:  0.8824400966400164\n",
      "test loss:  7.210708141326904\n",
      "test r2:  -0.2696046565254804\n",
      "train loss:  1.725020408630371\n",
      "train r2:  0.8825151134239693\n",
      "test loss:  7.210522174835205\n",
      "test r2:  -0.26969742280130315\n",
      "train loss:  1.7249101400375366\n",
      "train r2:  0.8824959195521754\n",
      "test loss:  7.210416793823242\n",
      "test r2:  -0.2697642546136596\n",
      "train loss:  1.7248061895370483\n",
      "train r2:  0.882484001593311\n",
      "test loss:  7.209559440612793\n",
      "test r2:  -0.2695340072589385\n",
      "train loss:  1.7247059345245361\n",
      "train r2:  0.8825381843859741\n",
      "test loss:  7.209702014923096\n",
      "test r2:  -0.2697597209249507\n",
      "train loss:  1.724603533744812\n",
      "train r2:  0.8824892553190196\n",
      "test loss:  7.209054470062256\n",
      "test r2:  -0.26956133432577256\n",
      "train loss:  1.7244956493377686\n",
      "train r2:  0.8825378662043409\n",
      "test loss:  7.20875358581543\n",
      "test r2:  -0.2696258695768028\n",
      "train loss:  1.7243865728378296\n",
      "train r2:  0.8825244622502297\n",
      "test loss:  7.208468914031982\n",
      "test r2:  -0.2696172620884165\n",
      "train loss:  1.7242803573608398\n",
      "train r2:  0.8825295287673864\n",
      "test loss:  7.207971096038818\n",
      "test r2:  -0.2695242479670281\n",
      "train loss:  1.7241772413253784\n",
      "train r2:  0.8825533710838772\n",
      "test loss:  7.20777702331543\n",
      "test r2:  -0.26962218399641547\n",
      "train loss:  1.724073886871338\n",
      "train r2:  0.8825327404794068\n",
      "test loss:  7.207252502441406\n",
      "test r2:  -0.2694810416489679\n",
      "train loss:  1.7239681482315063\n",
      "train r2:  0.8825683632405565\n",
      "test loss:  7.207059860229492\n",
      "test r2:  -0.2695760637888789\n",
      "train loss:  1.7238601446151733\n",
      "train r2:  0.8825485189528334\n",
      "test loss:  7.206533908843994\n",
      "test r2:  -0.2694787569711534\n",
      "train loss:  1.723752737045288\n",
      "train r2:  0.8825732155242572\n",
      "test loss:  7.206270217895508\n",
      "test r2:  -0.2694834877557466\n",
      "train loss:  1.7236473560333252\n",
      "train r2:  0.882575148693684\n",
      "test loss:  7.205949783325195\n",
      "test r2:  -0.26951770358488014\n",
      "train loss:  1.7235428094863892\n",
      "train r2:  0.8825691459268205\n",
      "test loss:  7.205400466918945\n",
      "test r2:  -0.269388093843391\n",
      "train loss:  1.7234373092651367\n",
      "train r2:  0.8826016565271422\n",
      "test loss:  7.205331802368164\n",
      "test r2:  -0.269512961391952\n",
      "train loss:  1.7233303785324097\n",
      "train r2:  0.8825757501644126\n",
      "test loss:  7.204683303833008\n",
      "test r2:  -0.2693723500420768\n",
      "train loss:  1.7232224941253662\n",
      "train r2:  0.8826099642016946\n",
      "test loss:  7.204471111297607\n",
      "test r2:  -0.2694131784739726\n",
      "train loss:  1.7231154441833496\n",
      "train r2:  0.8826035193832014\n",
      "test loss:  7.204159259796143\n",
      "test r2:  -0.2694238217950986\n",
      "train loss:  1.7230093479156494\n",
      "train r2:  0.8826035135524031\n",
      "test loss:  7.2035908699035645\n",
      "test r2:  -0.26931118806570353\n",
      "train loss:  1.7229031324386597\n",
      "train r2:  0.8826316452532543\n",
      "test loss:  7.20350456237793\n",
      "test r2:  -0.26941977161497555\n",
      "train loss:  1.7227964401245117\n",
      "train r2:  0.8826096511004603\n",
      "test loss:  7.202905178070068\n",
      "test r2:  -0.2692931391990405\n",
      "train loss:  1.722688913345337\n",
      "train r2:  0.882640933276027\n",
      "test loss:  7.20265007019043\n",
      "test r2:  -0.26933396953573907\n",
      "train loss:  1.7225806713104248\n",
      "train r2:  0.8826340683889692\n",
      "test loss:  7.202323913574219\n",
      "test r2:  -0.26932131704911266\n",
      "train loss:  1.7224735021591187\n",
      "train r2:  0.8826398418730637\n",
      "test loss:  7.201834201812744\n",
      "test r2:  -0.2692542412745307\n",
      "train loss:  1.7223659753799438\n",
      "train r2:  0.8826574693742147\n",
      "test loss:  7.201623439788818\n",
      "test r2:  -0.2693093812885716\n",
      "train loss:  1.7222589254379272\n",
      "train r2:  0.8826475073410417\n",
      "test loss:  7.201132297515869\n",
      "test r2:  -0.2692228418990905\n",
      "train loss:  1.7221509218215942\n",
      "train r2:  0.8826699936912412\n",
      "test loss:  7.200839042663574\n",
      "test r2:  -0.26925614713827484\n",
      "train loss:  1.7220426797866821\n",
      "train r2:  0.8826646375053098\n",
      "test loss:  7.20045280456543\n",
      "test r2:  -0.2692138772171695\n",
      "train loss:  1.721934199333191\n",
      "train r2:  0.8826772001765538\n",
      "test loss:  7.2000837326049805\n",
      "test r2:  -0.269201314125191\n",
      "train loss:  1.7218257188796997\n",
      "train r2:  0.8826825046588075\n",
      "test loss:  7.199737071990967\n",
      "test r2:  -0.26919826438436023\n",
      "train loss:  1.721717357635498\n",
      "train r2:  0.8826857465289679\n",
      "test loss:  7.199337482452393\n",
      "test r2:  -0.2691532828638348\n",
      "train loss:  1.7216092348098755\n",
      "train r2:  0.8826988506605971\n",
      "test loss:  7.199019908905029\n",
      "test r2:  -0.2691745300541388\n",
      "train loss:  1.721500277519226\n",
      "train r2:  0.8826962648651417\n",
      "test loss:  7.198584079742432\n",
      "test r2:  -0.26911481018552363\n",
      "train loss:  1.7213913202285767\n",
      "train r2:  0.8827127358351423\n",
      "test loss:  7.198301315307617\n",
      "test r2:  -0.2691391439428459\n",
      "train loss:  1.7212817668914795\n",
      "train r2:  0.882709810672625\n",
      "test loss:  7.197865009307861\n",
      "test r2:  -0.2690951139593851\n",
      "train loss:  1.7211722135543823\n",
      "train r2:  0.8827223714932051\n",
      "test loss:  7.1975202560424805\n",
      "test r2:  -0.26908237171763205\n",
      "train loss:  1.7210627794265747\n",
      "train r2:  0.882728094126912\n",
      "test loss:  7.197187423706055\n",
      "test r2:  -0.2690875709894953\n",
      "train loss:  1.720953106880188\n",
      "train r2:  0.8827294443264053\n",
      "test loss:  7.196732997894287\n",
      "test r2:  -0.2690290214112323\n",
      "train loss:  1.7208431959152222\n",
      "train r2:  0.8827454769651281\n",
      "test loss:  7.196473598480225\n",
      "test r2:  -0.2690619522563078\n",
      "train loss:  1.7207332849502563\n",
      "train r2:  0.882740718189288\n",
      "test loss:  7.196014881134033\n",
      "test r2:  -0.2690046034575304\n",
      "train loss:  1.7206226587295532\n",
      "train r2:  0.8827564228853629\n",
      "test loss:  7.195684909820557\n",
      "test r2:  -0.26900867546710305\n",
      "train loss:  1.72051203250885\n",
      "train r2:  0.8827581791980934\n",
      "test loss:  7.195324897766113\n",
      "test r2:  -0.2689936470769456\n",
      "train loss:  1.7204011678695679\n",
      "train r2:  0.8827643929234045\n",
      "test loss:  7.194908618927002\n",
      "test r2:  -0.268958263296476\n",
      "train loss:  1.7202900648117065\n",
      "train r2:  0.8827751082255645\n",
      "test loss:  7.1946001052856445\n",
      "test r2:  -0.26896992640395534\n",
      "train loss:  1.7201790809631348\n",
      "train r2:  0.8827752270650755\n",
      "test loss:  7.194175720214844\n",
      "test r2:  -0.2689256846432915\n",
      "train loss:  1.7200677394866943\n",
      "train r2:  0.8827880579120935\n",
      "test loss:  7.1938323974609375\n",
      "test r2:  -0.2689300809609003\n",
      "train loss:  1.7199561595916748\n",
      "train r2:  0.8827896412918934\n",
      "test loss:  7.193447589874268\n",
      "test r2:  -0.2689000242911872\n",
      "train loss:  1.719844102859497\n",
      "train r2:  0.882799434381578\n",
      "test loss:  7.193081855773926\n",
      "test r2:  -0.2688911700714427\n",
      "train loss:  1.7197319269180298\n",
      "train r2:  0.8828041051338061\n",
      "test loss:  7.192703723907471\n",
      "test r2:  -0.26887262451413907\n",
      "train loss:  1.7196197509765625\n",
      "train r2:  0.8828110999099561\n",
      "test loss:  7.192329406738281\n",
      "test r2:  -0.2688529803689954\n",
      "train loss:  1.719506859779358\n",
      "train r2:  0.8828184891493956\n",
      "test loss:  7.191963195800781\n",
      "test r2:  -0.26884544324459725\n",
      "train loss:  1.719394326210022\n",
      "train r2:  0.8828228695860382\n",
      "test loss:  7.191566467285156\n",
      "test r2:  -0.26881420757569185\n",
      "train loss:  1.7192813158035278\n",
      "train r2:  0.8828329246240243\n",
      "test loss:  7.191225051879883\n",
      "test r2:  -0.26881707122343457\n",
      "train loss:  1.7191678285598755\n",
      "train r2:  0.8828350211003263\n",
      "test loss:  7.190807819366455\n",
      "test r2:  -0.26878107326081113\n",
      "train loss:  1.7190539836883545\n",
      "train r2:  0.8828460727957661\n",
      "test loss:  7.190465927124023\n",
      "test r2:  -0.26878022162962867\n",
      "train loss:  1.7189401388168335\n",
      "train r2:  0.8828491411080585\n",
      "test loss:  7.190069675445557\n",
      "test r2:  -0.26875659604521274\n",
      "train loss:  1.7188259363174438\n",
      "train r2:  0.8828573876638821\n",
      "test loss:  7.1896867752075195\n",
      "test r2:  -0.2687375360273021\n",
      "train loss:  1.718711495399475\n",
      "train r2:  0.8828646151604612\n",
      "test loss:  7.189332485198975\n",
      "test r2:  -0.2687325252612771\n",
      "train loss:  1.7185964584350586\n",
      "train r2:  0.8828686723799992\n",
      "test loss:  7.188918590545654\n",
      "test r2:  -0.2687006509345262\n",
      "train loss:  1.718481421470642\n",
      "train r2:  0.8828788145769386\n",
      "test loss:  7.188568592071533\n",
      "test r2:  -0.26870003229554373\n",
      "train loss:  1.7183659076690674\n",
      "train r2:  0.8828819079598714\n",
      "test loss:  7.188166618347168\n",
      "test r2:  -0.2686715812721734\n",
      "train loss:  1.7182501554489136\n",
      "train r2:  0.8828914065533661\n",
      "test loss:  7.187794208526611\n",
      "test r2:  -0.26866272968228566\n",
      "train loss:  1.7181341648101807\n",
      "train r2:  0.8828963244947\n",
      "test loss:  7.187410354614258\n",
      "test r2:  -0.2686437095341503\n",
      "train loss:  1.7180174589157104\n",
      "train r2:  0.8829036824882551\n",
      "test loss:  7.1870222091674805\n",
      "test r2:  -0.2686270595014033\n",
      "train loss:  1.7179008722305298\n",
      "train r2:  0.8829104279872315\n",
      "test loss:  7.186642169952393\n",
      "test r2:  -0.26861331833600754\n",
      "train loss:  1.7177836894989014\n",
      "train r2:  0.8829165742662327\n",
      "test loss:  7.186253547668457\n",
      "test r2:  -0.2685936089114289\n",
      "train loss:  1.7176660299301147\n",
      "train r2:  0.8829241590968181\n",
      "test loss:  7.185868740081787\n",
      "test r2:  -0.26858178569401003\n",
      "train loss:  1.7175480127334595\n",
      "train r2:  0.8829298107760202\n",
      "test loss:  7.185476303100586\n",
      "test r2:  -0.268560030376056\n",
      "train loss:  1.7174296379089355\n",
      "train r2:  0.8829379457897645\n",
      "test loss:  7.1850996017456055\n",
      "test r2:  -0.26855139593368627\n",
      "train loss:  1.7173107862472534\n",
      "train r2:  0.8829429696821623\n",
      "test loss:  7.1846923828125\n",
      "test r2:  -0.2685270234945303\n",
      "train loss:  1.7171918153762817\n",
      "train r2:  0.8829516567124387\n",
      "test loss:  7.184318542480469\n",
      "test r2:  -0.26851797933112853\n",
      "train loss:  1.7170721292495728\n",
      "train r2:  0.882956867420998\n",
      "test loss:  7.183916091918945\n",
      "test r2:  -0.2684980352553281\n",
      "train loss:  1.7169520854949951\n",
      "train r2:  0.8829645725605462\n",
      "test loss:  7.1835222244262695\n",
      "test r2:  -0.268481624883639\n",
      "train loss:  1.7168316841125488\n",
      "train r2:  0.8829714521039101\n",
      "test loss:  7.183138847351074\n",
      "test r2:  -0.26846969399775444\n",
      "train loss:  1.7167106866836548\n",
      "train r2:  0.8829774189914015\n",
      "test loss:  7.182728290557861\n",
      "test r2:  -0.2684475284262431\n",
      "train loss:  1.716589331626892\n",
      "train r2:  0.8829856961777198\n",
      "test loss:  7.182343006134033\n",
      "test r2:  -0.26843760704176\n",
      "train loss:  1.716467261314392\n",
      "train r2:  0.8829911880434114\n",
      "test loss:  7.181938171386719\n",
      "test r2:  -0.26841675796343156\n",
      "train loss:  1.716344952583313\n",
      "train r2:  0.8829992252608041\n",
      "test loss:  7.181539535522461\n",
      "test r2:  -0.2684034840645937\n",
      "train loss:  1.716221570968628\n",
      "train r2:  0.8830055225564913\n",
      "test loss:  7.181141376495361\n",
      "test r2:  -0.2683863443336758\n",
      "train loss:  1.7160981893539429\n",
      "train r2:  0.8830128298123032\n",
      "test loss:  7.180736064910889\n",
      "test r2:  -0.2683715243699072\n",
      "train loss:  1.7159740924835205\n",
      "train r2:  0.8830195412864061\n",
      "test loss:  7.180327892303467\n",
      "test r2:  -0.26835325484515415\n",
      "train loss:  1.7158493995666504\n",
      "train r2:  0.8830270939008817\n",
      "test loss:  7.179931163787842\n",
      "test r2:  -0.26834058170063413\n",
      "train loss:  1.715724229812622\n",
      "train r2:  0.8830334351605073\n",
      "test loss:  7.179512023925781\n",
      "test r2:  -0.268321352220817\n",
      "train loss:  1.7155983448028564\n",
      "train r2:  0.8830412579472573\n",
      "test loss:  7.1791090965271\n",
      "test r2:  -0.268307157872115\n",
      "train loss:  1.7154717445373535\n",
      "train r2:  0.8830479919429997\n",
      "test loss:  7.178697109222412\n",
      "test r2:  -0.2682921876296471\n",
      "train loss:  1.7153444290161133\n",
      "train r2:  0.8830549322581647\n",
      "test loss:  7.178274631500244\n",
      "test r2:  -0.2682724300197026\n",
      "train loss:  1.7152163982391357\n",
      "train r2:  0.8830629810097411\n",
      "test loss:  7.177872180938721\n",
      "test r2:  -0.26826164682051035\n",
      "train loss:  1.715087890625\n",
      "train r2:  0.8830690652243478\n",
      "test loss:  7.17744255065918\n",
      "test r2:  -0.2682412133168981\n",
      "train loss:  1.714958667755127\n",
      "train r2:  0.8830773106820202\n",
      "test loss:  7.177024841308594\n",
      "test r2:  -0.26822745568827133\n",
      "train loss:  1.7148284912109375\n",
      "train r2:  0.8830841039779364\n",
      "test loss:  7.176605701446533\n",
      "test r2:  -0.2682114649753595\n",
      "train loss:  1.7146975994110107\n",
      "train r2:  0.8830915151659269\n",
      "test loss:  7.176173686981201\n",
      "test r2:  -0.26819469981469335\n",
      "train loss:  1.7145657539367676\n",
      "train r2:  0.8830990426815073\n",
      "test loss:  7.175747394561768\n",
      "test r2:  -0.2681788323978227\n",
      "train loss:  1.714432954788208\n",
      "train r2:  0.8831064358338084\n",
      "test loss:  7.175320148468018\n",
      "test r2:  -0.2681640888268868\n",
      "train loss:  1.7142996788024902\n",
      "train r2:  0.8831136478301777\n",
      "test loss:  7.17487907409668\n",
      "test r2:  -0.26814566659429895\n",
      "train loss:  1.714165210723877\n",
      "train r2:  0.8831217044881886\n",
      "test loss:  7.174447536468506\n",
      "test r2:  -0.2681324608218594\n",
      "train loss:  1.7140296697616577\n",
      "train r2:  0.8831286391866684\n",
      "test loss:  7.173999309539795\n",
      "test r2:  -0.2681140679928724\n",
      "train loss:  1.7138935327529907\n",
      "train r2:  0.8831367775848081\n",
      "test loss:  7.173559188842773\n",
      "test r2:  -0.26809899074554755\n",
      "train loss:  1.7137564420700073\n",
      "train r2:  0.8831442434171848\n",
      "test loss:  7.173112869262695\n",
      "test r2:  -0.2680837558338045\n",
      "train loss:  1.7136176824569702\n",
      "train r2:  0.8831518097319381\n",
      "test loss:  7.172653675079346\n",
      "test r2:  -0.2680656716443146\n",
      "train loss:  1.7134782075881958\n",
      "train r2:  0.8831599909662593\n",
      "test loss:  7.172203063964844\n",
      "test r2:  -0.2680512360656526\n",
      "train loss:  1.7133375406265259\n",
      "train r2:  0.8831674717232909\n",
      "test loss:  7.1717424392700195\n",
      "test r2:  -0.26803443748286604\n",
      "train loss:  1.7131959199905396\n",
      "train r2:  0.8831755514638904\n",
      "test loss:  7.171276569366455\n",
      "test r2:  -0.26801805771091236\n",
      "train loss:  1.7130528688430786\n",
      "train r2:  0.8831835463564279\n",
      "test loss:  7.170806407928467\n",
      "test r2:  -0.2680020613860008\n",
      "train loss:  1.7129086256027222\n",
      "train r2:  0.883191542041448\n",
      "test loss:  7.170333385467529\n",
      "test r2:  -0.267986238443203\n",
      "train loss:  1.7127629518508911\n",
      "train r2:  0.8831995568488099\n",
      "test loss:  7.1698503494262695\n",
      "test r2:  -0.26796854088361965\n",
      "train loss:  1.712615966796875\n",
      "train r2:  0.8832080499151537\n",
      "test loss:  7.169368267059326\n",
      "test r2:  -0.26795394180324017\n",
      "train loss:  1.7124675512313843\n",
      "train r2:  0.8832158671834246\n",
      "test loss:  7.16887092590332\n",
      "test r2:  -0.2679356317246213\n",
      "train loss:  1.7123174667358398\n",
      "train r2:  0.8832246286505865\n",
      "test loss:  7.1683759689331055\n",
      "test r2:  -0.26792021980959113\n",
      "train loss:  1.7121661901474\n",
      "train r2:  0.8832328134159336\n",
      "test loss:  7.167873859405518\n",
      "test r2:  -0.267903493134134\n",
      "train loss:  1.712012767791748\n",
      "train r2:  0.8832413749612208\n",
      "test loss:  7.167357921600342\n",
      "test r2:  -0.2678865140907407\n",
      "train loss:  1.7118582725524902\n",
      "train r2:  0.8832500103296475\n",
      "test loss:  7.166839122772217\n",
      "test r2:  -0.26786933172091487\n",
      "train loss:  1.7117016315460205\n",
      "train r2:  0.8832587737012557\n",
      "test loss:  7.166315078735352\n",
      "test r2:  -0.267853771489337\n",
      "train loss:  1.7115435600280762\n",
      "train r2:  0.8832672772834611\n",
      "test loss:  7.165776252746582\n",
      "test r2:  -0.267834625325184\n",
      "train loss:  1.7113834619522095\n",
      "train r2:  0.8832766727555453\n",
      "test loss:  7.165236949920654\n",
      "test r2:  -0.2678200300462177\n",
      "train loss:  1.7112213373184204\n",
      "train r2:  0.8832850920887038\n",
      "test loss:  7.164677619934082\n",
      "test r2:  -0.2678002135594333\n",
      "train loss:  1.7110573053359985\n",
      "train r2:  0.8832947972173213\n",
      "test loss:  7.164121627807617\n",
      "test r2:  -0.267785340466004\n",
      "train loss:  1.7108910083770752\n",
      "train r2:  0.8833034601217241\n",
      "test loss:  7.163544178009033\n",
      "test r2:  -0.26776548412992596\n",
      "train loss:  1.7107226848602295\n",
      "train r2:  0.8833133382002378\n",
      "test loss:  7.162963390350342\n",
      "test r2:  -0.2677498260078701\n",
      "train loss:  1.7105520963668823\n",
      "train r2:  0.8833222987244154\n",
      "test loss:  7.162365436553955\n",
      "test r2:  -0.2677294994640549\n",
      "train loss:  1.7103791236877441\n",
      "train r2:  0.8833324969992108\n",
      "test loss:  7.1617631912231445\n",
      "test r2:  -0.2677149886108636\n",
      "train loss:  1.710204005241394\n",
      "train r2:  0.8833414011816201\n",
      "test loss:  7.1611328125\n",
      "test r2:  -0.26769125489099843\n",
      "train loss:  1.7100262641906738\n",
      "train r2:  0.8833524835651274\n",
      "test loss:  7.160514831542969\n",
      "test r2:  -0.2676797919147986\n",
      "train loss:  1.7098459005355835\n",
      "train r2:  0.8833609046750323\n",
      "test loss:  7.159849166870117\n",
      "test r2:  -0.2676525079620491\n",
      "train loss:  1.709662914276123\n",
      "train r2:  0.8833729792537387\n",
      "test loss:  7.159204006195068\n",
      "test r2:  -0.26764276308109824\n",
      "train loss:  1.7094770669937134\n",
      "train r2:  0.883381136747204\n",
      "test loss:  7.158506393432617\n",
      "test r2:  -0.26761290224559375\n",
      "train loss:  1.7092888355255127\n",
      "train r2:  0.8833940179422765\n",
      "test loss:  7.157831192016602\n",
      "test r2:  -0.2676046954416911\n",
      "train loss:  1.7090973854064941\n",
      "train r2:  0.8834019801899575\n",
      "test loss:  7.157098293304443\n",
      "test r2:  -0.2675715858523795\n",
      "train loss:  1.7089030742645264\n",
      "train r2:  0.8834158526472476\n",
      "test loss:  7.1563920974731445\n",
      "test r2:  -0.2675665838197727\n",
      "train loss:  1.7087059020996094\n",
      "train r2:  0.8834231677094808\n",
      "test loss:  7.15561056137085\n",
      "test r2:  -0.2675259074689702\n",
      "train loss:  1.708505392074585\n",
      "train r2:  0.883438969193433\n",
      "test loss:  7.1548871994018555\n",
      "test r2:  -0.26753064475856725\n",
      "train loss:  1.7083020210266113\n",
      "train r2:  0.8834442250662119\n",
      "test loss:  7.154034614562988\n",
      "test r2:  -0.26747389452665704\n",
      "train loss:  1.7080954313278198\n",
      "train r2:  0.883463890151521\n",
      "test loss:  7.153311252593994\n",
      "test r2:  -0.2674983702921474\n",
      "train loss:  1.7078856229782104\n",
      "train r2:  0.8834648311495914\n",
      "test loss:  7.152360439300537\n",
      "test r2:  -0.2674140818060746\n",
      "train loss:  1.7076728343963623\n",
      "train r2:  0.8834909268416937\n",
      "test loss:  7.1516618728637695\n",
      "test r2:  -0.26747109657208057\n",
      "train loss:  1.7074569463729858\n",
      "train r2:  0.8834845322762234\n",
      "test loss:  7.150577068328857\n",
      "test r2:  -0.26734183797381705\n",
      "train loss:  1.707237958908081\n",
      "train r2:  0.8835211368437552\n",
      "test loss:  7.149952411651611\n",
      "test r2:  -0.26745728790702805\n",
      "train loss:  1.7070167064666748\n",
      "train r2:  0.8835014550256781\n",
      "test loss:  7.148647785186768\n",
      "test r2:  -0.2672437378569341\n",
      "train loss:  1.7067935466766357\n",
      "train r2:  0.8835574687662117\n",
      "test loss:  7.148224353790283\n",
      "test r2:  -0.2674753755456447\n",
      "train loss:  1.706569790840149\n",
      "train r2:  0.8835113550757936\n",
      "test loss:  7.146505355834961\n",
      "test r2:  -0.2670943890496771\n",
      "train loss:  1.7063477039337158\n",
      "train r2:  0.8836054964522716\n",
      "test loss:  7.146562576293945\n",
      "test r2:  -0.2675610461156581\n",
      "train loss:  1.706132173538208\n",
      "train r2:  0.8835059074946836\n",
      "test loss:  7.144014358520508\n",
      "test r2:  -0.2668411658531089\n",
      "train loss:  1.7059282064437866\n",
      "train r2:  0.8836765155609997\n",
      "test loss:  7.145172119140625\n",
      "test r2:  -0.2677894345057472\n",
      "train loss:  1.7057538032531738\n",
      "train r2:  0.8834676870836851\n",
      "test loss:  7.1409101486206055\n",
      "test r2:  -0.2663852066224808\n",
      "train loss:  1.7056152820587158\n",
      "train r2:  0.8837911738071254\n",
      "test loss:  7.144393444061279\n",
      "test r2:  -0.268279755649546\n",
      "train loss:  1.705554485321045\n",
      "train r2:  0.8833683748382263\n",
      "test loss:  7.136813163757324\n",
      "test r2:  -0.2656080685431377\n",
      "train loss:  1.7055153846740723\n",
      "train r2:  0.8839730120962337\n",
      "test loss:  7.144299030303955\n",
      "test r2:  -0.26901919936733476\n",
      "train loss:  1.705506443977356\n",
      "train r2:  0.8832113218540024\n",
      "test loss:  7.131603717803955\n",
      "test r2:  -0.26458551356483695\n",
      "train loss:  1.7052425146102905\n",
      "train r2:  0.8842054669624145\n",
      "test loss:  7.143477916717529\n",
      "test r2:  -0.2693811840299485\n",
      "train loss:  1.7047319412231445\n",
      "train r2:  0.8831510946190608\n",
      "test loss:  7.130774021148682\n",
      "test r2:  -0.26520608993453765\n",
      "train loss:  1.7040501832962036\n",
      "train r2:  0.8840880035424323\n",
      "test loss:  7.135981559753418\n",
      "test r2:  -0.26736209931193144\n",
      "train loss:  1.7035915851593018\n",
      "train r2:  0.8836261506451616\n",
      "test loss:  7.136491298675537\n",
      "test r2:  -0.26806846177486254\n",
      "train loss:  1.703501582145691\n",
      "train r2:  0.8834701590816272\n",
      "test loss:  7.127127170562744\n",
      "test r2:  -0.2649856837618616\n",
      "train loss:  1.703476905822754\n",
      "train r2:  0.8841593562268646\n",
      "test loss:  7.135094165802002\n",
      "test r2:  -0.2684873406028392\n",
      "train loss:  1.703202724456787\n",
      "train r2:  0.8833844663255457\n",
      "test loss:  7.128263473510742\n",
      "test r2:  -0.2661798144330987\n",
      "train loss:  1.7026824951171875\n",
      "train r2:  0.8839163560545124\n",
      "test loss:  7.126800060272217\n",
      "test r2:  -0.2662616770975186\n",
      "train loss:  1.7022722959518433\n",
      "train r2:  0.8839016220119287\n",
      "test loss:  7.131111145019531\n",
      "test r2:  -0.26807207261324617\n",
      "train loss:  1.702094554901123\n",
      "train r2:  0.8835128278295601\n",
      "test loss:  7.1228837966918945\n",
      "test r2:  -0.2655166425787252\n",
      "train loss:  1.701951026916504\n",
      "train r2:  0.8840849400723145\n",
      "test loss:  7.125645637512207\n",
      "test r2:  -0.2672092496942542\n",
      "train loss:  1.7016617059707642\n",
      "train r2:  0.8837096363054897\n",
      "test loss:  7.125627517700195\n",
      "test r2:  -0.26711670080353755\n",
      "train loss:  1.70125150680542\n",
      "train r2:  0.8837590219901381\n",
      "test loss:  7.11983060836792\n",
      "test r2:  -0.2658096571096602\n",
      "train loss:  1.700914740562439\n",
      "train r2:  0.8840444728431162\n",
      "test loss:  7.123154163360596\n",
      "test r2:  -0.26736775467550955\n",
      "train loss:  1.7006993293762207\n",
      "train r2:  0.8837092108796898\n",
      "test loss:  7.120120525360107\n",
      "test r2:  -0.2664225858292928\n",
      "train loss:  1.7004879713058472\n",
      "train r2:  0.8839362386845264\n",
      "test loss:  7.117480754852295\n",
      "test r2:  -0.2663130830426763\n",
      "train loss:  1.7001821994781494\n",
      "train r2:  0.8839545844551026\n",
      "test loss:  7.119475841522217\n",
      "test r2:  -0.2670140017103182\n",
      "train loss:  1.6998120546340942\n",
      "train r2:  0.8838248614203832\n",
      "test loss:  7.115893840789795\n",
      "test r2:  -0.26629953112865445\n",
      "train loss:  1.6995153427124023\n",
      "train r2:  0.8839855599475791\n",
      "test loss:  7.11471700668335\n",
      "test r2:  -0.2664741265443682\n",
      "train loss:  1.6992961168289185\n",
      "train r2:  0.8839474640283478\n",
      "test loss:  7.115325450897217\n",
      "test r2:  -0.2666707857577755\n",
      "train loss:  1.6990370750427246\n",
      "train r2:  0.8839275901474622\n",
      "test loss:  7.112548351287842\n",
      "test r2:  -0.266408202814995\n",
      "train loss:  1.6987055540084839\n",
      "train r2:  0.8839822435805996\n",
      "test loss:  7.111515998840332\n",
      "test r2:  -0.2662996365687056\n",
      "train loss:  1.6983771324157715\n",
      "train r2:  0.8840193998542331\n",
      "test loss:  7.1119184494018555\n",
      "test r2:  -0.26669959469973437\n",
      "train loss:  1.6981124877929688\n",
      "train r2:  0.8839431822380435\n",
      "test loss:  7.108772277832031\n",
      "test r2:  -0.2662275124768574\n",
      "train loss:  1.697862982749939\n",
      "train r2:  0.8840451705221248\n",
      "test loss:  7.108618259429932\n",
      "test r2:  -0.2662434624269896\n",
      "train loss:  1.697566270828247\n",
      "train r2:  0.8840608528646512\n",
      "test loss:  7.108841419219971\n",
      "test r2:  -0.2667980293286616\n",
      "train loss:  1.6972485780715942\n",
      "train r2:  0.8839420839313931\n",
      "test loss:  7.104762077331543\n",
      "test r2:  -0.26581540800421855\n",
      "train loss:  1.6969527006149292\n",
      "train r2:  0.884163103198413\n",
      "test loss:  7.106672286987305\n",
      "test r2:  -0.2665876132075853\n",
      "train loss:  1.6966787576675415\n",
      "train r2:  0.8840100143574418\n",
      "test loss:  7.104841232299805\n",
      "test r2:  -0.2664604079703432\n",
      "train loss:  1.6964006423950195\n",
      "train r2:  0.8840393232970771\n",
      "test loss:  7.101896286010742\n",
      "test r2:  -0.2657034276918182\n",
      "train loss:  1.6961053609848022\n",
      "train r2:  0.8842162237582687\n",
      "test loss:  7.104739189147949\n",
      "test r2:  -0.26693822138843104\n",
      "train loss:  1.6958036422729492\n",
      "train r2:  0.8839551975541701\n",
      "test loss:  7.100236892700195\n",
      "test r2:  -0.26580725700079677\n",
      "train loss:  1.6955077648162842\n",
      "train r2:  0.8842084610334703\n",
      "test loss:  7.100772380828857\n",
      "test r2:  -0.2661570450923556\n",
      "train loss:  1.6952219009399414\n",
      "train r2:  0.8841452878005394\n",
      "test loss:  7.101441860198975\n",
      "test r2:  -0.2667333413575075\n",
      "train loss:  1.6949403285980225\n",
      "train r2:  0.8840245004556381\n",
      "test loss:  7.096752643585205\n",
      "test r2:  -0.26546323711906794\n",
      "train loss:  1.6946498155593872\n",
      "train r2:  0.8843101786717374\n",
      "test loss:  7.099940299987793\n",
      "test r2:  -0.2667142225323951\n",
      "train loss:  1.6943480968475342\n",
      "train r2:  0.8840489157428412\n",
      "test loss:  7.0971174240112305\n",
      "test r2:  -0.26607742973884463\n",
      "train loss:  1.6940503120422363\n",
      "train r2:  0.8841956306037517\n",
      "test loss:  7.095369338989258\n",
      "test r2:  -0.26576386440531286\n",
      "train loss:  1.6937651634216309\n",
      "train r2:  0.8842721723433085\n",
      "test loss:  7.0976362228393555\n",
      "test r2:  -0.26674524846407976\n",
      "train loss:  1.6934815645217896\n",
      "train r2:  0.8840668801927651\n",
      "test loss:  7.093386650085449\n",
      "test r2:  -0.2655942749424127\n",
      "train loss:  1.6931880712509155\n",
      "train r2:  0.8843271100042155\n",
      "test loss:  7.0948381423950195\n",
      "test r2:  -0.26630391295337663\n",
      "train loss:  1.6928894519805908\n",
      "train r2:  0.884181449332641\n",
      "test loss:  7.094094753265381\n",
      "test r2:  -0.2662799428372442\n",
      "train loss:  1.6925960779190063\n",
      "train r2:  0.8841957118628041\n",
      "test loss:  7.091377258300781\n",
      "test r2:  -0.2656688155735847\n",
      "train loss:  1.6923089027404785\n",
      "train r2:  0.8843354878841219\n",
      "test loss:  7.093240737915039\n",
      "test r2:  -0.2664654618545492\n",
      "train loss:  1.6920205354690552\n",
      "train r2:  0.8841718483128278\n",
      "test loss:  7.090799331665039\n",
      "test r2:  -0.26586665174620205\n",
      "train loss:  1.6917295455932617\n",
      "train r2:  0.8843120274045337\n",
      "test loss:  7.09036111831665\n",
      "test r2:  -0.26600559798711654\n",
      "train loss:  1.6914377212524414\n",
      "train r2:  0.8842873100793994\n",
      "test loss:  7.090534687042236\n",
      "test r2:  -0.26622146404800695\n",
      "train loss:  1.6911453008651733\n",
      "train r2:  0.8842507469524538\n",
      "test loss:  7.088629245758057\n",
      "test r2:  -0.26583720811166445\n",
      "train loss:  1.6908551454544067\n",
      "train r2:  0.8843418708630371\n",
      "test loss:  7.088834762573242\n",
      "test r2:  -0.2661075836641016\n",
      "train loss:  1.6905677318572998\n",
      "train r2:  0.8842912872847642\n",
      "test loss:  7.088049411773682\n",
      "test r2:  -0.26601798677120625\n",
      "train loss:  1.6902809143066406\n",
      "train r2:  0.8843203815265412\n",
      "test loss:  7.087009906768799\n",
      "test r2:  -0.26594588771215344\n",
      "train loss:  1.6899925470352173\n",
      "train r2:  0.884341294252299\n",
      "test loss:  7.086729049682617\n",
      "test r2:  -0.26599115322853395\n",
      "train loss:  1.6897021532058716\n",
      "train r2:  0.8843421116182747\n",
      "test loss:  7.086286544799805\n",
      "test r2:  -0.26604134367602006\n",
      "train loss:  1.6894137859344482\n",
      "train r2:  0.8843391801999715\n",
      "test loss:  7.08511209487915\n",
      "test r2:  -0.26587616221761556\n",
      "train loss:  1.6891283988952637\n",
      "train r2:  0.8843819042404857\n",
      "test loss:  7.085052967071533\n",
      "test r2:  -0.2660015126685027\n",
      "train loss:  1.6888437271118164\n",
      "train r2:  0.8843640665025471\n",
      "test loss:  7.084442615509033\n",
      "test r2:  -0.26601232252264495\n",
      "train loss:  1.68855881690979\n",
      "train r2:  0.884368528031627\n",
      "test loss:  7.083293437957764\n",
      "test r2:  -0.265786725590321\n",
      "train loss:  1.6882737874984741\n",
      "train r2:  0.884426888007633\n",
      "test loss:  7.08381986618042\n",
      "test r2:  -0.2661256505710903\n",
      "train loss:  1.6879898309707642\n",
      "train r2:  0.884360985189966\n",
      "test loss:  7.082223892211914\n",
      "test r2:  -0.26580006302354864\n",
      "train loss:  1.6877063512802124\n",
      "train r2:  0.884438715616249\n",
      "test loss:  7.082179069519043\n",
      "test r2:  -0.2659247047505706\n",
      "train loss:  1.687424659729004\n",
      "train r2:  0.8844204616245974\n",
      "test loss:  7.082063674926758\n",
      "test r2:  -0.26604346598475814\n",
      "train loss:  1.6871442794799805\n",
      "train r2:  0.8844025896100398\n",
      "test loss:  7.080557346343994\n",
      "test r2:  -0.26571645366726004\n",
      "train loss:  1.6868650913238525\n",
      "train r2:  0.8844813903283293\n",
      "test loss:  7.081213474273682\n",
      "test r2:  -0.2660792870854183\n",
      "train loss:  1.6865859031677246\n",
      "train r2:  0.8844099429106275\n",
      "test loss:  7.079908847808838\n",
      "test r2:  -0.2658066057896866\n",
      "train loss:  1.686307430267334\n",
      "train r2:  0.884476995223547\n",
      "test loss:  7.079684734344482\n",
      "test r2:  -0.2658771973980527\n",
      "train loss:  1.6860302686691284\n",
      "train r2:  0.8844693988073797\n",
      "test loss:  7.079625129699707\n",
      "test r2:  -0.2659825643396252\n",
      "train loss:  1.6857545375823975\n",
      "train r2:  0.8844546321157606\n",
      "test loss:  7.078466892242432\n",
      "test r2:  -0.2657662514734458\n",
      "train loss:  1.6854805946350098\n",
      "train r2:  0.8845082667358592\n",
      "test loss:  7.078652858734131\n",
      "test r2:  -0.265958778562319\n",
      "train loss:  1.685207486152649\n",
      "train r2:  0.8844737678496837\n",
      "test loss:  7.077929496765137\n",
      "test r2:  -0.26584092078019084\n",
      "train loss:  1.6849355697631836\n",
      "train r2:  0.8845075189268107\n",
      "test loss:  7.077549457550049\n",
      "test r2:  -0.2658602056994981\n",
      "train loss:  1.6846649646759033\n",
      "train r2:  0.8845100129902643\n",
      "test loss:  7.077275276184082\n",
      "test r2:  -0.2658804796256964\n",
      "train loss:  1.6843955516815186\n",
      "train r2:  0.8845134209254628\n",
      "test loss:  7.076776027679443\n",
      "test r2:  -0.26585702496046393\n",
      "train loss:  1.6841272115707397\n",
      "train r2:  0.884524927770338\n",
      "test loss:  7.076343059539795\n",
      "test r2:  -0.2658299755227327\n",
      "train loss:  1.6838607788085938\n",
      "train r2:  0.8845381278731848\n",
      "test loss:  7.076205730438232\n",
      "test r2:  -0.2658858285684631\n",
      "train loss:  1.6835957765579224\n",
      "train r2:  0.8845336751090984\n",
      "test loss:  7.07564115524292\n",
      "test r2:  -0.2658307488437346\n",
      "train loss:  1.6833323240280151\n",
      "train r2:  0.8845519479914163\n",
      "test loss:  7.075309753417969\n",
      "test r2:  -0.26582336240997484\n",
      "train loss:  1.6830705404281616\n",
      "train r2:  0.8845608118389645\n",
      "test loss:  7.07520866394043\n",
      "test r2:  -0.2659005529704006\n",
      "train loss:  1.6828099489212036\n",
      "train r2:  0.8845506123328989\n",
      "test loss:  7.0744524002075195\n",
      "test r2:  -0.2657554749432396\n",
      "train loss:  1.6825511455535889\n",
      "train r2:  0.8845892589200506\n",
      "test loss:  7.07466459274292\n",
      "test r2:  -0.2659156541008545\n",
      "train loss:  1.6822936534881592\n",
      "train r2:  0.8845613765691647\n",
      "test loss:  7.0739359855651855\n",
      "test r2:  -0.2657850969669746\n",
      "train loss:  1.6820383071899414\n",
      "train r2:  0.8845961144505986\n",
      "test loss:  7.07380485534668\n",
      "test r2:  -0.26583458545715755\n",
      "train loss:  1.6817843914031982\n",
      "train r2:  0.8845919867319197\n",
      "test loss:  7.073640823364258\n",
      "test r2:  -0.26586539847174984\n",
      "train loss:  1.6815322637557983\n",
      "train r2:  0.8845921562919513\n",
      "test loss:  7.073068141937256\n",
      "test r2:  -0.2657713691521759\n",
      "train loss:  1.6812820434570312\n",
      "train r2:  0.8846190518522441\n",
      "test loss:  7.073165416717529\n",
      "test r2:  -0.26588307566045266\n",
      "train loss:  1.6810334920883179\n",
      "train r2:  0.8846012668019468\n",
      "test loss:  7.072593688964844\n",
      "test r2:  -0.2657845583549274\n",
      "train loss:  1.6807868480682373\n",
      "train r2:  0.8846289537035456\n",
      "test loss:  7.0725202560424805\n",
      "test r2:  -0.265841723624628\n",
      "train loss:  1.6805418729782104\n",
      "train r2:  0.8846227661238879\n",
      "test loss:  7.0722455978393555\n",
      "test r2:  -0.26582023300604773\n",
      "train loss:  1.680298924446106\n",
      "train r2:  0.8846341640257377\n",
      "test loss:  7.071994304656982\n",
      "test r2:  -0.26582239727664403\n",
      "train loss:  1.6800580024719238\n",
      "train r2:  0.8846394311226238\n",
      "test loss:  7.071750164031982\n",
      "test r2:  -0.26581159886780004\n",
      "train loss:  1.6798187494277954\n",
      "train r2:  0.8846480427594371\n",
      "test loss:  7.071617126464844\n",
      "test r2:  -0.2658407645923786\n",
      "train loss:  1.6795814037322998\n",
      "train r2:  0.8846476011079185\n",
      "test loss:  7.071252346038818\n",
      "test r2:  -0.2657903647888884\n",
      "train loss:  1.679345965385437\n",
      "train r2:  0.8846646259715094\n",
      "test loss:  7.071242809295654\n",
      "test r2:  -0.2658472618464027\n",
      "train loss:  1.6791130304336548\n",
      "train r2:  0.8846583706606432\n",
      "test loss:  7.0708909034729\n",
      "test r2:  -0.26580327556229255\n",
      "train loss:  1.6788815259933472\n",
      "train r2:  0.8846734810991845\n",
      "test loss:  7.070742607116699\n",
      "test r2:  -0.2658145440793773\n",
      "train loss:  1.678652286529541\n",
      "train r2:  0.8846768772787513\n",
      "test loss:  7.070643901824951\n",
      "test r2:  -0.2658411372815095\n",
      "train loss:  1.6784249544143677\n",
      "train r2:  0.8846768352629659\n",
      "test loss:  7.07028341293335\n",
      "test r2:  -0.26578317954723496\n",
      "train loss:  1.678200125694275\n",
      "train r2:  0.8846950942126031\n",
      "test loss:  7.07035493850708\n",
      "test r2:  -0.2658585363226529\n",
      "train loss:  1.6779768466949463\n",
      "train r2:  0.8846843251891191\n",
      "test loss:  7.069941997528076\n",
      "test r2:  -0.2657833804775591\n",
      "train loss:  1.6777557134628296\n",
      "train r2:  0.8847060172147265\n",
      "test loss:  7.069972038269043\n",
      "test r2:  -0.2658442439882327\n",
      "train loss:  1.6775367259979248\n",
      "train r2:  0.884698172768439\n",
      "test loss:  7.069700241088867\n",
      "test r2:  -0.2658040103760677\n",
      "train loss:  1.6773197650909424\n",
      "train r2:  0.8847124847698189\n",
      "test loss:  7.069621562957764\n",
      "test r2:  -0.2658302563577415\n",
      "train loss:  1.6771050691604614\n",
      "train r2:  0.8847118661726217\n",
      "test loss:  7.069417953491211\n",
      "test r2:  -0.26580877666526326\n",
      "train loss:  1.6768925189971924\n",
      "train r2:  0.8847218978449486\n",
      "test loss:  7.069357395172119\n",
      "test r2:  -0.2658389706011073\n",
      "train loss:  1.6766815185546875\n",
      "train r2:  0.884720282928131\n",
      "test loss:  7.069088459014893\n",
      "test r2:  -0.26579388418739325\n",
      "train loss:  1.6764732599258423\n",
      "train r2:  0.8847353332928906\n",
      "test loss:  7.069157600402832\n",
      "test r2:  -0.26585872561191803\n",
      "train loss:  1.6762667894363403\n",
      "train r2:  0.8847262408500649\n",
      "test loss:  7.068782329559326\n",
      "test r2:  -0.2657815042514198\n",
      "train loss:  1.6760623455047607\n",
      "train r2:  0.8847479206710867\n",
      "test loss:  7.068923473358154\n",
      "test r2:  -0.26586577480674434\n",
      "train loss:  1.6758602857589722\n",
      "train r2:  0.8847344169668594\n",
      "test loss:  7.068542003631592\n",
      "test r2:  -0.26578424845983495\n",
      "train loss:  1.6756601333618164\n",
      "train r2:  0.8847569801052648\n",
      "test loss:  7.068665981292725\n",
      "test r2:  -0.26586181430698974\n",
      "train loss:  1.675461769104004\n",
      "train r2:  0.8847447749288514\n",
      "test loss:  7.068329334259033\n",
      "test r2:  -0.26579035235941006\n",
      "train loss:  1.675266146659851\n",
      "train r2:  0.8847650513922761\n",
      "test loss:  7.068437576293945\n",
      "test r2:  -0.26586435548288523\n",
      "train loss:  1.6750723123550415\n",
      "train r2:  0.88475331447825\n",
      "test loss:  7.068072319030762\n",
      "test r2:  -0.2657804289308481\n",
      "train loss:  1.6748805046081543\n",
      "train r2:  0.8847762247655853\n",
      "test loss:  7.068289279937744\n",
      "test r2:  -0.26588741410275096\n",
      "train loss:  1.6746907234191895\n",
      "train r2:  0.8847571247846374\n",
      "test loss:  7.067753791809082\n",
      "test r2:  -0.26574887442867845\n",
      "train loss:  1.674503207206726\n",
      "train r2:  0.884791743814693\n",
      "test loss:  7.068208694458008\n",
      "test r2:  -0.2659296552982011\n",
      "train loss:  1.6743175983428955\n",
      "train r2:  0.8847564183757013\n",
      "test loss:  7.067387580871582\n",
      "test r2:  -0.2657001979594129\n",
      "train loss:  1.6741348505020142\n",
      "train r2:  0.8848105808189575\n",
      "test loss:  7.068182468414307\n",
      "test r2:  -0.2659873709456104\n",
      "train loss:  1.6739540100097656\n",
      "train r2:  0.8847519288825441\n",
      "test loss:  7.066964626312256\n",
      "test r2:  -0.26563055385320666\n",
      "train loss:  1.6737759113311768\n",
      "train r2:  0.8848336782980709\n",
      "test loss:  7.06825065612793\n",
      "test r2:  -0.26607610950159777\n",
      "train loss:  1.6736007928848267\n",
      "train r2:  0.8847401630004771\n",
      "test loss:  7.0663862228393555\n",
      "test r2:  -0.2655112709406431\n",
      "train loss:  1.6734298467636108\n",
      "train r2:  0.8848671043244393\n",
      "test loss:  7.068537712097168\n",
      "test r2:  -0.2662351772537652\n",
      "train loss:  1.6732646226882935\n",
      "train r2:  0.884712410837237\n",
      "test loss:  7.065496921539307\n",
      "test r2:  -0.26529162527584216\n",
      "train loss:  1.6731067895889282\n",
      "train r2:  0.8849217690133107\n",
      "test loss:  7.069237232208252\n",
      "test r2:  -0.2665264221512227\n",
      "train loss:  1.6729615926742554\n",
      "train r2:  0.8846549574571294\n",
      "test loss:  7.064083576202393\n",
      "test r2:  -0.2649059622924017\n",
      "train loss:  1.6728352308273315\n",
      "train r2:  0.8850113874259065\n",
      "test loss:  7.070489883422852\n",
      "test r2:  -0.2669996473377003\n",
      "train loss:  1.6727365255355835\n",
      "train r2:  0.8845557652273217\n",
      "test loss:  7.062097072601318\n",
      "test r2:  -0.2643339068371686\n",
      "train loss:  1.6726723909378052\n",
      "train r2:  0.8851396661877662\n",
      "test loss:  7.072033882141113\n",
      "test r2:  -0.2675810728394181\n",
      "train loss:  1.6726473569869995\n",
      "train r2:  0.8844295051672925\n",
      "test loss:  7.0593976974487305\n",
      "test r2:  -0.2635505557458213\n",
      "train loss:  1.6726467609405518\n",
      "train r2:  0.8853102917088285\n",
      "test loss:  7.073481559753418\n",
      "test r2:  -0.26814183208291165\n",
      "train loss:  1.6725958585739136\n",
      "train r2:  0.8843058619739592\n",
      "test loss:  7.058569431304932\n",
      "test r2:  -0.26335400104669016\n",
      "train loss:  1.6724094152450562\n",
      "train r2:  0.8853570235797785\n",
      "test loss:  7.070968151092529\n",
      "test r2:  -0.2674613360471687\n",
      "train loss:  1.6720302104949951\n",
      "train r2:  0.8844611367328266\n",
      "test loss:  7.064090251922607\n",
      "test r2:  -0.2651661722646379\n",
      "train loss:  1.6715972423553467\n",
      "train r2:  0.8849765822362787\n",
      "test loss:  7.0641069412231445\n",
      "test r2:  -0.2653297545161619\n",
      "train loss:  1.6713143587112427\n",
      "train r2:  0.884938834250537\n",
      "test loss:  7.068843364715576\n",
      "test r2:  -0.2668360015968463\n",
      "train loss:  1.6712323427200317\n",
      "train r2:  0.8846123177624267\n",
      "test loss:  7.062142848968506\n",
      "test r2:  -0.2647008391717749\n",
      "train loss:  1.6712318658828735\n",
      "train r2:  0.8850801123412109\n",
      "test loss:  7.066825866699219\n",
      "test r2:  -0.26642788574438137\n",
      "train loss:  1.671158790588379\n",
      "train r2:  0.8846942128657408\n",
      "test loss:  7.064485549926758\n",
      "test r2:  -0.26548375846481154\n",
      "train loss:  1.6709262132644653\n",
      "train r2:  0.8849151547832211\n",
      "test loss:  7.064711093902588\n",
      "test r2:  -0.26580181030119565\n",
      "train loss:  1.6706345081329346\n",
      "train r2:  0.8848387916885871\n",
      "test loss:  7.064353942871094\n",
      "test r2:  -0.2656967356526352\n",
      "train loss:  1.670436143875122\n",
      "train r2:  0.8848651253742297\n",
      "test loss:  7.064298629760742\n",
      "test r2:  -0.26565778112476\n",
      "train loss:  1.6703671216964722\n",
      "train r2:  0.8848767128022217\n",
      "test loss:  7.064605236053467\n",
      "test r2:  -0.2659919338290062\n",
      "train loss:  1.6703124046325684\n",
      "train r2:  0.8847938676868743\n",
      "test loss:  7.062069416046143\n",
      "test r2:  -0.26507737928044683\n",
      "train loss:  1.670166015625\n",
      "train r2:  0.8850017575513786\n",
      "test loss:  7.065834045410156\n",
      "test r2:  -0.26642348895159595\n",
      "train loss:  1.6699535846710205\n",
      "train r2:  0.8847043226542943\n",
      "test loss:  7.061494827270508\n",
      "test r2:  -0.26512833987042317\n",
      "train loss:  1.6697638034820557\n",
      "train r2:  0.8849863206233779\n",
      "test loss:  7.063047409057617\n",
      "test r2:  -0.2656193954856956\n",
      "train loss:  1.6696470975875854\n",
      "train r2:  0.884881917554513\n",
      "test loss:  7.064605236053467\n",
      "test r2:  -0.26624671709592596\n",
      "train loss:  1.669569969177246\n",
      "train r2:  0.8847403047406631\n",
      "test loss:  7.059704303741455\n",
      "test r2:  -0.2647048244206527\n",
      "train loss:  1.6694597005844116\n",
      "train r2:  0.8850781283084272\n",
      "test loss:  7.0645952224731445\n",
      "test r2:  -0.26634315467635616\n",
      "train loss:  1.6692945957183838\n",
      "train r2:  0.8847197691535682\n",
      "test loss:  7.061389446258545\n",
      "test r2:  -0.2653797190130738\n",
      "train loss:  1.669123888015747\n",
      "train r2:  0.8849306058158288\n",
      "test loss:  7.060645580291748\n",
      "test r2:  -0.2652172242728592\n",
      "train loss:  1.6689997911453247\n",
      "train r2:  0.884964954908624\n",
      "test loss:  7.063686847686768\n",
      "test r2:  -0.26622757215658166\n",
      "train loss:  1.6689083576202393\n",
      "train r2:  0.8847444185998322\n",
      "test loss:  7.059591770172119\n",
      "test r2:  -0.2649682948171972\n",
      "train loss:  1.6688027381896973\n",
      "train r2:  0.8850194133335042\n",
      "test loss:  7.0618791580200195\n",
      "test r2:  -0.2658050270952792\n",
      "train loss:  1.6686664819717407\n",
      "train r2:  0.8848343943920332\n",
      "test loss:  7.061271667480469\n",
      "test r2:  -0.2656035344878056\n",
      "train loss:  1.6685211658477783\n",
      "train r2:  0.8848816061861332\n",
      "test loss:  7.059929370880127\n",
      "test r2:  -0.26527446575955316\n",
      "train loss:  1.6683955192565918\n",
      "train r2:  0.8849512092248569\n",
      "test loss:  7.06126594543457\n",
      "test r2:  -0.265750769439143\n",
      "train loss:  1.6682935953140259\n",
      "train r2:  0.8848471384700555\n",
      "test loss:  7.059980392456055\n",
      "test r2:  -0.2653440290263387\n",
      "train loss:  1.6681932210922241\n",
      "train r2:  0.884937968919073\n",
      "test loss:  7.060379505157471\n",
      "test r2:  -0.2655956236451964\n",
      "train loss:  1.668074607849121\n",
      "train r2:  0.8848795052917349\n",
      "test loss:  7.059661388397217\n",
      "test r2:  -0.2653691411024659\n",
      "train loss:  1.667944312095642\n",
      "train r2:  0.8849314250776329\n",
      "test loss:  7.060141086578369\n",
      "test r2:  -0.26557797506157454\n",
      "train loss:  1.6678239107131958\n",
      "train r2:  0.8848856648897364\n",
      "test loss:  7.059431076049805\n",
      "test r2:  -0.2654329336565513\n",
      "train loss:  1.6677193641662598\n",
      "train r2:  0.8849157022239211\n",
      "test loss:  7.059080123901367\n",
      "test r2:  -0.26532294468643225\n",
      "train loss:  1.667618751525879\n",
      "train r2:  0.884941809223888\n",
      "test loss:  7.060066223144531\n",
      "test r2:  -0.26572056493215523\n",
      "train loss:  1.6675102710723877\n",
      "train r2:  0.8848533344549272\n",
      "test loss:  7.058032512664795\n",
      "test r2:  -0.2651184724635449\n",
      "train loss:  1.6673938035964966\n",
      "train r2:  0.8849848416056234\n",
      "test loss:  7.059484481811523\n",
      "test r2:  -0.2656114045430569\n",
      "train loss:  1.6672792434692383\n",
      "train r2:  0.8848783125275245\n",
      "test loss:  7.058821201324463\n",
      "test r2:  -0.26545968256453456\n",
      "train loss:  1.6671732664108276\n",
      "train r2:  0.8849108881153839\n",
      "test loss:  7.057760238647461\n",
      "test r2:  -0.2651567628133138\n",
      "train loss:  1.6670737266540527\n",
      "train r2:  0.8849775489461398\n",
      "test loss:  7.059440612792969\n",
      "test r2:  -0.2657297646052954\n",
      "train loss:  1.6669716835021973\n",
      "train r2:  0.8848530722182109\n",
      "test loss:  7.057490348815918\n",
      "test r2:  -0.2651555639386307\n",
      "train loss:  1.6668641567230225\n",
      "train r2:  0.8849783724619578\n",
      "test loss:  7.058256149291992\n",
      "test r2:  -0.26544238782772944\n",
      "train loss:  1.6667555570602417\n",
      "train r2:  0.8849162567585205\n",
      "test loss:  7.058384418487549\n",
      "test r2:  -0.26550238992257635\n",
      "train loss:  1.6666516065597534\n",
      "train r2:  0.8849046789020296\n",
      "test loss:  7.057244777679443\n",
      "test r2:  -0.2651840143188742\n",
      "train loss:  1.6665524244308472\n",
      "train r2:  0.8849743289136525\n",
      "test loss:  7.058280944824219\n",
      "test r2:  -0.26554271211114333\n",
      "train loss:  1.6664538383483887\n",
      "train r2:  0.8848971855426152\n",
      "test loss:  7.057432174682617\n",
      "test r2:  -0.2652894675766875\n",
      "train loss:  1.6663529872894287\n",
      "train r2:  0.8849540024000954\n",
      "test loss:  7.057551860809326\n",
      "test r2:  -0.2653767206117985\n",
      "train loss:  1.6662503480911255\n",
      "train r2:  0.8849351412411268\n",
      "test loss:  7.057581901550293\n",
      "test r2:  -0.2653917376263917\n",
      "train loss:  1.6661486625671387\n",
      "train r2:  0.8849341253114387\n",
      "test loss:  7.05735969543457\n",
      "test r2:  -0.2653414068420481\n",
      "train loss:  1.6660504341125488\n",
      "train r2:  0.8849466956410534\n",
      "test loss:  7.057441711425781\n",
      "test r2:  -0.26539595243063174\n",
      "train loss:  1.6659539937973022\n",
      "train r2:  0.8849360317983688\n",
      "test loss:  7.057204723358154\n",
      "test r2:  -0.2653157105936279\n",
      "train loss:  1.665857195854187\n",
      "train r2:  0.8849562887098296\n",
      "test loss:  7.057573318481445\n",
      "test r2:  -0.26545590773287153\n",
      "train loss:  1.6657589673995972\n",
      "train r2:  0.8849273691470586\n",
      "test loss:  7.057001113891602\n",
      "test r2:  -0.265278471649939\n",
      "train loss:  1.6656607389450073\n",
      "train r2:  0.8849685672414541\n",
      "test loss:  7.05753755569458\n",
      "test r2:  -0.26543793634047774\n",
      "train loss:  1.6655638217926025\n",
      "train r2:  0.8849371463891161\n",
      "test loss:  7.057426452636719\n",
      "test r2:  -0.2654042992723584\n",
      "train loss:  1.665468454360962\n",
      "train r2:  0.8849472922343681\n",
      "test loss:  7.057161331176758\n",
      "test r2:  -0.26530083894621037\n",
      "train loss:  1.6653738021850586\n",
      "train r2:  0.8849737592229313\n",
      "test loss:  7.057997226715088\n",
      "test r2:  -0.26554070818487463\n",
      "train loss:  1.6652789115905762\n",
      "train r2:  0.8849258482901469\n",
      "test loss:  7.057361125946045\n",
      "test r2:  -0.26531294314457043\n",
      "train loss:  1.6651833057403564\n",
      "train r2:  0.8849799700999654\n",
      "test loss:  7.058042526245117\n",
      "test r2:  -0.2654803729215862\n",
      "train loss:  1.6650876998901367\n",
      "train r2:  0.8849493943675346\n",
      "test loss:  7.0583086013793945\n",
      "test r2:  -0.2655023746636722\n",
      "train loss:  1.6649929285049438\n",
      "train r2:  0.884951257438874\n",
      "test loss:  7.058225631713867\n",
      "test r2:  -0.2654047397405941\n",
      "train loss:  1.6648991107940674\n",
      "train r2:  0.8849799289109136\n",
      "test loss:  7.0592122077941895\n",
      "test r2:  -0.2656143206076953\n",
      "train loss:  1.6648051738739014\n",
      "train r2:  0.8849435908563099\n",
      "test loss:  7.059265613555908\n",
      "test r2:  -0.2655113843358061\n",
      "train loss:  1.6647108793258667\n",
      "train r2:  0.8849764648047438\n",
      "test loss:  7.060098171234131\n",
      "test r2:  -0.2656302009239724\n",
      "train loss:  1.664616584777832\n",
      "train r2:  0.8849628142545372\n",
      "test loss:  7.060876369476318\n",
      "test r2:  -0.26568905597935033\n",
      "train loss:  1.6645222902297974\n",
      "train r2:  0.8849648220735972\n",
      "test loss:  7.061666965484619\n",
      "test r2:  -0.26572585999306897\n",
      "train loss:  1.6644287109375\n",
      "train r2:  0.8849735676674473\n",
      "test loss:  7.062854290008545\n",
      "test r2:  -0.26584600619093113\n",
      "train loss:  1.6643359661102295\n",
      "train r2:  0.8849669949315442\n",
      "test loss:  7.06399393081665\n",
      "test r2:  -0.2659063054186277\n",
      "train loss:  1.6642440557479858\n",
      "train r2:  0.8849763371071188\n",
      "test loss:  7.065519332885742\n",
      "test r2:  -0.2660569871741061\n",
      "train loss:  1.6641528606414795\n",
      "train r2:  0.8849684896636953\n",
      "test loss:  7.066887378692627\n",
      "test r2:  -0.2661142858786181\n",
      "train loss:  1.6640625\n",
      "train r2:  0.8849838847279737\n",
      "test loss:  7.068844318389893\n",
      "test r2:  -0.2663177463890578\n",
      "train loss:  1.6639735698699951\n",
      "train r2:  0.884970365649295\n",
      "test loss:  7.070539474487305\n",
      "test r2:  -0.2664090650803024\n",
      "train loss:  1.6638853549957275\n",
      "train r2:  0.8849836362164333\n",
      "test loss:  7.0725812911987305\n",
      "test r2:  -0.26656797383468933\n",
      "train loss:  1.6637986898422241\n",
      "train r2:  0.8849850805928747\n",
      "test loss:  7.074913501739502\n",
      "test r2:  -0.2667913494843126\n",
      "train loss:  1.663712501525879\n",
      "train r2:  0.884974680937142\n",
      "test loss:  7.0768280029296875\n",
      "test r2:  -0.26686650426896374\n",
      "train loss:  1.6636265516281128\n",
      "train r2:  0.8849980095345603\n",
      "test loss:  7.079440593719482\n",
      "test r2:  -0.26714557029364716\n",
      "train loss:  1.6635409593582153\n",
      "train r2:  0.8849782544684932\n",
      "test loss:  7.081488132476807\n",
      "test r2:  -0.2672613578767069\n",
      "train loss:  1.663455843925476\n",
      "train r2:  0.8849933179745588\n",
      "test loss:  7.083650588989258\n",
      "test r2:  -0.2674367619160236\n",
      "train loss:  1.6633708477020264\n",
      "train r2:  0.8849939906198278\n",
      "test loss:  7.085784435272217\n",
      "test r2:  -0.26764068664943297\n",
      "train loss:  1.6632863283157349\n",
      "train r2:  0.8849859056567848\n",
      "test loss:  7.087316513061523\n",
      "test r2:  -0.26771676478826034\n",
      "train loss:  1.6632015705108643\n",
      "train r2:  0.8850015030589413\n",
      "test loss:  7.088985919952393\n",
      "test r2:  -0.2678966425047573\n",
      "train loss:  1.6631171703338623\n",
      "train r2:  0.8849901042192267\n",
      "test loss:  7.090053081512451\n",
      "test r2:  -0.26795940471209856\n",
      "train loss:  1.663033127784729\n",
      "train r2:  0.8849990363629233\n",
      "test loss:  7.090954303741455\n",
      "test r2:  -0.2680453342902316\n",
      "train loss:  1.6629490852355957\n",
      "train r2:  0.8849974799466225\n",
      "test loss:  7.09152364730835\n",
      "test r2:  -0.268094746717946\n",
      "train loss:  1.6628652811050415\n",
      "train r2:  0.8849988105778007\n",
      "test loss:  7.091803073883057\n",
      "test r2:  -0.2681195866694408\n",
      "train loss:  1.6627819538116455\n",
      "train r2:  0.8850007036179659\n",
      "test loss:  7.091866970062256\n",
      "test r2:  -0.2681327241106646\n",
      "train loss:  1.6626988649368286\n",
      "train r2:  0.8850009545330726\n",
      "test loss:  7.0916948318481445\n",
      "test r2:  -0.2681139706758835\n",
      "train loss:  1.6626156568527222\n",
      "train r2:  0.8850050665868439\n",
      "test loss:  7.091506481170654\n",
      "test r2:  -0.26812290071906797\n",
      "train loss:  1.662532925605774\n",
      "train r2:  0.8850007677030948\n",
      "test loss:  7.091040134429932\n",
      "test r2:  -0.26806214061921607\n",
      "train loss:  1.6624504327774048\n",
      "train r2:  0.88501032204109\n",
      "test loss:  7.0908050537109375\n",
      "test r2:  -0.2680757398255995\n",
      "train loss:  1.662367820739746\n",
      "train r2:  0.8850035621666814\n",
      "test loss:  7.090395927429199\n",
      "test r2:  -0.2680306406251287\n",
      "train loss:  1.6622860431671143\n",
      "train r2:  0.8850099380846131\n",
      "test loss:  7.0901336669921875\n",
      "test r2:  -0.26801313047765807\n",
      "train loss:  1.6622041463851929\n",
      "train r2:  0.8850116480358332\n",
      "test loss:  7.090051174163818\n",
      "test r2:  -0.26802976317874805\n",
      "train loss:  1.6621228456497192\n",
      "train r2:  0.8850075095417249\n",
      "test loss:  7.089858531951904\n",
      "test r2:  -0.2679905849696764\n",
      "train loss:  1.662041425704956\n",
      "train r2:  0.8850171484324507\n",
      "test loss:  7.090003490447998\n",
      "test r2:  -0.2680340050598622\n",
      "train loss:  1.661960244178772\n",
      "train r2:  0.885010490890151\n",
      "test loss:  7.090012073516846\n",
      "test r2:  -0.26802174371732\n",
      "train loss:  1.661879539489746\n",
      "train r2:  0.885016914787285\n",
      "test loss:  7.090146064758301\n",
      "test r2:  -0.268042242709281\n",
      "train loss:  1.6617988348007202\n",
      "train r2:  0.8850166904411403\n",
      "test loss:  7.090278625488281\n",
      "test r2:  -0.2680620102569711\n",
      "train loss:  1.6617186069488525\n",
      "train r2:  0.8850166435228267\n",
      "test loss:  7.090318202972412\n",
      "test r2:  -0.2680612055289968\n",
      "train loss:  1.6616384983062744\n",
      "train r2:  0.885020502297478\n",
      "test loss:  7.090392589569092\n",
      "test r2:  -0.26808040567894764\n",
      "train loss:  1.6615588665008545\n",
      "train r2:  0.8850193519527358\n",
      "test loss:  7.090364456176758\n",
      "test r2:  -0.2680758115977495\n",
      "train loss:  1.6614789962768555\n",
      "train r2:  0.8850227511340787\n",
      "test loss:  7.0903639793396\n",
      "test r2:  -0.26808781006931404\n",
      "train loss:  1.661399483680725\n",
      "train r2:  0.885022022616952\n",
      "test loss:  7.090285778045654\n",
      "test r2:  -0.26807738473136156\n",
      "train loss:  1.6613203287124634\n",
      "train r2:  0.8850259333219999\n",
      "test loss:  7.090287685394287\n",
      "test r2:  -0.26809263492658686\n",
      "train loss:  1.6612414121627808\n",
      "train r2:  0.8850243182567379\n",
      "test loss:  7.090212821960449\n",
      "test r2:  -0.26808253011983574\n",
      "train loss:  1.661162257194519\n",
      "train r2:  0.8850282653574022\n",
      "test loss:  7.090216159820557\n",
      "test r2:  -0.2680917267330023\n",
      "train loss:  1.6610839366912842\n",
      "train r2:  0.8850283586217825\n",
      "test loss:  7.090240478515625\n",
      "test r2:  -0.2681017467248248\n",
      "train loss:  1.6610053777694702\n",
      "train r2:  0.885028726264232\n",
      "test loss:  7.090248107910156\n",
      "test r2:  -0.2680971976543214\n",
      "train loss:  1.6609269380569458\n",
      "train r2:  0.8850329084124344\n",
      "test loss:  7.09041166305542\n",
      "test r2:  -0.26812863502750495\n",
      "train loss:  1.66084885597229\n",
      "train r2:  0.8850302387470254\n",
      "test loss:  7.090527057647705\n",
      "test r2:  -0.26813080761279573\n",
      "train loss:  1.6607710123062134\n",
      "train r2:  0.8850349369540911\n",
      "test loss:  7.090786933898926\n",
      "test r2:  -0.2681634498536225\n",
      "train loss:  1.6606934070587158\n",
      "train r2:  0.8850342081686361\n",
      "test loss:  7.091079235076904\n",
      "test r2:  -0.26819139308934004\n",
      "train loss:  1.6606158018112183\n",
      "train r2:  0.8850355324313955\n",
      "test loss:  7.0913987159729\n",
      "test r2:  -0.2682183225890129\n",
      "train loss:  1.6605383157730103\n",
      "train r2:  0.8850378715756216\n",
      "test loss:  7.091796398162842\n",
      "test r2:  -0.268260602955811\n",
      "train loss:  1.6604613065719604\n",
      "train r2:  0.8850376084360329\n",
      "test loss:  7.0921783447265625\n",
      "test r2:  -0.26829244856305134\n",
      "train loss:  1.660384178161621\n",
      "train r2:  0.8850399917705225\n",
      "test loss:  7.092605113983154\n",
      "test r2:  -0.26833477898315095\n",
      "train loss:  1.6603072881698608\n",
      "train r2:  0.8850404877486105\n",
      "test loss:  7.093029975891113\n",
      "test r2:  -0.26837178968230946\n",
      "train loss:  1.6602303981781006\n",
      "train r2:  0.8850424967873063\n",
      "test loss:  7.093501091003418\n",
      "test r2:  -0.26841907904141293\n",
      "train loss:  1.660153865814209\n",
      "train r2:  0.8850426383454038\n",
      "test loss:  7.093954563140869\n",
      "test r2:  -0.2684560473351554\n",
      "train loss:  1.6600775718688965\n",
      "train r2:  0.8850454672406536\n",
      "test loss:  7.094473361968994\n",
      "test r2:  -0.26850899461805566\n",
      "train loss:  1.660001277923584\n",
      "train r2:  0.8850451481464533\n",
      "test loss:  7.094966411590576\n",
      "test r2:  -0.2685507991651168\n",
      "train loss:  1.6599249839782715\n",
      "train r2:  0.8850474795214831\n",
      "test loss:  7.095489978790283\n",
      "test r2:  -0.26859916667946626\n",
      "train loss:  1.659848928451538\n",
      "train r2:  0.8850486697076277\n",
      "test loss:  7.096034526824951\n",
      "test r2:  -0.26865276307819363\n",
      "train loss:  1.6597729921340942\n",
      "train r2:  0.8850488591510732\n",
      "test loss:  7.096541881561279\n",
      "test r2:  -0.26869348634449386\n",
      "train loss:  1.659697413444519\n",
      "train r2:  0.8850519720155747\n",
      "test loss:  7.0971174240112305\n",
      "test r2:  -0.26875338852526576\n",
      "train loss:  1.6596217155456543\n",
      "train r2:  0.8850510355926688\n",
      "test loss:  7.097639083862305\n",
      "test r2:  -0.2687957284570903\n",
      "train loss:  1.6595462560653687\n",
      "train r2:  0.8850540621675276\n",
      "test loss:  7.098209857940674\n",
      "test r2:  -0.2688520020581864\n",
      "train loss:  1.6594711542129517\n",
      "train r2:  0.885054130762166\n",
      "test loss:  7.098762035369873\n",
      "test r2:  -0.2689019577889089\n",
      "train loss:  1.6593959331512451\n",
      "train r2:  0.8850556439033368\n",
      "test loss:  7.099311828613281\n",
      "test r2:  -0.2689523174770987\n",
      "train loss:  1.6593209505081177\n",
      "train r2:  0.8850570616830178\n",
      "test loss:  7.099867343902588\n",
      "test r2:  -0.26900571606308055\n",
      "train loss:  1.6592460870742798\n",
      "train r2:  0.8850577227954475\n",
      "test loss:  7.100402355194092\n",
      "test r2:  -0.26905423287300523\n",
      "train loss:  1.6591711044311523\n",
      "train r2:  0.8850593365227568\n",
      "test loss:  7.100940227508545\n",
      "test r2:  -0.26910553531568526\n",
      "train loss:  1.6590967178344727\n",
      "train r2:  0.8850602686590683\n",
      "test loss:  7.101472854614258\n",
      "test r2:  -0.2691551338610658\n",
      "train loss:  1.6590220928192139\n",
      "train r2:  0.8850615646880404\n",
      "test loss:  7.10200834274292\n",
      "test r2:  -0.26920674056424465\n",
      "train loss:  1.6589475870132446\n",
      "train r2:  0.8850624751397697\n",
      "test loss:  7.102534770965576\n",
      "test r2:  -0.26925446987134727\n",
      "train loss:  1.6588733196258545\n",
      "train r2:  0.8850642466389568\n",
      "test loss:  7.103083610534668\n",
      "test r2:  -0.2693093298302218\n",
      "train loss:  1.6587992906570435\n",
      "train r2:  0.8850645334997129\n",
      "test loss:  7.103607177734375\n",
      "test r2:  -0.2693558768651483\n",
      "train loss:  1.6587252616882324\n",
      "train r2:  0.885066675574922\n",
      "test loss:  7.104158401489258\n",
      "test r2:  -0.26941083575087754\n",
      "train loss:  1.6586512327194214\n",
      "train r2:  0.8850670116888967\n",
      "test loss:  7.104689121246338\n",
      "test r2:  -0.26946007983908515\n",
      "train loss:  1.6585774421691895\n",
      "train r2:  0.8850686534242557\n",
      "test loss:  7.105226039886475\n",
      "test r2:  -0.2695113636556614\n",
      "train loss:  1.658503770828247\n",
      "train r2:  0.8850698222350338\n",
      "test loss:  7.105767726898193\n",
      "test r2:  -0.26956466485092\n",
      "train loss:  1.6584303379058838\n",
      "train r2:  0.8850704983596179\n",
      "test loss:  7.106285572052002\n",
      "test r2:  -0.2696119415604943\n",
      "train loss:  1.6583569049835205\n",
      "train r2:  0.8850724510073787\n",
      "test loss:  7.106825351715088\n",
      "test r2:  -0.26966681413203086\n",
      "train loss:  1.6582835912704468\n",
      "train r2:  0.8850726859004816\n",
      "test loss:  7.107332229614258\n",
      "test r2:  -0.26971364558064015\n",
      "train loss:  1.658210277557373\n",
      "train r2:  0.8850745434871767\n",
      "test loss:  7.107846260070801\n",
      "test r2:  -0.2697647805891068\n",
      "train loss:  1.658137321472168\n",
      "train r2:  0.8850752899322907\n",
      "test loss:  7.108344554901123\n",
      "test r2:  -0.269813393249527\n",
      "train loss:  1.6580642461776733\n",
      "train r2:  0.8850764467436424\n",
      "test loss:  7.10882568359375\n",
      "test r2:  -0.26986018024864156\n",
      "train loss:  1.6579911708831787\n",
      "train r2:  0.8850777550925991\n",
      "test loss:  7.109302997589111\n",
      "test r2:  -0.26990775876909745\n",
      "train loss:  1.6579186916351318\n",
      "train r2:  0.8850787056937204\n",
      "test loss:  7.109766960144043\n",
      "test r2:  -0.2699538180311376\n",
      "train loss:  1.6578459739685059\n",
      "train r2:  0.8850798128703776\n",
      "test loss:  7.110223770141602\n",
      "test r2:  -0.2699988821791408\n",
      "train loss:  1.6577731370925903\n",
      "train r2:  0.885081052307533\n",
      "test loss:  7.110678195953369\n",
      "test r2:  -0.2700442942055785\n",
      "train loss:  1.657700777053833\n",
      "train r2:  0.8850821094701433\n",
      "test loss:  7.111130237579346\n",
      "test r2:  -0.2700904020871979\n",
      "train loss:  1.6576282978057861\n",
      "train r2:  0.8850829748248723\n",
      "test loss:  7.111564636230469\n",
      "test r2:  -0.27013226803445045\n",
      "train loss:  1.657556176185608\n",
      "train r2:  0.8850846662783948\n",
      "test loss:  7.112011432647705\n",
      "test r2:  -0.2701798702400027\n",
      "train loss:  1.6574839353561401\n",
      "train r2:  0.8850849840134222\n",
      "test loss:  7.112431526184082\n",
      "test r2:  -0.2702203757811994\n",
      "train loss:  1.657411813735962\n",
      "train r2:  0.8850867831845848\n",
      "test loss:  7.112863063812256\n",
      "test r2:  -0.27026526374108895\n",
      "train loss:  1.6573398113250732\n",
      "train r2:  0.8850874940018345\n",
      "test loss:  7.113287448883057\n",
      "test r2:  -0.270308775511686\n",
      "train loss:  1.6572678089141846\n",
      "train r2:  0.8850885512296722\n",
      "test loss:  7.113703727722168\n",
      "test r2:  -0.27035039350277157\n",
      "train loss:  1.657196044921875\n",
      "train r2:  0.8850899197930838\n",
      "test loss:  7.114126205444336\n",
      "test r2:  -0.2703947785988212\n",
      "train loss:  1.6571242809295654\n",
      "train r2:  0.8850906907859616\n",
      "test loss:  7.114534378051758\n",
      "test r2:  -0.27043624674542066\n",
      "train loss:  1.6570526361465454\n",
      "train r2:  0.8850919540140332\n",
      "test loss:  7.1149396896362305\n",
      "test r2:  -0.2704785055121648\n",
      "train loss:  1.6569809913635254\n",
      "train r2:  0.8850929486082636\n",
      "test loss:  7.1153340339660645\n",
      "test r2:  -0.27051919898571075\n",
      "train loss:  1.6569095849990845\n",
      "train r2:  0.8850941335626012\n",
      "test loss:  7.115725994110107\n",
      "test r2:  -0.2705610257267965\n",
      "train loss:  1.6568384170532227\n",
      "train r2:  0.8850949472144114\n",
      "test loss:  7.116102695465088\n",
      "test r2:  -0.2705991981508391\n",
      "train loss:  1.6567670106887817\n",
      "train r2:  0.8850964475705204\n",
      "test loss:  7.116487503051758\n",
      "test r2:  -0.2706415126893895\n",
      "train loss:  1.6566957235336304\n",
      "train r2:  0.8850969377619234\n",
      "test loss:  7.116848468780518\n",
      "test r2:  -0.27067778527951525\n",
      "train loss:  1.6566247940063477\n",
      "train r2:  0.8850986333171322\n",
      "test loss:  7.117219924926758\n",
      "test r2:  -0.27071914726510604\n",
      "train loss:  1.6565536260604858\n",
      "train r2:  0.8850991065622827\n",
      "test loss:  7.1175689697265625\n",
      "test r2:  -0.2707550715630658\n",
      "train loss:  1.6564825773239136\n",
      "train r2:  0.885100645778736\n",
      "test loss:  7.117923259735107\n",
      "test r2:  -0.27079437231445014\n",
      "train loss:  1.6564117670059204\n",
      "train r2:  0.8851012906575194\n",
      "test loss:  7.118259906768799\n",
      "test r2:  -0.27082957163217936\n",
      "train loss:  1.6563408374786377\n",
      "train r2:  0.8851027336348297\n",
      "test loss:  7.118603229522705\n",
      "test r2:  -0.27086821104422776\n",
      "train loss:  1.656270146369934\n",
      "train r2:  0.8851032908644926\n",
      "test loss:  7.118926525115967\n",
      "test r2:  -0.2709019500541152\n",
      "train loss:  1.6561994552612305\n",
      "train r2:  0.8851048580997345\n",
      "test loss:  7.119259357452393\n",
      "test r2:  -0.270939690419729\n",
      "train loss:  1.6561288833618164\n",
      "train r2:  0.8851054427384566\n",
      "test loss:  7.119576930999756\n",
      "test r2:  -0.2709738468190155\n",
      "train loss:  1.6560585498809814\n",
      "train r2:  0.8851067569000756\n",
      "test loss:  7.1198954582214355\n",
      "test r2:  -0.27100942859656674\n",
      "train loss:  1.6559879779815674\n",
      "train r2:  0.8851076713531215\n",
      "test loss:  7.120206832885742\n",
      "test r2:  -0.2710440145555084\n",
      "train loss:  1.6559176445007324\n",
      "train r2:  0.8851086875169079\n",
      "test loss:  7.120510578155518\n",
      "test r2:  -0.271077785181026\n",
      "train loss:  1.655847430229187\n",
      "train r2:  0.8851098070927212\n",
      "test loss:  7.120811462402344\n",
      "test r2:  -0.27111210674924435\n",
      "train loss:  1.6557774543762207\n",
      "train r2:  0.8851106423265808\n",
      "test loss:  7.121102809906006\n",
      "test r2:  -0.27114388627826136\n",
      "train loss:  1.6557072401046753\n",
      "train r2:  0.8851119878895073\n",
      "test loss:  7.121399402618408\n",
      "test r2:  -0.2711791025671688\n",
      "train loss:  1.6556370258331299\n",
      "train r2:  0.8851125197685081\n",
      "test loss:  7.121675491333008\n",
      "test r2:  -0.27120872163609144\n",
      "train loss:  1.6555670499801636\n",
      "train r2:  0.8851141540683348\n",
      "test loss:  7.12196683883667\n",
      "test r2:  -0.27124431285982586\n",
      "train loss:  1.6554970741271973\n",
      "train r2:  0.8851144202603047\n",
      "test loss:  7.122226238250732\n",
      "test r2:  -0.2712715853305061\n",
      "train loss:  1.655427098274231\n",
      "train r2:  0.8851163299182225\n",
      "test loss:  7.122509479522705\n",
      "test r2:  -0.2713076421822582\n",
      "train loss:  1.6553574800491333\n",
      "train r2:  0.885116246676232\n",
      "test loss:  7.12275505065918\n",
      "test r2:  -0.2713327895812123\n",
      "train loss:  1.655287742614746\n",
      "train r2:  0.885118446777705\n",
      "test loss:  7.123032093048096\n",
      "test r2:  -0.2713687972562817\n",
      "train loss:  1.6552180051803589\n",
      "train r2:  0.8851182149513996\n",
      "test loss:  7.123267650604248\n",
      "test r2:  -0.2713930389481358\n",
      "train loss:  1.6551485061645508\n",
      "train r2:  0.8851204624190807\n",
      "test loss:  7.123535633087158\n",
      "test r2:  -0.271428835394913\n",
      "train loss:  1.6550787687301636\n",
      "train r2:  0.8851200964122281\n",
      "test loss:  7.123756408691406\n",
      "test r2:  -0.2714505928020057\n",
      "train loss:  1.6550092697143555\n",
      "train r2:  0.885122669845615\n",
      "test loss:  7.124020099639893\n",
      "test r2:  -0.2714876715906953\n",
      "train loss:  1.654939889907837\n",
      "train r2:  0.8851217651462023\n",
      "test loss:  7.124220371246338\n",
      "test r2:  -0.27150578445873186\n",
      "train loss:  1.6548705101013184\n",
      "train r2:  0.885124983558633\n",
      "test loss:  7.124485492706299\n",
      "test r2:  -0.2715453812574333\n",
      "train loss:  1.654801368713379\n",
      "train r2:  0.8851233453802374\n",
      "test loss:  7.124664306640625\n",
      "test r2:  -0.2715589835360792\n",
      "train loss:  1.6547318696975708\n",
      "train r2:  0.8851273289969783\n",
      "test loss:  7.124931335449219\n",
      "test r2:  -0.2716013268473927\n",
      "train loss:  1.6546629667282104\n",
      "train r2:  0.8851249614716314\n",
      "test loss:  7.12509298324585\n",
      "test r2:  -0.27161144069478826\n",
      "train loss:  1.6545937061309814\n",
      "train r2:  0.8851295706112514\n",
      "test loss:  7.125360488891602\n",
      "test r2:  -0.27165611119174105\n",
      "train loss:  1.6545246839523315\n",
      "train r2:  0.8851265196432241\n",
      "test loss:  7.1254987716674805\n",
      "test r2:  -0.2716607889531788\n",
      "train loss:  1.6544556617736816\n",
      "train r2:  0.8851321472378517\n",
      "test loss:  7.125781536102295\n",
      "test r2:  -0.27171203509971953\n",
      "train loss:  1.6543866395950317\n",
      "train r2:  0.8851274280241416\n",
      "test loss:  7.125875949859619\n",
      "test r2:  -0.2717052645662761\n",
      "train loss:  1.6543179750442505\n",
      "train r2:  0.885135394778001\n",
      "test loss:  7.126192092895508\n",
      "test r2:  -0.27176916467003287\n",
      "train loss:  1.6542489528656006\n",
      "train r2:  0.8851278156073347\n",
      "test loss:  7.12623405456543\n",
      "test r2:  -0.271747061551475\n",
      "train loss:  1.6541801691055298\n",
      "train r2:  0.8851390091822637\n",
      "test loss:  7.1265974044799805\n",
      "test r2:  -0.2718274176152009\n",
      "train loss:  1.6541115045547485\n",
      "train r2:  0.8851276738485823\n",
      "test loss:  7.126561164855957\n",
      "test r2:  -0.2717831257848502\n",
      "train loss:  1.6540429592132568\n",
      "train r2:  0.8851435275790364\n",
      "test loss:  7.127001762390137\n",
      "test r2:  -0.2718902969863475\n",
      "train loss:  1.6539747714996338\n",
      "train r2:  0.8851260931939327\n",
      "test loss:  7.1268415451049805\n",
      "test r2:  -0.27180861984971916\n",
      "train loss:  1.653906226158142\n",
      "train r2:  0.8851500515674544\n",
      "test loss:  7.1274309158325195\n",
      "test r2:  -0.2719640378338397\n",
      "train loss:  1.6538383960723877\n",
      "train r2:  0.8851218899174975\n",
      "test loss:  7.127063274383545\n",
      "test r2:  -0.2718186888543703\n",
      "train loss:  1.6537704467773438\n",
      "train r2:  0.885159674288972\n",
      "test loss:  7.127901077270508\n",
      "test r2:  -0.2720540655521624\n",
      "train loss:  1.6537033319473267\n",
      "train r2:  0.8851138305997532\n",
      "test loss:  7.127198696136475\n",
      "test r2:  -0.27180482363101244\n",
      "train loss:  1.6536370515823364\n",
      "train r2:  0.8851741890649263\n",
      "test loss:  7.128448963165283\n",
      "test r2:  -0.2721726014911916\n",
      "train loss:  1.6535720825195312\n",
      "train r2:  0.8850990890508418\n",
      "test loss:  7.127187728881836\n",
      "test r2:  -0.27174933587371664\n",
      "train loss:  1.653509497642517\n",
      "train r2:  0.8851973937730768\n",
      "test loss:  7.129147052764893\n",
      "test r2:  -0.27234212483490494\n",
      "train loss:  1.6534507274627686\n",
      "train r2:  0.885072660740165\n",
      "test loss:  7.126955986022949\n",
      "test r2:  -0.27162669809139706\n",
      "train loss:  1.6533983945846558\n",
      "train r2:  0.885234899415698\n",
      "test loss:  7.130088806152344\n",
      "test r2:  -0.27259154917471706\n",
      "train loss:  1.6533552408218384\n",
      "train r2:  0.8850281177643269\n",
      "test loss:  7.1264328956604\n",
      "test r2:  -0.2714132029733578\n",
      "train loss:  1.653326153755188\n",
      "train r2:  0.8852916653047994\n",
      "test loss:  7.1312947273254395\n",
      "test r2:  -0.27292835836199303\n",
      "train loss:  1.6533130407333374\n",
      "train r2:  0.8849631591828566\n",
      "test loss:  7.1256914138793945\n",
      "test r2:  -0.27113096488263744\n",
      "train loss:  1.6533185243606567\n",
      "train r2:  0.8853624525192941\n",
      "test loss:  7.132538318634033\n",
      "test r2:  -0.27328284830152816\n",
      "train loss:  1.653330683708191\n",
      "train r2:  0.8848928874459989\n",
      "test loss:  7.125118732452393\n",
      "test r2:  -0.27090229793869436\n",
      "train loss:  1.653328537940979\n",
      "train r2:  0.8854212516778446\n",
      "test loss:  7.13325309753418\n",
      "test r2:  -0.27346953242730243\n",
      "train loss:  1.653273582458496\n",
      "train r2:  0.8848606596815898\n",
      "test loss:  7.125319957733154\n",
      "test r2:  -0.27092985963422045\n",
      "train loss:  1.6531444787979126\n",
      "train r2:  0.8854257831052845\n",
      "test loss:  7.132728576660156\n",
      "test r2:  -0.2732603422413977\n",
      "train loss:  1.652949333190918\n",
      "train r2:  0.8849197132516982\n",
      "test loss:  7.1274518966674805\n",
      "test r2:  -0.2715866704836538\n",
      "train loss:  1.6527502536773682\n",
      "train r2:  0.8852936469828901\n",
      "test loss:  7.129890441894531\n",
      "test r2:  -0.2723583215082028\n",
      "train loss:  1.6526156663894653\n",
      "train r2:  0.8851280257349659\n",
      "test loss:  7.130598545074463\n",
      "test r2:  -0.2726000539225468\n",
      "train loss:  1.6525678634643555\n",
      "train r2:  0.885075711823066\n",
      "test loss:  7.126998424530029\n",
      "test r2:  -0.27150596208876077\n",
      "train loss:  1.652570366859436\n",
      "train r2:  0.8853139110771189\n",
      "test loss:  7.131786823272705\n",
      "test r2:  -0.2730787358651652\n",
      "train loss:  1.6525613069534302\n",
      "train r2:  0.8849644036204853\n",
      "test loss:  7.126220226287842\n",
      "test r2:  -0.2713786170348975\n",
      "train loss:  1.652496337890625\n",
      "train r2:  0.8853351733439913\n",
      "test loss:  7.130308151245117\n",
      "test r2:  -0.27276165226666516\n",
      "train loss:  1.652376413345337\n",
      "train r2:  0.8850265781424097\n",
      "test loss:  7.1272382736206055\n",
      "test r2:  -0.2718434253730255\n",
      "train loss:  1.6522451639175415\n",
      "train r2:  0.8852268008768716\n",
      "test loss:  7.127880573272705\n",
      "test r2:  -0.2721272420864671\n",
      "train loss:  1.6521499156951904\n",
      "train r2:  0.8851602324225007\n",
      "test loss:  7.128392219543457\n",
      "test r2:  -0.27236066250263824\n",
      "train loss:  1.652101993560791\n",
      "train r2:  0.88510469110452\n",
      "test loss:  7.125921726226807\n",
      "test r2:  -0.2716363582762136\n",
      "train loss:  1.6520752906799316\n",
      "train r2:  0.8852603706182639\n",
      "test loss:  7.128740310668945\n",
      "test r2:  -0.27260825023160073\n",
      "train loss:  1.6520320177078247\n",
      "train r2:  0.8850420055300952\n",
      "test loss:  7.125149250030518\n",
      "test r2:  -0.2715177857281037\n",
      "train loss:  1.651954174041748\n",
      "train r2:  0.8852802376927684\n",
      "test loss:  7.127933025360107\n",
      "test r2:  -0.2724439547645634\n",
      "train loss:  1.6518559455871582\n",
      "train r2:  0.8850758391680325\n",
      "test loss:  7.125946521759033\n",
      "test r2:  -0.27185376917312953\n",
      "train loss:  1.6517661809921265\n",
      "train r2:  0.885205442320683\n",
      "test loss:  7.1261820793151855\n",
      "test r2:  -0.2719479509099534\n",
      "train loss:  1.651701807975769\n",
      "train r2:  0.8851856105929109\n",
      "test loss:  7.127347946166992\n",
      "test r2:  -0.27234810115570496\n",
      "train loss:  1.6516563892364502\n",
      "train r2:  0.8850974681927194\n",
      "test loss:  7.1247968673706055\n",
      "test r2:  -0.2715732857539679\n",
      "train loss:  1.6516097784042358\n",
      "train r2:  0.8852673628191405\n",
      "test loss:  7.127534866333008\n",
      "test r2:  -0.27247199067610506\n",
      "train loss:  1.651546597480774\n",
      "train r2:  0.8850696322176792\n",
      "test loss:  7.124906539916992\n",
      "test r2:  -0.27168009739424015\n",
      "train loss:  1.6514687538146973\n",
      "train r2:  0.8852431113240807\n",
      "test loss:  7.126241683959961\n",
      "test r2:  -0.2721433566648128\n",
      "train loss:  1.6513899564743042\n",
      "train r2:  0.8851406439377151\n",
      "test loss:  7.125850200653076\n",
      "test r2:  -0.272055900360618\n",
      "train loss:  1.651322603225708\n",
      "train r2:  0.8851591682857548\n",
      "test loss:  7.124794006347656\n",
      "test r2:  -0.27177396311813684\n",
      "train loss:  1.6512680053710938\n",
      "train r2:  0.8852190333458422\n",
      "test loss:  7.126136779785156\n",
      "test r2:  -0.27225403193332887\n",
      "train loss:  1.651216745376587\n",
      "train r2:  0.8851109571603144\n",
      "test loss:  7.124082565307617\n",
      "test r2:  -0.27166509723203136\n",
      "train loss:  1.6511584520339966\n",
      "train r2:  0.8852372039335421\n",
      "test loss:  7.12540864944458\n",
      "test r2:  -0.27216067692187895\n",
      "train loss:  1.6510918140411377\n",
      "train r2:  0.885124195389037\n",
      "test loss:  7.123956203460693\n",
      "test r2:  -0.2717669810778496\n",
      "train loss:  1.6510218381881714\n",
      "train r2:  0.885207242297507\n",
      "test loss:  7.124231338500977\n",
      "test r2:  -0.271923947924708\n",
      "train loss:  1.650956153869629\n",
      "train r2:  0.8851690744410663\n",
      "test loss:  7.124059677124023\n",
      "test r2:  -0.27193846410725064\n",
      "train loss:  1.65089750289917\n",
      "train r2:  0.8851621637916556\n",
      "test loss:  7.123086452484131\n",
      "test r2:  -0.2716916006744283\n",
      "train loss:  1.6508429050445557\n",
      "train r2:  0.8852132100218286\n",
      "test loss:  7.123978137969971\n",
      "test r2:  -0.2720429882800939\n",
      "train loss:  1.6507867574691772\n",
      "train r2:  0.8851323089091038\n",
      "test loss:  7.122349262237549\n",
      "test r2:  -0.27159346272775253\n",
      "train loss:  1.6507261991500854\n",
      "train r2:  0.8852276120529015\n",
      "test loss:  7.123322010040283\n",
      "test r2:  -0.27196336429557344\n",
      "train loss:  1.6506625413894653\n",
      "train r2:  0.8851433718050232\n",
      "test loss:  7.122270107269287\n",
      "test r2:  -0.27169429538459733\n",
      "train loss:  1.650599479675293\n",
      "train r2:  0.8851993810799853\n",
      "test loss:  7.122233867645264\n",
      "test r2:  -0.27173781857991464\n",
      "train loss:  1.6505399942398071\n",
      "train r2:  0.8851873713216117\n",
      "test loss:  7.122451305389404\n",
      "test r2:  -0.2718594808205579\n",
      "train loss:  1.6504838466644287\n",
      "train r2:  0.8851584447349059\n",
      "test loss:  7.121354579925537\n",
      "test r2:  -0.27156834661672047\n",
      "train loss:  1.650428056716919\n",
      "train r2:  0.885219856385574\n",
      "test loss:  7.122193813323975\n",
      "test r2:  -0.2718867789425823\n",
      "train loss:  1.6503711938858032\n",
      "train r2:  0.8851476540192212\n",
      "test loss:  7.121004104614258\n",
      "test r2:  -0.2715697592102764\n",
      "train loss:  1.6503119468688965\n",
      "train r2:  0.8852145356734886\n",
      "test loss:  7.121403694152832\n",
      "test r2:  -0.2717580848869019\n",
      "train loss:  1.650252103805542\n",
      "train r2:  0.8851701964816084\n",
      "test loss:  7.12089729309082\n",
      "test r2:  -0.27165759538540013\n",
      "train loss:  1.650193452835083\n",
      "train r2:  0.8851893523910311\n",
      "test loss:  7.120535373687744\n",
      "test r2:  -0.2716069755052457\n",
      "train loss:  1.6501368284225464\n",
      "train r2:  0.8851972132898984\n",
      "test loss:  7.120666980743408\n",
      "test r2:  -0.2717118633602422\n",
      "train loss:  1.6500816345214844\n",
      "train r2:  0.8851709790013995\n",
      "test loss:  7.119836330413818\n",
      "test r2:  -0.2715132528750501\n",
      "train loss:  1.6500260829925537\n",
      "train r2:  0.8852111489443577\n",
      "test loss:  7.120187282562256\n",
      "test r2:  -0.2716942082961946\n",
      "train loss:  1.6499699354171753\n",
      "train r2:  0.885167678431436\n",
      "test loss:  7.119297981262207\n",
      "test r2:  -0.2714837392953351\n",
      "train loss:  1.6499131917953491\n",
      "train r2:  0.8852098942259979\n",
      "test loss:  7.119457721710205\n",
      "test r2:  -0.2716067046750599\n",
      "train loss:  1.649856448173523\n",
      "train r2:  0.88517885298218\n",
      "test loss:  7.118913173675537\n",
      "test r2:  -0.2715092519904043\n",
      "train loss:  1.649800419807434\n",
      "train r2:  0.8851959751175497\n",
      "test loss:  7.118589401245117\n",
      "test r2:  -0.27147798329672446\n",
      "train loss:  1.6497454643249512\n",
      "train r2:  0.8851988276813256\n",
      "test loss:  7.118582248687744\n",
      "test r2:  -0.2715472625717512\n",
      "train loss:  1.649691104888916\n",
      "train r2:  0.8851796568645862\n",
      "test loss:  7.117818832397461\n",
      "test r2:  -0.27137744106700423\n",
      "train loss:  1.64963698387146\n",
      "train r2:  0.8852129141434001\n",
      "test loss:  7.118072032928467\n",
      "test r2:  -0.27152607383226646\n",
      "train loss:  1.6495823860168457\n",
      "train r2:  0.8851765466243084\n",
      "test loss:  7.117300033569336\n",
      "test r2:  -0.27135417177492616\n",
      "train loss:  1.6495277881622314\n",
      "train r2:  0.8852102182259729\n",
      "test loss:  7.117330551147461\n",
      "test r2:  -0.2714339207964367\n",
      "train loss:  1.6494733095169067\n",
      "train r2:  0.8851888658955714\n",
      "test loss:  7.116927623748779\n",
      "test r2:  -0.27137616923223007\n",
      "train loss:  1.6494190692901611\n",
      "train r2:  0.8851976751292037\n",
      "test loss:  7.116561412811279\n",
      "test r2:  -0.2713312565385786\n",
      "train loss:  1.6493656635284424\n",
      "train r2:  0.8852036584539622\n",
      "test loss:  7.116502285003662\n",
      "test r2:  -0.2713805171227881\n",
      "train loss:  1.6493126153945923\n",
      "train r2:  0.8851891688422304\n",
      "test loss:  7.11591911315918\n",
      "test r2:  -0.27126556272095015\n",
      "train loss:  1.6492599248886108\n",
      "train r2:  0.8852105453227502\n",
      "test loss:  7.1159515380859375\n",
      "test r2:  -0.2713455055448797\n",
      "train loss:  1.6492071151733398\n",
      "train r2:  0.8851891864377062\n",
      "test loss:  7.11536979675293\n",
      "test r2:  -0.2712319439594195\n",
      "train loss:  1.6491543054580688\n",
      "train r2:  0.8852101696992013\n",
      "test loss:  7.115304470062256\n",
      "test r2:  -0.271283600445541\n",
      "train loss:  1.6491013765335083\n",
      "train r2:  0.8851948005257015\n",
      "test loss:  7.1148576736450195\n",
      "test r2:  -0.2712159416579334\n",
      "train loss:  1.6490492820739746\n",
      "train r2:  0.8852054304288182\n",
      "test loss:  7.114590644836426\n",
      "test r2:  -0.27120460724158457\n",
      "train loss:  1.6489973068237305\n",
      "train r2:  0.8852037705785769\n",
      "test loss:  7.1143646240234375\n",
      "test r2:  -0.2712077088094367\n",
      "train loss:  1.6489454507827759\n",
      "train r2:  0.8851987830699222\n",
      "test loss:  7.113873481750488\n",
      "test r2:  -0.2711275061990812\n",
      "train loss:  1.6488945484161377\n",
      "train r2:  0.885212022512068\n",
      "test loss:  7.113809108734131\n",
      "test r2:  -0.2711815223999581\n",
      "train loss:  1.6488430500030518\n",
      "train r2:  0.8851958917127857\n",
      "test loss:  7.113238334655762\n",
      "test r2:  -0.27107801611276194\n",
      "train loss:  1.6487921476364136\n",
      "train r2:  0.8852140674815937\n",
      "test loss:  7.1131391525268555\n",
      "test r2:  -0.2711223982922102\n",
      "train loss:  1.6487411260604858\n",
      "train r2:  0.8851999283384386\n",
      "test loss:  7.112679958343506\n",
      "test r2:  -0.2710543549556419\n",
      "train loss:  1.6486904621124268\n",
      "train r2:  0.8852103139168347\n",
      "test loss:  7.112411975860596\n",
      "test r2:  -0.2710470461495085\n",
      "train loss:  1.6486400365829468\n",
      "train r2:  0.8852074004093815\n",
      "test loss:  7.112125873565674\n",
      "test r2:  -0.27103344877009716\n",
      "train loss:  1.6485899686813354\n",
      "train r2:  0.885205882701083\n",
      "test loss:  7.111709117889404\n",
      "test r2:  -0.2709794584171892\n",
      "train loss:  1.6485400199890137\n",
      "train r2:  0.8852131327768021\n",
      "test loss:  7.11152458190918\n",
      "test r2:  -0.27099811284318887\n",
      "train loss:  1.648490309715271\n",
      "train r2:  0.8852045215432769\n",
      "test loss:  7.111055374145508\n",
      "test r2:  -0.27092697336233607\n",
      "train loss:  1.6484408378601074\n",
      "train r2:  0.8852155678867799\n",
      "test loss:  7.1108856201171875\n",
      "test r2:  -0.2709503159585991\n",
      "train loss:  1.648391604423523\n",
      "train r2:  0.8852059255721192\n",
      "test loss:  7.1104326248168945\n",
      "test r2:  -0.2708850943764012\n",
      "train loss:  1.648342251777649\n",
      "train r2:  0.8852156801082075\n",
      "test loss:  7.110212326049805\n",
      "test r2:  -0.270892412628718\n",
      "train loss:  1.6482932567596436\n",
      "train r2:  0.885209537264426\n",
      "test loss:  7.109836101531982\n",
      "test r2:  -0.27085191967970146\n",
      "train loss:  1.6482446193695068\n",
      "train r2:  0.8852137797485378\n",
      "test loss:  7.109514236450195\n",
      "test r2:  -0.2708279656253578\n",
      "train loss:  1.6481962203979492\n",
      "train r2:  0.8852144183449016\n",
      "test loss:  7.10923957824707\n",
      "test r2:  -0.2708195205982158\n",
      "train loss:  1.6481479406356812\n",
      "train r2:  0.8852116551641233\n",
      "test loss:  7.108823776245117\n",
      "test r2:  -0.27076715486594427\n",
      "train loss:  1.6481000185012817\n",
      "train r2:  0.8852184268835827\n",
      "test loss:  7.108611583709717\n",
      "test r2:  -0.2707784369473243\n",
      "train loss:  1.6480520963668823\n",
      "train r2:  0.8852113166488014\n",
      "test loss:  7.1081647872924805\n",
      "test r2:  -0.27071717008390705\n",
      "train loss:  1.6480046510696411\n",
      "train r2:  0.8852199652580865\n",
      "test loss:  7.107940196990967\n",
      "test r2:  -0.2707252415484993\n",
      "train loss:  1.6479569673538208\n",
      "train r2:  0.8852135003057312\n",
      "test loss:  7.10753059387207\n",
      "test r2:  -0.2706762707196131\n",
      "train loss:  1.6479098796844482\n",
      "train r2:  0.8852194198967869\n",
      "test loss:  7.107240676879883\n",
      "test r2:  -0.2706650686153722\n",
      "train loss:  1.6478629112243652\n",
      "train r2:  0.8852170307469022\n",
      "test loss:  7.106895446777344\n",
      "test r2:  -0.270636963078168\n",
      "train loss:  1.6478160619735718\n",
      "train r2:  0.8852183153953648\n",
      "test loss:  7.106537342071533\n",
      "test r2:  -0.27060539119313654\n",
      "train loss:  1.6477693319320679\n",
      "train r2:  0.8852203380444919\n",
      "test loss:  7.1062421798706055\n",
      "test r2:  -0.2705935650304421\n",
      "train loss:  1.6477229595184326\n",
      "train r2:  0.8852180025947035\n",
      "test loss:  7.1058454513549805\n",
      "test r2:  -0.2705501195428859\n",
      "train loss:  1.6476768255233765\n",
      "train r2:  0.8852226137190677\n",
      "test loss:  7.105575084686279\n",
      "test r2:  -0.27054595152305994\n",
      "train loss:  1.6476308107376099\n",
      "train r2:  0.8852185847674097\n",
      "test loss:  7.105164051055908\n",
      "test r2:  -0.27049831608791597\n",
      "train loss:  1.6475847959518433\n",
      "train r2:  0.885224083029758\n",
      "test loss:  7.104893207550049\n",
      "test r2:  -0.27049460943590375\n",
      "train loss:  1.6475390195846558\n",
      "train r2:  0.8852199618383153\n",
      "test loss:  7.104491710662842\n",
      "test r2:  -0.2704503101092324\n",
      "train loss:  1.6474937200546265\n",
      "train r2:  0.88522461944018\n",
      "test loss:  7.104189872741699\n",
      "test r2:  -0.27043776003955067\n",
      "train loss:  1.6474484205245972\n",
      "train r2:  0.8852223575055661\n",
      "test loss:  7.103825569152832\n",
      "test r2:  -0.27040600312238605\n",
      "train loss:  1.647403359413147\n",
      "train r2:  0.8852242683790865\n",
      "test loss:  7.1034746170043945\n",
      "test r2:  -0.2703785970820187\n",
      "train loss:  1.6473588943481445\n",
      "train r2:  0.8852251851980538\n",
      "test loss:  7.103154182434082\n",
      "test r2:  -0.27036074762567774\n",
      "train loss:  1.647314190864563\n",
      "train r2:  0.8852240121354633\n",
      "test loss:  7.102767467498779\n",
      "test r2:  -0.2703223227886393\n",
      "train loss:  1.647269606590271\n",
      "train r2:  0.8852273758891112\n",
      "test loss:  7.102468967437744\n",
      "test r2:  -0.2703111734412913\n",
      "train loss:  1.6472253799438477\n",
      "train r2:  0.8852247493926486\n",
      "test loss:  7.102074146270752\n",
      "test r2:  -0.270270560829696\n",
      "train loss:  1.6471810340881348\n",
      "train r2:  0.8852285049642029\n",
      "test loss:  7.101768493652344\n",
      "test r2:  -0.27025786696174103\n",
      "train loss:  1.64713716506958\n",
      "train r2:  0.8852261837292673\n",
      "test loss:  7.101379871368408\n",
      "test r2:  -0.27021987065207775\n",
      "train loss:  1.6470935344696045\n",
      "train r2:  0.8852293355337149\n",
      "test loss:  7.101062297821045\n",
      "test r2:  -0.2702039497368749\n",
      "train loss:  1.647050142288208\n",
      "train r2:  0.8852276929948213\n",
      "test loss:  7.100684642791748\n",
      "test r2:  -0.2701693966142753\n",
      "train loss:  1.6470065116882324\n",
      "train r2:  0.8852300756211845\n",
      "test loss:  7.100350856781006\n",
      "test r2:  -0.27014874055596283\n",
      "train loss:  1.6469635963439941\n",
      "train r2:  0.8852293661415283\n",
      "test loss:  7.09998893737793\n",
      "test r2:  -0.2701196955413485\n",
      "train loss:  1.6469206809997559\n",
      "train r2:  0.8852305677170289\n",
      "test loss:  7.099634170532227\n",
      "test r2:  -0.2700927554648995\n",
      "train loss:  1.6468780040740967\n",
      "train r2:  0.8852312580598695\n",
      "test loss:  7.0992937088012695\n",
      "test r2:  -0.27007050394786725\n",
      "train loss:  1.6468353271484375\n",
      "train r2:  0.8852308893466063\n",
      "test loss:  7.098912239074707\n",
      "test r2:  -0.27003630753952934\n",
      "train loss:  1.6467928886413574\n",
      "train r2:  0.8852331144211846\n",
      "test loss:  7.09858512878418\n",
      "test r2:  -0.27001907107330414\n",
      "train loss:  1.6467506885528564\n",
      "train r2:  0.885231576581387\n",
      "test loss:  7.098190784454346\n",
      "test r2:  -0.26998191542889427\n",
      "train loss:  1.6467084884643555\n",
      "train r2:  0.8852343563824702\n",
      "test loss:  7.097860813140869\n",
      "test r2:  -0.26996470694074004\n",
      "train loss:  1.6466667652130127\n",
      "train r2:  0.8852327722441662\n",
      "test loss:  7.097470283508301\n",
      "test r2:  -0.26992874239204445\n",
      "train loss:  1.64662504196167\n",
      "train r2:  0.8852352459852642\n",
      "test loss:  7.097134113311768\n",
      "test r2:  -0.2699093797808494\n",
      "train loss:  1.6465834379196167\n",
      "train r2:  0.8852341446694967\n",
      "test loss:  7.0967512130737305\n",
      "test r2:  -0.26987591552954737\n",
      "train loss:  1.6465420722961426\n",
      "train r2:  0.8852360980340224\n",
      "test loss:  7.09640645980835\n",
      "test r2:  -0.2698542379193547\n",
      "train loss:  1.646500825881958\n",
      "train r2:  0.8852354477391707\n",
      "test loss:  7.096029281616211\n",
      "test r2:  -0.2698226476990604\n",
      "train loss:  1.646459937095642\n",
      "train r2:  0.885236994008296\n",
      "test loss:  7.095675945281982\n",
      "test r2:  -0.26979901880069734\n",
      "train loss:  1.6464191675186157\n",
      "train r2:  0.8852367373390471\n",
      "test loss:  7.095300197601318\n",
      "test r2:  -0.26976913916704226\n",
      "train loss:  1.646378517150879\n",
      "train r2:  0.8852378202634209\n",
      "test loss:  7.094933986663818\n",
      "test r2:  -0.2697422635343727\n",
      "train loss:  1.6463379859924316\n",
      "train r2:  0.8852381828071996\n",
      "test loss:  7.094568252563477\n",
      "test r2:  -0.26971608748456366\n",
      "train loss:  1.646297812461853\n",
      "train r2:  0.8852384287322891\n",
      "test loss:  7.094189167022705\n",
      "test r2:  -0.2696851871264907\n",
      "train loss:  1.6462576389312744\n",
      "train r2:  0.8852396767907178\n",
      "test loss:  7.093834400177002\n",
      "test r2:  -0.2696621847771621\n",
      "train loss:  1.646217703819275\n",
      "train r2:  0.8852392353813519\n",
      "test loss:  7.093450546264648\n",
      "test r2:  -0.2696299712234682\n",
      "train loss:  1.6461780071258545\n",
      "train r2:  0.8852408020952849\n",
      "test loss:  7.09309720993042\n",
      "test r2:  -0.26960724177298223\n",
      "train loss:  1.6461386680603027\n",
      "train r2:  0.8852403138603708\n",
      "test loss:  7.092712879180908\n",
      "test r2:  -0.26957506593438363\n",
      "train loss:  1.6460989713668823\n",
      "train r2:  0.8852418285477572\n",
      "test loss:  7.092355728149414\n",
      "test r2:  -0.2695520593699108\n",
      "train loss:  1.6460597515106201\n",
      "train r2:  0.8852413254373556\n",
      "test loss:  7.091965198516846\n",
      "test r2:  -0.2695190815683741\n",
      "train loss:  1.6460206508636475\n",
      "train r2:  0.8852429411260776\n",
      "test loss:  7.091607570648193\n",
      "test r2:  -0.26949664661678496\n",
      "train loss:  1.6459815502166748\n",
      "train r2:  0.8852422795417161\n",
      "test loss:  7.091209888458252\n",
      "test r2:  -0.26946264750505255\n",
      "train loss:  1.6459426879882812\n",
      "train r2:  0.8852440219143952\n",
      "test loss:  7.090850830078125\n",
      "test r2:  -0.2694402824044251\n",
      "train loss:  1.6459040641784668\n",
      "train r2:  0.8852432988267314\n",
      "test loss:  7.090454578399658\n",
      "test r2:  -0.2694065052001693\n",
      "train loss:  1.6458660364151\n",
      "train r2:  0.88524500677101\n",
      "test loss:  7.090092182159424\n",
      "test r2:  -0.26938315896634757\n",
      "train loss:  1.6458276510238647\n",
      "train r2:  0.8852444607201975\n",
      "test loss:  7.08970308303833\n",
      "test r2:  -0.269351508247059\n",
      "train loss:  1.6457895040512085\n",
      "train r2:  0.8852457364063724\n",
      "test loss:  7.089332103729248\n",
      "test r2:  -0.2693259169307425\n",
      "train loss:  1.6457514762878418\n",
      "train r2:  0.8852457214594218\n",
      "test loss:  7.088945388793945\n",
      "test r2:  -0.2692955546733131\n",
      "train loss:  1.6457138061523438\n",
      "train r2:  0.8852466699301464\n",
      "test loss:  7.0885701179504395\n",
      "test r2:  -0.269269549097209\n",
      "train loss:  1.6456761360168457\n",
      "train r2:  0.8852466273387884\n",
      "test loss:  7.088174819946289\n",
      "test r2:  -0.26923776034730795\n",
      "train loss:  1.6456385850906372\n",
      "train r2:  0.8852477948204653\n",
      "test loss:  7.087800979614258\n",
      "test r2:  -0.269212563640588\n",
      "train loss:  1.6456013917922974\n",
      "train r2:  0.8852475735242746\n",
      "test loss:  7.087404251098633\n",
      "test r2:  -0.2691808563629936\n",
      "train loss:  1.645564317703247\n",
      "train r2:  0.8852487160735614\n",
      "test loss:  7.0870256423950195\n",
      "test r2:  -0.26915432196447897\n",
      "train loss:  1.6455273628234863\n",
      "train r2:  0.885248705970461\n",
      "test loss:  7.086636066436768\n",
      "test r2:  -0.26912469660356275\n",
      "train loss:  1.6454904079437256\n",
      "train r2:  0.885249435464788\n",
      "test loss:  7.086246967315674\n",
      "test r2:  -0.26909540448482216\n",
      "train loss:  1.6454538106918335\n",
      "train r2:  0.8852500549575175\n",
      "test loss:  7.085867404937744\n",
      "test r2:  -0.2690687869590753\n",
      "train loss:  1.6454172134399414\n",
      "train r2:  0.8852500763078908\n",
      "test loss:  7.085468769073486\n",
      "test r2:  -0.26903725817174307\n",
      "train loss:  1.6453808546066284\n",
      "train r2:  0.8852511510680727\n",
      "test loss:  7.085086345672607\n",
      "test r2:  -0.269010719005077\n",
      "train loss:  1.6453447341918945\n",
      "train r2:  0.8852511171341755\n",
      "test loss:  7.084689140319824\n",
      "test r2:  -0.26898015767322625\n",
      "train loss:  1.645308494567871\n",
      "train r2:  0.8852519167345799\n",
      "test loss:  7.0842976570129395\n",
      "test r2:  -0.2689516098244289\n",
      "train loss:  1.6452727317810059\n",
      "train r2:  0.8852522535817814\n",
      "test loss:  7.0839033126831055\n",
      "test r2:  -0.2689221682626446\n",
      "train loss:  1.6452369689941406\n",
      "train r2:  0.8852527901913769\n",
      "test loss:  7.083508014678955\n",
      "test r2:  -0.2688931685782403\n",
      "train loss:  1.6452014446258545\n",
      "train r2:  0.8852531495182397\n",
      "test loss:  7.083108425140381\n",
      "test r2:  -0.2688628462561278\n",
      "train loss:  1.645166039466858\n",
      "train r2:  0.8852538783311621\n",
      "test loss:  7.0827178955078125\n",
      "test r2:  -0.26883583736509387\n",
      "train loss:  1.6451306343078613\n",
      "train r2:  0.8852538020165182\n",
      "test loss:  7.082305431365967\n",
      "test r2:  -0.2688021713152977\n",
      "train loss:  1.6450954675674438\n",
      "train r2:  0.8852551599244338\n",
      "test loss:  7.08192253112793\n",
      "test r2:  -0.26877793162246255\n",
      "train loss:  1.6450607776641846\n",
      "train r2:  0.8852545025270812\n",
      "test loss:  7.081503391265869\n",
      "test r2:  -0.2687429504230865\n",
      "train loss:  1.645025610923767\n",
      "train r2:  0.8852560858237203\n",
      "test loss:  7.081115245819092\n",
      "test r2:  -0.26871733047328306\n",
      "train loss:  1.644991159439087\n",
      "train r2:  0.8852556755805447\n",
      "test loss:  7.080705165863037\n",
      "test r2:  -0.26868534670844335\n",
      "train loss:  1.6449567079544067\n",
      "train r2:  0.8852566053585884\n",
      "test loss:  7.08030366897583\n",
      "test r2:  -0.26865633021261814\n",
      "train loss:  1.644922137260437\n",
      "train r2:  0.885256906937166\n",
      "test loss:  7.079897880554199\n",
      "test r2:  -0.268625749509128\n",
      "train loss:  1.6448878049850464\n",
      "train r2:  0.8852575588478462\n",
      "test loss:  7.079502582550049\n",
      "test r2:  -0.2685989392501096\n",
      "train loss:  1.6448538303375244\n",
      "train r2:  0.8852573339140744\n",
      "test loss:  7.079074382781982\n",
      "test r2:  -0.2685624202276591\n",
      "train loss:  1.644819736480713\n",
      "train r2:  0.8852592534485851\n",
      "test loss:  7.078701496124268\n",
      "test r2:  -0.2685426239235915\n",
      "train loss:  1.6447862386703491\n",
      "train r2:  0.8852574661774026\n",
      "test loss:  7.078250408172607\n",
      "test r2:  -0.2685001163977958\n",
      "train loss:  1.6447523832321167\n",
      "train r2:  0.8852605889238058\n",
      "test loss:  7.077881336212158\n",
      "test r2:  -0.2684827165527439\n",
      "train loss:  1.6447187662124634\n",
      "train r2:  0.8852582187092297\n",
      "test loss:  7.077426433563232\n",
      "test r2:  -0.2684394845464724\n",
      "train loss:  1.6446855068206787\n",
      "train r2:  0.8852614454322\n",
      "test loss:  7.077053546905518\n",
      "test r2:  -0.2684219899118794\n",
      "train loss:  1.644652247428894\n",
      "train r2:  0.8852590807454481\n",
      "test loss:  7.076590061187744\n",
      "test r2:  -0.268376589215946\n",
      "train loss:  1.644619345664978\n",
      "train r2:  0.8852627158388645\n",
      "test loss:  7.076235771179199\n",
      "test r2:  -0.26836532048866735\n",
      "train loss:  1.6445863246917725\n",
      "train r2:  0.8852590020418106\n",
      "test loss:  7.075732707977295\n",
      "test r2:  -0.2683084251886152\n",
      "train loss:  1.644553542137146\n",
      "train r2:  0.8852650538185942\n",
      "test loss:  7.07542610168457\n",
      "test r2:  -0.26831211241983155\n",
      "train loss:  1.644520878791809\n",
      "train r2:  0.885258088637141\n",
      "test loss:  7.074867248535156\n",
      "test r2:  -0.2682385122532902\n",
      "train loss:  1.6444883346557617\n",
      "train r2:  0.8852677717351842\n",
      "test loss:  7.074615001678467\n",
      "test r2:  -0.2682589951384027\n",
      "train loss:  1.644455909729004\n",
      "train r2:  0.8852571244975533\n",
      "test loss:  7.073998928070068\n",
      "test r2:  -0.26816802107718707\n",
      "train loss:  1.644423484802246\n",
      "train r2:  0.8852705771954404\n",
      "test loss:  7.073807239532471\n",
      "test r2:  -0.2682082455800936\n",
      "train loss:  1.644391655921936\n",
      "train r2:  0.8852556007179556\n",
      "test loss:  7.073104381561279\n",
      "test r2:  -0.26809131910110895\n",
      "train loss:  1.6443599462509155\n",
      "train r2:  0.8852745898201437\n",
      "test loss:  7.073019504547119\n",
      "test r2:  -0.26816589395318946\n",
      "train loss:  1.6443283557891846\n",
      "train r2:  0.8852520973516067\n",
      "test loss:  7.0721588134765625\n",
      "test r2:  -0.26800159445124727\n",
      "train loss:  1.6442970037460327\n",
      "train r2:  0.885281273239643\n",
      "test loss:  7.072274684906006\n",
      "test r2:  -0.2681385883307481\n",
      "train loss:  1.6442663669586182\n",
      "train r2:  0.8852451952491215\n",
      "test loss:  7.071145534515381\n",
      "test r2:  -0.2678923095249137\n",
      "train loss:  1.6442360877990723\n",
      "train r2:  0.885292017920322\n",
      "test loss:  7.071597099304199\n",
      "test r2:  -0.26813335845505337\n",
      "train loss:  1.6442066431045532\n",
      "train r2:  0.8852334239694719\n",
      "test loss:  7.070039749145508\n",
      "test r2:  -0.2677561611156849\n",
      "train loss:  1.6441787481307983\n",
      "train r2:  0.8853084973776761\n",
      "test loss:  7.0710248947143555\n",
      "test r2:  -0.2681617674375829\n",
      "train loss:  1.6441528797149658\n",
      "train r2:  0.8852142445238289\n",
      "test loss:  7.068784713745117\n",
      "test r2:  -0.26757457414386265\n",
      "train loss:  1.6441305875778198\n",
      "train r2:  0.8853345925579683\n",
      "test loss:  7.070644855499268\n",
      "test r2:  -0.26825076655011015\n",
      "train loss:  1.6441136598587036\n",
      "train r2:  0.8851816817269189\n",
      "test loss:  7.067268371582031\n",
      "test r2:  -0.267313462941837\n",
      "train loss:  1.6441057920455933\n",
      "train r2:  0.8853775066851204\n",
      "test loss:  7.070587158203125\n",
      "test r2:  -0.26843887092551877\n",
      "train loss:  1.6441117525100708\n",
      "train r2:  0.8851271178663332\n",
      "test loss:  7.065370559692383\n",
      "test r2:  -0.2669355798775608\n",
      "train loss:  1.6441378593444824\n",
      "train r2:  0.8854447571305113\n",
      "test loss:  7.070938587188721\n",
      "test r2:  -0.2687525892167628\n",
      "train loss:  1.6441888809204102\n",
      "train r2:  0.8850441722638982\n",
      "test loss:  7.063119411468506\n",
      "test r2:  -0.26644804839732594\n",
      "train loss:  1.6442670822143555\n",
      "train r2:  0.8855342984890203\n",
      "test loss:  7.071447849273682\n",
      "test r2:  -0.269113766984433\n",
      "train loss:  1.6443467140197754\n",
      "train r2:  0.8849497852156909\n",
      "test loss:  7.060705661773682\n",
      "test r2:  -0.26591763578573446\n",
      "train loss:  1.6444003582000732\n",
      "train r2:  0.8856325850980481\n",
      "test loss:  7.07151985168457\n",
      "test r2:  -0.2693297150173848\n",
      "train loss:  1.6443405151367188\n",
      "train r2:  0.8848896494163888\n",
      "test loss:  7.059898853302002\n",
      "test r2:  -0.26588952269486055\n",
      "train loss:  1.6441740989685059\n",
      "train r2:  0.8856274656607623\n",
      "test loss:  7.068753242492676\n",
      "test r2:  -0.2686789782276644\n",
      "train loss:  1.6439340114593506\n",
      "train r2:  0.88502339632648\n",
      "test loss:  7.063675403594971\n",
      "test r2:  -0.2672286730502247\n",
      "train loss:  1.6437630653381348\n",
      "train r2:  0.8853329816374447\n",
      "test loss:  7.062334060668945\n",
      "test r2:  -0.2669190520839966\n",
      "train loss:  1.6437410116195679\n",
      "train r2:  0.885393695110323\n",
      "test loss:  7.067409992218018\n",
      "test r2:  -0.2685355715202986\n",
      "train loss:  1.6438180208206177\n",
      "train r2:  0.8850386003492056\n",
      "test loss:  7.059698104858398\n",
      "test r2:  -0.26628183439653363\n",
      "train loss:  1.6438782215118408\n",
      "train r2:  0.8855176209925236\n",
      "test loss:  7.065690517425537\n",
      "test r2:  -0.2682414306528482\n",
      "train loss:  1.6438368558883667\n",
      "train r2:  0.8850872125457866\n",
      "test loss:  7.061237812042236\n",
      "test r2:  -0.2669540621134847\n",
      "train loss:  1.643711805343628\n",
      "train r2:  0.8853613618274446\n",
      "test loss:  7.061968803405762\n",
      "test r2:  -0.26734278851546867\n",
      "train loss:  1.6435914039611816\n",
      "train r2:  0.8852687359149503\n",
      "test loss:  7.062109470367432\n",
      "test r2:  -0.26749447071023913\n",
      "train loss:  1.6435537338256836\n",
      "train r2:  0.8852288124784511\n",
      "test loss:  7.05976676940918\n",
      "test r2:  -0.2668827044815081\n",
      "train loss:  1.6435850858688354\n",
      "train r2:  0.885352976427687\n",
      "test loss:  7.061854839324951\n",
      "test r2:  -0.26768086331925955\n",
      "train loss:  1.6436059474945068\n",
      "train r2:  0.8851703663769009\n",
      "test loss:  7.058104991912842\n",
      "test r2:  -0.2666098933662975\n",
      "train loss:  1.643562912940979\n",
      "train r2:  0.8853963531931843\n",
      "test loss:  7.061142444610596\n",
      "test r2:  -0.26766304846069144\n",
      "train loss:  1.6434760093688965\n",
      "train r2:  0.8851622109608446\n",
      "test loss:  7.05792236328125\n",
      "test r2:  -0.26679486133439645\n",
      "train loss:  1.643408179283142\n",
      "train r2:  0.8853431962448237\n",
      "test loss:  7.058349609375\n",
      "test r2:  -0.2670055338378319\n",
      "train loss:  1.6433905363082886\n",
      "train r2:  0.8852923230557138\n",
      "test loss:  7.059570789337158\n",
      "test r2:  -0.2675022483108691\n",
      "train loss:  1.6433987617492676\n",
      "train r2:  0.8851771543381782\n",
      "test loss:  7.055368423461914\n",
      "test r2:  -0.266318876031328\n",
      "train loss:  1.6433879137039185\n",
      "train r2:  0.8854258675564785\n",
      "test loss:  7.0592360496521\n",
      "test r2:  -0.2676055907358692\n",
      "train loss:  1.6433395147323608\n",
      "train r2:  0.8851418143090171\n",
      "test loss:  7.0556535720825195\n",
      "test r2:  -0.2666303070927316\n",
      "train loss:  1.643278956413269\n",
      "train r2:  0.885345559324097\n",
      "test loss:  7.0558271408081055\n",
      "test r2:  -0.26679811145638443\n",
      "train loss:  1.6432406902313232\n",
      "train r2:  0.8853023673836234\n",
      "test loss:  7.0571088790893555\n",
      "test r2:  -0.26729327305635686\n",
      "train loss:  1.6432294845581055\n",
      "train r2:  0.8851886545272901\n",
      "test loss:  7.053564548492432\n",
      "test r2:  -0.26632715027344234\n",
      "train loss:  1.6432206630706787\n",
      "train r2:  0.885389716362595\n",
      "test loss:  7.056033134460449\n",
      "test r2:  -0.2671949149103823\n",
      "train loss:  1.6431926488876343\n",
      "train r2:  0.8851956118108174\n",
      "test loss:  7.053817272186279\n",
      "test r2:  -0.2666106183506245\n",
      "train loss:  1.6431487798690796\n",
      "train r2:  0.8853160422873876\n",
      "test loss:  7.053683757781982\n",
      "test r2:  -0.2666955399316995\n",
      "train loss:  1.6431077718734741\n",
      "train r2:  0.8852904377040242\n",
      "test loss:  7.05393648147583\n",
      "test r2:  -0.26687225794084757\n",
      "train loss:  1.6430823802947998\n",
      "train r2:  0.8852460358390023\n",
      "test loss:  7.052291393280029\n",
      "test r2:  -0.26647487269863257\n",
      "train loss:  1.6430673599243164\n",
      "train r2:  0.8853250506571834\n",
      "test loss:  7.053051471710205\n",
      "test r2:  -0.26683786469879167\n",
      "train loss:  1.64304780960083\n",
      "train r2:  0.8852387962533999\n",
      "test loss:  7.051367282867432\n",
      "test r2:  -0.2664208955113938\n",
      "train loss:  1.6430158615112305\n",
      "train r2:  0.8853225097071599\n",
      "test loss:  7.051934719085693\n",
      "test r2:  -0.266722765847361\n",
      "train loss:  1.6429790258407593\n",
      "train r2:  0.8852496925501577\n",
      "test loss:  7.05067253112793\n",
      "test r2:  -0.26645920046874694\n",
      "train loss:  1.6429486274719238\n",
      "train r2:  0.885299062440604\n",
      "test loss:  7.050274848937988\n",
      "test r2:  -0.26644599881313913\n",
      "train loss:  1.6429269313812256\n",
      "train r2:  0.8852950173839745\n",
      "test loss:  7.050515651702881\n",
      "test r2:  -0.2666497060016848\n",
      "train loss:  1.6429071426391602\n",
      "train r2:  0.885243063949951\n",
      "test loss:  7.048548698425293\n",
      "test r2:  -0.26616030375932986\n",
      "train loss:  1.6428823471069336\n",
      "train r2:  0.8853416631323423\n",
      "test loss:  7.049727916717529\n",
      "test r2:  -0.26663644237649287\n",
      "train loss:  1.6428520679473877\n",
      "train r2:  0.8852318979830193\n",
      "test loss:  7.048035144805908\n",
      "test r2:  -0.26623907890228216\n",
      "train loss:  1.6428213119506836\n",
      "train r2:  0.8853104203419297\n",
      "test loss:  7.047769069671631\n",
      "test r2:  -0.266272882917149\n",
      "train loss:  1.642795443534851\n",
      "train r2:  0.8852960591495972\n",
      "test loss:  7.048040866851807\n",
      "test r2:  -0.26647267893930815\n",
      "train loss:  1.6427733898162842\n",
      "train r2:  0.885245710066281\n",
      "test loss:  7.046182155609131\n",
      "test r2:  -0.2660255520784931\n",
      "train loss:  1.6427509784698486\n",
      "train r2:  0.8853347581924768\n",
      "test loss:  7.046987533569336\n",
      "test r2:  -0.26639320608552763\n",
      "train loss:  1.6427252292633057\n",
      "train r2:  0.8852480775895474\n",
      "test loss:  7.045681476593018\n",
      "test r2:  -0.2661089467245923\n",
      "train loss:  1.6426970958709717\n",
      "train r2:  0.8853023493723149\n",
      "test loss:  7.045304775238037\n",
      "test r2:  -0.26612031654979096\n",
      "train loss:  1.6426701545715332\n",
      "train r2:  0.8852923462631572\n",
      "test loss:  7.045180797576904\n",
      "test r2:  -0.2661961721380146\n",
      "train loss:  1.6426455974578857\n",
      "train r2:  0.8852689967430962\n",
      "test loss:  7.044086933135986\n",
      "test r2:  -0.2659788489849175\n",
      "train loss:  1.6426231861114502\n",
      "train r2:  0.885308766517217\n",
      "test loss:  7.04417085647583\n",
      "test r2:  -0.26612916009035104\n",
      "train loss:  1.6425995826721191\n",
      "train r2:  0.8852688816129574\n",
      "test loss:  7.043182849884033\n",
      "test r2:  -0.26593724729730517\n",
      "train loss:  1.642574667930603\n",
      "train r2:  0.8853035165736192\n",
      "test loss:  7.043067932128906\n",
      "test r2:  -0.26602795069628526\n",
      "train loss:  1.6425485610961914\n",
      "train r2:  0.885276492380801\n",
      "test loss:  7.042275905609131\n",
      "test r2:  -0.2659058160153942\n",
      "train loss:  1.642523169517517\n",
      "train r2:  0.8852955934600614\n",
      "test loss:  7.0418500900268555\n",
      "test r2:  -0.26589401402526147\n",
      "train loss:  1.6424994468688965\n",
      "train r2:  0.8852909453163154\n",
      "test loss:  7.041524887084961\n",
      "test r2:  -0.2659239483288047\n",
      "train loss:  1.6424766778945923\n",
      "train r2:  0.8852767547021754\n",
      "test loss:  7.040500164031982\n",
      "test r2:  -0.26573102887411104\n",
      "train loss:  1.6424529552459717\n",
      "train r2:  0.885311060741984\n",
      "test loss:  7.040639877319336\n",
      "test r2:  -0.2659001211015559\n",
      "train loss:  1.6424288749694824\n",
      "train r2:  0.8852669900336184\n",
      "test loss:  7.039513111114502\n",
      "test r2:  -0.2656821211003415\n",
      "train loss:  1.6424041986465454\n",
      "train r2:  0.8853064265781481\n",
      "test loss:  7.039274215698242\n",
      "test r2:  -0.2657340437959661\n",
      "train loss:  1.6423801183700562\n",
      "train r2:  0.8852877295246661\n",
      "test loss:  7.038853645324707\n",
      "test r2:  -0.2657319550219981\n",
      "train loss:  1.6423567533493042\n",
      "train r2:  0.8852805770565737\n",
      "test loss:  7.037878036499023\n",
      "test r2:  -0.2655613046453895\n",
      "train loss:  1.6423338651657104\n",
      "train r2:  0.8853097532695269\n",
      "test loss:  7.037897109985352\n",
      "test r2:  -0.2656957562153299\n",
      "train loss:  1.6423107385635376\n",
      "train r2:  0.8852730562335892\n",
      "test loss:  7.036890983581543\n",
      "test r2:  -0.26551567124400055\n",
      "train loss:  1.6422874927520752\n",
      "train r2:  0.8853042771811179\n",
      "test loss:  7.036577224731445\n",
      "test r2:  -0.265553017667723\n",
      "train loss:  1.642263650894165\n",
      "train r2:  0.8852883107599735\n",
      "test loss:  7.036027908325195\n",
      "test r2:  -0.2655115920371409\n",
      "train loss:  1.642240285873413\n",
      "train r2:  0.8852896678611921\n",
      "test loss:  7.035338878631592\n",
      "test r2:  -0.26543147795300714\n",
      "train loss:  1.6422175168991089\n",
      "train r2:  0.8852992050494085\n",
      "test loss:  7.034994602203369\n",
      "test r2:  -0.26545711595542554\n",
      "train loss:  1.6421948671340942\n",
      "train r2:  0.8852859292713756\n",
      "test loss:  7.034244060516357\n",
      "test r2:  -0.2653543837882757\n",
      "train loss:  1.6421725749969482\n",
      "train r2:  0.8853005393534985\n",
      "test loss:  7.033890247344971\n",
      "test r2:  -0.26538160050763104\n",
      "train loss:  1.6421496868133545\n",
      "train r2:  0.8852867520500803\n",
      "test loss:  7.033140182495117\n",
      "test r2:  -0.26528186031458323\n",
      "train loss:  1.6421267986297607\n",
      "train r2:  0.8853005649618212\n",
      "test loss:  7.032748699188232\n",
      "test r2:  -0.26529514730945225\n",
      "train loss:  1.642104148864746\n",
      "train r2:  0.8852898261139998\n",
      "test loss:  7.032107353210449\n",
      "test r2:  -0.2652336784918794\n",
      "train loss:  1.6420817375183105\n",
      "train r2:  0.8852951821281596\n",
      "test loss:  7.031493663787842\n",
      "test r2:  -0.26517783715402965\n",
      "train loss:  1.6420598030090332\n",
      "train r2:  0.8852994663166813\n",
      "test loss:  7.031120300292969\n",
      "test r2:  -0.26520031662475163\n",
      "train loss:  1.6420375108718872\n",
      "train r2:  0.8852865660458208\n",
      "test loss:  7.030271530151367\n",
      "test r2:  -0.2650760153269518\n",
      "train loss:  1.6420155763626099\n",
      "train r2:  0.8853054699524404\n",
      "test loss:  7.029962539672852\n",
      "test r2:  -0.2651192177043231\n",
      "train loss:  1.6419932842254639\n",
      "train r2:  0.885288100197472\n",
      "test loss:  7.029222011566162\n",
      "test r2:  -0.26503067665385505\n",
      "train loss:  1.641971230506897\n",
      "train r2:  0.8852991322766505\n",
      "test loss:  7.028651237487793\n",
      "test r2:  -0.264995924645266\n",
      "train loss:  1.6419492959976196\n",
      "train r2:  0.8852984638934279\n",
      "test loss:  7.02817964553833\n",
      "test r2:  -0.2649915892239978\n",
      "train loss:  1.6419278383255005\n",
      "train r2:  0.8852912282153115\n",
      "test loss:  7.027409076690674\n",
      "test r2:  -0.26489735154332084\n",
      "train loss:  1.6419061422348022\n",
      "train r2:  0.8853033156003328\n",
      "test loss:  7.026982307434082\n",
      "test r2:  -0.2649107824429684\n",
      "train loss:  1.6418848037719727\n",
      "train r2:  0.8852920466396825\n",
      "test loss:  7.026260852813721\n",
      "test r2:  -0.2648318055670633\n",
      "train loss:  1.641863226890564\n",
      "train r2:  0.8853008607624249\n",
      "test loss:  7.025724411010742\n",
      "test r2:  -0.26481402167690193\n",
      "train loss:  1.6418415307998657\n",
      "train r2:  0.8852961987642713\n",
      "test loss:  7.025090217590332\n",
      "test r2:  -0.26476413678845767\n",
      "train loss:  1.6418204307556152\n",
      "train r2:  0.8852986140222405\n",
      "test loss:  7.024481296539307\n",
      "test r2:  -0.2647242160462955\n",
      "train loss:  1.6417992115020752\n",
      "train r2:  0.8852987673335801\n",
      "test loss:  7.023886203765869\n",
      "test r2:  -0.2646912167225355\n",
      "train loss:  1.6417779922485352\n",
      "train r2:  0.8852972963935094\n",
      "test loss:  7.023208141326904\n",
      "test r2:  -0.26463152527849365\n",
      "train loss:  1.6417570114135742\n",
      "train r2:  0.8853016591402074\n",
      "test loss:  7.022674560546875\n",
      "test r2:  -0.2646201567026816\n",
      "train loss:  1.6417360305786133\n",
      "train r2:  0.8852953692626926\n",
      "test loss:  7.02192497253418\n",
      "test r2:  -0.26454153515237566\n",
      "train loss:  1.6417150497436523\n",
      "train r2:  0.8853036553051781\n",
      "test loss:  7.021399974822998\n",
      "test r2:  -0.26453353570981064\n",
      "train loss:  1.641694188117981\n",
      "train r2:  0.8852966834709138\n",
      "test loss:  7.020698547363281\n",
      "test r2:  -0.26447266695017624\n",
      "train loss:  1.6416734457015991\n",
      "train r2:  0.8853010093392123\n",
      "test loss:  7.020042419433594\n",
      "test r2:  -0.2644275185238665\n",
      "train loss:  1.6416529417037964\n",
      "train r2:  0.8853018465732772\n",
      "test loss:  7.019458293914795\n",
      "test r2:  -0.2644067023515182\n",
      "train loss:  1.6416325569152832\n",
      "train r2:  0.8852973766248632\n",
      "test loss:  7.018693923950195\n",
      "test r2:  -0.2643315496887766\n",
      "train loss:  1.641611933708191\n",
      "train r2:  0.8853045328594394\n",
      "test loss:  7.018124103546143\n",
      "test r2:  -0.2643181162207173\n",
      "train loss:  1.6415916681289673\n",
      "train r2:  0.8852983025808537\n",
      "test loss:  7.017392158508301\n",
      "test r2:  -0.2642546212418877\n",
      "train loss:  1.6415714025497437\n",
      "train r2:  0.8853028667020219\n",
      "test loss:  7.016735553741455\n",
      "test r2:  -0.2642180717384961\n",
      "train loss:  1.6415510177612305\n",
      "train r2:  0.885301496165078\n",
      "test loss:  7.016054153442383\n",
      "test r2:  -0.264174742280056\n",
      "train loss:  1.6415308713912964\n",
      "train r2:  0.8853014825141194\n",
      "test loss:  7.0153398513793945\n",
      "test r2:  -0.26412446568223147\n",
      "train loss:  1.641511082649231\n",
      "train r2:  0.8853028223700699\n",
      "test loss:  7.014656066894531\n",
      "test r2:  -0.26408514187249255\n",
      "train loss:  1.6414908170700073\n",
      "train r2:  0.8853017779283641\n",
      "test loss:  7.013925075531006\n",
      "test r2:  -0.26403153926369827\n",
      "train loss:  1.6414709091186523\n",
      "train r2:  0.8853037760834138\n",
      "test loss:  7.013243198394775\n",
      "test r2:  -0.26399697684648027\n",
      "train loss:  1.641451120376587\n",
      "train r2:  0.885301489365009\n",
      "test loss:  7.012466907501221\n",
      "test r2:  -0.2639346454563738\n",
      "train loss:  1.6414315700531006\n",
      "train r2:  0.8853051580105719\n",
      "test loss:  7.011783123016357\n",
      "test r2:  -0.26390397112260944\n",
      "train loss:  1.6414119005203247\n",
      "train r2:  0.8853017925719315\n",
      "test loss:  7.010993957519531\n",
      "test r2:  -0.2638432993277764\n",
      "train loss:  1.6413923501968384\n",
      "train r2:  0.8853048084493547\n",
      "test loss:  7.010255813598633\n",
      "test r2:  -0.2637994377124968\n",
      "train loss:  1.641372799873352\n",
      "train r2:  0.8853041465156566\n",
      "test loss:  7.009512424468994\n",
      "test r2:  -0.26375679398715723\n",
      "train loss:  1.6413534879684448\n",
      "train r2:  0.8853031322510418\n",
      "test loss:  7.008694171905518\n",
      "test r2:  -0.2636937097657357\n",
      "train loss:  1.641334056854248\n",
      "train r2:  0.885306373274412\n",
      "test loss:  7.007959365844727\n",
      "test r2:  -0.26366012691281004\n",
      "train loss:  1.6413147449493408\n",
      "train r2:  0.885303031048131\n",
      "test loss:  7.007115364074707\n",
      "test r2:  -0.26359542524346113\n",
      "train loss:  1.6412957906723022\n",
      "train r2:  0.8853063488422822\n",
      "test loss:  7.006331920623779\n",
      "test r2:  -0.26355261191693913\n",
      "train loss:  1.6412765979766846\n",
      "train r2:  0.8853047939944692\n",
      "test loss:  7.005505561828613\n",
      "test r2:  -0.2634985041544451\n",
      "train loss:  1.6412575244903564\n",
      "train r2:  0.8853055646455825\n",
      "test loss:  7.004664897918701\n",
      "test r2:  -0.26344463629469406\n",
      "train loss:  1.6412385702133179\n",
      "train r2:  0.8853060933078346\n",
      "test loss:  7.003823757171631\n",
      "test r2:  -0.2633939891123662\n",
      "train loss:  1.6412196159362793\n",
      "train r2:  0.8853057586004651\n",
      "test loss:  7.002950668334961\n",
      "test r2:  -0.2633366295524773\n",
      "train loss:  1.6412009000778198\n",
      "train r2:  0.8853067366108304\n",
      "test loss:  7.0020856857299805\n",
      "test r2:  -0.2632862288024742\n",
      "train loss:  1.6411820650100708\n",
      "train r2:  0.8853059994525163\n",
      "test loss:  7.001174449920654\n",
      "test r2:  -0.2632241873233523\n",
      "train loss:  1.6411633491516113\n",
      "train r2:  0.8853076696684608\n",
      "test loss:  7.000289440155029\n",
      "test r2:  -0.2631759834827667\n",
      "train loss:  1.641144871711731\n",
      "train r2:  0.8853060677420274\n",
      "test loss:  6.999332904815674\n",
      "test r2:  -0.26310946179688277\n",
      "train loss:  1.6411263942718506\n",
      "train r2:  0.8853082943672573\n",
      "test loss:  6.998412609100342\n",
      "test r2:  -0.2630584032140195\n",
      "train loss:  1.6411079168319702\n",
      "train r2:  0.8853069579606762\n",
      "test loss:  6.997439861297607\n",
      "test r2:  -0.2629961129225935\n",
      "train loss:  1.6410894393920898\n",
      "train r2:  0.8853078853078269\n",
      "test loss:  6.996450424194336\n",
      "test r2:  -0.2629339345516444\n",
      "train loss:  1.6410709619522095\n",
      "train r2:  0.8853084933057367\n",
      "test loss:  6.9954633712768555\n",
      "test r2:  -0.26287775203289243\n",
      "train loss:  1.6410528421401978\n",
      "train r2:  0.8853075851507429\n",
      "test loss:  6.994418144226074\n",
      "test r2:  -0.2628085094242951\n",
      "train loss:  1.6410346031188965\n",
      "train r2:  0.8853093043557724\n",
      "test loss:  6.993391036987305\n",
      "test r2:  -0.26275112330367234\n",
      "train loss:  1.6410164833068848\n",
      "train r2:  0.8853081861429103\n",
      "test loss:  6.992307662963867\n",
      "test r2:  -0.2626818022663564\n",
      "train loss:  1.6409984827041626\n",
      "train r2:  0.8853094224904021\n",
      "test loss:  6.9912190437316895\n",
      "test r2:  -0.26261840267923087\n",
      "train loss:  1.6409803628921509\n",
      "train r2:  0.8853090317719595\n",
      "test loss:  6.990092754364014\n",
      "test r2:  -0.262549103266547\n",
      "train loss:  1.6409624814987183\n",
      "train r2:  0.8853097004656352\n",
      "test loss:  6.988949775695801\n",
      "test r2:  -0.2624821527952179\n",
      "train loss:  1.6409448385238647\n",
      "train r2:  0.8853095184709708\n",
      "test loss:  6.987766742706299\n",
      "test r2:  -0.26241004815693625\n",
      "train loss:  1.6409269571304321\n",
      "train r2:  0.8853101875348356\n",
      "test loss:  6.9865641593933105\n",
      "test r2:  -0.2623395542772422\n",
      "train loss:  1.6409093141555786\n",
      "train r2:  0.8853101570149449\n",
      "test loss:  6.985325813293457\n",
      "test r2:  -0.2622664081214696\n",
      "train loss:  1.6408915519714355\n",
      "train r2:  0.8853103310642697\n",
      "test loss:  6.9840474128723145\n",
      "test r2:  -0.26218941885607117\n",
      "train loss:  1.6408740282058716\n",
      "train r2:  0.885311032096407\n",
      "test loss:  6.982751369476318\n",
      "test r2:  -0.2621165328717816\n",
      "train loss:  1.6408562660217285\n",
      "train r2:  0.8853104640564947\n",
      "test loss:  6.981396198272705\n",
      "test r2:  -0.26203389858608883\n",
      "train loss:  1.6408389806747437\n",
      "train r2:  0.8853116167610249\n",
      "test loss:  6.980026721954346\n",
      "test r2:  -0.2619573944555271\n",
      "train loss:  1.6408212184906006\n",
      "train r2:  0.885311082179042\n",
      "test loss:  6.9785990715026855\n",
      "test r2:  -0.26187301152810294\n",
      "train loss:  1.6408041715621948\n",
      "train r2:  0.8853118446984085\n",
      "test loss:  6.977142810821533\n",
      "test r2:  -0.2617907484782329\n",
      "train loss:  1.6407864093780518\n",
      "train r2:  0.8853117401169949\n",
      "test loss:  6.9756364822387695\n",
      "test r2:  -0.261703860948151\n",
      "train loss:  1.6407692432403564\n",
      "train r2:  0.8853122212938478\n",
      "test loss:  6.974091053009033\n",
      "test r2:  -0.2616169284196632\n",
      "train loss:  1.640751838684082\n",
      "train r2:  0.8853122605265901\n",
      "test loss:  6.972497463226318\n",
      "test r2:  -0.2615268325094007\n",
      "train loss:  1.6407346725463867\n",
      "train r2:  0.885312600614346\n",
      "test loss:  6.970859050750732\n",
      "test r2:  -0.2614349407019121\n",
      "train loss:  1.6407175064086914\n",
      "train r2:  0.8853128640534901\n",
      "test loss:  6.96917724609375\n",
      "test r2:  -0.26134217150129535\n",
      "train loss:  1.640700340270996\n",
      "train r2:  0.8853129299799716\n",
      "test loss:  6.967438220977783\n",
      "test r2:  -0.2612447763990329\n",
      "train loss:  1.6406832933425903\n",
      "train r2:  0.8853135110032618\n",
      "test loss:  6.965668201446533\n",
      "test r2:  -0.26115003574391427\n",
      "train loss:  1.640665888786316\n",
      "train r2:  0.8853131618046499\n",
      "test loss:  6.963831901550293\n",
      "test r2:  -0.2610473347049287\n",
      "train loss:  1.6406488418579102\n",
      "train r2:  0.8853141466706095\n",
      "test loss:  6.961970329284668\n",
      "test r2:  -0.2609497955258411\n",
      "train loss:  1.640631914138794\n",
      "train r2:  0.8853136438255896\n",
      "test loss:  6.960052013397217\n",
      "test r2:  -0.2608452687968754\n",
      "train loss:  1.6406147480010986\n",
      "train r2:  0.8853144295572916\n",
      "test loss:  6.958099842071533\n",
      "test r2:  -0.2607428861385075\n",
      "train loss:  1.6405978202819824\n",
      "train r2:  0.8853143865872359\n",
      "test loss:  6.956110954284668\n",
      "test r2:  -0.26063824730472884\n",
      "train loss:  1.6405807733535767\n",
      "train r2:  0.8853146527398463\n",
      "test loss:  6.954092502593994\n",
      "test r2:  -0.2605330509740893\n",
      "train loss:  1.6405636072158813\n",
      "train r2:  0.8853150028731706\n",
      "test loss:  6.952049255371094\n",
      "test r2:  -0.2604284599447162\n",
      "train loss:  1.6405466794967651\n",
      "train r2:  0.8853150594253287\n",
      "test loss:  6.94999361038208\n",
      "test r2:  -0.26032291631322724\n",
      "train loss:  1.640529751777649\n",
      "train r2:  0.8853154729274321\n",
      "test loss:  6.947930812835693\n",
      "test r2:  -0.2602198297913134\n",
      "train loss:  1.6405129432678223\n",
      "train r2:  0.8853154753486837\n",
      "test loss:  6.945869445800781\n",
      "test r2:  -0.26011525236182265\n",
      "train loss:  1.6404962539672852\n",
      "train r2:  0.8853161159076597\n",
      "test loss:  6.943840026855469\n",
      "test r2:  -0.26001773450423715\n",
      "train loss:  1.640479326248169\n",
      "train r2:  0.8853156218590478\n",
      "test loss:  6.94181489944458\n",
      "test r2:  -0.25991515369312657\n",
      "train loss:  1.6404623985290527\n",
      "train r2:  0.8853167973189557\n",
      "test loss:  6.939857482910156\n",
      "test r2:  -0.25982435606170906\n",
      "train loss:  1.6404457092285156\n",
      "train r2:  0.8853160538739087\n",
      "test loss:  6.937934875488281\n",
      "test r2:  -0.25972939410537355\n",
      "train loss:  1.6404290199279785\n",
      "train r2:  0.8853169950351447\n",
      "test loss:  6.936084270477295\n",
      "test r2:  -0.25964351805015085\n",
      "train loss:  1.640412449836731\n",
      "train r2:  0.8853167754068739\n",
      "test loss:  6.934310436248779\n",
      "test r2:  -0.25955962563607127\n",
      "train loss:  1.6403961181640625\n",
      "train r2:  0.8853171816736466\n",
      "test loss:  6.932611465454102\n",
      "test r2:  -0.2594815623855111\n",
      "train loss:  1.6403796672821045\n",
      "train r2:  0.8853171979344453\n",
      "test loss:  6.931006908416748\n",
      "test r2:  -0.2594070931496246\n",
      "train loss:  1.640363335609436\n",
      "train r2:  0.8853176011778091\n",
      "test loss:  6.92948579788208\n",
      "test r2:  -0.25933884228376836\n",
      "train loss:  1.6403471231460571\n",
      "train r2:  0.8853176150767073\n",
      "test loss:  6.928062438964844\n",
      "test r2:  -0.2592747772281865\n",
      "train loss:  1.6403313875198364\n",
      "train r2:  0.8853177751287558\n",
      "test loss:  6.926719665527344\n",
      "test r2:  -0.2592137101109919\n",
      "train loss:  1.640315294265747\n",
      "train r2:  0.8853182875287401\n",
      "test loss:  6.925473213195801\n",
      "test r2:  -0.2591608601942368\n",
      "train loss:  1.6402993202209473\n",
      "train r2:  0.8853178983213367\n",
      "test loss:  6.924300670623779\n",
      "test r2:  -0.2591065710863245\n",
      "train loss:  1.6402838230133057\n",
      "train r2:  0.8853188147714974\n",
      "test loss:  6.923202991485596\n",
      "test r2:  -0.2590616359938309\n",
      "train loss:  1.6402682065963745\n",
      "train r2:  0.8853182746389042\n",
      "test loss:  6.9221954345703125\n",
      "test r2:  -0.25901582062028194\n",
      "train loss:  1.640252709388733\n",
      "train r2:  0.8853190860926037\n",
      "test loss:  6.921199321746826\n",
      "test r2:  -0.25897480868009515\n",
      "train loss:  1.6402374505996704\n",
      "train r2:  0.8853188829043133\n",
      "test loss:  6.920364856719971\n",
      "test r2:  -0.2589382380886933\n",
      "train loss:  1.640222191810608\n",
      "train r2:  0.8853193645952002\n",
      "test loss:  6.91939115524292\n",
      "test r2:  -0.2588984623081678\n",
      "train loss:  1.6402069330215454\n",
      "train r2:  0.8853191975100841\n",
      "test loss:  6.918810844421387\n",
      "test r2:  -0.25887095711564667\n",
      "train loss:  1.640191912651062\n",
      "train r2:  0.885320239987416\n",
      "test loss:  6.917638778686523\n",
      "test r2:  -0.25882762821840655\n",
      "train loss:  1.6401771306991577\n",
      "train r2:  0.8853189191000378\n",
      "test loss:  6.917759895324707\n",
      "test r2:  -0.25882391147708406\n",
      "train loss:  1.640162467956543\n",
      "train r2:  0.8853215829212632\n",
      "test loss:  6.915624618530273\n",
      "test r2:  -0.25875062552517236\n",
      "train loss:  1.6401482820510864\n",
      "train r2:  0.8853176381326167\n",
      "test loss:  6.918369770050049\n",
      "test r2:  -0.25883952409278677\n",
      "train loss:  1.6401385068893433\n",
      "train r2:  0.8853250601067144\n",
      "test loss:  6.9150004386901855\n",
      "test r2:  -0.2587525410563025\n",
      "train loss:  1.6401177644729614\n",
      "train r2:  0.8853115014937994\n",
      "test loss:  6.912158489227295\n",
      "test r2:  -0.25855339626778373\n",
      "train loss:  1.640110969543457\n",
      "train r2:  0.8853318883083643\n",
      "test loss:  6.92390775680542\n",
      "test r2:  -0.2591272236750284\n",
      "train loss:  1.640120506286621\n",
      "train r2:  0.8853147824387372\n",
      "test loss:  6.929763317108154\n",
      "test r2:  -0.2594045513725898\n",
      "train loss:  1.6401187181472778\n",
      "train r2:  0.8853121252770766\n",
      "test loss:  6.930566787719727\n",
      "test r2:  -0.2594072021330187\n",
      "train loss:  1.640107274055481\n",
      "train r2:  0.8853218186984424\n",
      "test loss:  6.927606582641602\n",
      "test r2:  -0.25929093284376736\n",
      "train loss:  1.640091896057129\n",
      "train r2:  0.88531790121126\n",
      "test loss:  6.9222636222839355\n",
      "test r2:  -0.25906407864738634\n",
      "train loss:  1.6400762796401978\n",
      "train r2:  0.8853158236568183\n",
      "test loss:  6.916038990020752\n",
      "test r2:  -0.2587377569642717\n",
      "train loss:  1.6400619745254517\n",
      "train r2:  0.8853309628121426\n",
      "test loss:  6.91081428527832\n",
      "test r2:  -0.2585836076771211\n",
      "train loss:  1.640048623085022\n",
      "train r2:  0.8853156644963479\n",
      "test loss:  6.906079292297363\n",
      "test r2:  -0.25833954155984484\n",
      "train loss:  1.6400357484817505\n",
      "train r2:  0.8853291561804654\n",
      "test loss:  6.9025187492370605\n",
      "test r2:  -0.2582036672537855\n",
      "train loss:  1.6400212049484253\n",
      "train r2:  0.8853283627662559\n",
      "test loss:  6.8997111320495605\n",
      "test r2:  -0.2581346203401209\n",
      "train loss:  1.6400043964385986\n",
      "train r2:  0.8853188921295245\n",
      "test loss:  6.896456718444824\n",
      "test r2:  -0.257950793152268\n",
      "train loss:  1.639981985092163\n",
      "train r2:  0.8853339161812116\n",
      "test loss:  6.892323017120361\n",
      "test r2:  -0.25784760451244293\n",
      "train loss:  1.6399445533752441\n",
      "train r2:  0.8853220626122662\n",
      "test loss:  6.887301445007324\n",
      "test r2:  -0.2576304746742988\n",
      "train loss:  1.6403121948242188\n",
      "train r2:  0.8853259707104612\n",
      "test loss:  6.916111469268799\n",
      "test r2:  -0.25872142219481975\n",
      "train loss:  1.6399554014205933\n",
      "train r2:  0.8853364744497348\n",
      "test loss:  6.953073024749756\n",
      "test r2:  -0.2606752640541965\n",
      "train loss:  1.6401363611221313\n",
      "train r2:  0.8852818952301471\n",
      "test loss:  6.976594924926758\n",
      "test r2:  -0.26176462304292536\n",
      "train loss:  1.6480317115783691\n",
      "train r2:  0.885233443108813\n",
      "test loss:  6.9233317375183105\n",
      "test r2:  -0.2589762077065394\n",
      "train loss:  1.6399405002593994\n",
      "train r2:  0.8853507874151416\n",
      "test loss:  6.891296863555908\n",
      "test r2:  -0.258061212050714\n",
      "train loss:  1.639896273612976\n",
      "train r2:  0.8852597430703264\n",
      "test loss:  6.870038986206055\n",
      "test r2:  -0.2569332162920823\n",
      "train loss:  1.6442327499389648\n",
      "train r2:  0.885304969962094\n",
      "test loss:  6.8724684715271\n",
      "test r2:  -0.2573187428056196\n",
      "train loss:  1.6403003931045532\n",
      "train r2:  0.8852824666890788\n",
      "test loss:  6.874731540679932\n",
      "test r2:  -0.257232550475303\n",
      "train loss:  1.6398341655731201\n",
      "train r2:  0.8853257261226462\n",
      "test loss:  6.876821517944336\n",
      "test r2:  -0.2570899804884057\n",
      "train loss:  1.639855146408081\n",
      "train r2:  0.8853748935272127\n",
      "test loss:  6.882235527038574\n",
      "test r2:  -0.25799494563298175\n",
      "train loss:  1.6398706436157227\n",
      "train r2:  0.8851995169394122\n",
      "test loss:  6.88063383102417\n",
      "test r2:  -0.2568908265158698\n",
      "train loss:  1.6398733854293823\n",
      "train r2:  0.8854526152225445\n",
      "test loss:  6.887040615081787\n",
      "test r2:  -0.25819448000487544\n",
      "train loss:  1.639868974685669\n",
      "train r2:  0.8851910806093143\n",
      "test loss:  6.885622024536133\n",
      "test r2:  -0.2572389410395053\n",
      "train loss:  1.6398646831512451\n",
      "train r2:  0.8854112060224195\n",
      "test loss:  6.890088081359863\n",
      "test r2:  -0.25808334663743326\n",
      "train loss:  1.6398636102676392\n",
      "train r2:  0.8852458715819396\n",
      "test loss:  6.889505386352539\n",
      "test r2:  -0.25744018508045574\n",
      "train loss:  1.639866590499878\n",
      "train r2:  0.8853978740744702\n",
      "test loss:  6.893926620483398\n",
      "test r2:  -0.25834542498771373\n",
      "train loss:  1.6398718357086182\n",
      "train r2:  0.885217928150412\n",
      "test loss:  6.891392230987549\n",
      "test r2:  -0.2571927498586071\n",
      "train loss:  1.6398814916610718\n",
      "train r2:  0.8854769266764896\n",
      "test loss:  6.898262023925781\n",
      "test r2:  -0.25885526364618583\n",
      "train loss:  1.6398899555206299\n",
      "train r2:  0.8851340226174118\n",
      "test loss:  6.893174648284912\n",
      "test r2:  -0.25702110098847264\n",
      "train loss:  1.6398953199386597\n",
      "train r2:  0.885536506628334\n",
      "test loss:  6.900672435760498\n",
      "test r2:  -0.2589253230055448\n",
      "train loss:  1.6398903131484985\n",
      "train r2:  0.8851402315626328\n",
      "test loss:  6.896374702453613\n",
      "test r2:  -0.2573999582549189\n",
      "train loss:  1.6398767232894897\n",
      "train r2:  0.8854743569800728\n",
      "test loss:  6.90103006362915\n",
      "test r2:  -0.2585850212497047\n",
      "train loss:  1.6398534774780273\n",
      "train r2:  0.8852279101166615\n",
      "test loss:  6.898833751678467\n",
      "test r2:  -0.25780195365240965\n",
      "train loss:  1.6398245096206665\n",
      "train r2:  0.8853992258972612\n",
      "test loss:  6.90095853805542\n",
      "test r2:  -0.2584018024722481\n",
      "train loss:  1.639793038368225\n",
      "train r2:  0.8852722308185822\n",
      "test loss:  6.899165630340576\n",
      "test r2:  -0.25792496625895467\n",
      "train loss:  1.639764428138733\n",
      "train r2:  0.8853721038264823\n",
      "test loss:  6.899824619293213\n",
      "test r2:  -0.2582594007429304\n",
      "train loss:  1.6397409439086914\n",
      "train r2:  0.8852959909619024\n",
      "test loss:  6.898451328277588\n",
      "test r2:  -0.25808434602396346\n",
      "train loss:  1.6397223472595215\n",
      "train r2:  0.8853259866288898\n",
      "test loss:  6.896774768829346\n",
      "test r2:  -0.25786699093572096\n",
      "train loss:  1.639707326889038\n",
      "train r2:  0.8853633443022474\n",
      "test loss:  6.897404193878174\n",
      "test r2:  -0.25838325668964535\n",
      "train loss:  1.6396938562393188\n",
      "train r2:  0.8852428478294218\n",
      "test loss:  6.893032550811768\n",
      "test r2:  -0.2574498409149486\n",
      "train loss:  1.6396793127059937\n",
      "train r2:  0.8854311859641004\n",
      "test loss:  6.8950886726379395\n",
      "test r2:  -0.2584211501809215\n",
      "train loss:  1.6396602392196655\n",
      "train r2:  0.8852130604446806\n",
      "test loss:  6.8904218673706055\n",
      "test r2:  -0.25741225614509644\n",
      "train loss:  1.6396373510360718\n",
      "train r2:  0.8854178690186915\n",
      "test loss:  6.891576766967773\n",
      "test r2:  -0.2581158878049179\n",
      "train loss:  1.6396108865737915\n",
      "train r2:  0.8852575980225073\n",
      "test loss:  6.8884735107421875\n",
      "test r2:  -0.25753624756220517\n",
      "train loss:  1.6395840644836426\n",
      "train r2:  0.8853720676604954\n",
      "test loss:  6.888423442840576\n",
      "test r2:  -0.2578506141909698\n",
      "train loss:  1.6395580768585205\n",
      "train r2:  0.8852961607712515\n",
      "test loss:  6.886409282684326\n",
      "test r2:  -0.25755020897605574\n",
      "train loss:  1.6395362615585327\n",
      "train r2:  0.8853523720744441\n",
      "test loss:  6.886005878448486\n",
      "test r2:  -0.25770340920033696\n",
      "train loss:  1.639519214630127\n",
      "train r2:  0.8853124099085428\n",
      "test loss:  6.8846940994262695\n",
      "test r2:  -0.2575654887633141\n",
      "train loss:  1.6395065784454346\n",
      "train r2:  0.8853352158835632\n",
      "test loss:  6.883718967437744\n",
      "test r2:  -0.2574921297529984\n",
      "train loss:  1.6394964456558228\n",
      "train r2:  0.8853450636624228\n",
      "test loss:  6.883805751800537\n",
      "test r2:  -0.2577148756871086\n",
      "train loss:  1.639487862586975\n",
      "train r2:  0.885292234736109\n",
      "test loss:  6.881636142730713\n",
      "test r2:  -0.25724368450230206\n",
      "train loss:  1.6394790410995483\n",
      "train r2:  0.8853882462884474\n",
      "test loss:  6.883018970489502\n",
      "test r2:  -0.25779997167438484\n",
      "train loss:  1.639469027519226\n",
      "train r2:  0.8852654590444229\n",
      "test loss:  6.8805437088012695\n",
      "test r2:  -0.25719919338451946\n",
      "train loss:  1.639457106590271\n",
      "train r2:  0.8853902585618845\n",
      "test loss:  6.881808757781982\n",
      "test r2:  -0.25768798342325794\n",
      "train loss:  1.6394436359405518\n",
      "train r2:  0.8852828337626724\n",
      "test loss:  6.880166530609131\n",
      "test r2:  -0.25729930658710987\n",
      "train loss:  1.6394295692443848\n",
      "train r2:  0.8853632366898554\n",
      "test loss:  6.880711078643799\n",
      "test r2:  -0.2575536971615251\n",
      "train loss:  1.6394152641296387\n",
      "train r2:  0.8853065667128599\n",
      "test loss:  6.879783630371094\n",
      "test r2:  -0.2573561664004811\n",
      "train loss:  1.6394015550613403\n",
      "train r2:  0.8853467192829796\n",
      "test loss:  6.8800048828125\n",
      "test r2:  -0.2574961598200425\n",
      "train loss:  1.6393890380859375\n",
      "train r2:  0.885314957374733\n",
      "test loss:  6.879353046417236\n",
      "test r2:  -0.25737210776466357\n",
      "train loss:  1.639377236366272\n",
      "train r2:  0.8853398208506251\n",
      "test loss:  6.8793230056762695\n",
      "test r2:  -0.2574237382717328\n",
      "train loss:  1.6393665075302124\n",
      "train r2:  0.8853272827409353\n",
      "test loss:  6.879220485687256\n",
      "test r2:  -0.25745447832324153\n",
      "train loss:  1.6393567323684692\n",
      "train r2:  0.8853193485010613\n",
      "test loss:  6.878481864929199\n",
      "test r2:  -0.2572904114775987\n",
      "train loss:  1.639346957206726\n",
      "train r2:  0.8853532090121399\n",
      "test loss:  6.879162311553955\n",
      "test r2:  -0.25754269400471874\n",
      "train loss:  1.639337182044983\n",
      "train r2:  0.8852982083951063\n",
      "test loss:  6.877922058105469\n",
      "test r2:  -0.2572237489100424\n",
      "train loss:  1.6393274068832397\n",
      "train r2:  0.8853653820086306\n",
      "test loss:  6.878814697265625\n",
      "test r2:  -0.25753022287989613\n",
      "train loss:  1.639317274093628\n",
      "train r2:  0.8852990862020454\n",
      "test loss:  6.877743721008301\n",
      "test r2:  -0.25725025909912813\n",
      "train loss:  1.639306664466858\n",
      "train r2:  0.8853582088764567\n",
      "test loss:  6.878377914428711\n",
      "test r2:  -0.25747253715632423\n",
      "train loss:  1.6392958164215088\n",
      "train r2:  0.8853101301347703\n",
      "test loss:  6.8776397705078125\n",
      "test r2:  -0.25727957710680127\n",
      "train loss:  1.6392849683761597\n",
      "train r2:  0.8853509073518377\n",
      "test loss:  6.878133773803711\n",
      "test r2:  -0.25745007128958086\n",
      "train loss:  1.6392738819122314\n",
      "train r2:  0.8853141325500278\n",
      "test loss:  6.877492904663086\n",
      "test r2:  -0.25727773744007454\n",
      "train loss:  1.6392627954483032\n",
      "train r2:  0.8853507024471609\n",
      "test loss:  6.877991199493408\n",
      "test r2:  -0.2574384555359084\n",
      "train loss:  1.6392520666122437\n",
      "train r2:  0.8853162242410054\n",
      "test loss:  6.877513408660889\n",
      "test r2:  -0.25730794157429426\n",
      "train loss:  1.6392416954040527\n",
      "train r2:  0.8853439873648978\n",
      "test loss:  6.877737045288086\n",
      "test r2:  -0.2573806349604919\n",
      "train loss:  1.6392312049865723\n",
      "train r2:  0.8853284327090623\n",
      "test loss:  6.87770414352417\n",
      "test r2:  -0.2573755283357786\n",
      "train loss:  1.6392215490341187\n",
      "train r2:  0.885329580424671\n",
      "test loss:  6.8775129318237305\n",
      "test r2:  -0.25732329046288216\n",
      "train loss:  1.6392114162445068\n",
      "train r2:  0.885340790259911\n",
      "test loss:  6.8778076171875\n",
      "test r2:  -0.2574125992308014\n",
      "train loss:  1.6392016410827637\n",
      "train r2:  0.8853217949020221\n",
      "test loss:  6.877453804016113\n",
      "test r2:  -0.2573106313278797\n",
      "train loss:  1.6391922235488892\n",
      "train r2:  0.8853436780591536\n",
      "test loss:  6.8777852058410645\n",
      "test r2:  -0.2574121213342151\n",
      "train loss:  1.6391825675964355\n",
      "train r2:  0.8853221000385127\n",
      "test loss:  6.877448558807373\n",
      "test r2:  -0.2573141897125004\n",
      "train loss:  1.6391730308532715\n",
      "train r2:  0.8853431459733097\n",
      "test loss:  6.877782821655273\n",
      "test r2:  -0.2574182988062861\n",
      "train loss:  1.6391634941101074\n",
      "train r2:  0.8853210122563594\n",
      "test loss:  6.877356052398682\n",
      "test r2:  -0.25729530742293094\n",
      "train loss:  1.6391539573669434\n",
      "train r2:  0.8853474036050659\n",
      "test loss:  6.877833843231201\n",
      "test r2:  -0.25744178389818306\n",
      "train loss:  1.6391444206237793\n",
      "train r2:  0.8853162548874447\n",
      "test loss:  6.877262592315674\n",
      "test r2:  -0.25727728938130223\n",
      "train loss:  1.6391350030899048\n",
      "train r2:  0.885351460805119\n",
      "test loss:  6.877804279327393\n",
      "test r2:  -0.257442405199793\n",
      "train loss:  1.6391253471374512\n",
      "train r2:  0.8853163225562691\n",
      "test loss:  6.8772735595703125\n",
      "test r2:  -0.2572896486266114\n",
      "train loss:  1.639115571975708\n",
      "train r2:  0.8853490952229168\n",
      "test loss:  6.87770414352417\n",
      "test r2:  -0.25742179245219\n",
      "train loss:  1.639106273651123\n",
      "train r2:  0.885320987760368\n",
      "test loss:  6.87730598449707\n",
      "test r2:  -0.25730649868413313\n",
      "train loss:  1.6390968561172485\n",
      "train r2:  0.8853457890743442\n",
      "test loss:  6.877650737762451\n",
      "test r2:  -0.2574122785029753\n",
      "train loss:  1.6390873193740845\n",
      "train r2:  0.8853233440236477\n",
      "test loss:  6.87729024887085\n",
      "test r2:  -0.25730679201557005\n",
      "train loss:  1.63907790184021\n",
      "train r2:  0.8853460364834972\n",
      "test loss:  6.877657890319824\n",
      "test r2:  -0.25741761707122324\n",
      "train loss:  1.639068603515625\n",
      "train r2:  0.8853225409898648\n",
      "test loss:  6.877270698547363\n",
      "test r2:  -0.2573042072309557\n",
      "train loss:  1.6390594244003296\n",
      "train r2:  0.8853469424382119\n",
      "test loss:  6.877641201019287\n",
      "test r2:  -0.257414444943741\n",
      "train loss:  1.6390502452850342\n",
      "train r2:  0.8853235562798557\n",
      "test loss:  6.877308368682861\n",
      "test r2:  -0.2573164514056945\n",
      "train loss:  1.6390409469604492\n",
      "train r2:  0.8853446705009764\n",
      "test loss:  6.877591133117676\n",
      "test r2:  -0.25740131188970805\n",
      "train loss:  1.639032006263733\n",
      "train r2:  0.8853267003250876\n",
      "test loss:  6.877342700958252\n",
      "test r2:  -0.2573282157053103\n",
      "train loss:  1.6390228271484375\n",
      "train r2:  0.8853424623463606\n",
      "test loss:  6.877571105957031\n",
      "test r2:  -0.25739799434999044\n",
      "train loss:  1.6390140056610107\n",
      "train r2:  0.8853277307931935\n",
      "test loss:  6.877323627471924\n",
      "test r2:  -0.25732636726420166\n",
      "train loss:  1.6390048265457153\n",
      "train r2:  0.8853431646936725\n",
      "test loss:  6.877577304840088\n",
      "test r2:  -0.2574047553471308\n",
      "train loss:  1.6389960050582886\n",
      "train r2:  0.8853265615291986\n",
      "test loss:  6.877277851104736\n",
      "test r2:  -0.25731966274343976\n",
      "train loss:  1.6389873027801514\n",
      "train r2:  0.8853448044026887\n",
      "test loss:  6.877563953399658\n",
      "test r2:  -0.2574089364261207\n",
      "train loss:  1.6389784812927246\n",
      "train r2:  0.8853258399360633\n",
      "test loss:  6.877242565155029\n",
      "test r2:  -0.25731868545671843\n",
      "train loss:  1.6389697790145874\n",
      "train r2:  0.8853452327138998\n",
      "test loss:  6.877520561218262\n",
      "test r2:  -0.2574070252289289\n",
      "train loss:  1.6389610767364502\n",
      "train r2:  0.8853263888841931\n",
      "test loss:  6.877199172973633\n",
      "test r2:  -0.2573176496905032\n",
      "train loss:  1.6389524936676025\n",
      "train r2:  0.8853455250548586\n",
      "test loss:  6.877488613128662\n",
      "test r2:  -0.257410586673523\n",
      "train loss:  1.6389439105987549\n",
      "train r2:  0.8853257130837568\n",
      "test loss:  6.877114772796631\n",
      "test r2:  -0.2573064527435669\n",
      "train loss:  1.6389354467391968\n",
      "train r2:  0.8853480162350181\n",
      "test loss:  6.8774871826171875\n",
      "test r2:  -0.25742465148334626\n",
      "train loss:  1.6389269828796387\n",
      "train r2:  0.8853227758029112\n",
      "test loss:  6.876999378204346\n",
      "test r2:  -0.25728737426340653\n",
      "train loss:  1.6389186382293701\n",
      "train r2:  0.885352121314818\n",
      "test loss:  6.877496719360352\n",
      "test r2:  -0.2574426951558375\n",
      "train loss:  1.6389105319976807\n",
      "train r2:  0.8853189361742492\n",
      "test loss:  6.876877307891846\n",
      "test r2:  -0.2572666464493296\n",
      "train loss:  1.6389025449752808\n",
      "train r2:  0.8853565401052068\n",
      "test loss:  6.877510070800781\n",
      "test r2:  -0.25746283284152827\n",
      "train loss:  1.6388946771621704\n",
      "train r2:  0.8853146259292491\n",
      "test loss:  6.876734733581543\n",
      "test r2:  -0.2572404472551424\n",
      "train loss:  1.6388872861862183\n",
      "train r2:  0.8853620724639162\n",
      "test loss:  6.877555847167969\n",
      "test r2:  -0.25749315325883804\n",
      "train loss:  1.6388798952102661\n",
      "train r2:  0.8853080427293266\n",
      "test loss:  6.8765363693237305\n",
      "test r2:  -0.2571985203664897\n",
      "train loss:  1.6388731002807617\n",
      "train r2:  0.8853709377019088\n",
      "test loss:  6.877667427062988\n",
      "test r2:  -0.25754416458211016\n",
      "train loss:  1.6388670206069946\n",
      "train r2:  0.8852970311208767\n",
      "test loss:  6.876251697540283\n",
      "test r2:  -0.2571329926353756\n",
      "train loss:  1.6388620138168335\n",
      "train r2:  0.8853847560670267\n",
      "test loss:  6.877854824066162\n",
      "test r2:  -0.2576191494337743\n",
      "train loss:  1.6388580799102783\n",
      "train r2:  0.8852807600506448\n",
      "test loss:  6.8758769035339355\n",
      "test r2:  -0.25704197606633516\n",
      "train loss:  1.6388561725616455\n",
      "train r2:  0.8854038803173409\n",
      "test loss:  6.878126621246338\n",
      "test r2:  -0.2577216574527439\n",
      "train loss:  1.6388567686080933\n",
      "train r2:  0.8852584614035008\n",
      "test loss:  6.875382900238037\n",
      "test r2:  -0.25691788656622006\n",
      "train loss:  1.6388611793518066\n",
      "train r2:  0.8854298768311992\n",
      "test loss:  6.8785247802734375\n",
      "test r2:  -0.2578639041925599\n",
      "train loss:  1.6388697624206543\n",
      "train r2:  0.8852274315363787\n",
      "test loss:  6.874721050262451\n",
      "test r2:  -0.25674609467611886\n",
      "train loss:  1.6388851404190063\n",
      "train r2:  0.8854657408087926\n",
      "test loss:  6.879091262817383\n",
      "test r2:  -0.25805753893961625\n",
      "train loss:  1.6389063596725464\n",
      "train r2:  0.8851849919870366\n",
      "test loss:  6.873893737792969\n",
      "test r2:  -0.2565268841215276\n",
      "train loss:  1.6389355659484863\n",
      "train r2:  0.8855112675091392\n",
      "test loss:  6.8797502517700195\n",
      "test r2:  -0.2582794851310104\n",
      "train loss:  1.6389667987823486\n",
      "train r2:  0.88513612808054\n",
      "test loss:  6.873092174530029\n",
      "test r2:  -0.25631726020997947\n",
      "train loss:  1.638997197151184\n",
      "train r2:  0.8855545305330306\n",
      "test loss:  6.880164623260498\n",
      "test r2:  -0.2584309631923669\n",
      "train loss:  1.6390093564987183\n",
      "train r2:  0.885102537876507\n",
      "test loss:  6.872786045074463\n",
      "test r2:  -0.2562575235504254\n",
      "train loss:  1.6389976739883423\n",
      "train r2:  0.8855665963614607\n",
      "test loss:  6.879764080047607\n",
      "test r2:  -0.2583434176860526\n",
      "train loss:  1.6389480829238892\n",
      "train r2:  0.8851214858818617\n",
      "test loss:  6.8735198974609375\n",
      "test r2:  -0.2565091691606489\n",
      "train loss:  1.638875126838684\n",
      "train r2:  0.885514003564708\n",
      "test loss:  6.87820291519165\n",
      "test r2:  -0.2579148301356071\n",
      "train loss:  1.6387962102890015\n",
      "train r2:  0.885214589985657\n",
      "test loss:  6.87525749206543\n",
      "test r2:  -0.2570592415756823\n",
      "train loss:  1.638738989830017\n",
      "train r2:  0.8853978188969691\n",
      "test loss:  6.876016139984131\n",
      "test r2:  -0.25730093344025695\n",
      "train loss:  1.6387172937393188\n",
      "train r2:  0.8853461580146219\n",
      "test loss:  6.8770976066589355\n",
      "test r2:  -0.25763791339617526\n",
      "train loss:  1.6387273073196411\n",
      "train r2:  0.8852736737495467\n",
      "test loss:  6.8742828369140625\n",
      "test r2:  -0.2568201954084479\n",
      "train loss:  1.6387524604797363\n",
      "train r2:  0.8854475601299048\n",
      "test loss:  6.878057956695557\n",
      "test r2:  -0.25795637408106864\n",
      "train loss:  1.6387724876403809\n",
      "train r2:  0.8852042222575852\n",
      "test loss:  6.873681545257568\n",
      "test r2:  -0.2566759393351812\n",
      "train loss:  1.6387733221054077\n",
      "train r2:  0.8854773201841508\n",
      "test loss:  6.877796649932861\n",
      "test r2:  -0.25791513838595104\n",
      "train loss:  1.6387509107589722\n",
      "train r2:  0.8852125551212804\n",
      "test loss:  6.874197483062744\n",
      "test r2:  -0.25686629383978765\n",
      "train loss:  1.6387152671813965\n",
      "train r2:  0.8854367493149515\n",
      "test loss:  6.876600742340088\n",
      "test r2:  -0.25759859992152756\n",
      "train loss:  1.6386805772781372\n",
      "train r2:  0.88528042426113\n",
      "test loss:  6.875342845916748\n",
      "test r2:  -0.25724510867214323\n",
      "train loss:  1.6386587619781494\n",
      "train r2:  0.8853558114868594\n",
      "test loss:  6.8751139640808105\n",
      "test r2:  -0.2571962158172809\n",
      "train loss:  1.6386538743972778\n",
      "train r2:  0.8853658724910357\n",
      "test loss:  6.876408100128174\n",
      "test r2:  -0.257600042672413\n",
      "train loss:  1.638659954071045\n",
      "train r2:  0.8852791364706565\n",
      "test loss:  6.874050617218018\n",
      "test r2:  -0.2569207121260997\n",
      "train loss:  1.6386668682098389\n",
      "train r2:  0.8854236611040694\n",
      "test loss:  6.876768589019775\n",
      "test r2:  -0.25774692566125457\n",
      "train loss:  1.6386659145355225\n",
      "train r2:  0.8852467447955954\n",
      "test loss:  6.873843193054199\n",
      "test r2:  -0.2569004160263584\n",
      "train loss:  1.6386544704437256\n",
      "train r2:  0.8854272605643974\n",
      "test loss:  6.876237869262695\n",
      "test r2:  -0.2576317538046726\n",
      "train loss:  1.6386357545852661\n",
      "train r2:  0.8852708868500305\n",
      "test loss:  6.874387741088867\n",
      "test r2:  -0.2571046414810203\n",
      "train loss:  1.6386160850524902\n",
      "train r2:  0.8853832653506257\n",
      "test loss:  6.875187873840332\n",
      "test r2:  -0.2573638431121048\n",
      "train loss:  1.6386017799377441\n",
      "train r2:  0.8853276482840924\n",
      "test loss:  6.87514066696167\n",
      "test r2:  -0.2573711850085545\n",
      "train loss:  1.6385948657989502\n",
      "train r2:  0.8853256869285246\n",
      "test loss:  6.87422513961792\n",
      "test r2:  -0.2571215577765227\n",
      "train loss:  1.6385929584503174\n",
      "train r2:  0.8853785184319483\n",
      "test loss:  6.875572204589844\n",
      "test r2:  -0.2575432939725375\n",
      "train loss:  1.6385927200317383\n",
      "train r2:  0.8852880073928856\n",
      "test loss:  6.873720169067383\n",
      "test r2:  -0.2570161084716873\n",
      "train loss:  1.6385890245437622\n",
      "train r2:  0.885400118870166\n",
      "test loss:  6.8754801750183105\n",
      "test r2:  -0.25756102839927175\n",
      "train loss:  1.6385810375213623\n",
      "train r2:  0.8852833610301586\n",
      "test loss:  6.873721122741699\n",
      "test r2:  -0.2570620180408063\n",
      "train loss:  1.6385698318481445\n",
      "train r2:  0.8853895697227567\n",
      "test loss:  6.874933242797852\n",
      "test r2:  -0.25744476023651663\n",
      "train loss:  1.6385574340820312\n",
      "train r2:  0.8853075060381008\n",
      "test loss:  6.874066352844238\n",
      "test r2:  -0.25721134527668377\n",
      "train loss:  1.6385469436645508\n",
      "train r2:  0.8853569945958059\n",
      "test loss:  6.874175548553467\n",
      "test r2:  -0.2572668390924815\n",
      "train loss:  1.6385393142700195\n",
      "train r2:  0.8853447099163178\n",
      "test loss:  6.874452114105225\n",
      "test r2:  -0.2573728262808539\n",
      "train loss:  1.6385341882705688\n",
      "train r2:  0.8853216056458352\n",
      "test loss:  6.873537063598633\n",
      "test r2:  -0.25712580871876334\n",
      "train loss:  1.6385303735733032\n",
      "train r2:  0.8853738551508561\n",
      "test loss:  6.874570846557617\n",
      "test r2:  -0.2574563637543914\n",
      "train loss:  1.6385257244110107\n",
      "train r2:  0.8853027774397642\n",
      "test loss:  6.873239040374756\n",
      "test r2:  -0.2570861267077875\n",
      "train loss:  1.6385194063186646\n",
      "train r2:  0.8853813831647942\n",
      "test loss:  6.874330043792725\n",
      "test r2:  -0.2574346971551875\n",
      "train loss:  1.6385116577148438\n",
      "train r2:  0.8853065197423952\n",
      "test loss:  6.873249530792236\n",
      "test r2:  -0.2571391001581722\n",
      "train loss:  1.6385029554367065\n",
      "train r2:  0.8853691814775966\n",
      "test loss:  6.8738484382629395\n",
      "test r2:  -0.2573427047986898\n",
      "train loss:  1.6384942531585693\n",
      "train r2:  0.8853252627452304\n",
      "test loss:  6.873399257659912\n",
      "test r2:  -0.2572349616525047\n",
      "train loss:  1.638486623764038\n",
      "train r2:  0.8853477920222239\n",
      "test loss:  6.873310565948486\n",
      "test r2:  -0.25723434987490856\n",
      "train loss:  1.6384800672531128\n",
      "train r2:  0.8853474269618106\n",
      "test loss:  6.873520374298096\n",
      "test r2:  -0.2573229020182928\n",
      "train loss:  1.6384745836257935\n",
      "train r2:  0.8853280101526065\n",
      "test loss:  6.87286376953125\n",
      "test r2:  -0.2571540270080037\n",
      "train loss:  1.6384690999984741\n",
      "train r2:  0.8853635690709197\n",
      "test loss:  6.873493671417236\n",
      "test r2:  -0.25736734669575423\n",
      "train loss:  1.6384636163711548\n",
      "train r2:  0.8853174959881286\n",
      "test loss:  6.872594833374023\n",
      "test r2:  -0.2571272815491472\n",
      "train loss:  1.6384572982788086\n",
      "train r2:  0.885368257264521\n",
      "test loss:  6.873268127441406\n",
      "test r2:  -0.2573538975099998\n",
      "train loss:  1.6384507417678833\n",
      "train r2:  0.8853193137151887\n",
      "test loss:  6.872504711151123\n",
      "test r2:  -0.2571545101847852\n",
      "train loss:  1.6384434700012207\n",
      "train r2:  0.8853614221067561\n",
      "test loss:  6.872891426086426\n",
      "test r2:  -0.2572966480313268\n",
      "train loss:  1.6384363174438477\n",
      "train r2:  0.8853305211681303\n",
      "test loss:  6.872509956359863\n",
      "test r2:  -0.2572109578725672\n",
      "train loss:  1.6384297609329224\n",
      "train r2:  0.8853483081693206\n",
      "test loss:  6.8724684715271\n",
      "test r2:  -0.25722628367002964\n",
      "train loss:  1.6384234428405762\n",
      "train r2:  0.8853444737889722\n",
      "test loss:  6.872504711151123\n",
      "test r2:  -0.2572645825647848\n",
      "train loss:  1.638417363166809\n",
      "train r2:  0.8853357589398254\n",
      "test loss:  6.872097492218018\n",
      "test r2:  -0.257171912848126\n",
      "train loss:  1.638411521911621\n",
      "train r2:  0.8853549958619137\n",
      "test loss:  6.872409343719482\n",
      "test r2:  -0.2572927707089847\n",
      "train loss:  1.6384059190750122\n",
      "train r2:  0.8853286377280182\n",
      "test loss:  6.871823310852051\n",
      "test r2:  -0.2571473386637284\n",
      "train loss:  1.6384000778198242\n",
      "train r2:  0.8853591448741411\n",
      "test loss:  6.872210502624512\n",
      "test r2:  -0.25729079234803676\n",
      "train loss:  1.6383938789367676\n",
      "train r2:  0.8853278987623197\n",
      "test loss:  6.871638774871826\n",
      "test r2:  -0.25715007640605503\n",
      "train loss:  1.6383877992630005\n",
      "train r2:  0.8853574181464433\n",
      "test loss:  6.871928691864014\n",
      "test r2:  -0.25726489845891787\n",
      "train loss:  1.6383813619613647\n",
      "train r2:  0.8853323084754394\n",
      "test loss:  6.871517658233643\n",
      "test r2:  -0.2571721945950849\n",
      "train loss:  1.6383750438690186\n",
      "train r2:  0.8853515413430286\n",
      "test loss:  6.871596813201904\n",
      "test r2:  -0.2572248963591466\n",
      "train loss:  1.638369083404541\n",
      "train r2:  0.885339691024937\n",
      "test loss:  6.871419906616211\n",
      "test r2:  -0.2572019814382178\n",
      "train loss:  1.638363003730774\n",
      "train r2:  0.8853440048780042\n",
      "test loss:  6.87125825881958\n",
      "test r2:  -0.257183706252309\n",
      "train loss:  1.638357400894165\n",
      "train r2:  0.8853473165150766\n",
      "test loss:  6.871301174163818\n",
      "test r2:  -0.25722628139245907\n",
      "train loss:  1.6383514404296875\n",
      "train r2:  0.885337647040209\n",
      "test loss:  6.8709564208984375\n",
      "test r2:  -0.25715431662814736\n",
      "train loss:  1.6383459568023682\n",
      "train r2:  0.8853524150459703\n",
      "test loss:  6.871124267578125\n",
      "test r2:  -0.25723421998374363\n",
      "train loss:  1.6383403539657593\n",
      "train r2:  0.885334712540267\n",
      "test loss:  6.870711803436279\n",
      "test r2:  -0.2571421493992483\n",
      "train loss:  1.6383343935012817\n",
      "train r2:  0.8853538103899158\n",
      "test loss:  6.870892524719238\n",
      "test r2:  -0.25722627769345485\n",
      "train loss:  1.6383285522460938\n",
      "train r2:  0.8853351931019627\n",
      "test loss:  6.870506763458252\n",
      "test r2:  -0.25714245052603935\n",
      "train loss:  1.6383229494094849\n",
      "train r2:  0.8853524772703475\n",
      "test loss:  6.8706278800964355\n",
      "test r2:  -0.25720916611265476\n",
      "train loss:  1.6383169889450073\n",
      "train r2:  0.8853376294670481\n",
      "test loss:  6.870323181152344\n",
      "test r2:  -0.25714980709561486\n",
      "train loss:  1.6383112668991089\n",
      "train r2:  0.8853496819544019\n",
      "test loss:  6.870340347290039\n",
      "test r2:  -0.25718601232945626\n",
      "train loss:  1.6383055448532104\n",
      "train r2:  0.8853413149229147\n",
      "test loss:  6.870151042938232\n",
      "test r2:  -0.25716115045839216\n",
      "train loss:  1.638299822807312\n",
      "train r2:  0.8853459824317231\n",
      "test loss:  6.870047092437744\n",
      "test r2:  -0.2571617092046401\n",
      "train loss:  1.6382941007614136\n",
      "train r2:  0.8853452591286094\n",
      "test loss:  6.8699727058410645\n",
      "test r2:  -0.25717115483902453\n",
      "train loss:  1.6382888555526733\n",
      "train r2:  0.885342601768899\n",
      "test loss:  6.869762897491455\n",
      "test r2:  -0.2571405715097739\n",
      "train loss:  1.6382832527160645\n",
      "train r2:  0.8853484689479927\n",
      "test loss:  6.8697733879089355\n",
      "test r2:  -0.25717534159145927\n",
      "train loss:  1.6382778882980347\n",
      "train r2:  0.8853403945783155\n",
      "test loss:  6.869500637054443\n",
      "test r2:  -0.25712648758228474\n",
      "train loss:  1.6382724046707153\n",
      "train r2:  0.8853502013252224\n",
      "test loss:  6.869548320770264\n",
      "test r2:  -0.2571728405567224\n",
      "train loss:  1.6382668018341064\n",
      "train r2:  0.885339646794739\n",
      "test loss:  6.869255542755127\n",
      "test r2:  -0.25711825277573275\n",
      "train loss:  1.6382615566253662\n",
      "train r2:  0.8853506593453642\n",
      "test loss:  6.869305610656738\n",
      "test r2:  -0.2571654824960754\n",
      "train loss:  1.6382561922073364\n",
      "train r2:  0.8853399045108177\n",
      "test loss:  6.869020462036133\n",
      "test r2:  -0.2571135081127056\n",
      "train loss:  1.638250708580017\n",
      "train r2:  0.8853503390586601\n",
      "test loss:  6.8690505027771\n",
      "test r2:  -0.2571548348901673\n",
      "train loss:  1.6382453441619873\n",
      "train r2:  0.8853408695419078\n",
      "test loss:  6.868795871734619\n",
      "test r2:  -0.25711229810823943\n",
      "train loss:  1.638240098953247\n",
      "train r2:  0.8853492821638275\n",
      "test loss:  6.868781566619873\n",
      "test r2:  -0.2571407339792109\n",
      "train loss:  1.6382346153259277\n",
      "train r2:  0.8853425388635217\n",
      "test loss:  6.868577480316162\n",
      "test r2:  -0.2571133277545077\n",
      "train loss:  1.638229489326477\n",
      "train r2:  0.8853477113991128\n",
      "test loss:  6.868507385253906\n",
      "test r2:  -0.2571255629418545\n",
      "train loss:  1.6382241249084473\n",
      "train r2:  0.8853444335515739\n",
      "test loss:  6.8683576583862305\n",
      "test r2:  -0.2571141446486416\n",
      "train loss:  1.638218879699707\n",
      "train r2:  0.8853461930234545\n",
      "test loss:  6.868237018585205\n",
      "test r2:  -0.2571118471820222\n",
      "train loss:  1.6382136344909668\n",
      "train r2:  0.8853460051372334\n",
      "test loss:  6.868127346038818\n",
      "test r2:  -0.2571128567029224\n",
      "train loss:  1.6382085084915161\n",
      "train r2:  0.8853451240162775\n",
      "test loss:  6.867969989776611\n",
      "test r2:  -0.25709970375291724\n",
      "train loss:  1.6382032632827759\n",
      "train r2:  0.8853472457954822\n",
      "test loss:  6.867894172668457\n",
      "test r2:  -0.2571107336015406\n",
      "train loss:  1.6381981372833252\n",
      "train r2:  0.8853441559317891\n",
      "test loss:  6.867702960968018\n",
      "test r2:  -0.25708778240333574\n",
      "train loss:  1.6381932497024536\n",
      "train r2:  0.8853483843728484\n",
      "test loss:  6.8676557540893555\n",
      "test r2:  -0.25710755174113054\n",
      "train loss:  1.638188123703003\n",
      "train r2:  0.8853434715405427\n",
      "test loss:  6.867441177368164\n",
      "test r2:  -0.2570779611131666\n",
      "train loss:  1.6381829977035522\n",
      "train r2:  0.8853491237012807\n",
      "test loss:  6.867408275604248\n",
      "test r2:  -0.25710222625662493\n",
      "train loss:  1.6381779909133911\n",
      "train r2:  0.8853432168249539\n",
      "test loss:  6.867182731628418\n",
      "test r2:  -0.25706954582143005\n",
      "train loss:  1.6381728649139404\n",
      "train r2:  0.8853495125704172\n",
      "test loss:  6.8671555519104\n",
      "test r2:  -0.25709593476264936\n",
      "train loss:  1.6381679773330688\n",
      "train r2:  0.8853431950439695\n",
      "test loss:  6.866926193237305\n",
      "test r2:  -0.25706213731832817\n",
      "train loss:  1.6381629705429077\n",
      "train r2:  0.8853496761907848\n",
      "test loss:  6.866898059844971\n",
      "test r2:  -0.25708838145357205\n",
      "train loss:  1.6381579637527466\n",
      "train r2:  0.8853433882162347\n",
      "test loss:  6.866670608520508\n",
      "test r2:  -0.25705547158590525\n",
      "train loss:  1.638153076171875\n",
      "train r2:  0.8853497004672538\n",
      "test loss:  6.86663818359375\n",
      "test r2:  -0.2570803154862815\n",
      "train loss:  1.6381481885910034\n",
      "train r2:  0.8853436960365102\n",
      "test loss:  6.866416931152344\n",
      "test r2:  -0.25704948284497187\n",
      "train loss:  1.6381433010101318\n",
      "train r2:  0.8853495530911506\n",
      "test loss:  6.8663740158081055\n",
      "test r2:  -0.2570715101687642\n",
      "train loss:  1.6381385326385498\n",
      "train r2:  0.8853441550841861\n",
      "test loss:  6.866161823272705\n",
      "test r2:  -0.25704362488820776\n",
      "train loss:  1.6381335258483887\n",
      "train r2:  0.8853494254093528\n",
      "test loss:  6.8661112785339355\n",
      "test r2:  -0.25706340818636364\n",
      "train loss:  1.638128638267517\n",
      "train r2:  0.8853444267896851\n",
      "test loss:  6.865902900695801\n",
      "test r2:  -0.25703663830916446\n",
      "train loss:  1.6381242275238037\n",
      "train r2:  0.8853494351144092\n",
      "test loss:  6.865849018096924\n",
      "test r2:  -0.2570559756417832\n",
      "train loss:  1.6381192207336426\n",
      "train r2:  0.8853446208858571\n",
      "test loss:  6.865640640258789\n",
      "test r2:  -0.25702936177817315\n",
      "train loss:  1.6381144523620605\n",
      "train r2:  0.8853495553399788\n",
      "test loss:  6.865586757659912\n",
      "test r2:  -0.25704868058300057\n",
      "train loss:  1.6381096839904785\n",
      "train r2:  0.8853447193198986\n",
      "test loss:  6.865377426147461\n",
      "test r2:  -0.25702193362078374\n",
      "train loss:  1.6381051540374756\n",
      "train r2:  0.8853497043062187\n",
      "test loss:  6.865324020385742\n",
      "test r2:  -0.257041580207352\n",
      "train loss:  1.6381003856658936\n",
      "train r2:  0.8853447930485796\n",
      "test loss:  6.865110874176025\n",
      "test r2:  -0.25701401000575497\n",
      "train loss:  1.638095736503601\n",
      "train r2:  0.8853499440297671\n",
      "test loss:  6.865062236785889\n",
      "test r2:  -0.2570351644178259\n",
      "train loss:  1.6380910873413086\n",
      "train r2:  0.8853446984598037\n",
      "test loss:  6.864840984344482\n",
      "test r2:  -0.2570050570230098\n",
      "train loss:  1.6380865573883057\n",
      "train r2:  0.8853504240360379\n",
      "test loss:  6.864805698394775\n",
      "test r2:  -0.25703023893780963\n",
      "train loss:  1.6380821466445923\n",
      "train r2:  0.8853442843269168\n",
      "test loss:  6.864563465118408\n",
      "test r2:  -0.25699435145374805\n",
      "train loss:  1.6380773782730103\n",
      "train r2:  0.8853512179541975\n",
      "test loss:  6.864551067352295\n",
      "test r2:  -0.25702643796324054\n",
      "train loss:  1.6380728483200073\n",
      "train r2:  0.8853436280069158\n",
      "test loss:  6.864284038543701\n",
      "test r2:  -0.2569830198229175\n",
      "train loss:  1.638068437576294\n",
      "train r2:  0.8853521656277595\n",
      "test loss:  6.8642988204956055\n",
      "test r2:  -0.25702343755885004\n",
      "train loss:  1.6380637884140015\n",
      "train r2:  0.8853428310162056\n",
      "test loss:  6.863997936248779\n",
      "test r2:  -0.25697015128249845\n",
      "train loss:  1.638059377670288\n",
      "train r2:  0.8853534557804743\n",
      "test loss:  6.864053249359131\n",
      "test r2:  -0.25702296837110405\n",
      "train loss:  1.6380549669265747\n",
      "train r2:  0.8853414500394602\n",
      "test loss:  6.8637003898620605\n",
      "test r2:  -0.25695416613652644\n",
      "train loss:  1.6380505561828613\n",
      "train r2:  0.8853553950377179\n",
      "test loss:  6.863818168640137\n",
      "test r2:  -0.25702561238074795\n",
      "train loss:  1.638046383857727\n",
      "train r2:  0.8853393788333604\n",
      "test loss:  6.86338996887207\n",
      "test r2:  -0.2569345412360353\n",
      "train loss:  1.6380419731140137\n",
      "train r2:  0.8853581120602653\n",
      "test loss:  6.863597393035889\n",
      "test r2:  -0.2570325948716339\n",
      "train loss:  1.6380380392074585\n",
      "train r2:  0.8853364403700427\n",
      "test loss:  6.863062858581543\n",
      "test r2:  -0.25691008774240043\n",
      "train loss:  1.6380337476730347\n",
      "train r2:  0.8853618467247937\n",
      "test loss:  6.8633952140808105\n",
      "test r2:  -0.25704552572573025\n",
      "train loss:  1.6380298137664795\n",
      "train r2:  0.8853321540480964\n",
      "test loss:  6.862707138061523\n",
      "test r2:  -0.2568774429536438\n",
      "train loss:  1.6380259990692139\n",
      "train r2:  0.8853673311087072\n",
      "test loss:  6.863229274749756\n",
      "test r2:  -0.2570694476851709\n",
      "train loss:  1.6380226612091064\n",
      "train r2:  0.8853255724325612\n",
      "test loss:  6.862304210662842\n",
      "test r2:  -0.25683086538042743\n",
      "train loss:  1.6380192041397095\n",
      "train r2:  0.8853757453044084\n",
      "test loss:  6.863119602203369\n",
      "test r2:  -0.2571102224794588\n",
      "train loss:  1.638016700744629\n",
      "train r2:  0.8853153057880084\n",
      "test loss:  6.861833095550537\n",
      "test r2:  -0.2567642887379107\n",
      "train loss:  1.6380151510238647\n",
      "train r2:  0.8853884430911791\n",
      "test loss:  6.863090515136719\n",
      "test r2:  -0.2571751233420232\n",
      "train loss:  1.638014554977417\n",
      "train r2:  0.885299853184944\n",
      "test loss:  6.861262798309326\n",
      "test r2:  -0.25666830292754605\n",
      "train loss:  1.638015627861023\n",
      "train r2:  0.8854073336727615\n",
      "test loss:  6.8631815910339355\n",
      "test r2:  -0.2572755539380107\n",
      "train loss:  1.6380196809768677\n",
      "train r2:  0.885276705539198\n",
      "test loss:  6.860548496246338\n",
      "test r2:  -0.25652936303597396\n",
      "train loss:  1.6380279064178467\n",
      "train r2:  0.885435194930088\n",
      "test loss:  6.863446235656738\n",
      "test r2:  -0.25742809151622037\n",
      "train loss:  1.6380419731140137\n",
      "train r2:  0.8852421675865836\n",
      "test loss:  6.859623908996582\n",
      "test r2:  -0.25632810956522545\n",
      "train loss:  1.6380643844604492\n",
      "train r2:  0.8854760356247429\n",
      "test loss:  6.86395263671875\n",
      "test r2:  -0.2576519272105362\n",
      "train loss:  1.638096570968628\n",
      "train r2:  0.8851919368057642\n",
      "test loss:  6.858456134796143\n",
      "test r2:  -0.256054257469146\n",
      "train loss:  1.6381421089172363\n",
      "train r2:  0.8855317582933401\n",
      "test loss:  6.8646626472473145\n",
      "test r2:  -0.2579357529195627\n",
      "train loss:  1.6381961107254028\n",
      "train r2:  0.8851282172707121\n",
      "test loss:  6.857208251953125\n",
      "test r2:  -0.2557573356182974\n",
      "train loss:  1.6382553577423096\n",
      "train r2:  0.8855918712230679\n",
      "test loss:  6.865213394165039\n",
      "test r2:  -0.25817180802208495\n",
      "train loss:  1.6382932662963867\n",
      "train r2:  0.8850747164827607\n",
      "test loss:  6.856378555297852\n",
      "test r2:  -0.25558748114612495\n",
      "train loss:  1.6382983922958374\n",
      "train r2:  0.8856258329635835\n",
      "test loss:  6.864880561828613\n",
      "test r2:  -0.25814666470719194\n",
      "train loss:  1.638238549232483\n",
      "train r2:  0.8850792009394092\n",
      "test loss:  6.857065200805664\n",
      "test r2:  -0.25587048122350264\n",
      "train loss:  1.638135552406311\n",
      "train r2:  0.8855660583277727\n",
      "test loss:  6.862627983093262\n",
      "test r2:  -0.2575581939011562\n",
      "train loss:  1.6380226612091064\n",
      "train r2:  0.8852064745129155\n",
      "test loss:  6.859516620635986\n",
      "test r2:  -0.25667485665346845\n",
      "train loss:  1.6379514932632446\n",
      "train r2:  0.8853953888758602\n",
      "test loss:  6.859364032745361\n",
      "test r2:  -0.2566688349451096\n",
      "train loss:  1.637943983078003\n",
      "train r2:  0.8853959486294556\n",
      "test loss:  6.861839294433594\n",
      "test r2:  -0.2574374884900623\n",
      "train loss:  1.637984275817871\n",
      "train r2:  0.8852303802924477\n",
      "test loss:  6.857316493988037\n",
      "test r2:  -0.25613384733926314\n",
      "train loss:  1.6380341053009033\n",
      "train r2:  0.8855072819135207\n",
      "test loss:  6.862344741821289\n",
      "test r2:  -0.2576636797659162\n",
      "train loss:  1.6380549669265747\n",
      "train r2:  0.8851793818551105\n",
      "test loss:  6.857194423675537\n",
      "test r2:  -0.256170591411091\n",
      "train loss:  1.6380337476730347\n",
      "train r2:  0.8854978407870358\n",
      "test loss:  6.861168384552002\n",
      "test r2:  -0.25739160961489427\n",
      "train loss:  1.6379814147949219\n",
      "train r2:  0.8852369605174878\n",
      "test loss:  6.858300685882568\n",
      "test r2:  -0.2565769239052573\n",
      "train loss:  1.6379319429397583\n",
      "train r2:  0.8854109093110389\n",
      "test loss:  6.859216213226318\n",
      "test r2:  -0.2568860596997813\n",
      "train loss:  1.6379109621047974\n",
      "train r2:  0.8853444049346327\n",
      "test loss:  6.859755039215088\n",
      "test r2:  -0.2570854922814718\n",
      "train loss:  1.6379218101501465\n",
      "train r2:  0.8853007950671661\n",
      "test loss:  6.8573899269104\n",
      "test r2:  -0.2564183543655245\n",
      "train loss:  1.6379454135894775\n",
      "train r2:  0.8854421715593503\n",
      "test loss:  6.860576152801514\n",
      "test r2:  -0.25740226243135966\n",
      "train loss:  1.6379588842391968\n",
      "train r2:  0.8852309631017815\n",
      "test loss:  6.856707572937012\n",
      "test r2:  -0.2562924020010524\n",
      "train loss:  1.6379505395889282\n",
      "train r2:  0.8854673364978252\n",
      "test loss:  6.859904766082764\n",
      "test r2:  -0.2572777793293506\n",
      "train loss:  1.6379247903823853\n",
      "train r2:  0.8852564622338914\n",
      "test loss:  6.857512950897217\n",
      "test r2:  -0.25660707778135805\n",
      "train loss:  1.6378980875015259\n",
      "train r2:  0.8853993247811975\n",
      "test loss:  6.858136177062988\n",
      "test r2:  -0.2568302471961399\n",
      "train loss:  1.6378850936889648\n",
      "train r2:  0.8853510167558301\n",
      "test loss:  6.8587188720703125\n",
      "test r2:  -0.2570394513874654\n",
      "train loss:  1.6378878355026245\n",
      "train r2:  0.8853054813229883\n",
      "test loss:  6.856725692749023\n",
      "test r2:  -0.25648681818423635\n",
      "train loss:  1.6378976106643677\n",
      "train r2:  0.8854225867190033\n",
      "test loss:  6.8590240478515625\n",
      "test r2:  -0.2572061735732565\n",
      "train loss:  1.6379027366638184\n",
      "train r2:  0.8852680284353829\n",
      "test loss:  6.8564252853393555\n",
      "test r2:  -0.2564715794014425\n",
      "train loss:  1.63789701461792\n",
      "train r2:  0.8854242370379222\n",
      "test loss:  6.858320713043213\n",
      "test r2:  -0.25707374348654133\n",
      "train loss:  1.6378827095031738\n",
      "train r2:  0.8852950187604556\n",
      "test loss:  6.856844902038574\n",
      "test r2:  -0.25667222430613323\n",
      "train loss:  1.6378681659698486\n",
      "train r2:  0.8853801911521844\n",
      "test loss:  6.857217788696289\n",
      "test r2:  -0.2568211269389389\n",
      "train loss:  1.6378597021102905\n",
      "train r2:  0.8853477212884344\n",
      "test loss:  6.857385635375977\n",
      "test r2:  -0.25690945543389754\n",
      "train loss:  1.6378592252731323\n",
      "train r2:  0.8853280632553335\n",
      "test loss:  6.856224536895752\n",
      "test r2:  -0.2566010153675684\n",
      "train loss:  1.637862205505371\n",
      "train r2:  0.8853931198247115\n",
      "test loss:  6.857618808746338\n",
      "test r2:  -0.2570534295553881\n",
      "train loss:  1.6378631591796875\n",
      "train r2:  0.8852956325546607\n",
      "test loss:  6.855729579925537\n",
      "test r2:  -0.2565299164815449\n",
      "train loss:  1.6378588676452637\n",
      "train r2:  0.8854067441124537\n",
      "test loss:  6.857211112976074\n",
      "test r2:  -0.2570071924216344\n",
      "train loss:  1.6378505229949951\n",
      "train r2:  0.8853040939286502\n",
      "test loss:  6.855899333953857\n",
      "test r2:  -0.2566563992455224\n",
      "train loss:  1.6378414630889893\n",
      "train r2:  0.8853784003146901\n",
      "test loss:  6.856268405914307\n",
      "test r2:  -0.2568033158940728\n",
      "train loss:  1.6378353834152222\n",
      "train r2:  0.8853463042809255\n",
      "test loss:  6.8563313484191895\n",
      "test r2:  -0.2568595721512228\n",
      "train loss:  1.6378329992294312\n",
      "train r2:  0.8853335266624894\n",
      "test loss:  6.855398178100586\n",
      "test r2:  -0.25662074797748846\n",
      "train loss:  1.637832522392273\n",
      "train r2:  0.8853837574159594\n",
      "test loss:  6.856407165527344\n",
      "test r2:  -0.25695770517818217\n",
      "train loss:  1.6378315687179565\n",
      "train r2:  0.8853109755050408\n",
      "test loss:  6.855034351348877\n",
      "test r2:  -0.25658794831802423\n",
      "train loss:  1.6378283500671387\n",
      "train r2:  0.885389214895594\n",
      "test loss:  6.855978012084961\n",
      "test r2:  -0.2569065545175617\n",
      "train loss:  1.637823224067688\n",
      "train r2:  0.8853204500957212\n",
      "test loss:  6.855056285858154\n",
      "test r2:  -0.2566700376089164\n",
      "train loss:  1.6378170251846313\n",
      "train r2:  0.8853702700509399\n",
      "test loss:  6.8553242683410645\n",
      "test r2:  -0.2567883293194573\n",
      "train loss:  1.6378118991851807\n",
      "train r2:  0.8853442817281412\n",
      "test loss:  6.855154514312744\n",
      "test r2:  -0.2567758839033276\n",
      "train loss:  1.6378085613250732\n",
      "train r2:  0.8853461748054143\n",
      "test loss:  6.854698181152344\n",
      "test r2:  -0.2566778755692649\n",
      "train loss:  1.6378065347671509\n",
      "train r2:  0.8853663769933799\n",
      "test loss:  6.8551530838012695\n",
      "test r2:  -0.25685174934736965\n",
      "train loss:  1.6378042697906494\n",
      "train r2:  0.8853284568092343\n",
      "test loss:  6.854235649108887\n",
      "test r2:  -0.2566166848569955\n",
      "train loss:  1.6378017663955688\n",
      "train r2:  0.8853779050225435\n",
      "test loss:  6.854925155639648\n",
      "test r2:  -0.2568595524764532\n",
      "train loss:  1.6377979516983032\n",
      "train r2:  0.8853253121035327\n",
      "test loss:  6.854046821594238\n",
      "test r2:  -0.2566373328659801\n",
      "train loss:  1.637793779373169\n",
      "train r2:  0.8853720431274142\n",
      "test loss:  6.854420185089111\n",
      "test r2:  -0.2567858031863832\n",
      "train loss:  1.637789249420166\n",
      "train r2:  0.8853396000630009\n",
      "test loss:  6.854068279266357\n",
      "test r2:  -0.2567196584220559\n",
      "train loss:  1.6377856731414795\n",
      "train r2:  0.8853530077440098\n",
      "test loss:  6.853826522827148\n",
      "test r2:  -0.2566860992706117\n",
      "train loss:  1.6377825736999512\n",
      "train r2:  0.8853593978522373\n",
      "test loss:  6.854041576385498\n",
      "test r2:  -0.2567877944713157\n",
      "train loss:  1.637779951095581\n",
      "train r2:  0.8853369152875168\n",
      "test loss:  6.853388786315918\n",
      "test r2:  -0.2566322901443281\n",
      "train loss:  1.6377774477005005\n",
      "train r2:  0.8853694190769984\n",
      "test loss:  6.853808403015137\n",
      "test r2:  -0.256795219208253\n",
      "train loss:  1.6377743482589722\n",
      "train r2:  0.8853338628670351\n",
      "test loss:  6.853147506713867\n",
      "test r2:  -0.2566368410172255\n",
      "train loss:  1.6377710103988647\n",
      "train r2:  0.8853669129830839\n",
      "test loss:  6.853424072265625\n",
      "test r2:  -0.25675782674565206\n",
      "train loss:  1.6377673149108887\n",
      "train r2:  0.8853403560458732\n",
      "test loss:  6.852998733520508\n",
      "test r2:  -0.25666965631655403\n",
      "train loss:  1.6377638578414917\n",
      "train r2:  0.8853584442378228\n",
      "test loss:  6.852989196777344\n",
      "test r2:  -0.25670508308821804\n",
      "train loss:  1.6377605199813843\n",
      "train r2:  0.885350125831711\n",
      "test loss:  6.852874279022217\n",
      "test r2:  -0.25670956345064155\n",
      "train loss:  1.6377575397491455\n",
      "train r2:  0.8853484192663018\n",
      "test loss:  6.852554798126221\n",
      "test r2:  -0.2566529247951148\n",
      "train loss:  1.6377545595169067\n",
      "train r2:  0.8853597828534275\n",
      "test loss:  6.852713108062744\n",
      "test r2:  -0.2567386506822398\n",
      "train loss:  1.6377519369125366\n",
      "train r2:  0.8853407159515518\n",
      "test loss:  6.852195739746094\n",
      "test r2:  -0.2566234644679508\n",
      "train loss:  1.6377488374710083\n",
      "train r2:  0.8853645776967696\n",
      "test loss:  6.852441310882568\n",
      "test r2:  -0.256734854860879\n",
      "train loss:  1.6377456188201904\n",
      "train r2:  0.8853400289249972\n",
      "test loss:  6.851962566375732\n",
      "test r2:  -0.25663129420692465\n",
      "train loss:  1.637742519378662\n",
      "train r2:  0.8853614217382174\n",
      "test loss:  6.852056980133057\n",
      "test r2:  -0.25669810407922977\n",
      "train loss:  1.6377394199371338\n",
      "train r2:  0.8853464266625554\n",
      "test loss:  6.851799011230469\n",
      "test r2:  -0.25665992421621553\n",
      "train loss:  1.637736201286316\n",
      "train r2:  0.8853538082251216\n",
      "test loss:  6.851654052734375\n",
      "test r2:  -0.25665586501183335\n",
      "train loss:  1.6377331018447876\n",
      "train r2:  0.8853539442478616\n",
      "test loss:  6.851609706878662\n",
      "test r2:  -0.25668133742339583\n",
      "train loss:  1.6377302408218384\n",
      "train r2:  0.8853477373609877\n",
      "test loss:  6.851298809051514\n",
      "test r2:  -0.2566276285307023\n",
      "train loss:  1.6377273797988892\n",
      "train r2:  0.8853584950653753\n",
      "test loss:  6.851366996765137\n",
      "test r2:  -0.2566870106880237\n",
      "train loss:  1.6377246379852295\n",
      "train r2:  0.8853450388176004\n",
      "test loss:  6.850993633270264\n",
      "test r2:  -0.2566148021540149\n",
      "train loss:  1.6377215385437012\n",
      "train r2:  0.8853597354415985\n",
      "test loss:  6.851074695587158\n",
      "test r2:  -0.256678101892607\n",
      "train loss:  1.637718677520752\n",
      "train r2:  0.8853454741112399\n",
      "test loss:  6.850734233856201\n",
      "test r2:  -0.2566157185525888\n",
      "train loss:  1.6377155780792236\n",
      "train r2:  0.8853580124799798\n",
      "test loss:  6.850739002227783\n",
      "test r2:  -0.25665627798536716\n",
      "train loss:  1.6377125978469849\n",
      "train r2:  0.8853486115638252\n",
      "test loss:  6.850509166717529\n",
      "test r2:  -0.2566268082079235\n",
      "train loss:  1.6377099752426147\n",
      "train r2:  0.885354142646588\n",
      "test loss:  6.850383281707764\n",
      "test r2:  -0.25662879938225447\n",
      "train loss:  1.6377068758010864\n",
      "train r2:  0.8853529918814222\n",
      "test loss:  6.850285053253174\n",
      "test r2:  -0.25663874228076833\n",
      "train loss:  1.6377041339874268\n",
      "train r2:  0.8853501430312745\n",
      "test loss:  6.850041389465332\n",
      "test r2:  -0.25660571643723795\n",
      "train loss:  1.6377012729644775\n",
      "train r2:  0.8853564198560223\n",
      "test loss:  6.850030422210693\n",
      "test r2:  -0.25664170161515276\n",
      "train loss:  1.6376986503601074\n",
      "train r2:  0.8853479705412612\n",
      "test loss:  6.849737167358398\n",
      "test r2:  -0.2565938091176554\n",
      "train loss:  1.6376956701278687\n",
      "train r2:  0.8853574343751578\n",
      "test loss:  6.849736213684082\n",
      "test r2:  -0.25663336142589843\n",
      "train loss:  1.637692928314209\n",
      "train r2:  0.8853482747551257\n",
      "test loss:  6.849462985992432\n",
      "test r2:  -0.2565915119992257\n",
      "train loss:  1.6376900672912598\n",
      "train r2:  0.8853564440954929\n",
      "test loss:  6.849420547485352\n",
      "test r2:  -0.2566187022602562\n",
      "train loss:  1.6376873254776\n",
      "train r2:  0.8853498991072806\n",
      "test loss:  6.849200248718262\n",
      "test r2:  -0.25659267658745843\n",
      "train loss:  1.6376844644546509\n",
      "train r2:  0.8853546736624731\n",
      "test loss:  6.849096298217773\n",
      "test r2:  -0.25660137619866186\n",
      "train loss:  1.6376817226409912\n",
      "train r2:  0.8853520618551656\n",
      "test loss:  6.848943710327148\n",
      "test r2:  -0.2565960901579112\n",
      "train loss:  1.6376789808273315\n",
      "train r2:  0.8853524734315855\n",
      "test loss:  6.848767280578613\n",
      "test r2:  -0.2565835644738017\n",
      "train loss:  1.6376763582229614\n",
      "train r2:  0.8853543539708266\n",
      "test loss:  6.848679065704346\n",
      "test r2:  -0.2565974343301316\n",
      "train loss:  1.6376736164093018\n",
      "train r2:  0.8853506666686427\n",
      "test loss:  6.848452568054199\n",
      "test r2:  -0.2565700573369827\n",
      "train loss:  1.6376709938049316\n",
      "train r2:  0.8853557438199634\n",
      "test loss:  6.848395824432373\n",
      "test r2:  -0.25659331156268506\n",
      "train loss:  1.6376680135726929\n",
      "train r2:  0.8853500141005082\n",
      "test loss:  6.8481526374816895\n",
      "test r2:  -0.2565614536991654\n",
      "train loss:  1.6376653909683228\n",
      "train r2:  0.8853560534871489\n",
      "test loss:  6.848095417022705\n",
      "test r2:  -0.2565846947837769\n",
      "train loss:  1.6376627683639526\n",
      "train r2:  0.8853503140798826\n",
      "test loss:  6.847867012023926\n",
      "test r2:  -0.2565573475792857\n",
      "train loss:  1.6376599073410034\n",
      "train r2:  0.8853554054800852\n",
      "test loss:  6.847779750823975\n",
      "test r2:  -0.25657178005291437\n",
      "train loss:  1.6376572847366333\n",
      "train r2:  0.8853515635069509\n",
      "test loss:  6.847591876983643\n",
      "test r2:  -0.25655647409817184\n",
      "train loss:  1.6376547813415527\n",
      "train r2:  0.8853540655981721\n",
      "test loss:  6.84745979309082\n",
      "test r2:  -0.25655820772678006\n",
      "train loss:  1.6376519203186035\n",
      "train r2:  0.8853529460505758\n",
      "test loss:  6.847308158874512\n",
      "test r2:  -0.25655378773636417\n",
      "train loss:  1.6376495361328125\n",
      "train r2:  0.8853530954978797\n",
      "test loss:  6.8471455574035645\n",
      "test r2:  -0.2565467182594845\n",
      "train loss:  1.6376467943191528\n",
      "train r2:  0.8853538473693078\n",
      "test loss:  6.84701681137085\n",
      "test r2:  -0.256549573317181\n",
      "train loss:  1.6376441717147827\n",
      "train r2:  0.8853524476215855\n",
      "test loss:  6.846835136413574\n",
      "test r2:  -0.2565364098846159\n",
      "train loss:  1.6376417875289917\n",
      "train r2:  0.8853544858574945\n",
      "test loss:  6.846721172332764\n",
      "test r2:  -0.2565441507041184\n",
      "train loss:  1.637639045715332\n",
      "train r2:  0.8853520615432325\n",
      "test loss:  6.846524238586426\n",
      "test r2:  -0.2565272269819332\n",
      "train loss:  1.637636423110962\n",
      "train r2:  0.8853549145593013\n",
      "test loss:  6.846419811248779\n",
      "test r2:  -0.2565377310722161\n",
      "train loss:  1.6376338005065918\n",
      "train r2:  0.8853518930338389\n",
      "test loss:  6.846216201782227\n",
      "test r2:  -0.2565191163111742\n",
      "train loss:  1.6376314163208008\n",
      "train r2:  0.8853550441155863\n",
      "test loss:  6.846109390258789\n",
      "test r2:  -0.2565291558262013\n",
      "train loss:  1.6376287937164307\n",
      "train r2:  0.8853521319240427\n",
      "test loss:  6.845916271209717\n",
      "test r2:  -0.2565138244167391\n",
      "train loss:  1.6376261711120605\n",
      "train r2:  0.8853546444137695\n",
      "test loss:  6.845788478851318\n",
      "test r2:  -0.2565183786199692\n",
      "train loss:  1.6376237869262695\n",
      "train r2:  0.8853528798019983\n",
      "test loss:  6.845614910125732\n",
      "test r2:  -0.2565091997972513\n",
      "train loss:  1.6376211643218994\n",
      "train r2:  0.8853540163896346\n",
      "test loss:  6.8454670906066895\n",
      "test r2:  -0.25650794274620425\n",
      "train loss:  1.6376186609268188\n",
      "train r2:  0.8853535096517795\n",
      "test loss:  6.84530782699585\n",
      "test r2:  -0.2565034532857873\n",
      "train loss:  1.6376162767410278\n",
      "train r2:  0.8853536817800274\n",
      "test loss:  6.845147609710693\n",
      "test r2:  -0.2564986889029308\n",
      "train loss:  1.6376135349273682\n",
      "train r2:  0.8853538894303965\n",
      "test loss:  6.844995498657227\n",
      "test r2:  -0.25649691536767993\n",
      "train loss:  1.6376113891601562\n",
      "train r2:  0.8853534767812661\n",
      "test loss:  6.844825267791748\n",
      "test r2:  -0.2564895926872086\n",
      "train loss:  1.6376086473464966\n",
      "train r2:  0.8853542354158033\n",
      "test loss:  6.8446807861328125\n",
      "test r2:  -0.25649045292482286\n",
      "train loss:  1.6376060247421265\n",
      "train r2:  0.8853532453938714\n",
      "test loss:  6.844498157501221\n",
      "test r2:  -0.25648019721263093\n",
      "train loss:  1.637603759765625\n",
      "train r2:  0.88535458593447\n",
      "test loss:  6.844360828399658\n",
      "test r2:  -0.2564835327926742\n",
      "train loss:  1.637601375579834\n",
      "train r2:  0.8853530702864795\n",
      "test loss:  6.844171524047852\n",
      "test r2:  -0.25647155778500297\n",
      "train loss:  1.6375987529754639\n",
      "train r2:  0.8853548115164809\n",
      "test loss:  6.844035625457764\n",
      "test r2:  -0.25647602096733424\n",
      "train loss:  1.6375964879989624\n",
      "train r2:  0.8853530540691562\n",
      "test loss:  6.84384298324585\n",
      "test r2:  -0.25646354746662836\n",
      "train loss:  1.6375938653945923\n",
      "train r2:  0.8853548530890292\n",
      "test loss:  6.84370231628418\n",
      "test r2:  -0.25646697820898057\n",
      "train loss:  1.6375913619995117\n",
      "train r2:  0.885353301448011\n",
      "test loss:  6.843514919281006\n",
      "test r2:  -0.2564568274329888\n",
      "train loss:  1.6375888586044312\n",
      "train r2:  0.8853546495546301\n",
      "test loss:  6.843362808227539\n",
      "test r2:  -0.25645758513486405\n",
      "train loss:  1.6375863552093506\n",
      "train r2:  0.8853536108435075\n",
      "test loss:  6.8431782722473145\n",
      "test r2:  -0.25644918185772214\n",
      "train loss:  1.6375839710235596\n",
      "train r2:  0.8853545821888448\n",
      "test loss:  6.843022346496582\n",
      "test r2:  -0.2564493120561133\n",
      "train loss:  1.6375813484191895\n",
      "train r2:  0.8853536608416551\n",
      "test loss:  6.84283447265625\n",
      "test r2:  -0.25644029205708074\n",
      "train loss:  1.6375792026519775\n",
      "train r2:  0.8853547294313484\n",
      "test loss:  6.842678546905518\n",
      "test r2:  -0.25644119015725875\n",
      "train loss:  1.637576699256897\n",
      "train r2:  0.8853536783094803\n",
      "test loss:  6.84248685836792\n",
      "test r2:  -0.2564320540840501\n",
      "train loss:  1.6375741958618164\n",
      "train r2:  0.8853547362889026\n",
      "test loss:  6.8423237800598145\n",
      "test r2:  -0.2564319929869887\n",
      "train loss:  1.6375716924667358\n",
      "train r2:  0.8853539052940108\n",
      "test loss:  6.842134475708008\n",
      "test r2:  -0.25642443735528064\n",
      "train loss:  1.6375693082809448\n",
      "train r2:  0.8853545980795731\n",
      "test loss:  6.84196138381958\n",
      "test r2:  -0.2564218787381507\n",
      "train loss:  1.6375668048858643\n",
      "train r2:  0.885354237602177\n",
      "test loss:  6.841777324676514\n",
      "test r2:  -0.25641711755044727\n",
      "train loss:  1.6375644207000732\n",
      "train r2:  0.8853543517303412\n",
      "test loss:  6.841590881347656\n",
      "test r2:  -0.2564117045228438\n",
      "train loss:  1.6375617980957031\n",
      "train r2:  0.8853546107310496\n",
      "test loss:  6.84141206741333\n",
      "test r2:  -0.2564094242486057\n",
      "train loss:  1.637559175491333\n",
      "train r2:  0.8853541746944541\n",
      "test loss:  6.841215133666992\n",
      "test r2:  -0.2564021146191058\n",
      "train loss:  1.6375569105148315\n",
      "train r2:  0.8853547906697421\n",
      "test loss:  6.841031074523926\n",
      "test r2:  -0.2563996256808905\n",
      "train loss:  1.6375542879104614\n",
      "train r2:  0.8853543469085868\n",
      "test loss:  6.840836048126221\n",
      "test r2:  -0.25639411246066035\n",
      "train loss:  1.6375517845153809\n",
      "train r2:  0.8853545905306581\n",
      "test loss:  6.840639114379883\n",
      "test r2:  -0.2563890469059529\n",
      "train loss:  1.6375492811203003\n",
      "train r2:  0.8853546968449387\n",
      "test loss:  6.840444564819336\n",
      "test r2:  -0.2563852054922158\n",
      "train loss:  1.6375466585159302\n",
      "train r2:  0.8853545582629124\n",
      "test loss:  6.840242385864258\n",
      "test r2:  -0.2563801421823082\n",
      "train loss:  1.6375442743301392\n",
      "train r2:  0.8853545966307629\n",
      "test loss:  6.840033054351807\n",
      "test r2:  -0.2563737096960592\n",
      "train loss:  1.6375412940979004\n",
      "train r2:  0.8853550054250552\n",
      "test loss:  6.839836597442627\n",
      "test r2:  -0.25637206002214574\n",
      "train loss:  1.6375389099121094\n",
      "train r2:  0.885354330303222\n",
      "test loss:  6.839613437652588\n",
      "test r2:  -0.25636334377156844\n",
      "train loss:  1.637536644935608\n",
      "train r2:  0.8853551495397806\n",
      "test loss:  6.839407444000244\n",
      "test r2:  -0.25636065785216666\n",
      "train loss:  1.6375335454940796\n",
      "train r2:  0.8853546382399824\n",
      "test loss:  6.83918571472168\n",
      "test r2:  -0.25635456832463577\n",
      "train loss:  1.63753080368042\n",
      "train r2:  0.8853548709591317\n",
      "test loss:  6.83896017074585\n",
      "test r2:  -0.2563487101179942\n",
      "train loss:  1.6375279426574707\n",
      "train r2:  0.8853549948861148\n",
      "test loss:  6.838735580444336\n",
      "test r2:  -0.2563441588026911\n",
      "train loss:  1.6375250816345215\n",
      "train r2:  0.8853548500802081\n",
      "test loss:  6.838501453399658\n",
      "test r2:  -0.2563383307656679\n",
      "train loss:  1.6375222206115723\n",
      "train r2:  0.8853549682756366\n",
      "test loss:  6.838260173797607\n",
      "test r2:  -0.25633173078376026\n",
      "train loss:  1.6375192403793335\n",
      "train r2:  0.8853552123112022\n",
      "test loss:  6.838022232055664\n",
      "test r2:  -0.2563280245536723\n",
      "train loss:  1.6375160217285156\n",
      "train r2:  0.8853548286016719\n",
      "test loss:  6.837764263153076\n",
      "test r2:  -0.2563197082297537\n",
      "train loss:  1.6375126838684082\n",
      "train r2:  0.885355388302958\n",
      "test loss:  6.83751106262207\n",
      "test r2:  -0.25631493967271624\n",
      "train loss:  1.6375091075897217\n",
      "train r2:  0.8853551364201911\n",
      "test loss:  6.8372483253479\n",
      "test r2:  -0.25630924537742694\n",
      "train loss:  1.6375057697296143\n",
      "train r2:  0.8853550621415651\n",
      "test loss:  6.836966037750244\n",
      "test r2:  -0.2563001145024868\n",
      "train loss:  1.6375019550323486\n",
      "train r2:  0.8853556750025495\n",
      "test loss:  6.836695671081543\n",
      "test r2:  -0.2562968140896089\n",
      "train loss:  1.6374980211257935\n",
      "train r2:  0.885355027048562\n",
      "test loss:  6.836394786834717\n",
      "test r2:  -0.25628720179112485\n",
      "train loss:  1.63749361038208\n",
      "train r2:  0.8853556941501314\n",
      "test loss:  6.836095809936523\n",
      "test r2:  -0.25628126638466964\n",
      "train loss:  1.6374889612197876\n",
      "train r2:  0.8853554978735193\n",
      "test loss:  6.835781574249268\n",
      "test r2:  -0.25627400600149053\n",
      "train loss:  1.637484073638916\n",
      "train r2:  0.8853555208871199\n",
      "test loss:  6.835450649261475\n",
      "test r2:  -0.25626543889492326\n",
      "train loss:  1.6374788284301758\n",
      "train r2:  0.885355830299059\n",
      "test loss:  6.835108757019043\n",
      "test r2:  -0.2562575091353694\n",
      "train loss:  1.6374725103378296\n",
      "train r2:  0.8853558933408111\n",
      "test loss:  6.834754467010498\n",
      "test r2:  -0.2562504223186397\n",
      "train loss:  1.6374657154083252\n",
      "train r2:  0.8853557303130027\n",
      "test loss:  6.834366321563721\n",
      "test r2:  -0.2562380878357666\n",
      "train loss:  1.6374578475952148\n",
      "train r2:  0.8853566083240816\n",
      "test loss:  6.833986282348633\n",
      "test r2:  -0.2562334343738777\n",
      "train loss:  1.6374489068984985\n",
      "train r2:  0.8853557544391292\n",
      "test loss:  6.833548069000244\n",
      "test r2:  -0.2562177627543485\n",
      "train loss:  1.6374382972717285\n",
      "train r2:  0.8853572088798332\n",
      "test loss:  6.833125591278076\n",
      "test r2:  -0.2562130432797778\n",
      "train loss:  1.6374261379241943\n",
      "train r2:  0.8853562169528536\n",
      "test loss:  6.832638740539551\n",
      "test r2:  -0.2561957467815421\n",
      "train loss:  1.6374115943908691\n",
      "train r2:  0.885357819085491\n",
      "test loss:  6.832164287567139\n",
      "test r2:  -0.25618941965341735\n",
      "train loss:  1.637394905090332\n",
      "train r2:  0.8853569825964128\n",
      "test loss:  6.831627368927002\n",
      "test r2:  -0.25617020822621495\n",
      "train loss:  1.6373764276504517\n",
      "train r2:  0.8853588302235689\n",
      "test loss:  6.831126689910889\n",
      "test r2:  -0.2561651292887317\n",
      "train loss:  1.6373580694198608\n",
      "train r2:  0.8853576455780153\n",
      "test loss:  6.830567836761475\n",
      "test r2:  -0.2561404543464112\n",
      "train loss:  1.6373440027236938\n",
      "train r2:  0.8853605862714724\n",
      "test loss:  6.83015251159668\n",
      "test r2:  -0.25614429073392664\n",
      "train loss:  1.637342095375061\n",
      "train r2:  0.8853575152102046\n",
      "test loss:  6.829744338989258\n",
      "test r2:  -0.2561165858033754\n",
      "train loss:  1.6373546123504639\n",
      "train r2:  0.8853615424819726\n",
      "test loss:  6.829697132110596\n",
      "test r2:  -0.25614045147077324\n",
      "train loss:  1.6373645067214966\n",
      "train r2:  0.8853555078454172\n",
      "test loss:  6.829711437225342\n",
      "test r2:  -0.25611707111025894\n",
      "train loss:  1.6373525857925415\n",
      "train r2:  0.8853609943884503\n",
      "test loss:  6.830119609832764\n",
      "test r2:  -0.25616517432810104\n",
      "train loss:  1.6373317241668701\n",
      "train r2:  0.8853520919963072\n",
      "test loss:  6.830304145812988\n",
      "test r2:  -0.25613251863486064\n",
      "train loss:  1.6373199224472046\n",
      "train r2:  0.8853605817991581\n",
      "test loss:  6.830773830413818\n",
      "test r2:  -0.2562008799997604\n",
      "train loss:  1.637318730354309\n",
      "train r2:  0.8853471478747968\n",
      "test loss:  6.830680847167969\n",
      "test r2:  -0.256131786928423\n",
      "train loss:  1.6373209953308105\n",
      "train r2:  0.8853625845700965\n",
      "test loss:  6.831018447875977\n",
      "test r2:  -0.2562305551886792\n",
      "train loss:  1.637321949005127\n",
      "train r2:  0.8853415978164064\n",
      "test loss:  6.830460071563721\n",
      "test r2:  -0.2560988303214018\n",
      "train loss:  1.637319803237915\n",
      "train r2:  0.8853693161176535\n",
      "test loss:  6.83074951171875\n",
      "test r2:  -0.2562556924737447\n",
      "train loss:  1.6373143196105957\n",
      "train r2:  0.8853348574424849\n",
      "test loss:  6.829668998718262\n",
      "test r2:  -0.25602904846108676\n",
      "train loss:  1.6373071670532227\n",
      "train r2:  0.8853820147989192\n",
      "test loss:  6.830166816711426\n",
      "test r2:  -0.25629386388598885\n",
      "train loss:  1.6373006105422974\n",
      "train r2:  0.8853238036938514\n",
      "test loss:  6.828497409820557\n",
      "test r2:  -0.25591534107833436\n",
      "train loss:  1.6372971534729004\n",
      "train r2:  0.8854029491848336\n",
      "test loss:  6.829653739929199\n",
      "test r2:  -0.25637856292465266\n",
      "train loss:  1.6373012065887451\n",
      "train r2:  0.8853020968472146\n",
      "test loss:  6.827204704284668\n",
      "test r2:  -0.25573987477449633\n",
      "train loss:  1.637314796447754\n",
      "train r2:  0.8854369544329495\n",
      "test loss:  6.829730033874512\n",
      "test r2:  -0.2565611864655748\n",
      "train loss:  1.6373388767242432\n",
      "train r2:  0.8852600530451783\n",
      "test loss:  6.826012134552002\n",
      "test r2:  -0.2554711763701927\n",
      "train loss:  1.6373764276504517\n",
      "train r2:  0.8854921112433654\n",
      "test loss:  6.830810070037842\n",
      "test r2:  -0.2569006087432444\n",
      "train loss:  1.6374365091323853\n",
      "train r2:  0.8851857274620917\n",
      "test loss:  6.824763774871826\n",
      "test r2:  -0.2550572059281633\n",
      "train loss:  1.6375389099121094\n",
      "train r2:  0.8855786777559548\n",
      "test loss:  6.832769393920898\n",
      "test r2:  -0.2574199682287033\n",
      "train loss:  1.6376837491989136\n",
      "train r2:  0.8850719312460872\n",
      "test loss:  6.822998523712158\n",
      "test r2:  -0.25446550733344053\n",
      "train loss:  1.6378687620162964\n",
      "train r2:  0.8857010971755529\n",
      "test loss:  6.834833145141602\n",
      "test r2:  -0.2579917240830356\n",
      "train loss:  1.6379868984222412\n",
      "train r2:  0.8849455657362291\n",
      "test loss:  6.821157455444336\n",
      "test r2:  -0.2539250388316623\n",
      "train loss:  1.6379848718643188\n",
      "train r2:  0.8858141026301358\n",
      "test loss:  6.834865093231201\n",
      "test r2:  -0.25803451338856087\n",
      "train loss:  1.6377325057983398\n",
      "train r2:  0.8849390504028032\n",
      "test loss:  6.8235626220703125\n",
      "test r2:  -0.254742023834891\n",
      "train loss:  1.6374197006225586\n",
      "train r2:  0.8856464297046099\n",
      "test loss:  6.828903675079346\n",
      "test r2:  -0.2563873633798024\n",
      "train loss:  1.6372402906417847\n",
      "train r2:  0.8852968686640175\n",
      "test loss:  6.830558776855469\n",
      "test r2:  -0.25694261907045224\n",
      "train loss:  1.6373100280761719\n",
      "train r2:  0.8851760480164402\n",
      "test loss:  6.822465896606445\n",
      "test r2:  -0.25459769428744083\n",
      "train loss:  1.6374913454055786\n",
      "train r2:  0.8856732959531731\n",
      "test loss:  6.8321380615234375\n",
      "test r2:  -0.2575172041017415\n",
      "train loss:  1.637555718421936\n",
      "train r2:  0.8850479061710926\n",
      "test loss:  6.8241963386535645\n",
      "test r2:  -0.25517820333938035\n",
      "train loss:  1.6374462842941284\n",
      "train r2:  0.8855493210244394\n",
      "test loss:  6.827627182006836\n",
      "test r2:  -0.2562406566159414\n",
      "train loss:  1.637274980545044\n",
      "train r2:  0.885324329796405\n",
      "test loss:  6.828553676605225\n",
      "test r2:  -0.2565091083257538\n",
      "train loss:  1.6372215747833252\n",
      "train r2:  0.885267683804864\n",
      "test loss:  6.824820041656494\n",
      "test r2:  -0.2554163927877655\n",
      "train loss:  1.637304425239563\n",
      "train r2:  0.8854997741586603\n",
      "test loss:  6.829034805297852\n",
      "test r2:  -0.2567091791024021\n",
      "train loss:  1.6373873949050903\n",
      "train r2:  0.8852219635959863\n",
      "test loss:  6.825275897979736\n",
      "test r2:  -0.2555957666122384\n",
      "train loss:  1.6373591423034668\n",
      "train r2:  0.8854601581051431\n",
      "test loss:  6.82774019241333\n",
      "test r2:  -0.2563919263697034\n",
      "train loss:  1.6372535228729248\n",
      "train r2:  0.8852905978587691\n",
      "test loss:  6.826115608215332\n",
      "test r2:  -0.25595251478764824\n",
      "train loss:  1.6372015476226807\n",
      "train r2:  0.8853845544382034\n",
      "test loss:  6.825818061828613\n",
      "test r2:  -0.2558985628339261\n",
      "train loss:  1.6372425556182861\n",
      "train r2:  0.8853949088076977\n",
      "test loss:  6.827753067016602\n",
      "test r2:  -0.25653838588196987\n",
      "train loss:  1.6372947692871094\n",
      "train r2:  0.8852564891197612\n",
      "test loss:  6.823836803436279\n",
      "test r2:  -0.25539583177706415\n",
      "train loss:  1.6372828483581543\n",
      "train r2:  0.8855003410309867\n",
      "test loss:  6.827871799468994\n",
      "test r2:  -0.2566231261135301\n",
      "train loss:  1.6372218132019043\n",
      "train r2:  0.8852384718744309\n",
      "test loss:  6.825277328491211\n",
      "test r2:  -0.25587587335562434\n",
      "train loss:  1.6371876001358032\n",
      "train r2:  0.8853983618347011\n",
      "test loss:  6.824816703796387\n",
      "test r2:  -0.2557407933318465\n",
      "train loss:  1.6372087001800537\n",
      "train r2:  0.8854268573693098\n",
      "test loss:  6.828030109405518\n",
      "test r2:  -0.25670735659938226\n",
      "train loss:  1.6372401714324951\n",
      "train r2:  0.8852195737815578\n",
      "test loss:  6.823644638061523\n",
      "test r2:  -0.2554170643925546\n",
      "train loss:  1.6372321844100952\n",
      "train r2:  0.8854952009454004\n",
      "test loss:  6.826783657073975\n",
      "test r2:  -0.25637212342135607\n",
      "train loss:  1.637194037437439\n",
      "train r2:  0.8852913774208373\n",
      "test loss:  6.826018810272217\n",
      "test r2:  -0.25616877384007664\n",
      "train loss:  1.6371737718582153\n",
      "train r2:  0.8853347717005375\n",
      "test loss:  6.824120044708252\n",
      "test r2:  -0.25564278600548596\n",
      "train loss:  1.6371864080429077\n",
      "train r2:  0.8854463166406397\n",
      "test loss:  6.826878547668457\n",
      "test r2:  -0.2565002916367687\n",
      "train loss:  1.637203335762024\n",
      "train r2:  0.8852623017803437\n",
      "test loss:  6.824268817901611\n",
      "test r2:  -0.2557559837531316\n",
      "train loss:  1.637196660041809\n",
      "train r2:  0.8854209715216627\n",
      "test loss:  6.825301647186279\n",
      "test r2:  -0.25610862587420313\n",
      "train loss:  1.6371734142303467\n",
      "train r2:  0.885345298387891\n",
      "test loss:  6.825325012207031\n",
      "test r2:  -0.25613752359226116\n",
      "train loss:  1.6371607780456543\n",
      "train r2:  0.8853389215482927\n",
      "test loss:  6.824341297149658\n",
      "test r2:  -0.2558698755166975\n",
      "train loss:  1.6371673345565796\n",
      "train r2:  0.8853956529696512\n",
      "test loss:  6.825413703918457\n",
      "test r2:  -0.25621897786286674\n",
      "train loss:  1.6371768712997437\n",
      "train r2:  0.8853205242137064\n",
      "test loss:  6.82415771484375\n",
      "test r2:  -0.2558571542810275\n",
      "train loss:  1.6371716260910034\n",
      "train r2:  0.8853977223219164\n",
      "test loss:  6.825160503387451\n",
      "test r2:  -0.2561862505818122\n",
      "train loss:  1.637156367301941\n",
      "train r2:  0.8853271429646242\n",
      "test loss:  6.8242902755737305\n",
      "test r2:  -0.25595586018254624\n",
      "train loss:  1.6371482610702515\n",
      "train r2:  0.8853760779762907\n",
      "test loss:  6.824249744415283\n",
      "test r2:  -0.25596909528894884\n",
      "train loss:  1.6371513605117798\n",
      "train r2:  0.8853728234557611\n",
      "test loss:  6.824985980987549\n",
      "test r2:  -0.2562273133822819\n",
      "train loss:  1.6371556520462036\n",
      "train r2:  0.8853169900813835\n",
      "test loss:  6.82330322265625\n",
      "test r2:  -0.2557568144191944\n",
      "train loss:  1.637151837348938\n",
      "train r2:  0.885417103684244\n",
      "test loss:  6.824773788452148\n",
      "test r2:  -0.25622452689748565\n",
      "train loss:  1.6371421813964844\n",
      "train r2:  0.8853168435647758\n",
      "test loss:  6.823858737945557\n",
      "test r2:  -0.2559819353228676\n",
      "train loss:  1.6371362209320068\n",
      "train r2:  0.8853683002007127\n",
      "test loss:  6.823419094085693\n",
      "test r2:  -0.2558738810711825\n",
      "train loss:  1.6371368169784546\n",
      "train r2:  0.8853910584266818\n",
      "test loss:  6.824635028839111\n",
      "test r2:  -0.2562563118869374\n",
      "train loss:  1.637138843536377\n",
      "train r2:  0.8853089500529032\n",
      "test loss:  6.823051452636719\n",
      "test r2:  -0.2558055757730262\n",
      "train loss:  1.6371359825134277\n",
      "train r2:  0.8854050022228991\n",
      "test loss:  6.823967456817627\n",
      "test r2:  -0.25610103881939383\n",
      "train loss:  1.6371291875839233\n",
      "train r2:  0.8853416433324351\n",
      "test loss:  6.823762893676758\n",
      "test r2:  -0.2560605360104624\n",
      "train loss:  1.6371245384216309\n",
      "train r2:  0.8853500051517462\n",
      "test loss:  6.823077201843262\n",
      "test r2:  -0.2558844098378783\n",
      "train loss:  1.637123703956604\n",
      "train r2:  0.8853872277701351\n",
      "test loss:  6.823838710784912\n",
      "test r2:  -0.2561391988560737\n",
      "train loss:  1.6371240615844727\n",
      "train r2:  0.8853323667842343\n",
      "test loss:  6.823014736175537\n",
      "test r2:  -0.25591954236052294\n",
      "train loss:  1.6371220350265503\n",
      "train r2:  0.8853789197780209\n",
      "test loss:  6.823318004608154\n",
      "test r2:  -0.25604245091567934\n",
      "train loss:  1.6371172666549683\n",
      "train r2:  0.8853522478996989\n",
      "test loss:  6.823093891143799\n",
      "test r2:  -0.2559999989322945\n",
      "train loss:  1.6371132135391235\n",
      "train r2:  0.8853610221040421\n",
      "test loss:  6.82293701171875\n",
      "test r2:  -0.2559779619493088\n",
      "train loss:  1.6371115446090698\n",
      "train r2:  0.8853653689918433\n",
      "test loss:  6.823086738586426\n",
      "test r2:  -0.2560500369996537\n",
      "train loss:  1.637110948562622\n",
      "train r2:  0.885349597522724\n",
      "test loss:  6.822580337524414\n",
      "test r2:  -0.2559192650294295\n",
      "train loss:  1.6371092796325684\n",
      "train r2:  0.8853772258480246\n",
      "test loss:  6.823044300079346\n",
      "test r2:  -0.2560837602263044\n",
      "train loss:  1.6371057033538818\n",
      "train r2:  0.8853417692167823\n",
      "test loss:  6.822453022003174\n",
      "test r2:  -0.2559338530660491\n",
      "train loss:  1.6371023654937744\n",
      "train r2:  0.8853734272092998\n",
      "test loss:  6.822559833526611\n",
      "test r2:  -0.25599112486573383\n",
      "train loss:  1.6371002197265625\n",
      "train r2:  0.8853608481191563\n",
      "test loss:  6.822686672210693\n",
      "test r2:  -0.2560581095497789\n",
      "train loss:  1.637098789215088\n",
      "train r2:  0.8853461245874655\n",
      "test loss:  6.822007656097412\n",
      "test r2:  -0.25588356207774643\n",
      "train loss:  1.6370970010757446\n",
      "train r2:  0.885383047586302\n",
      "test loss:  6.822561740875244\n",
      "test r2:  -0.2560758848539906\n",
      "train loss:  1.6370946168899536\n",
      "train r2:  0.8853415354846862\n",
      "test loss:  6.822044849395752\n",
      "test r2:  -0.2559484065950153\n",
      "train loss:  1.6370916366577148\n",
      "train r2:  0.8853684509639408\n",
      "test loss:  6.8219828605651855\n",
      "test r2:  -0.2559547774189066\n",
      "train loss:  1.6370891332626343\n",
      "train r2:  0.8853667606917234\n",
      "test loss:  6.822216510772705\n",
      "test r2:  -0.2560473501258025\n",
      "train loss:  1.6370877027511597\n",
      "train r2:  0.8853466304439201\n",
      "test loss:  6.8216776847839355\n",
      "test r2:  -0.255910313201855\n",
      "train loss:  1.6370856761932373\n",
      "train r2:  0.8853756210145813\n",
      "test loss:  6.821967601776123\n",
      "test r2:  -0.2560212387123013\n",
      "train loss:  1.6370835304260254\n",
      "train r2:  0.8853515821009068\n",
      "test loss:  6.821700572967529\n",
      "test r2:  -0.2559643247533745\n",
      "train loss:  1.6370810270309448\n",
      "train r2:  0.8853634019074006\n",
      "test loss:  6.821608066558838\n",
      "test r2:  -0.25596343008184164\n",
      "train loss:  1.637078881263733\n",
      "train r2:  0.8853632480816525\n",
      "test loss:  6.821621894836426\n",
      "test r2:  -0.25599309557060335\n",
      "train loss:  1.637076735496521\n",
      "train r2:  0.8853565621256486\n",
      "test loss:  6.821383476257324\n",
      "test r2:  -0.255946465109411\n",
      "train loss:  1.6370750665664673\n",
      "train r2:  0.8853661796354686\n",
      "test loss:  6.821461200714111\n",
      "test r2:  -0.2559967223151143\n",
      "train loss:  1.6370729207992554\n",
      "train r2:  0.8853550793261109\n",
      "test loss:  6.8211822509765625\n",
      "test r2:  -0.2559372178162014\n",
      "train loss:  1.637070655822754\n",
      "train r2:  0.8853674869598114\n",
      "test loss:  6.8212785720825195\n",
      "test r2:  -0.25599015029489247\n",
      "train loss:  1.637068510055542\n",
      "train r2:  0.885355831733687\n",
      "test loss:  6.821086406707764\n",
      "test r2:  -0.25595726429256116\n",
      "train loss:  1.63706636428833\n",
      "train r2:  0.8853625046735031\n",
      "test loss:  6.82096529006958\n",
      "test r2:  -0.2559440937733104\n",
      "train loss:  1.6370644569396973\n",
      "train r2:  0.8853650085495101\n",
      "test loss:  6.821067810058594\n",
      "test r2:  -0.255999427049052\n",
      "train loss:  1.6370625495910645\n",
      "train r2:  0.8853528478743017\n",
      "test loss:  6.820705890655518\n",
      "test r2:  -0.25591651506359425\n",
      "train loss:  1.637060523033142\n",
      "train r2:  0.8853702390600584\n",
      "test loss:  6.820849895477295\n",
      "test r2:  -0.2559846921091258\n",
      "train loss:  1.6370583772659302\n",
      "train r2:  0.8853553161496862\n",
      "test loss:  6.820662021636963\n",
      "test r2:  -0.25595415451152737\n",
      "train loss:  1.6370562314987183\n",
      "train r2:  0.885361511604758\n",
      "test loss:  6.820501327514648\n",
      "test r2:  -0.25593185194987633\n",
      "train loss:  1.637054443359375\n",
      "train r2:  0.8853659218613544\n",
      "test loss:  6.820591449737549\n",
      "test r2:  -0.25598338817944843\n",
      "train loss:  1.6370524168014526\n",
      "train r2:  0.8853545836697353\n",
      "test loss:  6.820309638977051\n",
      "test r2:  -0.2559239031832581\n",
      "train loss:  1.6370505094528198\n",
      "train r2:  0.8853669692678855\n",
      "test loss:  6.820353984832764\n",
      "test r2:  -0.2559616991363425\n",
      "train loss:  1.637048363685608\n",
      "train r2:  0.885358538181259\n",
      "test loss:  6.820225238800049\n",
      "test r2:  -0.2559463824696444\n",
      "train loss:  1.637046217918396\n",
      "train r2:  0.8853615097636588\n",
      "test loss:  6.820117473602295\n",
      "test r2:  -0.2559387317124948\n",
      "train loss:  1.6370444297790527\n",
      "train r2:  0.8853628198248475\n",
      "test loss:  6.820083141326904\n",
      "test r2:  -0.2559528293176967\n",
      "train loss:  1.6370424032211304\n",
      "train r2:  0.8853594700632491\n",
      "test loss:  6.819931507110596\n",
      "test r2:  -0.25593155106067367\n",
      "train loss:  1.6370407342910767\n",
      "train r2:  0.8853636826963971\n",
      "test loss:  6.81991720199585\n",
      "test r2:  -0.25595228639564915\n",
      "train loss:  1.6370387077331543\n",
      "train r2:  0.8853589187805648\n",
      "test loss:  6.8197479248046875\n",
      "test r2:  -0.25592603264627156\n",
      "train loss:  1.6370365619659424\n",
      "train r2:  0.8853642262172582\n",
      "test loss:  6.819736003875732\n",
      "test r2:  -0.25594661148428854\n",
      "train loss:  1.6370346546173096\n",
      "train r2:  0.8853594846770114\n",
      "test loss:  6.819612503051758\n",
      "test r2:  -0.2559339715980351\n",
      "train loss:  1.6370327472686768\n",
      "train r2:  0.8853618580155143\n",
      "test loss:  6.819504261016846\n",
      "test r2:  -0.2559250356602025\n",
      "train loss:  1.6370309591293335\n",
      "train r2:  0.8853634730419311\n",
      "test loss:  6.819505214691162\n",
      "test r2:  -0.2559488776998533\n",
      "train loss:  1.6370291709899902\n",
      "train r2:  0.8853580613924734\n",
      "test loss:  6.819307327270508\n",
      "test r2:  -0.2559134327977439\n",
      "train loss:  1.6370270252227783\n",
      "train r2:  0.8853653124401097\n",
      "test loss:  6.819318771362305\n",
      "test r2:  -0.2559403818533921\n",
      "train loss:  1.6370253562927246\n",
      "train r2:  0.8853592288726411\n",
      "test loss:  6.819192409515381\n",
      "test r2:  -0.25592653496529705\n",
      "train loss:  1.6370232105255127\n",
      "train r2:  0.885361890541076\n",
      "test loss:  6.819082260131836\n",
      "test r2:  -0.25591799179370356\n",
      "train loss:  1.637021541595459\n",
      "train r2:  0.885363377902247\n",
      "test loss:  6.819063186645508\n",
      "test r2:  -0.25593631401800043\n",
      "train loss:  1.6370196342468262\n",
      "train r2:  0.8853591444947255\n",
      "test loss:  6.818902492523193\n",
      "test r2:  -0.2559120572679634\n",
      "train loss:  1.637017846107483\n",
      "train r2:  0.8853639894703614\n",
      "test loss:  6.818872451782227\n",
      "test r2:  -0.25592730173649136\n",
      "train loss:  1.6370158195495605\n",
      "train r2:  0.8853604449438544\n",
      "test loss:  6.818760871887207\n",
      "test r2:  -0.2559173342352987\n",
      "train loss:  1.6370141506195068\n",
      "train r2:  0.8853622594257531\n",
      "test loss:  6.818684101104736\n",
      "test r2:  -0.25591784079404656\n",
      "train loss:  1.6370121240615845\n",
      "train r2:  0.8853618059618887\n",
      "test loss:  6.818603515625\n",
      "test r2:  -0.25591741127125855\n",
      "train loss:  1.6370103359222412\n",
      "train r2:  0.8853616115816836\n",
      "test loss:  6.818509101867676\n",
      "test r2:  -0.25591258380461057\n",
      "train loss:  1.6370083093643188\n",
      "train r2:  0.8853623535549029\n",
      "test loss:  6.818446159362793\n",
      "test r2:  -0.2559176459634438\n",
      "train loss:  1.6370068788528442\n",
      "train r2:  0.88536092743938\n",
      "test loss:  6.818324565887451\n",
      "test r2:  -0.25590488833579994\n",
      "train loss:  1.6370049715042114\n",
      "train r2:  0.8853633426315681\n",
      "test loss:  6.818285942077637\n",
      "test r2:  -0.2559172134380312\n",
      "train loss:  1.6370030641555786\n",
      "train r2:  0.8853604010675754\n",
      "test loss:  6.818162441253662\n",
      "test r2:  -0.25590388140788933\n",
      "train loss:  1.637001395225525\n",
      "train r2:  0.8853629446276539\n",
      "test loss:  6.818093776702881\n",
      "test r2:  -0.25590652759269505\n",
      "train loss:  1.6369993686676025\n",
      "train r2:  0.8853620673935113\n",
      "test loss:  6.818029880523682\n",
      "test r2:  -0.2559107286495843\n",
      "train loss:  1.6369976997375488\n",
      "train r2:  0.8853608839482906\n",
      "test loss:  6.817903518676758\n",
      "test r2:  -0.2558961615248321\n",
      "train loss:  1.6369961500167847\n",
      "train r2:  0.8853636581643989\n",
      "test loss:  6.817869186401367\n",
      "test r2:  -0.25590895624082965\n",
      "train loss:  1.6369941234588623\n",
      "train r2:  0.8853606229753418\n",
      "test loss:  6.817751884460449\n",
      "test r2:  -0.2558970878242839\n",
      "train loss:  1.636992335319519\n",
      "train r2:  0.8853628593368705\n",
      "test loss:  6.817682266235352\n",
      "test r2:  -0.2558994929757543\n",
      "train loss:  1.6369906663894653\n",
      "train r2:  0.8853620336523996\n",
      "test loss:  6.817605972290039\n",
      "test r2:  -0.2558998292369401\n",
      "train loss:  1.6369889974594116\n",
      "train r2:  0.8853616460074754\n",
      "test loss:  6.817505359649658\n",
      "test r2:  -0.2558930580275991\n",
      "train loss:  1.6369869709014893\n",
      "train r2:  0.8853627930985909\n",
      "test loss:  6.817443370819092\n",
      "test r2:  -0.25589763230704077\n",
      "train loss:  1.6369853019714355\n",
      "train r2:  0.8853615202647567\n",
      "test loss:  6.817342758178711\n",
      "test r2:  -0.25589038316015\n",
      "train loss:  1.6369837522506714\n",
      "train r2:  0.885362787867427\n",
      "test loss:  6.817278861999512\n",
      "test r2:  -0.25589431844584576\n",
      "train loss:  1.6369819641113281\n",
      "train r2:  0.8853616172125676\n",
      "test loss:  6.817180156707764\n",
      "test r2:  -0.25588760979596303\n",
      "train loss:  1.6369801759719849\n",
      "train r2:  0.8853627569220224\n",
      "test loss:  6.817111492156982\n",
      "test r2:  -0.2558900913402662\n",
      "train loss:  1.6369785070419312\n",
      "train r2:  0.8853619134902175\n",
      "test loss:  6.817025661468506\n",
      "test r2:  -0.25588737341608137\n",
      "train loss:  1.636976718902588\n",
      "train r2:  0.8853622119199069\n",
      "test loss:  6.816936016082764\n",
      "test r2:  -0.25588339857602915\n",
      "train loss:  1.636974811553955\n",
      "train r2:  0.8853627921639197\n",
      "test loss:  6.816874980926514\n",
      "test r2:  -0.2558879712660871\n",
      "train loss:  1.6369733810424805\n",
      "train r2:  0.8853614969559466\n",
      "test loss:  6.816766738891602\n",
      "test r2:  -0.25587864850991626\n",
      "train loss:  1.6369714736938477\n",
      "train r2:  0.885363198558456\n",
      "test loss:  6.816708564758301\n",
      "test r2:  -0.2558840350996763\n",
      "train loss:  1.6369699239730835\n",
      "train r2:  0.885361764476465\n",
      "test loss:  6.816615104675293\n",
      "test r2:  -0.2558787179840136\n",
      "train loss:  1.6369682550430298\n",
      "train r2:  0.8853625924795507\n",
      "test loss:  6.816534042358398\n",
      "test r2:  -0.2558774116989351\n",
      "train loss:  1.636966586112976\n",
      "train r2:  0.8853625862334832\n",
      "test loss:  6.816462993621826\n",
      "test r2:  -0.2558786855941735\n",
      "train loss:  1.636965036392212\n",
      "train r2:  0.8853620242890596\n",
      "test loss:  6.816368579864502\n",
      "test r2:  -0.25587309075826425\n",
      "train loss:  1.6369632482528687\n",
      "train r2:  0.8853628952121751\n",
      "test loss:  6.816301345825195\n",
      "test r2:  -0.2558755584732897\n",
      "train loss:  1.6369614601135254\n",
      "train r2:  0.8853620978841971\n",
      "test loss:  6.816212177276611\n",
      "test r2:  -0.25587105040725056\n",
      "train loss:  1.6369600296020508\n",
      "train r2:  0.8853627504412142\n",
      "test loss:  6.816138744354248\n",
      "test r2:  -0.2558717098294945\n",
      "train loss:  1.6369584798812866\n",
      "train r2:  0.8853623012883531\n",
      "test loss:  6.816052436828613\n",
      "test r2:  -0.25586861217775314\n",
      "train loss:  1.636956810951233\n",
      "train r2:  0.8853627005697007\n",
      "test loss:  6.815977096557617\n",
      "test r2:  -0.255868355021184\n",
      "train loss:  1.6369551420211792\n",
      "train r2:  0.8853624674402667\n",
      "test loss:  6.815896987915039\n",
      "test r2:  -0.25586700266445606\n",
      "train loss:  1.6369534730911255\n",
      "train r2:  0.8853624419624437\n",
      "test loss:  6.815811634063721\n",
      "test r2:  -0.2558636760881903\n",
      "train loss:  1.6369519233703613\n",
      "train r2:  0.8853629039612498\n",
      "test loss:  6.8157429695129395\n",
      "test r2:  -0.25586560111465984\n",
      "train loss:  1.6369502544403076\n",
      "train r2:  0.8853621932114153\n",
      "test loss:  6.8156514167785645\n",
      "test r2:  -0.2558602105186696\n",
      "train loss:  1.636948585510254\n",
      "train r2:  0.8853630450023248\n",
      "test loss:  6.815584182739258\n",
      "test r2:  -0.255862467394556\n",
      "train loss:  1.6369469165802002\n",
      "train r2:  0.8853622996789962\n",
      "test loss:  6.815496444702148\n",
      "test r2:  -0.2558583090339237\n",
      "train loss:  1.6369454860687256\n",
      "train r2:  0.8853628855075332\n",
      "test loss:  6.8154215812683105\n",
      "test r2:  -0.25585812926969664\n",
      "train loss:  1.6369438171386719\n",
      "train r2:  0.8853626251808729\n",
      "test loss:  6.815342903137207\n",
      "test r2:  -0.255856947726671\n",
      "train loss:  1.6369422674179077\n",
      "train r2:  0.8853625905642015\n",
      "test loss:  6.815258979797363\n",
      "test r2:  -0.2558539764104626\n",
      "train loss:  1.636940598487854\n",
      "train r2:  0.8853629747012564\n",
      "test loss:  6.815188884735107\n",
      "test r2:  -0.2558549843870388\n",
      "train loss:  1.6369390487670898\n",
      "train r2:  0.8853624696902624\n",
      "test loss:  6.815101623535156\n",
      "test r2:  -0.255850910091703\n",
      "train loss:  1.6369376182556152\n",
      "train r2:  0.8853630493998292\n",
      "test loss:  6.8150315284729\n",
      "test r2:  -0.25585188679264625\n",
      "train loss:  1.636936068534851\n",
      "train r2:  0.8853625397142164\n",
      "test loss:  6.814947128295898\n",
      "test r2:  -0.2558486098887216\n",
      "train loss:  1.6369343996047974\n",
      "train r2:  0.8853629850969653\n",
      "test loss:  6.814873218536377\n",
      "test r2:  -0.25584850224073774\n",
      "train loss:  1.6369328498840332\n",
      "train r2:  0.8853627156455737\n",
      "test loss:  6.814793109893799\n",
      "test r2:  -0.2558463725892921\n",
      "train loss:  1.636931300163269\n",
      "train r2:  0.8853629216138778\n",
      "test loss:  6.814715385437012\n",
      "test r2:  -0.2558450353480961\n",
      "train loss:  1.6369296312332153\n",
      "train r2:  0.8853628995489428\n",
      "test loss:  6.814640998840332\n",
      "test r2:  -0.25584458491344075\n",
      "train loss:  1.6369282007217407\n",
      "train r2:  0.8853627316759618\n",
      "test loss:  6.81455659866333\n",
      "test r2:  -0.2558411283108306\n",
      "train loss:  1.6369267702102661\n",
      "train r2:  0.8853631732189592\n",
      "test loss:  6.814488410949707\n",
      "test r2:  -0.2558424559174113\n",
      "train loss:  1.636925220489502\n",
      "train r2:  0.8853626241397431\n",
      "test loss:  6.814401626586914\n",
      "test r2:  -0.25583834745851575\n",
      "train loss:  1.6369236707687378\n",
      "train r2:  0.8853632221666523\n",
      "test loss:  6.814331531524658\n",
      "test r2:  -0.25583910906830876\n",
      "train loss:  1.6369221210479736\n",
      "train r2:  0.8853627813864684\n",
      "test loss:  6.814251899719238\n",
      "test r2:  -0.2558367712731229\n",
      "train loss:  1.6369208097457886\n",
      "train r2:  0.8853630123955807\n",
      "test loss:  6.814173698425293\n",
      "test r2:  -0.2558350804759508\n",
      "train loss:  1.6369192600250244\n",
      "train r2:  0.8853631249643746\n",
      "test loss:  6.814100742340088\n",
      "test r2:  -0.25583486715442394\n",
      "train loss:  1.6369175910949707\n",
      "train r2:  0.8853629171205727\n",
      "test loss:  6.814020156860352\n",
      "test r2:  -0.25583240909449567\n",
      "train loss:  1.636916160583496\n",
      "train r2:  0.885363138997762\n",
      "test loss:  6.813946723937988\n",
      "test r2:  -0.25583188714985683\n",
      "train loss:  1.6369147300720215\n",
      "train r2:  0.885362977731342\n",
      "test loss:  6.813867568969727\n",
      "test r2:  -0.25582962001670984\n",
      "train loss:  1.6369131803512573\n",
      "train r2:  0.8853632023427672\n",
      "test loss:  6.813795566558838\n",
      "test r2:  -0.255829548957325\n",
      "train loss:  1.6369117498397827\n",
      "train r2:  0.8853629271088478\n",
      "test loss:  6.813713550567627\n",
      "test r2:  -0.25582660081416897\n",
      "train loss:  1.636910080909729\n",
      "train r2:  0.8853633051849332\n",
      "test loss:  6.813641548156738\n",
      "test r2:  -0.25582626750645154\n",
      "train loss:  1.636908769607544\n",
      "train r2:  0.8853631112402534\n",
      "test loss:  6.813567638397217\n",
      "test r2:  -0.25582547421139057\n",
      "train loss:  1.6369074583053589\n",
      "train r2:  0.8853630173067328\n",
      "test loss:  6.813486099243164\n",
      "test r2:  -0.25582236717081486\n",
      "train loss:  1.6369057893753052\n",
      "train r2:  0.8853634078884699\n",
      "test loss:  6.81341552734375\n",
      "test r2:  -0.25582274573910424\n",
      "train loss:  1.6369044780731201\n",
      "train r2:  0.8853630805407022\n",
      "test loss:  6.8133392333984375\n",
      "test r2:  -0.25582090259867263\n",
      "train loss:  1.6369030475616455\n",
      "train r2:  0.8853631945310111\n",
      "test loss:  6.81326150894165\n",
      "test r2:  -0.25581888220098015\n",
      "train loss:  1.6369014978408813\n",
      "train r2:  0.8853633702009068\n",
      "test loss:  6.813190937042236\n",
      "test r2:  -0.25581881964152164\n",
      "train loss:  1.6369000673294067\n",
      "train r2:  0.8853631064589415\n",
      "test loss:  6.813110828399658\n",
      "test r2:  -0.25581621165518054\n",
      "train loss:  1.6368987560272217\n",
      "train r2:  0.8853634204996492\n",
      "test loss:  6.8130388259887695\n",
      "test r2:  -0.25581578629428403\n",
      "train loss:  1.636897325515747\n",
      "train r2:  0.8853632220170204\n",
      "test loss:  6.812963485717773\n",
      "test r2:  -0.2558142572742659\n",
      "train loss:  1.636896014213562\n",
      "train r2:  0.885363276429569\n",
      "test loss:  6.812887668609619\n",
      "test r2:  -0.25581255590031815\n",
      "train loss:  1.6368943452835083\n",
      "train r2:  0.8853633885124783\n",
      "test loss:  6.8128132820129395\n",
      "test r2:  -0.2558115793427469\n",
      "train loss:  1.6368930339813232\n",
      "train r2:  0.88536334798737\n",
      "test loss:  6.812741279602051\n",
      "test r2:  -0.25581085688177163\n",
      "train loss:  1.6368916034698486\n",
      "train r2:  0.8853632440190076\n",
      "test loss:  6.8126630783081055\n",
      "test r2:  -0.2558083222282894\n",
      "train loss:  1.6368904113769531\n",
      "train r2:  0.8853635296385275\n",
      "test loss:  6.81259298324585\n",
      "test r2:  -0.2558082321167803\n",
      "train loss:  1.6368889808654785\n",
      "train r2:  0.8853632890962156\n",
      "test loss:  6.812515735626221\n",
      "test r2:  -0.25580609664442133\n",
      "train loss:  1.6368876695632935\n",
      "train r2:  0.8853634549142895\n",
      "test loss:  6.812442302703857\n",
      "test r2:  -0.2558048053028279\n",
      "train loss:  1.6368861198425293\n",
      "train r2:  0.8853634711744549\n",
      "test loss:  6.812370777130127\n",
      "test r2:  -0.2558043784221855\n",
      "train loss:  1.6368848085403442\n",
      "train r2:  0.8853633461825419\n",
      "test loss:  6.812292575836182\n",
      "test r2:  -0.2558016472094411\n",
      "train loss:  1.6368834972381592\n",
      "train r2:  0.8853636259497847\n",
      "test loss:  6.8122239112854\n",
      "test r2:  -0.2558018939735702\n",
      "train loss:  1.6368820667266846\n",
      "train r2:  0.8853633319074216\n",
      "test loss:  6.812146186828613\n",
      "test r2:  -0.25579942545156387\n",
      "train loss:  1.63688063621521\n",
      "train r2:  0.8853635897786936\n",
      "test loss:  6.812074661254883\n",
      "test r2:  -0.25579871284640676\n",
      "train loss:  1.6368794441223145\n",
      "train r2:  0.8853635063204902\n",
      "test loss:  6.812002182006836\n",
      "test r2:  -0.2557973967505698\n",
      "train loss:  1.6368780136108398\n",
      "train r2:  0.8853635474555195\n",
      "test loss:  6.811929702758789\n",
      "test r2:  -0.255796425743553\n",
      "train loss:  1.6368763446807861\n",
      "train r2:  0.8853634942796298\n",
      "test loss:  6.811854839324951\n",
      "test r2:  -0.2557945185525916\n",
      "train loss:  1.6368751525878906\n",
      "train r2:  0.8853636421136037\n",
      "test loss:  6.8117828369140625\n",
      "test r2:  -0.25579366935873726\n",
      "train loss:  1.636873722076416\n",
      "train r2:  0.8853635745806101\n",
      "test loss:  6.811709880828857\n",
      "test r2:  -0.25579240799423375\n",
      "train loss:  1.6368728876113892\n",
      "train r2:  0.8853635941792009\n",
      "test loss:  6.811636447906494\n",
      "test r2:  -0.255790743958517\n",
      "train loss:  1.6368712186813354\n",
      "train r2:  0.8853636951967045\n",
      "test loss:  6.811567306518555\n",
      "test r2:  -0.2557904838075158\n",
      "train loss:  1.6368699073791504\n",
      "train r2:  0.885363508029297\n",
      "test loss:  6.811489582061768\n",
      "test r2:  -0.25578764032200807\n",
      "train loss:  1.6368687152862549\n",
      "train r2:  0.8853638458207125\n",
      "test loss:  6.811422348022461\n",
      "test r2:  -0.2557879383068986\n",
      "train loss:  1.6368671655654907\n",
      "train r2:  0.885363561662942\n",
      "test loss:  6.811349391937256\n",
      "test r2:  -0.255786358930449\n",
      "train loss:  1.6368659734725952\n",
      "train r2:  0.8853636306922397\n",
      "test loss:  6.811273097991943\n",
      "test r2:  -0.25578389523803957\n",
      "train loss:  1.6368649005889893\n",
      "train r2:  0.8853639078745817\n",
      "test loss:  6.811208724975586\n",
      "test r2:  -0.25578481475393566\n",
      "train loss:  1.636863350868225\n",
      "train r2:  0.8853634682097491\n",
      "test loss:  6.811130046844482\n",
      "test r2:  -0.2557817204898758\n",
      "train loss:  1.6368621587753296\n",
      "train r2:  0.8853638915799338\n",
      "test loss:  6.811059474945068\n",
      "test r2:  -0.25578078158185824\n",
      "train loss:  1.6368606090545654\n",
      "train r2:  0.8853638339438767\n",
      "test loss:  6.81099271774292\n",
      "test r2:  -0.25578111871556675\n",
      "train loss:  1.63685941696167\n",
      "train r2:  0.8853635054116218\n",
      "test loss:  6.8109130859375\n",
      "test r2:  -0.255777202879341\n",
      "train loss:  1.6368582248687744\n",
      "train r2:  0.8853641023846652\n",
      "test loss:  6.810849189758301\n",
      "test r2:  -0.25577832373494025\n",
      "train loss:  1.636857032775879\n",
      "train r2:  0.8853636288676557\n",
      "test loss:  6.8107757568359375\n",
      "test r2:  -0.255776460915643\n",
      "train loss:  1.6368556022644043\n",
      "train r2:  0.8853637932748313\n",
      "test loss:  6.8107008934021\n",
      "test r2:  -0.25577403950985533\n",
      "train loss:  1.6368545293807983\n",
      "train r2:  0.8853640633671773\n",
      "test loss:  6.810637950897217\n",
      "test r2:  -0.25577499110017277\n",
      "train loss:  1.6368533372879028\n",
      "train r2:  0.8853636187982962\n",
      "test loss:  6.810561656951904\n",
      "test r2:  -0.2557722817578414\n",
      "train loss:  1.6368517875671387\n",
      "train r2:  0.8853639168305363\n",
      "test loss:  6.810488700866699\n",
      "test r2:  -0.25577044209521094\n",
      "train loss:  1.6368505954742432\n",
      "train r2:  0.8853640862624004\n",
      "test loss:  6.810426712036133\n",
      "test r2:  -0.2557719971844008\n",
      "train loss:  1.6368494033813477\n",
      "train r2:  0.8853635301797472\n",
      "test loss:  6.810344219207764\n",
      "test r2:  -0.2557672329981693\n",
      "train loss:  1.6368484497070312\n",
      "train r2:  0.8853642815829404\n",
      "test loss:  6.810283184051514\n",
      "test r2:  -0.2557686907539847\n",
      "train loss:  1.636846899986267\n",
      "train r2:  0.8853637354607972\n",
      "test loss:  6.810211181640625\n",
      "test r2:  -0.2557668862134601\n",
      "train loss:  1.6368457078933716\n",
      "train r2:  0.8853638841769155\n",
      "test loss:  6.810135364532471\n",
      "test r2:  -0.25576420478365813\n",
      "train loss:  1.6368446350097656\n",
      "train r2:  0.8853642316985308\n",
      "test loss:  6.810075283050537\n",
      "test r2:  -0.25576574601489566\n",
      "train loss:  1.636843204498291\n",
      "train r2:  0.885363685402799\n",
      "test loss:  6.809997081756592\n",
      "test r2:  -0.2557621320919605\n",
      "train loss:  1.6368420124053955\n",
      "train r2:  0.8853641888204322\n",
      "test loss:  6.809929370880127\n",
      "test r2:  -0.25576184754719455\n",
      "train loss:  1.6368408203125\n",
      "train r2:  0.8853640222139345\n",
      "test loss:  6.80986213684082\n",
      "test r2:  -0.25576126178142156\n",
      "train loss:  1.6368396282196045\n",
      "train r2:  0.8853639214051321\n",
      "test loss:  6.809790134429932\n",
      "test r2:  -0.25575943300279325\n",
      "train loss:  1.636838436126709\n",
      "train r2:  0.8853640788487981\n",
      "test loss:  6.809719562530518\n",
      "test r2:  -0.2557577254597423\n",
      "train loss:  1.636837363243103\n",
      "train r2:  0.8853641805357284\n",
      "test loss:  6.809655666351318\n",
      "test r2:  -0.2557583312034146\n",
      "train loss:  1.636836051940918\n",
      "train r2:  0.8853638209706567\n",
      "test loss:  6.8095784187316895\n",
      "test r2:  -0.2557547170674692\n",
      "train loss:  1.636834740638733\n",
      "train r2:  0.8853643918169009\n",
      "test loss:  6.809518337249756\n",
      "test r2:  -0.2557562817666965\n",
      "train loss:  1.6368335485458374\n",
      "train r2:  0.8853638309655071\n",
      "test loss:  6.809441089630127\n",
      "test r2:  -0.25575266837628674\n",
      "train loss:  1.6368324756622314\n",
      "train r2:  0.8853643389599306\n",
      "test loss:  6.809377670288086\n",
      "test r2:  -0.2557530532242809\n",
      "train loss:  1.6368314027786255\n",
      "train r2:  0.8853640300891651\n",
      "test loss:  6.809308052062988\n",
      "test r2:  -0.25575151435254084\n",
      "train loss:  1.6368299722671509\n",
      "train r2:  0.8853641311284794\n",
      "test loss:  6.809236526489258\n",
      "test r2:  -0.2557495861391108\n",
      "train loss:  1.636828899383545\n",
      "train r2:  0.885364300866131\n",
      "test loss:  6.809173107147217\n",
      "test r2:  -0.2557499063344115\n",
      "train loss:  1.6368275880813599\n",
      "train r2:  0.8853639805652017\n",
      "test loss:  6.809099197387695\n",
      "test r2:  -0.25574728259760415\n",
      "train loss:  1.6368266344070435\n",
      "train r2:  0.8853643124387489\n",
      "test loss:  6.809031963348389\n",
      "test r2:  -0.25574635529045\n",
      "train loss:  1.636825442314148\n",
      "train r2:  0.885364280104932\n",
      "test loss:  6.8089704513549805\n",
      "test r2:  -0.25574709729920797\n",
      "train loss:  1.636824131011963\n",
      "train r2:  0.8853639376847158\n",
      "test loss:  6.8088908195495605\n",
      "test r2:  -0.2557425970326195\n",
      "train loss:  1.6368231773376465\n",
      "train r2:  0.8853646551310866\n",
      "test loss:  6.808834552764893\n",
      "test r2:  -0.2557448806576721\n",
      "train loss:  1.6368221044540405\n",
      "train r2:  0.8853639292738518\n",
      "test loss:  6.808759689331055\n",
      "test r2:  -0.2557418268245877\n",
      "train loss:  1.6368207931518555\n",
      "train r2:  0.8853643425279206\n",
      "test loss:  6.808691024780273\n",
      "test r2:  -0.25574034567451664\n",
      "train loss:  1.63681960105896\n",
      "train r2:  0.8853644554453836\n",
      "test loss:  6.808629989624023\n",
      "test r2:  -0.25574110256531446\n",
      "train loss:  1.636818528175354\n",
      "train r2:  0.8853640591120496\n",
      "test loss:  6.808556079864502\n",
      "test r2:  -0.2557381768865423\n",
      "train loss:  1.6368173360824585\n",
      "train r2:  0.8853644425794949\n",
      "test loss:  6.808489799499512\n",
      "test r2:  -0.2557375854227464\n",
      "train loss:  1.6368162631988525\n",
      "train r2:  0.8853643789454394\n",
      "test loss:  6.808427333831787\n",
      "test r2:  -0.2557377373195038\n",
      "train loss:  1.6368151903152466\n",
      "train r2:  0.8853640785231105\n",
      "test loss:  6.808350086212158\n",
      "test r2:  -0.2557338058024501\n",
      "train loss:  1.636813998222351\n",
      "train r2:  0.8853647241745589\n",
      "test loss:  6.808292865753174\n",
      "test r2:  -0.2557354766790716\n",
      "train loss:  1.6368129253387451\n",
      "train r2:  0.8853641382714039\n",
      "test loss:  6.808224201202393\n",
      "test r2:  -0.25573376260643865\n",
      "train loss:  1.6368118524551392\n",
      "train r2:  0.885364289058713\n",
      "test loss:  6.808148384094238\n",
      "test r2:  -0.25573021542123886\n",
      "train loss:  1.6368106603622437\n",
      "train r2:  0.8853648070648334\n",
      "test loss:  6.808095932006836\n",
      "test r2:  -0.2557332813057853\n",
      "train loss:  1.6368095874786377\n",
      "train r2:  0.8853639401359839\n",
      "test loss:  6.808016777038574\n",
      "test r2:  -0.2557285802811755\n",
      "train loss:  1.6368085145950317\n",
      "train r2:  0.8853647327932586\n",
      "test loss:  6.807957649230957\n",
      "test r2:  -0.2557295711432013\n",
      "train loss:  1.6368074417114258\n",
      "train r2:  0.8853642812713827\n",
      "test loss:  6.807887554168701\n",
      "test r2:  -0.2557273157747715\n",
      "train loss:  1.6368063688278198\n",
      "train r2:  0.885364521098714\n",
      "test loss:  6.807823657989502\n",
      "test r2:  -0.2557270539934231\n",
      "train loss:  1.6368050575256348\n",
      "train r2:  0.8853644110130574\n",
      "test loss:  6.8077545166015625\n",
      "test r2:  -0.2557248759313122\n",
      "train loss:  1.6368041038513184\n",
      "train r2:  0.8853646274512516\n",
      "test loss:  6.807694911956787\n",
      "test r2:  -0.2557258898312107\n",
      "train loss:  1.6368030309677124\n",
      "train r2:  0.885364200732675\n",
      "test loss:  6.807617664337158\n",
      "test r2:  -0.25572147259763844\n",
      "train loss:  1.6368019580841064\n",
      "train r2:  0.8853649170302816\n",
      "test loss:  6.807565212249756\n",
      "test r2:  -0.2557243398092057\n",
      "train loss:  1.6368008852005005\n",
      "train r2:  0.8853640791747441\n",
      "test loss:  6.8074870109558105\n",
      "test r2:  -0.2557192499344678\n",
      "train loss:  1.636799931526184\n",
      "train r2:  0.8853649699697985\n",
      "test loss:  6.807434558868408\n",
      "test r2:  -0.25572243328185307\n",
      "train loss:  1.6367987394332886\n",
      "train r2:  0.8853640556765805\n",
      "test loss:  6.807351589202881\n",
      "test r2:  -0.25571612379670805\n",
      "train loss:  1.6367976665496826\n",
      "train r2:  0.8853652094516514\n",
      "test loss:  6.807308673858643\n",
      "test r2:  -0.25572174396444614\n",
      "train loss:  1.6367965936660767\n",
      "train r2:  0.8853638025570226\n",
      "test loss:  6.807217121124268\n",
      "test r2:  -0.25571279923994283\n",
      "train loss:  1.6367955207824707\n",
      "train r2:  0.8853654793773968\n",
      "test loss:  6.807180404663086\n",
      "test r2:  -0.2557204690246384\n",
      "train loss:  1.6367945671081543\n",
      "train r2:  0.8853636304471831\n",
      "test loss:  6.807084560394287\n",
      "test r2:  -0.2557100825692411\n",
      "train loss:  1.6367934942245483\n",
      "train r2:  0.885365633798431\n",
      "test loss:  6.807052135467529\n",
      "test r2:  -0.25571872581057087\n",
      "train loss:  1.6367924213409424\n",
      "train r2:  0.8853635571256675\n",
      "test loss:  6.806951999664307\n",
      "test r2:  -0.255707136367755\n",
      "train loss:  1.6367915868759155\n",
      "train r2:  0.8853658106611957\n",
      "test loss:  6.80692720413208\n",
      "test r2:  -0.25571808693561904\n",
      "train loss:  1.6367902755737305\n",
      "train r2:  0.8853632702964254\n",
      "test loss:  6.806814193725586\n",
      "test r2:  -0.2557024794608356\n",
      "train loss:  1.6367892026901245\n",
      "train r2:  0.8853663923844088\n",
      "test loss:  6.8068084716796875\n",
      "test r2:  -0.2557192430157327\n",
      "train loss:  1.6367883682250977\n",
      "train r2:  0.8853626096313926\n",
      "test loss:  6.806675434112549\n",
      "test r2:  -0.2556972796441579\n",
      "train loss:  1.6367874145507812\n",
      "train r2:  0.8853670986872149\n",
      "test loss:  6.8066911697387695\n",
      "test r2:  -0.25572059876833486\n",
      "train loss:  1.6367864608764648\n",
      "train r2:  0.8853618748192278\n",
      "test loss:  6.806530475616455\n",
      "test r2:  -0.2556904202567847\n",
      "train loss:  1.6367853879928589\n",
      "train r2:  0.8853681376221639\n",
      "test loss:  6.806582927703857\n",
      "test r2:  -0.2557248317030203\n",
      "train loss:  1.636784315109253\n",
      "train r2:  0.8853605668276523\n",
      "test loss:  6.8063764572143555\n",
      "test r2:  -0.25568051706828854\n",
      "train loss:  1.636783480644226\n",
      "train r2:  0.885369806291232\n",
      "test loss:  6.806487560272217\n",
      "test r2:  -0.2557323639609548\n",
      "train loss:  1.6367825269699097\n",
      "train r2:  0.8853585407626694\n",
      "test loss:  6.806208610534668\n",
      "test r2:  -0.2556663537412458\n",
      "train loss:  1.636781930923462\n",
      "train r2:  0.8853724363481852\n",
      "test loss:  6.806408882141113\n",
      "test r2:  -0.25574538685594117\n",
      "train loss:  1.6367809772491455\n",
      "train r2:  0.8853553242459621\n",
      "test loss:  6.8060197830200195\n",
      "test r2:  -0.25564576446163256\n",
      "train loss:  1.6367802619934082\n",
      "train r2:  0.885376422242061\n",
      "test loss:  6.806359767913818\n",
      "test r2:  -0.25576667265434483\n",
      "train loss:  1.6367801427841187\n",
      "train r2:  0.8853503440088076\n",
      "test loss:  6.805793762207031\n",
      "test r2:  -0.25561366065735003\n",
      "train loss:  1.6367801427841187\n",
      "train r2:  0.8853828528509371\n",
      "test loss:  6.806360244750977\n",
      "test r2:  -0.25580309087790876\n",
      "train loss:  1.6367807388305664\n",
      "train r2:  0.8853420903517729\n",
      "test loss:  6.805505752563477\n",
      "test r2:  -0.2555627022998843\n",
      "train loss:  1.636782169342041\n",
      "train r2:  0.885393249415239\n",
      "test loss:  6.806437969207764\n",
      "test r2:  -0.25586307336762415\n",
      "train loss:  1.636785626411438\n",
      "train r2:  0.8853287731093784\n",
      "test loss:  6.805119037628174\n",
      "test r2:  -0.2554817214772289\n",
      "train loss:  1.6367912292480469\n",
      "train r2:  0.8854100259011296\n",
      "test loss:  6.806646823883057\n",
      "test r2:  -0.25596195261848576\n",
      "train loss:  1.63680100440979\n",
      "train r2:  0.8853069435224662\n",
      "test loss:  6.804568290710449\n",
      "test r2:  -0.2553511155279773\n",
      "train loss:  1.6368175745010376\n",
      "train r2:  0.8854371451010661\n",
      "test loss:  6.807060718536377\n",
      "test r2:  -0.25612289725476844\n",
      "train loss:  1.6368439197540283\n",
      "train r2:  0.8852714962241479\n",
      "test loss:  6.803771495819092\n",
      "test r2:  -0.2551454947172007\n",
      "train loss:  1.6368858814239502\n",
      "train r2:  0.8854797252075344\n",
      "test loss:  6.80776834487915\n",
      "test r2:  -0.2563713393266973\n",
      "train loss:  1.6369470357894897\n",
      "train r2:  0.8852164848759535\n",
      "test loss:  6.802664279937744\n",
      "test r2:  -0.2548461675264493\n",
      "train loss:  1.6370354890823364\n",
      "train r2:  0.8855411874290436\n",
      "test loss:  6.8087568283081055\n",
      "test r2:  -0.2567031184828137\n",
      "train loss:  1.6371361017227173\n",
      "train r2:  0.8851424402304937\n",
      "test loss:  6.801435947418213\n",
      "test r2:  -0.25451126281015846\n",
      "train loss:  1.637239933013916\n",
      "train r2:  0.8856094444079028\n",
      "test loss:  6.809518814086914\n",
      "test r2:  -0.25696410908419653\n",
      "train loss:  1.6372733116149902\n",
      "train r2:  0.8850842221264517\n",
      "test loss:  6.800879001617432\n",
      "test r2:  -0.25438453364867497\n",
      "train loss:  1.6372191905975342\n",
      "train r2:  0.8856362251788188\n",
      "test loss:  6.808870315551758\n",
      "test r2:  -0.2568006552532476\n",
      "train loss:  1.6370484828948975\n",
      "train r2:  0.8851218946503266\n",
      "test loss:  6.802685737609863\n",
      "test r2:  -0.2549699981536244\n",
      "train loss:  1.6368649005889893\n",
      "train r2:  0.8855156679286901\n",
      "test loss:  6.8055572509765625\n",
      "test r2:  -0.2558472126482858\n",
      "train loss:  1.6367652416229248\n",
      "train r2:  0.8853294289267335\n",
      "test loss:  6.806197643280029\n",
      "test r2:  -0.25605651013398467\n",
      "train loss:  1.6367911100387573\n",
      "train r2:  0.8852840863967665\n",
      "test loss:  6.802294731140137\n",
      "test r2:  -0.25490425137838213\n",
      "train loss:  1.6368893384933472\n",
      "train r2:  0.8855287313828191\n",
      "test loss:  6.807958602905273\n",
      "test r2:  -0.25661650958236826\n",
      "train loss:  1.636962890625\n",
      "train r2:  0.8851614652335346\n",
      "test loss:  6.801922798156738\n",
      "test r2:  -0.2548237542855156\n",
      "train loss:  1.6369538307189941\n",
      "train r2:  0.885544684647713\n",
      "test loss:  6.806644916534424\n",
      "test r2:  -0.2562624562277287\n",
      "train loss:  1.6368660926818848\n",
      "train r2:  0.88523814841427\n",
      "test loss:  6.8038530349731445\n",
      "test r2:  -0.25543792673486454\n",
      "train loss:  1.6367793083190918\n",
      "train r2:  0.885415498764882\n",
      "test loss:  6.804229736328125\n",
      "test r2:  -0.25557118148239333\n",
      "train loss:  1.636756420135498\n",
      "train r2:  0.8853871064351205\n",
      "test loss:  6.805765151977539\n",
      "test r2:  -0.2560495851148905\n",
      "train loss:  1.6367979049682617\n",
      "train r2:  0.8852840366758022\n",
      "test loss:  6.802633762359619\n",
      "test r2:  -0.2551224906228269\n",
      "train loss:  1.6368494033813477\n",
      "train r2:  0.885481294903166\n",
      "test loss:  6.806391716003418\n",
      "test r2:  -0.2562707827597519\n",
      "train loss:  1.6368564367294312\n",
      "train r2:  0.8852354543761538\n",
      "test loss:  6.802635669708252\n",
      "test r2:  -0.255159797516771\n",
      "train loss:  1.636816143989563\n",
      "train r2:  0.8854733721700281\n",
      "test loss:  6.805271625518799\n",
      "test r2:  -0.2559665218389351\n",
      "train loss:  1.6367661952972412\n",
      "train r2:  0.8853014257101514\n",
      "test loss:  6.804183483123779\n",
      "test r2:  -0.25566059573542366\n",
      "train loss:  1.6367498636245728\n",
      "train r2:  0.8853668282831693\n",
      "test loss:  6.803235054016113\n",
      "test r2:  -0.2553902198962421\n",
      "train loss:  1.6367706060409546\n",
      "train r2:  0.8854241833449226\n",
      "test loss:  6.805673599243164\n",
      "test r2:  -0.2561382234495768\n",
      "train loss:  1.6367981433868408\n",
      "train r2:  0.8852636719567659\n",
      "test loss:  6.802328586578369\n",
      "test r2:  -0.25515325035320147\n",
      "train loss:  1.6368026733398438\n",
      "train r2:  0.8854739213630649\n",
      "test loss:  6.805299282073975\n",
      "test r2:  -0.25605941845652147\n",
      "train loss:  1.63677978515625\n",
      "train r2:  0.8852803708997656\n",
      "test loss:  6.803352355957031\n",
      "test r2:  -0.2554930446572894\n",
      "train loss:  1.6367532014846802\n",
      "train r2:  0.8854016345551933\n",
      "test loss:  6.803616523742676\n",
      "test r2:  -0.25559082741354566\n",
      "train loss:  1.636744499206543\n",
      "train r2:  0.8853806183682214\n",
      "test loss:  6.804656982421875\n",
      "test r2:  -0.25591761220542275\n",
      "train loss:  1.6367558240890503\n",
      "train r2:  0.88531042747478\n",
      "test loss:  6.802610397338867\n",
      "test r2:  -0.2553213734497579\n",
      "train loss:  1.636770486831665\n",
      "train r2:  0.8854374580812496\n",
      "test loss:  6.804758071899414\n",
      "test r2:  -0.2559832009434788\n",
      "train loss:  1.6367712020874023\n",
      "train r2:  0.8852957652706567\n",
      "test loss:  6.802854537963867\n",
      "test r2:  -0.25542696703213985\n",
      "train loss:  1.6367586851119995\n",
      "train r2:  0.8854147082337762\n",
      "test loss:  6.803907871246338\n",
      "test r2:  -0.2557620504557996\n",
      "train loss:  1.6367437839508057\n",
      "train r2:  0.8853430631040222\n",
      "test loss:  6.80360221862793\n",
      "test r2:  -0.2556863282652164\n",
      "train loss:  1.6367394924163818\n",
      "train r2:  0.8853591228045805\n",
      "test loss:  6.802975654602051\n",
      "test r2:  -0.255513915479044\n",
      "train loss:  1.6367453336715698\n",
      "train r2:  0.8853956804400122\n",
      "test loss:  6.8041157722473145\n",
      "test r2:  -0.2558743563624901\n",
      "train loss:  1.6367524862289429\n",
      "train r2:  0.8853183328165988\n",
      "test loss:  6.8025221824646\n",
      "test r2:  -0.2554111964406962\n",
      "train loss:  1.636752724647522\n",
      "train r2:  0.8854171754094713\n",
      "test loss:  6.8039655685424805\n",
      "test r2:  -0.2558605761998416\n",
      "train loss:  1.6367453336715698\n",
      "train r2:  0.8853209828027924\n",
      "test loss:  6.802832126617432\n",
      "test r2:  -0.2555380234250677\n",
      "train loss:  1.6367372274398804\n",
      "train r2:  0.8853898404583703\n",
      "test loss:  6.803133010864258\n",
      "test r2:  -0.25564368610877897\n",
      "train loss:  1.6367343664169312\n",
      "train r2:  0.8853671406486688\n",
      "test loss:  6.803510665893555\n",
      "test r2:  -0.25577359010748024\n",
      "train loss:  1.6367368698120117\n",
      "train r2:  0.8853391379203722\n",
      "test loss:  6.8024001121521\n",
      "test r2:  -0.2554571596474231\n",
      "train loss:  1.6367406845092773\n",
      "train r2:  0.8854065420935935\n",
      "test loss:  6.8036580085754395\n",
      "test r2:  -0.25585030182467894\n",
      "train loss:  1.6367405652999878\n",
      "train r2:  0.8853223212407304\n",
      "test loss:  6.802425861358643\n",
      "test r2:  -0.25549730083876154\n",
      "train loss:  1.636736273765564\n",
      "train r2:  0.8853976230062744\n",
      "test loss:  6.803091526031494\n",
      "test r2:  -0.25571374334213215\n",
      "train loss:  1.6367316246032715\n",
      "train r2:  0.8853512090160514\n",
      "test loss:  6.8028883934021\n",
      "test r2:  -0.2556683344412096\n",
      "train loss:  1.6367292404174805\n",
      "train r2:  0.8853607968344862\n",
      "test loss:  6.802462577819824\n",
      "test r2:  -0.25555755873838226\n",
      "train loss:  1.6367300748825073\n",
      "train r2:  0.8853842545879288\n",
      "test loss:  6.803103923797607\n",
      "test r2:  -0.25576616140937247\n",
      "train loss:  1.6367316246032715\n",
      "train r2:  0.8853394876557956\n",
      "test loss:  6.802234172821045\n",
      "test r2:  -0.25552063312860773\n",
      "train loss:  1.6367318630218506\n",
      "train r2:  0.8853917787841185\n",
      "test loss:  6.802924633026123\n",
      "test r2:  -0.25574501421097384\n",
      "train loss:  1.6367295980453491\n",
      "train r2:  0.8853436435415388\n",
      "test loss:  6.802316188812256\n",
      "test r2:  -0.25557795216740176\n",
      "train loss:  1.6367264986038208\n",
      "train r2:  0.8853791899787731\n",
      "test loss:  6.802527904510498\n",
      "test r2:  -0.2556576733050573\n",
      "train loss:  1.636724591255188\n",
      "train r2:  0.8853620076227685\n",
      "test loss:  6.802525520324707\n",
      "test r2:  -0.25567375654632474\n",
      "train loss:  1.6367242336273193\n",
      "train r2:  0.8853583551697063\n",
      "test loss:  6.802109241485596\n",
      "test r2:  -0.25556418449452467\n",
      "train loss:  1.6367247104644775\n",
      "train r2:  0.8853815831143115\n",
      "test loss:  6.802631855010986\n",
      "test r2:  -0.2557373562688263\n",
      "train loss:  1.6367247104644775\n",
      "train r2:  0.8853444039762833\n",
      "test loss:  6.801922798156738\n",
      "test r2:  -0.255540849894337\n",
      "train loss:  1.636723518371582\n",
      "train r2:  0.8853862206009409\n",
      "test loss:  6.802423000335693\n",
      "test r2:  -0.2557065977468751\n",
      "train loss:  1.6367218494415283\n",
      "train r2:  0.8853506414051717\n",
      "test loss:  6.802047252655029\n",
      "test r2:  -0.25561030339122937\n",
      "train loss:  1.636719822883606\n",
      "train r2:  0.8853710553170494\n",
      "test loss:  6.802006244659424\n",
      "test r2:  -0.25561396797372615\n",
      "train loss:  1.6367191076278687\n",
      "train r2:  0.885370100316709\n",
      "test loss:  6.802210807800293\n",
      "test r2:  -0.2556909275487793\n",
      "train loss:  1.6367191076278687\n",
      "train r2:  0.8853534906229124\n",
      "test loss:  6.801723957061768\n",
      "test r2:  -0.2555610539736701\n",
      "train loss:  1.6367188692092896\n",
      "train r2:  0.8853810413402019\n",
      "test loss:  6.80213737487793\n",
      "test r2:  -0.255700996147892\n",
      "train loss:  1.6367181539535522\n",
      "train r2:  0.8853509771136344\n",
      "test loss:  6.801687240600586\n",
      "test r2:  -0.2555815164958264\n",
      "train loss:  1.6367169618606567\n",
      "train r2:  0.8853763295706414\n",
      "test loss:  6.801881313323975\n",
      "test r2:  -0.2556562561031075\n",
      "train loss:  1.6367154121398926\n",
      "train r2:  0.8853602061906797\n",
      "test loss:  6.8017425537109375\n",
      "test r2:  -0.25562995099369257\n",
      "train loss:  1.6367144584655762\n",
      "train r2:  0.8853656678425191\n",
      "test loss:  6.801616191864014\n",
      "test r2:  -0.25560792651686337\n",
      "train loss:  1.636713981628418\n",
      "train r2:  0.8853701992849204\n",
      "test loss:  6.801753520965576\n",
      "test r2:  -0.2556652913856221\n",
      "train loss:  1.6367135047912598\n",
      "train r2:  0.8853577429616862\n",
      "test loss:  6.801425457000732\n",
      "test r2:  -0.25558203473736474\n",
      "train loss:  1.636712908744812\n",
      "train r2:  0.8853753755278306\n",
      "test loss:  6.801673412322998\n",
      "test r2:  -0.25567232111152083\n",
      "train loss:  1.6367121934890747\n",
      "train r2:  0.8853559259407452\n",
      "test loss:  6.80134391784668\n",
      "test r2:  -0.2555892435393037\n",
      "train loss:  1.6367111206054688\n",
      "train r2:  0.8853734902705789\n",
      "test loss:  6.8014750480651855\n",
      "test r2:  -0.2556443665330099\n",
      "train loss:  1.6367100477218628\n",
      "train r2:  0.8853615486321157\n",
      "test loss:  6.801361560821533\n",
      "test r2:  -0.2556261569993039\n",
      "train loss:  1.636709451675415\n",
      "train r2:  0.8853652845726224\n",
      "test loss:  6.8012285232543945\n",
      "test r2:  -0.2556018232706563\n",
      "train loss:  1.6367088556289673\n",
      "train r2:  0.885370305533425\n",
      "test loss:  6.801359176635742\n",
      "test r2:  -0.2556566186628608\n",
      "train loss:  1.6367082595825195\n",
      "train r2:  0.8853584288951061\n",
      "test loss:  6.801066875457764\n",
      "test r2:  -0.25558461868632376\n",
      "train loss:  1.6367074251174927\n",
      "train r2:  0.8853736506323624\n",
      "test loss:  6.80124044418335\n",
      "test r2:  -0.2556523256592975\n",
      "train loss:  1.6367065906524658\n",
      "train r2:  0.8853589917377409\n",
      "test loss:  6.801012992858887\n",
      "test r2:  -0.2555992866263479\n",
      "train loss:  1.636705756187439\n",
      "train r2:  0.8853701830727814\n",
      "test loss:  6.801053047180176\n",
      "test r2:  -0.255627228944483\n",
      "train loss:  1.6367050409317017\n",
      "train r2:  0.8853640322588341\n",
      "test loss:  6.8009843826293945\n",
      "test r2:  -0.25562198123737634\n",
      "train loss:  1.6367042064666748\n",
      "train r2:  0.8853649816822311\n",
      "test loss:  6.800875663757324\n",
      "test r2:  -0.25560470749846176\n",
      "train loss:  1.6367034912109375\n",
      "train r2:  0.8853685311372331\n",
      "test loss:  6.800926685333252\n",
      "test r2:  -0.255635740385749\n",
      "train loss:  1.6367028951644897\n",
      "train r2:  0.8853616996480214\n",
      "test loss:  6.800735950469971\n",
      "test r2:  -0.25559366816678786\n",
      "train loss:  1.636702060699463\n",
      "train r2:  0.8853705335080713\n",
      "test loss:  6.800828456878662\n",
      "test r2:  -0.25563708507001315\n",
      "train loss:  1.6367014646530151\n",
      "train r2:  0.8853610855613349\n",
      "test loss:  6.8006391525268555\n",
      "test r2:  -0.25559579246840025\n",
      "train loss:  1.6367007493972778\n",
      "train r2:  0.8853697427203059\n",
      "test loss:  6.800685405731201\n",
      "test r2:  -0.25562480187753955\n",
      "train loss:  1.6367000341415405\n",
      "train r2:  0.8853633997283855\n",
      "test loss:  6.800587177276611\n",
      "test r2:  -0.25561071963365056\n",
      "train loss:  1.6366993188858032\n",
      "train r2:  0.8853662396039204\n",
      "test loss:  6.800513744354248\n",
      "test r2:  -0.255604111028926\n",
      "train loss:  1.636698603630066\n",
      "train r2:  0.8853674861610041\n",
      "test loss:  6.800536632537842\n",
      "test r2:  -0.255626100322204\n",
      "train loss:  1.6366980075836182\n",
      "train r2:  0.8853625987096049\n",
      "test loss:  6.800370693206787\n",
      "test r2:  -0.2555917358529112\n",
      "train loss:  1.6366972923278809\n",
      "train r2:  0.8853697993164572\n",
      "test loss:  6.8004374504089355\n",
      "test r2:  -0.2556269133411908\n",
      "train loss:  1.636696457862854\n",
      "train r2:  0.8853621275557831\n",
      "test loss:  6.800282001495361\n",
      "test r2:  -0.2555955247514403\n",
      "train loss:  1.6366958618164062\n",
      "train r2:  0.885368661189154\n",
      "test loss:  6.800294876098633\n",
      "test r2:  -0.25561467550350536\n",
      "train loss:  1.6366952657699585\n",
      "train r2:  0.885364395884614\n",
      "test loss:  6.800215244293213\n",
      "test r2:  -0.25560602456923\n",
      "train loss:  1.6366944313049316\n",
      "train r2:  0.885366086041913\n",
      "test loss:  6.80015230178833\n",
      "test r2:  -0.2556022585037563\n",
      "train loss:  1.6366937160491943\n",
      "train r2:  0.8853667230614957\n",
      "test loss:  6.800136089324951\n",
      "test r2:  -0.2556126485393637\n",
      "train loss:  1.6366931200027466\n",
      "train r2:  0.885364352202184\n",
      "test loss:  6.800027847290039\n",
      "test r2:  -0.2555951581690712\n",
      "train loss:  1.6366925239562988\n",
      "train r2:  0.88536792264676\n",
      "test loss:  6.800041198730469\n",
      "test r2:  -0.2556144072171529\n",
      "train loss:  1.636691689491272\n",
      "train r2:  0.8853636717064448\n",
      "test loss:  6.7999186515808105\n",
      "test r2:  -0.255592399531263\n",
      "train loss:  1.6366913318634033\n",
      "train r2:  0.8853681798160384\n",
      "test loss:  6.799931049346924\n",
      "test r2:  -0.25561152391102615\n",
      "train loss:  1.636690378189087\n",
      "train r2:  0.8853639919011487\n",
      "test loss:  6.799827575683594\n",
      "test r2:  -0.25559530950462883\n",
      "train loss:  1.6366897821426392\n",
      "train r2:  0.8853672673060236\n",
      "test loss:  6.799802780151367\n",
      "test r2:  -0.25560268646993145\n",
      "train loss:  1.636689305305481\n",
      "train r2:  0.8853655383941674\n",
      "test loss:  6.7997517585754395\n",
      "test r2:  -0.2556025413444407\n",
      "train loss:  1.6366885900497437\n",
      "train r2:  0.8853653901695799\n",
      "test loss:  6.79966926574707\n",
      "test r2:  -0.25559290937937984\n",
      "train loss:  1.6366876363754272\n",
      "train r2:  0.8853673261750171\n",
      "test loss:  6.799665451049805\n",
      "test r2:  -0.25560644618196626\n",
      "train loss:  1.6366870403289795\n",
      "train r2:  0.8853642291275025\n",
      "test loss:  6.799559116363525\n",
      "test r2:  -0.255589548377388\n",
      "train loss:  1.6366864442825317\n",
      "train r2:  0.8853677333217366\n",
      "test loss:  6.799555778503418\n",
      "test r2:  -0.2556033871915768\n",
      "train loss:  1.636685848236084\n",
      "train r2:  0.8853645679734988\n",
      "test loss:  6.79946756362915\n",
      "test r2:  -0.255591643574433\n",
      "train loss:  1.6366851329803467\n",
      "train r2:  0.8853669501243041\n",
      "test loss:  6.799437046051025\n",
      "test r2:  -0.2555976167779104\n",
      "train loss:  1.636684536933899\n",
      "train r2:  0.8853655181702206\n",
      "test loss:  6.799375534057617\n",
      "test r2:  -0.25559371800298303\n",
      "train loss:  1.6366839408874512\n",
      "train r2:  0.8853661688788345\n",
      "test loss:  6.799324035644531\n",
      "test r2:  -0.25559299516514344\n",
      "train loss:  1.6366832256317139\n",
      "train r2:  0.8853661680307068\n",
      "test loss:  6.799280166625977\n",
      "test r2:  -0.25559495170073787\n",
      "train loss:  1.6366826295852661\n",
      "train r2:  0.8853656094837357\n",
      "test loss:  6.799212455749512\n",
      "test r2:  -0.25558928778398093\n",
      "train loss:  1.6366817951202393\n",
      "train r2:  0.8853666924409049\n",
      "test loss:  6.799183368682861\n",
      "test r2:  -0.25559515052528203\n",
      "train loss:  1.636681318283081\n",
      "train r2:  0.8853652712993018\n",
      "test loss:  6.799105644226074\n",
      "test r2:  -0.2555866539291889\n",
      "train loss:  1.6366807222366333\n",
      "train r2:  0.8853669169159972\n",
      "test loss:  6.799081325531006\n",
      "test r2:  -0.2555940227919109\n",
      "train loss:  1.636680006980896\n",
      "train r2:  0.8853652199215716\n",
      "test loss:  6.799004077911377\n",
      "test r2:  -0.2555857067875076\n",
      "train loss:  1.6366794109344482\n",
      "train r2:  0.8853668227635307\n",
      "test loss:  6.798973560333252\n",
      "test r2:  -0.25559094796503223\n",
      "train loss:  1.6366788148880005\n",
      "train r2:  0.8853655511310558\n",
      "test loss:  6.798910140991211\n",
      "test r2:  -0.2555866543593057\n",
      "train loss:  1.6366782188415527\n",
      "train r2:  0.885366280686905\n",
      "test loss:  6.798859119415283\n",
      "test r2:  -0.25558588587993336\n",
      "train loss:  1.6366775035858154\n",
      "train r2:  0.8853663083933205\n",
      "test loss:  6.798820495605469\n",
      "test r2:  -0.255588729656282\n",
      "train loss:  1.6366769075393677\n",
      "train r2:  0.8853655509283771\n",
      "test loss:  6.798748970031738\n",
      "test r2:  -0.25558199370832235\n",
      "train loss:  1.63667631149292\n",
      "train r2:  0.8853668414652757\n",
      "test loss:  6.7987213134765625\n",
      "test r2:  -0.25558815599522333\n",
      "train loss:  1.6366757154464722\n",
      "train r2:  0.8853653661186789\n",
      "test loss:  6.798649311065674\n",
      "test r2:  -0.25558100088004854\n",
      "train loss:  1.6366751194000244\n",
      "train r2:  0.8853667722882622\n",
      "test loss:  6.7986159324646\n",
      "test r2:  -0.25558537406966475\n",
      "train loss:  1.636674165725708\n",
      "train r2:  0.8853656895868515\n",
      "test loss:  6.798553943634033\n",
      "test r2:  -0.255581334761255\n",
      "train loss:  1.6366736888885498\n",
      "train r2:  0.8853663919417774\n",
      "test loss:  6.798508167266846\n",
      "test r2:  -0.2555820739926875\n",
      "train loss:  1.6366733312606812\n",
      "train r2:  0.8853660659874787\n",
      "test loss:  6.798457145690918\n",
      "test r2:  -0.25558104645194324\n",
      "train loss:  1.6366726160049438\n",
      "train r2:  0.8853661561545442\n",
      "test loss:  6.798405170440674\n",
      "test r2:  -0.2555797988511761\n",
      "train loss:  1.636672019958496\n",
      "train r2:  0.8853662454234881\n",
      "test loss:  6.79835844039917\n",
      "test r2:  -0.2555802538409726\n",
      "train loss:  1.6366713047027588\n",
      "train r2:  0.8853659839809408\n",
      "test loss:  6.7983012199401855\n",
      "test r2:  -0.255577384601712\n",
      "train loss:  1.6366708278656006\n",
      "train r2:  0.885366442208943\n",
      "test loss:  6.79826021194458\n",
      "test r2:  -0.25557960497092647\n",
      "train loss:  1.6366702318191528\n",
      "train r2:  0.8853658777829285\n",
      "test loss:  6.798199653625488\n",
      "test r2:  -0.25557582032850523\n",
      "train loss:  1.6366695165634155\n",
      "train r2:  0.8853665284884855\n",
      "test loss:  6.798159599304199\n",
      "test r2:  -0.25557793998485656\n",
      "train loss:  1.6366691589355469\n",
      "train r2:  0.8853658936348997\n",
      "test loss:  6.798099994659424\n",
      "test r2:  -0.2555743614380006\n",
      "train loss:  1.6366684436798096\n",
      "train r2:  0.8853665437075418\n",
      "test loss:  6.798060417175293\n",
      "test r2:  -0.25557675385801515\n",
      "train loss:  1.6366677284240723\n",
      "train r2:  0.8853658762711273\n",
      "test loss:  6.798001289367676\n",
      "test r2:  -0.2555729622149314\n",
      "train loss:  1.6366673707962036\n",
      "train r2:  0.8853665147229088\n",
      "test loss:  6.797959804534912\n",
      "test r2:  -0.2555747614138155\n",
      "train loss:  1.6366667747497559\n",
      "train r2:  0.8853660029590048\n",
      "test loss:  6.7979044914245605\n",
      "test r2:  -0.25557243654671047\n",
      "train loss:  1.6366660594940186\n",
      "train r2:  0.8853663540755264\n",
      "test loss:  6.797855854034424\n",
      "test r2:  -0.25557195285788503\n",
      "train loss:  1.6366654634475708\n",
      "train r2:  0.8853663201255327\n",
      "test loss:  6.7978105545043945\n",
      "test r2:  -0.25557259905711094\n",
      "train loss:  1.636664867401123\n",
      "train r2:  0.8853660261403143\n",
      "test loss:  6.797752380371094\n",
      "test r2:  -0.2555691332418093\n",
      "train loss:  1.6366643905639648\n",
      "train r2:  0.8853666182229348\n",
      "test loss:  6.797714710235596\n",
      "test r2:  -0.255571993903313\n",
      "train loss:  1.6366636753082275\n",
      "train r2:  0.8853658617807528\n",
      "test loss:  6.7976531982421875\n",
      "test r2:  -0.2555676143233907\n",
      "train loss:  1.6366631984710693\n",
      "train r2:  0.885366670497371\n",
      "test loss:  6.797615051269531\n",
      "test r2:  -0.255570272870981\n",
      "train loss:  1.6366626024246216\n",
      "train r2:  0.8853659561651764\n",
      "test loss:  6.797555923461914\n",
      "test r2:  -0.2555664846401571\n",
      "train loss:  1.6366621255874634\n",
      "train r2:  0.8853666018125961\n",
      "test loss:  6.7975172996521\n",
      "test r2:  -0.25556879391245735\n",
      "train loss:  1.6366615295410156\n",
      "train r2:  0.88536599393143\n",
      "test loss:  6.797459125518799\n",
      "test r2:  -0.2555653400011493\n",
      "train loss:  1.6366609334945679\n",
      "train r2:  0.8853665862613284\n",
      "test loss:  6.797418117523193\n",
      "test r2:  -0.255567074395775\n",
      "train loss:  1.6366603374481201\n",
      "train r2:  0.8853660643425032\n",
      "test loss:  6.797361373901367\n",
      "test r2:  -0.2555639808649619\n",
      "train loss:  1.636659860610962\n",
      "train r2:  0.8853665725026816\n",
      "test loss:  6.797320365905762\n",
      "test r2:  -0.25556544114003277\n",
      "train loss:  1.6366592645645142\n",
      "train r2:  0.8853661290635395\n",
      "test loss:  6.797266006469727\n",
      "test r2:  -0.25556325076839004\n",
      "train loss:  1.636658787727356\n",
      "train r2:  0.8853664228509017\n",
      "test loss:  6.7972187995910645\n",
      "test r2:  -0.2555630524272152\n",
      "train loss:  1.6366580724716187\n",
      "train r2:  0.8853663292320569\n",
      "test loss:  6.797172546386719\n",
      "test r2:  -0.2555627001411078\n",
      "train loss:  1.6366573572158813\n",
      "train r2:  0.8853662514409644\n",
      "test loss:  6.797119617462158\n",
      "test r2:  -0.2555608036784873\n",
      "train loss:  1.6366571187973022\n",
      "train r2:  0.8853665146940157\n",
      "test loss:  6.797077655792236\n",
      "test r2:  -0.25556196961032285\n",
      "train loss:  1.6366565227508545\n",
      "train r2:  0.885366157858011\n",
      "test loss:  6.797021865844727\n",
      "test r2:  -0.2555591632787104\n",
      "train loss:  1.6366559267044067\n",
      "train r2:  0.8853665869898125\n",
      "test loss:  6.796980381011963\n",
      "test r2:  -0.2555605923109192\n",
      "train loss:  1.636655330657959\n",
      "train r2:  0.8853661552154262\n",
      "test loss:  6.796926498413086\n",
      "test r2:  -0.2555579203313969\n",
      "train loss:  1.6366548538208008\n",
      "train r2:  0.8853665898441956\n",
      "test loss:  6.796885967254639\n",
      "test r2:  -0.2555594853583323\n",
      "train loss:  1.6366543769836426\n",
      "train r2:  0.8853661060166058\n",
      "test loss:  6.79682731628418\n",
      "test r2:  -0.2555556944566879\n",
      "train loss:  1.6366537809371948\n",
      "train r2:  0.8853668118440556\n",
      "test loss:  6.7967939376831055\n",
      "test r2:  -0.2555592939645672\n",
      "train loss:  1.636652946472168\n",
      "train r2:  0.8853658759610096\n",
      "test loss:  6.796728610992432\n",
      "test r2:  -0.25555342145347115\n",
      "train loss:  1.6366527080535889\n",
      "train r2:  0.8853669854991105\n",
      "test loss:  6.796699523925781\n",
      "test r2:  -0.2555582471136286\n",
      "train loss:  1.6366521120071411\n",
      "train r2:  0.885365828726581\n",
      "test loss:  6.796634197235107\n",
      "test r2:  -0.25555243990654564\n",
      "train loss:  1.636651635169983\n",
      "train r2:  0.8853669166532905\n",
      "test loss:  6.796600341796875\n",
      "test r2:  -0.2555557148647041\n",
      "train loss:  1.6366511583328247\n",
      "train r2:  0.8853660755198077\n",
      "test loss:  6.796543598175049\n",
      "test r2:  -0.25555217957530507\n",
      "train loss:  1.636650562286377\n",
      "train r2:  0.8853667142260022\n",
      "test loss:  6.796505451202393\n",
      "test r2:  -0.25555435396708615\n",
      "train loss:  1.6366499662399292\n",
      "train r2:  0.8853660938137645\n",
      "test loss:  6.796444892883301\n",
      "test r2:  -0.25554992232255436\n",
      "train loss:  1.636649489402771\n",
      "train r2:  0.8853669263416507\n",
      "test loss:  6.796414375305176\n",
      "test r2:  -0.25555414135013144\n",
      "train loss:  1.6366488933563232\n",
      "train r2:  0.8853658739776306\n",
      "test loss:  6.796348571777344\n",
      "test r2:  -0.2555479599906243\n",
      "train loss:  1.6366485357284546\n",
      "train r2:  0.8853670717682909\n",
      "test loss:  6.796319961547852\n",
      "test r2:  -0.25555279577286294\n",
      "train loss:  1.6366478204727173\n",
      "train r2:  0.8853659012869641\n",
      "test loss:  6.796257019042969\n",
      "test r2:  -0.2555472996589907\n",
      "train loss:  1.6366474628448486\n",
      "train r2:  0.8853669197174365\n",
      "test loss:  6.79622220993042\n",
      "test r2:  -0.25555032548123324\n",
      "train loss:  1.6366468667984009\n",
      "train r2:  0.8853661355441103\n",
      "test loss:  6.796165466308594\n",
      "test r2:  -0.2555465904087444\n",
      "train loss:  1.6366462707519531\n",
      "train r2:  0.8853667830004508\n",
      "test loss:  6.796128749847412\n",
      "test r2:  -0.25554916297804287\n",
      "train loss:  1.636645793914795\n",
      "train r2:  0.8853661286718618\n",
      "test loss:  6.796069622039795\n",
      "test r2:  -0.25554461443187226\n",
      "train loss:  1.6366451978683472\n",
      "train r2:  0.8853669570618246\n",
      "test loss:  6.796037197113037\n",
      "test r2:  -0.25554852514356385\n",
      "train loss:  1.636644721031189\n",
      "train r2:  0.8853659804883302\n",
      "test loss:  6.7959747314453125\n",
      "test r2:  -0.2555429688584052\n",
      "train loss:  1.6366442441940308\n",
      "train r2:  0.8853670458906009\n",
      "test loss:  6.795943737030029\n",
      "test r2:  -0.255546883936806\n",
      "train loss:  1.636643648147583\n",
      "train r2:  0.8853660696011582\n",
      "test loss:  6.79588508605957\n",
      "test r2:  -0.25554261207860196\n",
      "train loss:  1.636643409729004\n",
      "train r2:  0.8853668209193528\n",
      "test loss:  6.795846939086914\n",
      "test r2:  -0.25554461376826354\n",
      "train loss:  1.6366428136825562\n",
      "train r2:  0.8853662754038959\n",
      "test loss:  6.795793056488037\n",
      "test r2:  -0.2555415682261917\n",
      "train loss:  1.636642336845398\n",
      "train r2:  0.8853668013301218\n",
      "test loss:  6.7957563400268555\n",
      "test r2:  -0.2555439237790553\n",
      "train loss:  1.6366417407989502\n",
      "train r2:  0.8853661758121089\n",
      "test loss:  6.79569673538208\n",
      "test r2:  -0.25553904946245143\n",
      "train loss:  1.636641263961792\n",
      "train r2:  0.8853670759079812\n",
      "test loss:  6.795669078826904\n",
      "test r2:  -0.25554391353818007\n",
      "train loss:  1.6366407871246338\n",
      "train r2:  0.8853658869630334\n",
      "test loss:  6.795600891113281\n",
      "test r2:  -0.255536791861511\n",
      "train loss:  1.636640191078186\n",
      "train r2:  0.8853673000294376\n",
      "test loss:  6.7955780029296875\n",
      "test r2:  -0.25554287980785073\n",
      "train loss:  1.6366398334503174\n",
      "train r2:  0.8853658522319723\n",
      "test loss:  6.795510768890381\n",
      "test r2:  -0.2555358743241518\n",
      "train loss:  1.6366392374038696\n",
      "train r2:  0.885367232332012\n",
      "test loss:  6.795485019683838\n",
      "test r2:  -0.2555413119831085\n",
      "train loss:  1.6366386413574219\n",
      "train r2:  0.8853659244668765\n",
      "test loss:  6.7954182624816895\n",
      "test r2:  -0.2555346068970503\n",
      "train loss:  1.6366382837295532\n",
      "train r2:  0.8853672195977959\n",
      "test loss:  6.795393466949463\n",
      "test r2:  -0.25553998121004895\n",
      "train loss:  1.6366379261016846\n",
      "train r2:  0.8853659455917908\n",
      "test loss:  6.7953267097473145\n",
      "test r2:  -0.25553296340452913\n",
      "train loss:  1.6366372108459473\n",
      "train r2:  0.8853673188675185\n",
      "test loss:  6.795306205749512\n",
      "test r2:  -0.25553984743554436\n",
      "train loss:  1.6366368532180786\n",
      "train r2:  0.8853657375737392\n",
      "test loss:  6.795231819152832\n",
      "test r2:  -0.25553052890271033\n",
      "train loss:  1.6366362571716309\n",
      "train r2:  0.8853675586992177\n",
      "test loss:  6.795217514038086\n",
      "test r2:  -0.25553917672785587\n",
      "train loss:  1.6366358995437622\n",
      "train r2:  0.8853655979218873\n",
      "test loss:  6.795138835906982\n",
      "test r2:  -0.25552866727954715\n",
      "train loss:  1.6366353034973145\n",
      "train r2:  0.8853677017530188\n",
      "test loss:  6.795129776000977\n",
      "test r2:  -0.25553890263287893\n",
      "train loss:  1.6366348266601562\n",
      "train r2:  0.8853653975843584\n",
      "test loss:  6.795044422149658\n",
      "test r2:  -0.2555264065408025\n",
      "train loss:  1.636634349822998\n",
      "train r2:  0.8853679718469238\n",
      "test loss:  6.7950439453125\n",
      "test r2:  -0.25553911487296954\n",
      "train loss:  1.636634111404419\n",
      "train r2:  0.8853650968543024\n",
      "test loss:  6.794946193695068\n",
      "test r2:  -0.2555225036162725\n",
      "train loss:  1.6366336345672607\n",
      "train r2:  0.8853685076265366\n",
      "test loss:  6.794964790344238\n",
      "test r2:  -0.2555411550888038\n",
      "train loss:  1.636633038520813\n",
      "train r2:  0.885364414630817\n",
      "test loss:  6.7948455810546875\n",
      "test r2:  -0.25551813867670536\n",
      "train loss:  1.6366325616836548\n",
      "train r2:  0.885369208351283\n",
      "test loss:  6.794885635375977\n",
      "test r2:  -0.2555429658598769\n",
      "train loss:  1.6366320848464966\n",
      "train r2:  0.8853637610980091\n",
      "test loss:  6.794743537902832\n",
      "test r2:  -0.2555130502438827\n",
      "train loss:  1.6366316080093384\n",
      "train r2:  0.8853700245966832\n",
      "test loss:  6.79481315612793\n",
      "test r2:  -0.2555468710865558\n",
      "train loss:  1.6366313695907593\n",
      "train r2:  0.8853626640426915\n",
      "test loss:  6.7946319580078125\n",
      "test r2:  -0.2555050227044524\n",
      "train loss:  1.636630892753601\n",
      "train r2:  0.8853714898891826\n",
      "test loss:  6.794751167297363\n",
      "test r2:  -0.25555408038005667\n",
      "train loss:  1.6366304159164429\n",
      "train r2:  0.8853608834907166\n",
      "test loss:  6.794508457183838\n",
      "test r2:  -0.25549351387780606\n",
      "train loss:  1.6366302967071533\n",
      "train r2:  0.8853737141759156\n",
      "test loss:  6.79470682144165\n",
      "test r2:  -0.2555662005582786\n",
      "train loss:  1.6366300582885742\n",
      "train r2:  0.885358047630314\n",
      "test loss:  6.7943644523620605\n",
      "test r2:  -0.2554756717252573\n",
      "train loss:  1.636629581451416\n",
      "train r2:  0.8853772430997943\n",
      "test loss:  6.794684886932373\n",
      "test r2:  -0.25558492942724853\n",
      "train loss:  1.636629581451416\n",
      "train r2:  0.8853537744801716\n",
      "test loss:  6.794194221496582\n",
      "test r2:  -0.2554498298925554\n",
      "train loss:  1.6366298198699951\n",
      "train r2:  0.885382532661462\n",
      "test loss:  6.794698715209961\n",
      "test r2:  -0.25561455977342273\n",
      "train loss:  1.6366302967071533\n",
      "train r2:  0.885347162812725\n",
      "test loss:  6.793977737426758\n",
      "test r2:  -0.25541002175086414\n",
      "train loss:  1.6366311311721802\n",
      "train r2:  0.885390727060545\n",
      "test loss:  6.79477071762085\n",
      "test r2:  -0.25566162874889176\n",
      "train loss:  1.6366331577301025\n",
      "train r2:  0.8853367781177991\n",
      "test loss:  6.793687343597412\n",
      "test r2:  -0.25534782387719224\n",
      "train loss:  1.6366362571716309\n",
      "train r2:  0.8854037194651925\n",
      "test loss:  6.794938564300537\n",
      "test r2:  -0.2557374711018081\n",
      "train loss:  1.636641263961792\n",
      "train r2:  0.8853202035144805\n",
      "test loss:  6.793278694152832\n",
      "test r2:  -0.25524949218544646\n",
      "train loss:  1.6366496086120605\n",
      "train r2:  0.8854242757454639\n",
      "test loss:  6.795258045196533\n",
      "test r2:  -0.25585874035091316\n",
      "train loss:  1.6366629600524902\n",
      "train r2:  0.8852936879099607\n",
      "test loss:  6.792683124542236\n",
      "test r2:  -0.2550948904236583\n",
      "train loss:  1.6366842985153198\n",
      "train r2:  0.8854565976270844\n",
      "test loss:  6.79580545425415\n",
      "test r2:  -0.2560480859572647\n",
      "train loss:  1.6367161273956299\n",
      "train r2:  0.8852521748190892\n",
      "test loss:  6.7918243408203125\n",
      "test r2:  -0.2548607446913558\n",
      "train loss:  1.636765480041504\n",
      "train r2:  0.8855052487597262\n",
      "test loss:  6.796648025512695\n",
      "test r2:  -0.2563253798148779\n",
      "train loss:  1.6368321180343628\n",
      "train r2:  0.8851909979297302\n",
      "test loss:  6.7906904220581055\n",
      "test r2:  -0.2545434988323325\n",
      "train loss:  1.6369229555130005\n",
      "train r2:  0.8855705650417255\n",
      "test loss:  6.797672748565674\n",
      "test r2:  -0.25665588503479264\n",
      "train loss:  1.6370126008987427\n",
      "train r2:  0.8851174907680345\n",
      "test loss:  6.789621353149414\n",
      "test r2:  -0.25424698785359\n",
      "train loss:  1.637090802192688\n",
      "train r2:  0.885631204097064\n",
      "test loss:  6.798186779022217\n",
      "test r2:  -0.25683204413383875\n",
      "train loss:  1.6370843648910522\n",
      "train r2:  0.885078482577131\n",
      "test loss:  6.789471626281738\n",
      "test r2:  -0.25423253965407344\n",
      "train loss:  1.6369990110397339\n",
      "train r2:  0.8856352122815373\n",
      "test loss:  6.797162055969238\n",
      "test r2:  -0.2565474047340244\n",
      "train loss:  1.6368311643600464\n",
      "train r2:  0.8851427105609093\n",
      "test loss:  6.791706562042236\n",
      "test r2:  -0.2549331028240698\n",
      "train loss:  1.6366806030273438\n",
      "train r2:  0.8854898335667916\n",
      "test loss:  6.793696880340576\n",
      "test r2:  -0.2555401205105301\n",
      "train loss:  1.6366196870803833\n",
      "train r2:  0.8853608922166323\n",
      "test loss:  6.795163154602051\n",
      "test r2:  -0.25598926122716636\n",
      "train loss:  1.636661171913147\n",
      "train r2:  0.885264129061447\n",
      "test loss:  6.7908034324646\n",
      "test r2:  -0.25469754485459384\n",
      "train loss:  1.6367499828338623\n",
      "train r2:  0.8855387584797376\n",
      "test loss:  6.7965617179870605\n",
      "test r2:  -0.25643089448107537\n",
      "train loss:  1.6368063688278198\n",
      "train r2:  0.8851673821577772\n",
      "test loss:  6.790763854980469\n",
      "test r2:  -0.2547055708333148\n",
      "train loss:  1.636791706085205\n",
      "train r2:  0.8855363374556695\n",
      "test loss:  6.795193672180176\n",
      "test r2:  -0.25605118281841044\n",
      "train loss:  1.636713981628418\n",
      "train r2:  0.8852496702039587\n",
      "test loss:  6.792620658874512\n",
      "test r2:  -0.2552867002918118\n",
      "train loss:  1.6366393566131592\n",
      "train r2:  0.8854140487277836\n",
      "test loss:  6.793040752410889\n",
      "test r2:  -0.2554285121835844\n",
      "train loss:  1.6366175413131714\n",
      "train r2:  0.8853839016318793\n",
      "test loss:  6.794348239898682\n",
      "test r2:  -0.2558332680540485\n",
      "train loss:  1.6366502046585083\n",
      "train r2:  0.8852967639594406\n",
      "test loss:  6.791585922241211\n",
      "test r2:  -0.25501219749871407\n",
      "train loss:  1.636696219444275\n",
      "train r2:  0.8854715562527429\n",
      "test loss:  6.795078754425049\n",
      "test r2:  -0.2560756299667992\n",
      "train loss:  1.6367095708847046\n",
      "train r2:  0.8852438900900411\n",
      "test loss:  6.791393756866455\n",
      "test r2:  -0.25498072905061875\n",
      "train loss:  1.636682391166687\n",
      "train r2:  0.885478180043706\n",
      "test loss:  6.794317722320557\n",
      "test r2:  -0.2558683282392471\n",
      "train loss:  1.6366387605667114\n",
      "train r2:  0.885288966121457\n",
      "test loss:  6.792686939239502\n",
      "test r2:  -0.25539513053108576\n",
      "train loss:  1.6366150379180908\n",
      "train r2:  0.8853903383856723\n",
      "test loss:  6.792457103729248\n",
      "test r2:  -0.2553348381074265\n",
      "train loss:  1.636623501777649\n",
      "train r2:  0.8854029852787225\n",
      "test loss:  6.79429817199707\n",
      "test r2:  -0.25589871779475337\n",
      "train loss:  1.6366480588912964\n",
      "train r2:  0.88528199403881\n",
      "test loss:  6.791279315948486\n",
      "test r2:  -0.25500688378302216\n",
      "train loss:  1.636662483215332\n",
      "train r2:  0.8854722636569571\n",
      "test loss:  6.794398307800293\n",
      "test r2:  -0.25595100810502713\n",
      "train loss:  1.636653184890747\n",
      "train r2:  0.8852704850977786\n",
      "test loss:  6.791929721832275\n",
      "test r2:  -0.25522466073797445\n",
      "train loss:  1.6366304159164429\n",
      "train r2:  0.885425972229066\n",
      "test loss:  6.792993545532227\n",
      "test r2:  -0.2555568334181546\n",
      "train loss:  1.6366137266159058\n",
      "train r2:  0.8853550718021195\n",
      "test loss:  6.793255805969238\n",
      "test r2:  -0.25564478719948913\n",
      "train loss:  1.636614203453064\n",
      "train r2:  0.8853361797757162\n",
      "test loss:  6.7918291091918945\n",
      "test r2:  -0.2552307656595889\n",
      "train loss:  1.6366260051727295\n",
      "train r2:  0.8854243651090667\n",
      "test loss:  6.7937211990356445\n",
      "test r2:  -0.2558093736712366\n",
      "train loss:  1.6366355419158936\n",
      "train r2:  0.8853003952999629\n",
      "test loss:  6.7917327880859375\n",
      "test r2:  -0.2552234806286713\n",
      "train loss:  1.636634111404419\n",
      "train r2:  0.8854255572312821\n",
      "test loss:  6.7932515144348145\n",
      "test r2:  -0.25569316631470196\n",
      "train loss:  1.6366227865219116\n",
      "train r2:  0.8853251889768642\n",
      "test loss:  6.792268753051758\n",
      "test r2:  -0.2554085647282951\n",
      "train loss:  1.6366122961044312\n",
      "train r2:  0.8853860782495558\n",
      "test loss:  6.792460918426514\n",
      "test r2:  -0.25547768957502015\n",
      "train loss:  1.6366095542907715\n",
      "train r2:  0.8853712392919917\n",
      "test loss:  6.792884349822998\n",
      "test r2:  -0.25561760110854315\n",
      "train loss:  1.6366145610809326\n",
      "train r2:  0.8853411082050836\n",
      "test loss:  6.7917938232421875\n",
      "test r2:  -0.25530012069251407\n",
      "train loss:  1.6366205215454102\n",
      "train r2:  0.8854087939328734\n",
      "test loss:  6.7931742668151855\n",
      "test r2:  -0.25572621100553916\n",
      "train loss:  1.636621356010437\n",
      "train r2:  0.885317573846012\n",
      "test loss:  6.7916717529296875\n",
      "test r2:  -0.25528797297453054\n",
      "train loss:  1.6366164684295654\n",
      "train r2:  0.8854112278592543\n",
      "test loss:  6.792766094207764\n",
      "test r2:  -0.2556261156261679\n",
      "train loss:  1.6366102695465088\n",
      "train r2:  0.8853389080048963\n",
      "test loss:  6.792211532592773\n",
      "test r2:  -0.2554725884558011\n",
      "train loss:  1.6366069316864014\n",
      "train r2:  0.8853716824395854\n",
      "test loss:  6.791958332061768\n",
      "test r2:  -0.2554078640435169\n",
      "train loss:  1.6366080045700073\n",
      "train r2:  0.8853853478042331\n",
      "test loss:  6.792745590209961\n",
      "test r2:  -0.255654540412416\n",
      "train loss:  1.6366113424301147\n",
      "train r2:  0.8853324680235329\n",
      "test loss:  6.791549205780029\n",
      "test r2:  -0.2553082879789277\n",
      "train loss:  1.6366125345230103\n",
      "train r2:  0.8854063587862592\n",
      "test loss:  6.792651176452637\n",
      "test r2:  -0.2556496357705327\n",
      "train loss:  1.6366112232208252\n",
      "train r2:  0.8853332928529113\n",
      "test loss:  6.7917680740356445\n",
      "test r2:  -0.2553960446397998\n",
      "train loss:  1.6366077661514282\n",
      "train r2:  0.8853874498021789\n",
      "test loss:  6.792125225067139\n",
      "test r2:  -0.2555156320094871\n",
      "train loss:  1.6366052627563477\n",
      "train r2:  0.8853617868101559\n",
      "test loss:  6.792131423950195\n",
      "test r2:  -0.2555279167831517\n",
      "train loss:  1.6366044282913208\n",
      "train r2:  0.8853590437889921\n",
      "test loss:  6.791703701019287\n",
      "test r2:  -0.2554110858597256\n",
      "train loss:  1.6366055011749268\n",
      "train r2:  0.8853838976895771\n",
      "test loss:  6.792261123657227\n",
      "test r2:  -0.25559033148892274\n",
      "train loss:  1.6366065740585327\n",
      "train r2:  0.8853454609062167\n",
      "test loss:  6.791542053222656\n",
      "test r2:  -0.25538488641975743\n",
      "train loss:  1.6366066932678223\n",
      "train r2:  0.8853892755368927\n",
      "test loss:  6.792154312133789\n",
      "test r2:  -0.25558052988171576\n",
      "train loss:  1.6366052627563477\n",
      "train r2:  0.885347358769164\n",
      "test loss:  6.7915940284729\n",
      "test r2:  -0.2554238032366336\n",
      "train loss:  1.636603593826294\n",
      "train r2:  0.8853807705049842\n",
      "test loss:  6.791853427886963\n",
      "test r2:  -0.25551235753469803\n",
      "train loss:  1.6366020441055298\n",
      "train r2:  0.8853617334875028\n",
      "test loss:  6.791797161102295\n",
      "test r2:  -0.2555075506849802\n",
      "train loss:  1.6366020441055298\n",
      "train r2:  0.8853626382506038\n",
      "test loss:  6.79148530960083\n",
      "test r2:  -0.25542468719621114\n",
      "train loss:  1.636602520942688\n",
      "train r2:  0.885380240224682\n",
      "test loss:  6.791944980621338\n",
      "test r2:  -0.25557405937724176\n",
      "train loss:  1.636602759361267\n",
      "train r2:  0.885348190630723\n",
      "test loss:  6.791304111480713\n",
      "test r2:  -0.2553935705795283\n",
      "train loss:  1.636602520942688\n",
      "train r2:  0.8853866590510112\n",
      "test loss:  6.791813850402832\n",
      "test r2:  -0.25555722359140365\n",
      "train loss:  1.636601448059082\n",
      "train r2:  0.8853516033245763\n",
      "test loss:  6.79141092300415\n",
      "test r2:  -0.2554476512733408\n",
      "train loss:  1.636600375175476\n",
      "train r2:  0.8853749376081419\n",
      "test loss:  6.791487216949463\n",
      "test r2:  -0.25548198849780923\n",
      "train loss:  1.6365995407104492\n",
      "train r2:  0.8853674777013835\n",
      "test loss:  6.791566848754883\n",
      "test r2:  -0.2555165960854795\n",
      "train loss:  1.6365995407104492\n",
      "train r2:  0.8853599856442227\n",
      "test loss:  6.791245937347412\n",
      "test r2:  -0.25543185509609456\n",
      "train loss:  1.6365995407104492\n",
      "train r2:  0.8853780062753981\n",
      "test loss:  6.791564464569092\n",
      "test r2:  -0.25553830983776926\n",
      "train loss:  1.6365994215011597\n",
      "train r2:  0.8853551037244405\n",
      "test loss:  6.791171073913574\n",
      "test r2:  -0.2554311240655547\n",
      "train loss:  1.636599063873291\n",
      "train r2:  0.8853779496669808\n",
      "test loss:  6.7914323806762695\n",
      "test r2:  -0.2555211916864235\n",
      "train loss:  1.6365984678268433\n",
      "train r2:  0.8853585691242852\n",
      "test loss:  6.791177749633789\n",
      "test r2:  -0.255455502030687\n",
      "train loss:  1.636597752571106\n",
      "train r2:  0.8853725222116925\n",
      "test loss:  6.791254043579102\n",
      "test r2:  -0.2554893539605607\n",
      "train loss:  1.6365972757339478\n",
      "train r2:  0.88536516513747\n",
      "test loss:  6.791213512420654\n",
      "test r2:  -0.2554885042915298\n",
      "train loss:  1.6365970373153687\n",
      "train r2:  0.8853652443156707\n",
      "test loss:  6.791060924530029\n",
      "test r2:  -0.25545349426613817\n",
      "train loss:  1.6365967988967896\n",
      "train r2:  0.8853726231373549\n",
      "test loss:  6.791238784790039\n",
      "test r2:  -0.25551811001454383\n",
      "train loss:  1.6365966796875\n",
      "train r2:  0.8853587120181745\n",
      "test loss:  6.790919303894043\n",
      "test r2:  -0.25543340519592994\n",
      "train loss:  1.6365962028503418\n",
      "train r2:  0.8853766971103567\n",
      "test loss:  6.79116678237915\n",
      "test r2:  -0.2555182698827987\n",
      "train loss:  1.6365957260131836\n",
      "train r2:  0.8853584728339513\n",
      "test loss:  6.7909016609191895\n",
      "test r2:  -0.25545019860912266\n",
      "train loss:  1.6365951299667358\n",
      "train r2:  0.8853729163489853\n",
      "test loss:  6.790985584259033\n",
      "test r2:  -0.2554860503525298\n",
      "train loss:  1.6365948915481567\n",
      "train r2:  0.8853651344888525\n",
      "test loss:  6.790945053100586\n",
      "test r2:  -0.25548465602050263\n",
      "train loss:  1.6365944147109985\n",
      "train r2:  0.8853653630482325\n",
      "test loss:  6.790807723999023\n",
      "test r2:  -0.2554546599030365\n",
      "train loss:  1.636594295501709\n",
      "train r2:  0.8853716668836009\n",
      "test loss:  6.790931701660156\n",
      "test r2:  -0.25550268023533085\n",
      "train loss:  1.6365939378738403\n",
      "train r2:  0.8853612621988186\n",
      "test loss:  6.790710926055908\n",
      "test r2:  -0.25544740708171965\n",
      "train loss:  1.6365935802459717\n",
      "train r2:  0.8853729760860858\n",
      "test loss:  6.790841579437256\n",
      "test r2:  -0.25549772975119356\n",
      "train loss:  1.636593222618103\n",
      "train r2:  0.8853621748322767\n",
      "test loss:  6.79066801071167\n",
      "test r2:  -0.25545612502408965\n",
      "train loss:  1.636592984199524\n",
      "train r2:  0.8853709084158768\n",
      "test loss:  6.790726184844971\n",
      "test r2:  -0.2554847064629575\n",
      "train loss:  1.6365925073623657\n",
      "train r2:  0.885364722452295\n",
      "test loss:  6.790634632110596\n",
      "test r2:  -0.25546813338014696\n",
      "train loss:  1.636592149734497\n",
      "train r2:  0.8853681319457514\n",
      "test loss:  6.790604114532471\n",
      "test r2:  -0.2554696758689641\n",
      "train loss:  1.636591911315918\n",
      "train r2:  0.8853677399108968\n",
      "test loss:  6.790609359741211\n",
      "test r2:  -0.2554820128424178\n",
      "train loss:  1.6365916728973389\n",
      "train r2:  0.8853649820963692\n",
      "test loss:  6.790482997894287\n",
      "test r2:  -0.255454819439487\n",
      "train loss:  1.6365911960601807\n",
      "train r2:  0.8853706925942805\n",
      "test loss:  6.790567398071289\n",
      "test r2:  -0.255490919794477\n",
      "train loss:  1.636590838432312\n",
      "train r2:  0.885362894404421\n",
      "test loss:  6.7903971672058105\n",
      "test r2:  -0.2554507157774173\n",
      "train loss:  1.636590600013733\n",
      "train r2:  0.8853714077098905\n",
      "test loss:  6.790478229522705\n",
      "test r2:  -0.255485717999262\n",
      "train loss:  1.6365902423858643\n",
      "train r2:  0.8853638282726208\n",
      "test loss:  6.790358066558838\n",
      "test r2:  -0.25546040092129485\n",
      "train loss:  1.6365900039672852\n",
      "train r2:  0.8853691125507823\n",
      "test loss:  6.790356159210205\n",
      "test r2:  -0.2554705168987925\n",
      "train loss:  1.6365896463394165\n",
      "train r2:  0.8853668344777574\n",
      "test loss:  6.7903289794921875\n",
      "test r2:  -0.2554730842534374\n",
      "train loss:  1.6365894079208374\n",
      "train r2:  0.8853661792698801\n",
      "test loss:  6.790245532989502\n",
      "test r2:  -0.2554588817489025\n",
      "train loss:  1.6365889310836792\n",
      "train r2:  0.8853691406821289\n",
      "test loss:  6.790277004241943\n",
      "test r2:  -0.25547881731248756\n",
      "train loss:  1.6365886926651\n",
      "train r2:  0.885364757980061\n",
      "test loss:  6.790161609649658\n",
      "test r2:  -0.25545499629120916\n",
      "train loss:  1.6365883350372314\n",
      "train r2:  0.8853697491117725\n",
      "test loss:  6.7902021408081055\n",
      "test r2:  -0.25547786017161567\n",
      "train loss:  1.6365879774093628\n",
      "train r2:  0.8853647568928725\n",
      "test loss:  6.790094375610352\n",
      "test r2:  -0.25545603336006373\n",
      "train loss:  1.6365876197814941\n",
      "train r2:  0.8853693552804663\n",
      "test loss:  6.790115833282471\n",
      "test r2:  -0.25547314108619834\n",
      "train loss:  1.636587381362915\n",
      "train r2:  0.8853655913244413\n",
      "test loss:  6.7900390625\n",
      "test r2:  -0.2554607830820832\n",
      "train loss:  1.6365870237350464\n",
      "train r2:  0.8853681410675632\n",
      "test loss:  6.790019512176514\n",
      "test r2:  -0.25546524111530244\n",
      "train loss:  1.6365866661071777\n",
      "train r2:  0.8853670973580341\n",
      "test loss:  6.789990425109863\n",
      "test r2:  -0.2554671646015445\n",
      "train loss:  1.6365864276885986\n",
      "train r2:  0.8853665839121836\n",
      "test loss:  6.789922714233398\n",
      "test r2:  -0.25545740841876374\n",
      "train loss:  1.6365859508514404\n",
      "train r2:  0.8853685505660638\n",
      "test loss:  6.789935111999512\n",
      "test r2:  -0.25547170695403376\n",
      "train loss:  1.6365858316421509\n",
      "train r2:  0.8853653978027127\n",
      "test loss:  6.789839267730713\n",
      "test r2:  -0.2554532629493451\n",
      "train loss:  1.6365855932235718\n",
      "train r2:  0.8853692537600267\n",
      "test loss:  6.789863109588623\n",
      "test r2:  -0.2554710296184508\n",
      "train loss:  1.6365853548049927\n",
      "train r2:  0.885365376705073\n",
      "test loss:  6.7897748947143555\n",
      "test r2:  -0.2554549143887854\n",
      "train loss:  1.636584758758545\n",
      "train r2:  0.8853686932582979\n",
      "test loss:  6.78977632522583\n",
      "test r2:  -0.2554657680984518\n",
      "train loss:  1.6365846395492554\n",
      "train r2:  0.8853662948839812\n",
      "test loss:  6.789716720581055\n",
      "test r2:  -0.2554584682469394\n",
      "train loss:  1.6365842819213867\n",
      "train r2:  0.8853677316925394\n",
      "test loss:  6.789689540863037\n",
      "test r2:  -0.25546070530468423\n",
      "train loss:  1.6365840435028076\n",
      "train r2:  0.8853671555743661\n",
      "test loss:  6.789655685424805\n",
      "test r2:  -0.2554608191258676\n",
      "train loss:  1.636583685874939\n",
      "train r2:  0.8853670599292948\n",
      "test loss:  6.789608955383301\n",
      "test r2:  -0.25545731587402276\n",
      "train loss:  1.6365834474563599\n",
      "train r2:  0.8853677193272853\n",
      "test loss:  6.789590358734131\n",
      "test r2:  -0.2554622496532444\n",
      "train loss:  1.6365830898284912\n",
      "train r2:  0.8853665393217022\n",
      "test loss:  6.789527893066406\n",
      "test r2:  -0.2554539050727027\n",
      "train loss:  1.636582851409912\n",
      "train r2:  0.8853682491542221\n",
      "test loss:  6.789525032043457\n",
      "test r2:  -0.2554634846986985\n",
      "train loss:  1.6365824937820435\n",
      "train r2:  0.8853661128947823\n",
      "test loss:  6.789453029632568\n",
      "test r2:  -0.2554521200594788\n",
      "train loss:  1.6365821361541748\n",
      "train r2:  0.8853684403846603\n",
      "test loss:  6.7894511222839355\n",
      "test r2:  -0.2554616618311034\n",
      "train loss:  1.6365817785263062\n",
      "train r2:  0.8853662713799278\n",
      "test loss:  6.789388656616211\n",
      "test r2:  -0.2554533182623604\n",
      "train loss:  1.636581540107727\n",
      "train r2:  0.8853679950637525\n",
      "test loss:  6.789369106292725\n",
      "test r2:  -0.25545769706397614\n",
      "train loss:  1.6365814208984375\n",
      "train r2:  0.8853669415935065\n",
      "test loss:  6.789327621459961\n",
      "test r2:  -0.25545547859546813\n",
      "train loss:  1.6365810632705688\n",
      "train r2:  0.8853673237980634\n",
      "test loss:  6.789289474487305\n",
      "test r2:  -0.25545440746955883\n",
      "train loss:  1.6365808248519897\n",
      "train r2:  0.8853674565333937\n",
      "test loss:  6.789261341094971\n",
      "test r2:  -0.25545633353240516\n",
      "train loss:  1.636580467224121\n",
      "train r2:  0.8853669634752601\n",
      "test loss:  6.789213180541992\n",
      "test r2:  -0.25545195190021164\n",
      "train loss:  1.6365803480148315\n",
      "train r2:  0.8853677960595135\n",
      "test loss:  6.789194107055664\n",
      "test r2:  -0.2554566385916923\n",
      "train loss:  1.6365798711776733\n",
      "train r2:  0.8853667052302978\n",
      "test loss:  6.789139270782471\n",
      "test r2:  -0.255450363057097\n",
      "train loss:  1.6365796327590942\n",
      "train r2:  0.885367956008357\n",
      "test loss:  6.789124011993408\n",
      "test r2:  -0.2554559960709888\n",
      "train loss:  1.6365792751312256\n",
      "train r2:  0.8853666684186432\n",
      "test loss:  6.789069652557373\n",
      "test r2:  -0.25544972416166334\n",
      "train loss:  1.636579155921936\n",
      "train r2:  0.885367933005701\n",
      "test loss:  6.7890520095825195\n",
      "test r2:  -0.2554547179974733\n",
      "train loss:  1.6365786790847778\n",
      "train r2:  0.8853667508262658\n",
      "test loss:  6.789000988006592\n",
      "test r2:  -0.25544944213205634\n",
      "train loss:  1.6365783214569092\n",
      "train r2:  0.8853677994468864\n",
      "test loss:  6.7889790534973145\n",
      "test r2:  -0.2554530403086217\n",
      "train loss:  1.63657808303833\n",
      "train r2:  0.8853669064173275\n",
      "test loss:  6.788932800292969\n",
      "test r2:  -0.2554491961257519\n",
      "train loss:  1.6365777254104614\n",
      "train r2:  0.8853676414431735\n",
      "test loss:  6.788905143737793\n",
      "test r2:  -0.25545110857233055\n",
      "train loss:  1.6365774869918823\n",
      "train r2:  0.8853671669881569\n",
      "test loss:  6.788868427276611\n",
      "test r2:  -0.25545007124950225\n",
      "train loss:  1.6365772485733032\n",
      "train r2:  0.8853672861873334\n",
      "test loss:  6.788827896118164\n",
      "test r2:  -0.255448101986548\n",
      "train loss:  1.6365770101547241\n",
      "train r2:  0.8853675959103416\n",
      "test loss:  6.788801670074463\n",
      "test r2:  -0.255450419959496\n",
      "train loss:  1.6365766525268555\n",
      "train r2:  0.8853670156690018\n",
      "test loss:  6.78875732421875\n",
      "test r2:  -0.2554469259858838\n",
      "train loss:  1.6365764141082764\n",
      "train r2:  0.8853676789589074\n",
      "test loss:  6.788731575012207\n",
      "test r2:  -0.2554494271312222\n",
      "train loss:  1.6365761756896973\n",
      "train r2:  0.8853670619560778\n",
      "test loss:  6.788688659667969\n",
      "test r2:  -0.25544636372496754\n",
      "train loss:  1.6365759372711182\n",
      "train r2:  0.8853675819372551\n",
      "test loss:  6.788660049438477\n",
      "test r2:  -0.2554480472920817\n",
      "train loss:  1.6365758180618286\n",
      "train r2:  0.8853671584564036\n",
      "test loss:  6.7886199951171875\n",
      "test r2:  -0.2554458296919997\n",
      "train loss:  1.6365753412246704\n",
      "train r2:  0.8853675296888154\n",
      "test loss:  6.788591384887695\n",
      "test r2:  -0.2554472054757537\n",
      "train loss:  1.6365752220153809\n",
      "train r2:  0.8853671417204474\n",
      "test loss:  6.788548469543457\n",
      "test r2:  -0.2554443263233259\n",
      "train loss:  1.6365748643875122\n",
      "train r2:  0.8853676626030915\n",
      "test loss:  6.788524150848389\n",
      "test r2:  -0.2554468766863105\n",
      "train loss:  1.6365745067596436\n",
      "train r2:  0.8853670449412967\n",
      "test loss:  6.78848123550415\n",
      "test r2:  -0.2554439689823227\n",
      "train loss:  1.636574149131775\n",
      "train r2:  0.8853675835409798\n",
      "test loss:  6.788451671600342\n",
      "test r2:  -0.2554447972110572\n",
      "train loss:  1.6365739107131958\n",
      "train r2:  0.8853673074637449\n",
      "test loss:  6.788415908813477\n",
      "test r2:  -0.2554442777529029\n",
      "train loss:  1.6365737915039062\n",
      "train r2:  0.8853673420409622\n",
      "test loss:  6.788380146026611\n",
      "test r2:  -0.2554432292142681\n",
      "train loss:  1.6365734338760376\n",
      "train r2:  0.8853674795094376\n",
      "test loss:  6.78834867477417\n",
      "test r2:  -0.2554438154183507\n",
      "train loss:  1.636573314666748\n",
      "train r2:  0.8853672640357978\n",
      "test loss:  6.788311958312988\n",
      "test r2:  -0.2554424715369712\n",
      "train loss:  1.6365728378295898\n",
      "train r2:  0.8853674268986343\n",
      "test loss:  6.788278102874756\n",
      "test r2:  -0.25544203449738045\n",
      "train loss:  1.6365725994110107\n",
      "train r2:  0.8853674438866241\n",
      "test loss:  6.788245677947998\n",
      "test r2:  -0.25544220661781836\n",
      "train loss:  1.6365723609924316\n",
      "train r2:  0.8853673101320659\n",
      "test loss:  6.788209915161133\n",
      "test r2:  -0.2554413881711679\n",
      "train loss:  1.6365721225738525\n",
      "train r2:  0.8853674005779009\n",
      "test loss:  6.788174152374268\n",
      "test r2:  -0.25544042440240156\n",
      "train loss:  1.6365717649459839\n",
      "train r2:  0.8853674997997826\n",
      "test loss:  6.788145065307617\n",
      "test r2:  -0.25544152837694223\n",
      "train loss:  1.6365716457366943\n",
      "train r2:  0.8853671880231169\n",
      "test loss:  6.788104057312012\n",
      "test r2:  -0.25543882558467446\n",
      "train loss:  1.6365711688995361\n",
      "train r2:  0.8853676875815635\n",
      "test loss:  6.788079738616943\n",
      "test r2:  -0.2554414646008678\n",
      "train loss:  1.6365711688995361\n",
      "train r2:  0.8853670626656448\n",
      "test loss:  6.788033962249756\n",
      "test r2:  -0.2554374417024363\n",
      "train loss:  1.636570692062378\n",
      "train r2:  0.8853678086255786\n",
      "test loss:  6.788012504577637\n",
      "test r2:  -0.25544072522196637\n",
      "train loss:  1.6365705728530884\n",
      "train r2:  0.885367011396426\n",
      "test loss:  6.787967205047607\n",
      "test r2:  -0.2554368498535835\n",
      "train loss:  1.6365700960159302\n",
      "train r2:  0.8853677769153717\n",
      "test loss:  6.7879438400268555\n",
      "test r2:  -0.2554395142630508\n",
      "train loss:  1.6365700960159302\n",
      "train r2:  0.8853671048130336\n",
      "test loss:  6.787900924682617\n",
      "test r2:  -0.25543629936148093\n",
      "train loss:  1.636569857597351\n",
      "train r2:  0.8853676928754203\n",
      "test loss:  6.787876605987549\n",
      "test r2:  -0.25543859335849195\n",
      "train loss:  1.6365694999694824\n",
      "train r2:  0.8853671420589804\n",
      "test loss:  6.787832260131836\n",
      "test r2:  -0.2554349334499306\n",
      "train loss:  1.6365692615509033\n",
      "train r2:  0.8853678041676085\n",
      "test loss:  6.78781270980835\n",
      "test r2:  -0.2554387097439905\n",
      "train loss:  1.6365690231323242\n",
      "train r2:  0.885366956199323\n",
      "test loss:  6.787764072418213\n",
      "test r2:  -0.2554337488919911\n",
      "train loss:  1.6365687847137451\n",
      "train r2:  0.8853679161330412\n",
      "test loss:  6.787743091583252\n",
      "test r2:  -0.25543722824982606\n",
      "train loss:  1.6365684270858765\n",
      "train r2:  0.8853670998143676\n",
      "test loss:  6.78770112991333\n",
      "test r2:  -0.2554342005965151\n",
      "train loss:  1.636568307876587\n",
      "train r2:  0.8853676264904763\n",
      "test loss:  6.78767204284668\n",
      "test r2:  -0.2554349070530506\n",
      "train loss:  1.6365679502487183\n",
      "train r2:  0.8853673987807126\n",
      "test loss:  6.787637710571289\n",
      "test r2:  -0.25543420268565353\n",
      "train loss:  1.6365678310394287\n",
      "train r2:  0.88536744382684\n",
      "test loss:  6.787605285644531\n",
      "test r2:  -0.2554340577404022\n",
      "train loss:  1.6365675926208496\n",
      "train r2:  0.8853674138956468\n",
      "test loss:  6.787569999694824\n",
      "test r2:  -0.25543276039355955\n",
      "train loss:  1.6365671157836914\n",
      "train r2:  0.8853675973832789\n",
      "test loss:  6.787542343139648\n",
      "test r2:  -0.2554341910192486\n",
      "train loss:  1.6365671157836914\n",
      "train r2:  0.8853672081096917\n",
      "test loss:  6.787501335144043\n",
      "test r2:  -0.25543134220438946\n",
      "train loss:  1.6365667581558228\n",
      "train r2:  0.8853677052028789\n",
      "test loss:  6.787475109100342\n",
      "test r2:  -0.2554330162229115\n",
      "train loss:  1.6365665197372437\n",
      "train r2:  0.8853672994800097\n",
      "test loss:  6.787437915802002\n",
      "test r2:  -0.2554314287807484\n",
      "train loss:  1.6365662813186646\n",
      "train r2:  0.8853675308354004\n",
      "test loss:  6.787406921386719\n",
      "test r2:  -0.2554315724069751\n",
      "train loss:  1.6365660429000854\n",
      "train r2:  0.8853674168691601\n",
      "test loss:  6.78737211227417\n",
      "test r2:  -0.2554306232294079\n",
      "train loss:  1.6365656852722168\n",
      "train r2:  0.8853675375813981\n",
      "test loss:  6.787342548370361\n",
      "test r2:  -0.25543116381653586\n",
      "train loss:  1.6365654468536377\n",
      "train r2:  0.8853673436903947\n",
      "test loss:  6.787304401397705\n",
      "test r2:  -0.2554291530329771\n",
      "train loss:  1.6365654468536377\n",
      "train r2:  0.8853676918358825\n",
      "test loss:  6.787280082702637\n",
      "test r2:  -0.25543109857396806\n",
      "train loss:  1.6365649700164795\n",
      "train r2:  0.8853671912404416\n",
      "test loss:  6.787238597869873\n",
      "test r2:  -0.25542803351688437\n",
      "train loss:  1.6365647315979004\n",
      "train r2:  0.8853677390538671\n",
      "test loss:  6.78721284866333\n",
      "test r2:  -0.2554297856609953\n",
      "train loss:  1.6365646123886108\n",
      "train r2:  0.885367284590489\n",
      "test loss:  6.787175178527832\n",
      "test r2:  -0.25542807620494856\n",
      "train loss:  1.6365643739700317\n",
      "train r2:  0.8853676085468274\n",
      "test loss:  6.787145614624023\n",
      "test r2:  -0.2554283051704367\n",
      "train loss:  1.636564016342163\n",
      "train r2:  0.8853674596628778\n",
      "test loss:  6.787112712860107\n",
      "test r2:  -0.25542789730505144\n",
      "train loss:  1.6365638971328735\n",
      "train r2:  0.8853674440843076\n",
      "test loss:  6.7870774269104\n",
      "test r2:  -0.2554266258471414\n",
      "train loss:  1.6365635395050049\n",
      "train r2:  0.8853676302206707\n",
      "test loss:  6.787050247192383\n",
      "test r2:  -0.25542776844616677\n",
      "train loss:  1.6365634202957153\n",
      "train r2:  0.8853672969204098\n",
      "test loss:  6.787012100219727\n",
      "test r2:  -0.2554257071546113\n",
      "train loss:  1.6365630626678467\n",
      "train r2:  0.8853676820168115\n",
      "test loss:  6.786984443664551\n",
      "test r2:  -0.2554266744994913\n",
      "train loss:  1.6365630626678467\n",
      "train r2:  0.885367370539694\n",
      "test loss:  6.786949157714844\n",
      "test r2:  -0.25542534733122\n",
      "train loss:  1.636562466621399\n",
      "train r2:  0.8853675739246772\n",
      "test loss:  6.786919116973877\n",
      "test r2:  -0.25542551081245546\n",
      "train loss:  1.6365623474121094\n",
      "train r2:  0.8853674652956115\n",
      "test loss:  6.7868852615356445\n",
      "test r2:  -0.2554245600496008\n",
      "train loss:  1.6365622282028198\n",
      "train r2:  0.8853675636028964\n",
      "test loss:  6.786855697631836\n",
      "test r2:  -0.2554249988792965\n",
      "train loss:  1.6365618705749512\n",
      "train r2:  0.8853674304250037\n",
      "test loss:  6.786819934844971\n",
      "test r2:  -0.25542342023609343\n",
      "train loss:  1.6365617513656616\n",
      "train r2:  0.8853676449716884\n",
      "test loss:  6.786794662475586\n",
      "test r2:  -0.2554248680500675\n",
      "train loss:  1.636561632156372\n",
      "train r2:  0.8853672710653558\n",
      "test loss:  6.786752700805664\n",
      "test r2:  -0.25542173894655007\n",
      "train loss:  1.636561393737793\n",
      "train r2:  0.8853678450762402\n",
      "test loss:  6.786731243133545\n",
      "test r2:  -0.2554243596889254\n",
      "train loss:  1.6365607976913452\n",
      "train r2:  0.8853672128827823\n",
      "test loss:  6.786691665649414\n",
      "test r2:  -0.2554217339817737\n",
      "train loss:  1.6365607976913452\n",
      "train r2:  0.8853677136723807\n",
      "test loss:  6.786661148071289\n",
      "test r2:  -0.2554217677316022\n",
      "train loss:  1.6365605592727661\n",
      "train r2:  0.8853676096900291\n",
      "test loss:  6.786635875701904\n",
      "test r2:  -0.25542314953289447\n",
      "train loss:  1.636560320854187\n",
      "train r2:  0.8853672306122321\n",
      "test loss:  6.786593437194824\n",
      "test r2:  -0.2554197058706542\n",
      "train loss:  1.636560082435608\n",
      "train r2:  0.8853679030231232\n",
      "test loss:  6.786571025848389\n",
      "test r2:  -0.2554222932072947\n",
      "train loss:  1.6365599632263184\n",
      "train r2:  0.885367261083162\n",
      "test loss:  6.786533832550049\n",
      "test r2:  -0.25541987080199746\n",
      "train loss:  1.6365597248077393\n",
      "train r2:  0.8853676799028175\n",
      "test loss:  6.786504745483398\n",
      "test r2:  -0.255420279195812\n",
      "train loss:  1.6365596055984497\n",
      "train r2:  0.8853675325470732\n",
      "test loss:  6.786472797393799\n",
      "test r2:  -0.2554198958798528\n",
      "train loss:  1.6365591287612915\n",
      "train r2:  0.8853675442838748\n",
      "test loss:  6.786443710327148\n",
      "test r2:  -0.2554201471417743\n",
      "train loss:  1.6365591287612915\n",
      "train r2:  0.8853674010528588\n",
      "test loss:  6.786404132843018\n",
      "test r2:  -0.25541733193337124\n",
      "train loss:  1.6365586519241333\n",
      "train r2:  0.8853679335909439\n",
      "test loss:  6.786388874053955\n",
      "test r2:  -0.25542177007471434\n",
      "train loss:  1.6365585327148438\n",
      "train r2:  0.8853669026648929\n",
      "test loss:  6.786333084106445\n",
      "test r2:  -0.255414144067712\n",
      "train loss:  1.636558175086975\n",
      "train r2:  0.885368472650755\n",
      "test loss:  6.786332607269287\n",
      "test r2:  -0.2554228860269825\n",
      "train loss:  1.636558175086975\n",
      "train r2:  0.8853664844544923\n",
      "test loss:  6.786265850067139\n",
      "test r2:  -0.25541194592119676\n",
      "train loss:  1.6365578174591064\n",
      "train r2:  0.8853687372816638\n",
      "test loss:  6.786274433135986\n",
      "test r2:  -0.25542323334012074\n",
      "train loss:  1.6365575790405273\n",
      "train r2:  0.8853662660827308\n",
      "test loss:  6.786198616027832\n",
      "test r2:  -0.25540967531844117\n",
      "train loss:  1.6365574598312378\n",
      "train r2:  0.8853690734567332\n",
      "test loss:  6.786220073699951\n",
      "test r2:  -0.25542521526489326\n",
      "train loss:  1.6365573406219482\n",
      "train r2:  0.8853656912032959\n",
      "test loss:  6.7861223220825195\n",
      "test r2:  -0.25540454123589296\n",
      "train loss:  1.6365571022033691\n",
      "train r2:  0.8853700401394118\n",
      "test loss:  6.78618049621582\n",
      "test r2:  -0.2554311841139505\n",
      "train loss:  1.63655686378479\n",
      "train r2:  0.8853642664748004\n",
      "test loss:  6.78602933883667\n",
      "test r2:  -0.255394479219615\n",
      "train loss:  1.6365567445755005\n",
      "train r2:  0.8853720129385767\n",
      "test loss:  6.786158561706543\n",
      "test r2:  -0.2554422274149879\n",
      "train loss:  1.6365567445755005\n",
      "train r2:  0.8853617232658338\n",
      "test loss:  6.785916328430176\n",
      "test r2:  -0.25537850640365667\n",
      "train loss:  1.6365563869476318\n",
      "train r2:  0.8853752739818094\n",
      "test loss:  6.786162853240967\n",
      "test r2:  -0.2554614437045579\n",
      "train loss:  1.6365565061569214\n",
      "train r2:  0.8853574393844412\n",
      "test loss:  6.7857666015625\n",
      "test r2:  -0.25535112576885255\n",
      "train loss:  1.6365569829940796\n",
      "train r2:  0.8853809453338441\n",
      "test loss:  6.786220073699951\n",
      "test r2:  -0.25549637483015064\n",
      "train loss:  1.6365575790405273\n",
      "train r2:  0.8853498068879663\n",
      "test loss:  6.785545349121094\n",
      "test r2:  -0.2553022963869347\n",
      "train loss:  1.636559009552002\n",
      "train r2:  0.885391216234719\n",
      "test loss:  6.786375522613525\n",
      "test r2:  -0.2555607346017359\n",
      "train loss:  1.6365617513656616\n",
      "train r2:  0.8853358477028201\n",
      "test loss:  6.785193920135498\n",
      "test r2:  -0.25521410635270514\n",
      "train loss:  1.6365668773651123\n",
      "train r2:  0.8854097754794641\n",
      "test loss:  6.786705017089844\n",
      "test r2:  -0.25567729768940817\n",
      "train loss:  1.6365761756896973\n",
      "train r2:  0.8853105281568338\n",
      "test loss:  6.784608364105225\n",
      "test r2:  -0.2550552665112158\n",
      "train loss:  1.636593222618103\n",
      "train r2:  0.8854431938207946\n",
      "test loss:  6.787353038787842\n",
      "test r2:  -0.25588926744547\n",
      "train loss:  1.636623501777649\n",
      "train r2:  0.8852643712006345\n",
      "test loss:  6.783607482910156\n",
      "test r2:  -0.2547707519435738\n",
      "train loss:  1.6366790533065796\n",
      "train r2:  0.8855026249691457\n",
      "test loss:  6.788540840148926\n",
      "test r2:  -0.2562626032621187\n",
      "train loss:  1.6367712020874023\n",
      "train r2:  0.8851822845094999\n",
      "test loss:  6.781968593597412\n",
      "test r2:  -0.2542934161967729\n",
      "train loss:  1.636926293373108\n",
      "train r2:  0.8856009639741633\n",
      "test loss:  6.790410995483398\n",
      "test r2:  -0.25683727838853176\n",
      "train loss:  1.6371333599090576\n",
      "train r2:  0.8850540768679696\n",
      "test loss:  6.779475212097168\n",
      "test r2:  -0.2535616441254709\n",
      "train loss:  1.6373953819274902\n",
      "train r2:  0.885750269048201\n",
      "test loss:  6.792610168457031\n",
      "test r2:  -0.2575002423859092\n",
      "train loss:  1.6375125646591187\n",
      "train r2:  0.8849065276080172\n",
      "test loss:  6.777576923370361\n",
      "test r2:  -0.25302159894051046\n",
      "train loss:  1.6374359130859375\n",
      "train r2:  0.8858641235379965\n",
      "test loss:  6.791913032531738\n",
      "test r2:  -0.25730078267409207\n",
      "train loss:  1.6370213031768799\n",
      "train r2:  0.8849558517679299\n",
      "test loss:  6.782095432281494\n",
      "test r2:  -0.2544052767073186\n",
      "train loss:  1.6366431713104248\n",
      "train r2:  0.885580207895363\n",
      "test loss:  6.784472465515137\n",
      "test r2:  -0.2551166720524689\n",
      "train loss:  1.6365704536437988\n",
      "train r2:  0.8854294504643866\n",
      "test loss:  6.789971828460693\n",
      "test r2:  -0.256755872803047\n",
      "train loss:  1.6367894411087036\n",
      "train r2:  0.885075667339112\n",
      "test loss:  6.779555797576904\n",
      "test r2:  -0.2536623826707205\n",
      "train loss:  1.6369946002960205\n",
      "train r2:  0.885733473530837\n",
      "test loss:  6.789616107940674\n",
      "test r2:  -0.2566768114972704\n",
      "train loss:  1.6369131803512573\n",
      "train r2:  0.8850907639033926\n",
      "test loss:  6.7842607498168945\n",
      "test r2:  -0.2550721693911717\n",
      "train loss:  1.6366777420043945\n",
      "train r2:  0.8854373756117552\n",
      "test loss:  6.783563613891602\n",
      "test r2:  -0.2549005394297894\n",
      "train loss:  1.6365569829940796\n",
      "train r2:  0.885475256869454\n",
      "test loss:  6.788129806518555\n",
      "test r2:  -0.2562535325052122\n",
      "train loss:  1.6366527080535889\n",
      "train r2:  0.885184768432527\n",
      "test loss:  6.782908916473389\n",
      "test r2:  -0.2546937352735932\n",
      "train loss:  1.6367897987365723\n",
      "train r2:  0.8855163989941486\n",
      "test loss:  6.786425590515137\n",
      "test r2:  -0.2557861222392448\n",
      "train loss:  1.6367614269256592\n",
      "train r2:  0.8852830337861503\n",
      "test loss:  6.784821033477783\n",
      "test r2:  -0.25528244384407683\n",
      "train loss:  1.6366173028945923\n",
      "train r2:  0.885392879843088\n",
      "test loss:  6.785094738006592\n",
      "test r2:  -0.25538477993923325\n",
      "train loss:  1.6365512609481812\n",
      "train r2:  0.8853716955395488\n",
      "test loss:  6.785584926605225\n",
      "test r2:  -0.255554665961494\n",
      "train loss:  1.6366262435913086\n",
      "train r2:  0.8853341472592733\n",
      "test loss:  6.783966064453125\n",
      "test r2:  -0.2550488890758156\n",
      "train loss:  1.6366997957229614\n",
      "train r2:  0.8854414766745827\n",
      "test loss:  6.786858081817627\n",
      "test r2:  -0.25594252938130935\n",
      "train loss:  1.6366559267044067\n",
      "train r2:  0.8852507135501778\n",
      "test loss:  6.7833099365234375\n",
      "test r2:  -0.2548890237991057\n",
      "train loss:  1.6365714073181152\n",
      "train r2:  0.8854769467606227\n",
      "test loss:  6.785638332366943\n",
      "test r2:  -0.25557743574464276\n",
      "train loss:  1.636558175086975\n",
      "train r2:  0.8853301321970208\n",
      "test loss:  6.786096572875977\n",
      "test r2:  -0.25573954562457435\n",
      "train loss:  1.6366114616394043\n",
      "train r2:  0.8852945412074756\n",
      "test loss:  6.782581806182861\n",
      "test r2:  -0.25468915223615474\n",
      "train loss:  1.6366389989852905\n",
      "train r2:  0.8855185292176847\n",
      "test loss:  6.787252426147461\n",
      "test r2:  -0.25608745690370394\n",
      "train loss:  1.6365978717803955\n",
      "train r2:  0.8852202185497375\n",
      "test loss:  6.78403902053833\n",
      "test r2:  -0.25514566280273376\n",
      "train loss:  1.636552095413208\n",
      "train r2:  0.8854220548781169\n",
      "test loss:  6.783851623535156\n",
      "test r2:  -0.25509514687565527\n",
      "train loss:  1.6365619897842407\n",
      "train r2:  0.8854326865007657\n",
      "test loss:  6.787013530731201\n",
      "test r2:  -0.2560424201029339\n",
      "train loss:  1.6365978717803955\n",
      "train r2:  0.8852296221492408\n",
      "test loss:  6.782888412475586\n",
      "test r2:  -0.25482386200313734\n",
      "train loss:  1.6365981101989746\n",
      "train r2:  0.8854899707086947\n",
      "test loss:  6.785460948944092\n",
      "test r2:  -0.2556028186304742\n",
      "train loss:  1.6365647315979004\n",
      "train r2:  0.885323919215066\n",
      "test loss:  6.785459518432617\n",
      "test r2:  -0.2556022290182285\n",
      "train loss:  1.6365485191345215\n",
      "train r2:  0.8853242707348679\n",
      "test loss:  6.783368110656738\n",
      "test r2:  -0.25499341478322246\n",
      "train loss:  1.6365644931793213\n",
      "train r2:  0.8854540021888296\n",
      "test loss:  6.785852432250977\n",
      "test r2:  -0.2557430715497171\n",
      "train loss:  1.636580467224121\n",
      "train r2:  0.8852935184154678\n",
      "test loss:  6.784235000610352\n",
      "test r2:  -0.2552589650318844\n",
      "train loss:  1.636572003364563\n",
      "train r2:  0.8853971460315397\n",
      "test loss:  6.784482002258301\n",
      "test r2:  -0.2553529271756694\n",
      "train loss:  1.6365519762039185\n",
      "train r2:  0.8853771515201171\n",
      "test loss:  6.7850341796875\n",
      "test r2:  -0.25551890543151434\n",
      "train loss:  1.6365485191345215\n",
      "train r2:  0.8853416677183347\n",
      "test loss:  6.78420877456665\n",
      "test r2:  -0.25527582126260584\n",
      "train loss:  1.6365617513656616\n",
      "train r2:  0.8853934518973783\n",
      "test loss:  6.784928798675537\n",
      "test r2:  -0.2555098054676317\n",
      "train loss:  1.6365673542022705\n",
      "train r2:  0.8853431595339538\n",
      "test loss:  6.784148693084717\n",
      "test r2:  -0.25527454074356926\n",
      "train loss:  1.6365567445755005\n",
      "train r2:  0.8853936344731004\n",
      "test loss:  6.784877300262451\n",
      "test r2:  -0.2555021696375819\n",
      "train loss:  1.6365467309951782\n",
      "train r2:  0.8853450304473202\n",
      "test loss:  6.784404277801514\n",
      "test r2:  -0.2553746654446143\n",
      "train loss:  1.636549472808838\n",
      "train r2:  0.8853721106085017\n",
      "test loss:  6.784082412719727\n",
      "test r2:  -0.2552778140918621\n",
      "train loss:  1.6365571022033691\n",
      "train r2:  0.8853927101944039\n",
      "test loss:  6.785191059112549\n",
      "test r2:  -0.2556210846733298\n",
      "train loss:  1.63655686378479\n",
      "train r2:  0.8853192266942891\n",
      "test loss:  6.783671855926514\n",
      "test r2:  -0.25517632751417163\n",
      "train loss:  1.636549472808838\n",
      "train r2:  0.8854142920940747\n",
      "test loss:  6.784655570983887\n",
      "test r2:  -0.25547368279162996\n",
      "train loss:  1.6365454196929932\n",
      "train r2:  0.8853507714704614\n",
      "test loss:  6.784730434417725\n",
      "test r2:  -0.25550668826401135\n",
      "train loss:  1.6365485191345215\n",
      "train r2:  0.8853435805181461\n",
      "test loss:  6.7835283279418945\n",
      "test r2:  -0.2551550979094983\n",
      "train loss:  1.6365525722503662\n",
      "train r2:  0.8854185870307635\n",
      "test loss:  6.785050868988037\n",
      "test r2:  -0.25561560233138647\n",
      "train loss:  1.636550784111023\n",
      "train r2:  0.8853201369790192\n",
      "test loss:  6.783998012542725\n",
      "test r2:  -0.2553099454563881\n",
      "train loss:  1.6365456581115723\n",
      "train r2:  0.8853854593058939\n",
      "test loss:  6.7839674949646\n",
      "test r2:  -0.2553098304677448\n",
      "train loss:  1.6365444660186768\n",
      "train r2:  0.8853854267652176\n",
      "test loss:  6.784814357757568\n",
      "test r2:  -0.2555676051066029\n",
      "train loss:  1.6365470886230469\n",
      "train r2:  0.8853302505644814\n",
      "test loss:  6.783674240112305\n",
      "test r2:  -0.25523593522062504\n",
      "train loss:  1.6365488767623901\n",
      "train r2:  0.8854010406655158\n",
      "test loss:  6.784376621246338\n",
      "test r2:  -0.2554557217425202\n",
      "train loss:  1.6365467309951782\n",
      "train r2:  0.8853539989157667\n",
      "test loss:  6.784246444702148\n",
      "test r2:  -0.2554204195244769\n",
      "train loss:  1.6365439891815186\n",
      "train r2:  0.8853615336231146\n",
      "test loss:  6.783865451812744\n",
      "test r2:  -0.2553172620414903\n",
      "train loss:  1.6365437507629395\n",
      "train r2:  0.8853835121977214\n",
      "test loss:  6.78431510925293\n",
      "test r2:  -0.25545961112861315\n",
      "train loss:  1.6365455389022827\n",
      "train r2:  0.8853529927088992\n",
      "test loss:  6.783921718597412\n",
      "test r2:  -0.25534611293826703\n",
      "train loss:  1.636546015739441\n",
      "train r2:  0.8853772243961691\n",
      "test loss:  6.784120559692383\n",
      "test r2:  -0.255417423925105\n",
      "train loss:  1.6365444660186768\n",
      "train r2:  0.8853618847373864\n",
      "test loss:  6.7839436531066895\n",
      "test r2:  -0.2553701511562194\n",
      "train loss:  1.636542797088623\n",
      "train r2:  0.8853719523615666\n",
      "test loss:  6.7840046882629395\n",
      "test r2:  -0.25539454205762535\n",
      "train loss:  1.6365429162979126\n",
      "train r2:  0.8853666720097825\n",
      "test loss:  6.784040451049805\n",
      "test r2:  -0.25541581068412933\n",
      "train loss:  1.636543869972229\n",
      "train r2:  0.8853620439422204\n",
      "test loss:  6.783721923828125\n",
      "test r2:  -0.2553254658960211\n",
      "train loss:  1.6365437507629395\n",
      "train r2:  0.8853812761469178\n",
      "test loss:  6.7841644287109375\n",
      "test r2:  -0.255465671416397\n",
      "train loss:  1.636542797088623\n",
      "train r2:  0.885351247205259\n",
      "test loss:  6.7837114334106445\n",
      "test r2:  -0.255339222357188\n",
      "train loss:  1.6365418434143066\n",
      "train r2:  0.885378218065295\n",
      "test loss:  6.783816337585449\n",
      "test r2:  -0.2553762147210834\n",
      "train loss:  1.6365420818328857\n",
      "train r2:  0.8853702846482728\n",
      "test loss:  6.784060955047607\n",
      "test r2:  -0.2554576052729636\n",
      "train loss:  1.636542558670044\n",
      "train r2:  0.8853527924314853\n",
      "test loss:  6.783499240875244\n",
      "test r2:  -0.2552976631528223\n",
      "train loss:  1.6365423202514648\n",
      "train r2:  0.8853869124054468\n",
      "test loss:  6.7839765548706055\n",
      "test r2:  -0.255446738045342\n",
      "train loss:  1.636541485786438\n",
      "train r2:  0.8853549983791832\n",
      "test loss:  6.783746719360352\n",
      "test r2:  -0.25538577626169356\n",
      "train loss:  1.6365410089492798\n",
      "train r2:  0.8853679776441112\n",
      "test loss:  6.783553600311279\n",
      "test r2:  -0.25533609355270426\n",
      "train loss:  1.6365408897399902\n",
      "train r2:  0.8853785319843268\n",
      "test loss:  6.78392219543457\n",
      "test r2:  -0.255452823632184\n",
      "train loss:  1.6365412473678589\n",
      "train r2:  0.8853534658033697\n",
      "test loss:  6.783515930175781\n",
      "test r2:  -0.255338846848872\n",
      "train loss:  1.6365411281585693\n",
      "train r2:  0.8853777970769583\n",
      "test loss:  6.783677577972412\n",
      "test r2:  -0.2553957689595354\n",
      "train loss:  1.6365405321121216\n",
      "train r2:  0.8853655820810126\n",
      "test loss:  6.783684253692627\n",
      "test r2:  -0.25540373422215557\n",
      "train loss:  1.636540174484253\n",
      "train r2:  0.8853638119466916\n",
      "test loss:  6.7835001945495605\n",
      "test r2:  -0.25535670482152484\n",
      "train loss:  1.6365400552749634\n",
      "train r2:  0.8853737849832923\n",
      "test loss:  6.783642292022705\n",
      "test r2:  -0.25540695913520506\n",
      "train loss:  1.636540174484253\n",
      "train r2:  0.8853629425639589\n",
      "test loss:  6.783498764038086\n",
      "test r2:  -0.25537004228752336\n",
      "train loss:  1.6365400552749634\n",
      "train r2:  0.8853708390727175\n",
      "test loss:  6.78355073928833\n",
      "test r2:  -0.25539424141010714\n",
      "train loss:  1.6365395784378052\n",
      "train r2:  0.8853655717256932\n",
      "test loss:  6.783463001251221\n",
      "test r2:  -0.25537491567015924\n",
      "train loss:  1.6365394592285156\n",
      "train r2:  0.8853696239842455\n",
      "test loss:  6.78347635269165\n",
      "test r2:  -0.2553854886938214\n",
      "train loss:  1.636539340019226\n",
      "train r2:  0.8853673356976041\n",
      "test loss:  6.78347635269165\n",
      "test r2:  -0.2553941402015856\n",
      "train loss:  1.636539340019226\n",
      "train r2:  0.8853653924567286\n",
      "test loss:  6.783331394195557\n",
      "test r2:  -0.2553572067350116\n",
      "train loss:  1.6365389823913574\n",
      "train r2:  0.8853732546759493\n",
      "test loss:  6.783492565155029\n",
      "test r2:  -0.25541263151092486\n",
      "train loss:  1.6365388631820679\n",
      "train r2:  0.8853613459191382\n",
      "test loss:  6.783298969268799\n",
      "test r2:  -0.2553626874670891\n",
      "train loss:  1.6365387439727783\n",
      "train r2:  0.8853719441781464\n",
      "test loss:  6.783330917358398\n",
      "test r2:  -0.25537871929097045\n",
      "train loss:  1.6365383863449097\n",
      "train r2:  0.8853684663607044\n",
      "test loss:  6.783397197723389\n",
      "test r2:  -0.2554060038254018\n",
      "train loss:  1.6365383863449097\n",
      "train r2:  0.8853625638164354\n",
      "test loss:  6.783179759979248\n",
      "test r2:  -0.25534839930377773\n",
      "train loss:  1.6365382671356201\n",
      "train r2:  0.8853748177940864\n",
      "test loss:  6.7833452224731445\n",
      "test r2:  -0.25540474663507906\n",
      "train loss:  1.6365379095077515\n",
      "train r2:  0.8853626973913631\n",
      "test loss:  6.7832255363464355\n",
      "test r2:  -0.2553759448125763\n",
      "train loss:  1.6365379095077515\n",
      "train r2:  0.8853687873828973\n",
      "test loss:  6.783169269561768\n",
      "test r2:  -0.255366690735811\n",
      "train loss:  1.6365376710891724\n",
      "train r2:  0.8853706924262631\n",
      "test loss:  6.783261299133301\n",
      "test r2:  -0.25540109257200916\n",
      "train loss:  1.6365376710891724\n",
      "train r2:  0.8853632936227867\n",
      "test loss:  6.783107280731201\n",
      "test r2:  -0.25536210582634067\n",
      "train loss:  1.6365374326705933\n",
      "train r2:  0.8853715481491097\n",
      "test loss:  6.783165454864502\n",
      "test r2:  -0.25538721079939686\n",
      "train loss:  1.6365371942520142\n",
      "train r2:  0.8853661476327714\n",
      "test loss:  6.7831196784973145\n",
      "test r2:  -0.25538000691307805\n",
      "train loss:  1.6365370750427246\n",
      "train r2:  0.8853676241931805\n",
      "test loss:  6.783073425292969\n",
      "test r2:  -0.25537358579420055\n",
      "train loss:  1.6365368366241455\n",
      "train r2:  0.8853689021611872\n",
      "test loss:  6.783083915710449\n",
      "test r2:  -0.25538388766816156\n",
      "train loss:  1.636536717414856\n",
      "train r2:  0.8853666504258135\n",
      "test loss:  6.783024787902832\n",
      "test r2:  -0.2553727886731485\n",
      "train loss:  1.6365365982055664\n",
      "train r2:  0.88536896008646\n",
      "test loss:  6.783036708831787\n",
      "test r2:  -0.25538416960355237\n",
      "train loss:  1.6365365982055664\n",
      "train r2:  0.885366470040484\n",
      "test loss:  6.7829670906066895\n",
      "test r2:  -0.25536993800673913\n",
      "train loss:  1.6365362405776978\n",
      "train r2:  0.8853694462211869\n",
      "test loss:  6.782989025115967\n",
      "test r2:  -0.25538333677871305\n",
      "train loss:  1.6365362405776978\n",
      "train r2:  0.8853665032432338\n",
      "test loss:  6.78294038772583\n",
      "test r2:  -0.25537603472746073\n",
      "train loss:  1.6365360021591187\n",
      "train r2:  0.885368007944121\n",
      "test loss:  6.782897472381592\n",
      "test r2:  -0.2553700129658494\n",
      "train loss:  1.6365357637405396\n",
      "train r2:  0.8853692634608415\n",
      "test loss:  6.782935619354248\n",
      "test r2:  -0.2553885008588328\n",
      "train loss:  1.63653564453125\n",
      "train r2:  0.8853652333567366\n",
      "test loss:  6.7828288078308105\n",
      "test r2:  -0.25536371391820434\n",
      "train loss:  1.6365355253219604\n",
      "train r2:  0.8853704741736728\n",
      "test loss:  6.782867908477783\n",
      "test r2:  -0.2553823691716668\n",
      "train loss:  1.6365352869033813\n",
      "train r2:  0.8853664244302695\n",
      "test loss:  6.7828288078308105\n",
      "test r2:  -0.25537761483306065\n",
      "train loss:  1.6365351676940918\n",
      "train r2:  0.8853673971629031\n",
      "test loss:  6.782766819000244\n",
      "test r2:  -0.25536604320117506\n",
      "train loss:  1.6365350484848022\n",
      "train r2:  0.8853697861145802\n",
      "test loss:  6.782809734344482\n",
      "test r2:  -0.2553858221694889\n",
      "train loss:  1.6365349292755127\n",
      "train r2:  0.8853655158483803\n",
      "test loss:  6.782723903656006\n",
      "test r2:  -0.25536701669057993\n",
      "train loss:  1.6365346908569336\n",
      "train r2:  0.8853694478653329\n",
      "test loss:  6.7827301025390625\n",
      "test r2:  -0.25537609262117655\n",
      "train loss:  1.636534571647644\n",
      "train r2:  0.8853674767483476\n",
      "test loss:  6.782711505889893\n",
      "test r2:  -0.25537701447199224\n",
      "train loss:  1.6365344524383545\n",
      "train r2:  0.8853672024779389\n",
      "test loss:  6.782660007476807\n",
      "test r2:  -0.2553688344008702\n",
      "train loss:  1.6365342140197754\n",
      "train r2:  0.8853689035811732\n",
      "test loss:  6.78266716003418\n",
      "test r2:  -0.2553776062757853\n",
      "train loss:  1.6365340948104858\n",
      "train r2:  0.8853669542096028\n",
      "test loss:  6.782620429992676\n",
      "test r2:  -0.25537047160549387\n",
      "train loss:  1.6365340948104858\n",
      "train r2:  0.8853683982947457\n",
      "test loss:  6.782609939575195\n",
      "test r2:  -0.2553744419846209\n",
      "train loss:  1.6365338563919067\n",
      "train r2:  0.8853675092508575\n",
      "test loss:  6.782576084136963\n",
      "test r2:  -0.25537101527307726\n",
      "train loss:  1.6365338563919067\n",
      "train r2:  0.8853681623263323\n",
      "test loss:  6.782562255859375\n",
      "test r2:  -0.2553734896569604\n",
      "train loss:  1.6365336179733276\n",
      "train r2:  0.8853675970658536\n",
      "test loss:  6.782533168792725\n",
      "test r2:  -0.2553719278456599\n",
      "train loss:  1.636533260345459\n",
      "train r2:  0.8853678667312245\n",
      "test loss:  6.782503128051758\n",
      "test r2:  -0.2553695496031132\n",
      "train loss:  1.6365333795547485\n",
      "train r2:  0.8853683197897868\n",
      "test loss:  6.78249979019165\n",
      "test r2:  -0.2553755960984865\n",
      "train loss:  1.6365330219268799\n",
      "train r2:  0.8853669679899974\n",
      "test loss:  6.782446384429932\n",
      "test r2:  -0.2553663379130817\n",
      "train loss:  1.636533260345459\n",
      "train r2:  0.885368880260462\n",
      "test loss:  6.7824482917785645\n",
      "test r2:  -0.2553736429178024\n",
      "train loss:  1.6365329027175903\n",
      "train r2:  0.8853672531208273\n",
      "test loss:  6.7824177742004395\n",
      "test r2:  -0.2553712098988623\n",
      "train loss:  1.6365329027175903\n",
      "train r2:  0.8853677071409966\n",
      "test loss:  6.782378673553467\n",
      "test r2:  -0.2553663311377188\n",
      "train loss:  1.6365325450897217\n",
      "train r2:  0.8853687127487826\n",
      "test loss:  6.782385349273682\n",
      "test r2:  -0.2553748579280084\n",
      "train loss:  1.6365324258804321\n",
      "train r2:  0.8853668159752651\n",
      "test loss:  6.7823333740234375\n",
      "test r2:  -0.2553660945284415\n",
      "train loss:  1.6365323066711426\n",
      "train r2:  0.8853686320089905\n",
      "test loss:  6.782325267791748\n",
      "test r2:  -0.2553704129703389\n",
      "train loss:  1.636532187461853\n",
      "train r2:  0.8853676488089532\n",
      "test loss:  6.782302379608154\n",
      "test r2:  -0.25537011802084364\n",
      "train loss:  1.636531949043274\n",
      "train r2:  0.8853676504422191\n",
      "test loss:  6.782269477844238\n",
      "test r2:  -0.25536705091558476\n",
      "train loss:  1.6365318298339844\n",
      "train r2:  0.8853682473072018\n",
      "test loss:  6.782257080078125\n",
      "test r2:  -0.2553700469368807\n",
      "train loss:  1.6365317106246948\n",
      "train r2:  0.8853675800619067\n",
      "test loss:  6.782226085662842\n",
      "test r2:  -0.25536735347200223\n",
      "train loss:  1.6365314722061157\n",
      "train r2:  0.8853680852164267\n",
      "test loss:  6.78220796585083\n",
      "test r2:  -0.25536866101056366\n",
      "train loss:  1.6365313529968262\n",
      "train r2:  0.8853677239512336\n",
      "test loss:  6.782180309295654\n",
      "test r2:  -0.25536684430387924\n",
      "train loss:  1.6365313529968262\n",
      "train r2:  0.8853680485810144\n",
      "test loss:  6.782162666320801\n",
      "test r2:  -0.2553684237581595\n",
      "train loss:  1.6365312337875366\n",
      "train r2:  0.885367684642261\n",
      "test loss:  6.782134532928467\n",
      "test r2:  -0.25536655577336465\n",
      "train loss:  1.636531114578247\n",
      "train r2:  0.8853680148442521\n",
      "test loss:  6.782112121582031\n",
      "test r2:  -0.25536649979674086\n",
      "train loss:  1.636530876159668\n",
      "train r2:  0.8853679690014935\n",
      "test loss:  6.7820963859558105\n",
      "test r2:  -0.2553683940964886\n",
      "train loss:  1.6365306377410889\n",
      "train r2:  0.8853675285684821\n",
      "test loss:  6.782059192657471\n",
      "test r2:  -0.2553639191822108\n",
      "train loss:  1.6365306377410889\n",
      "train r2:  0.8853684012531333\n",
      "test loss:  6.782051086425781\n",
      "test r2:  -0.2553679303814662\n",
      "train loss:  1.6365306377410889\n",
      "train r2:  0.8853674876259078\n",
      "test loss:  6.782020568847656\n",
      "test r2:  -0.25536538656854546\n",
      "train loss:  1.6365303993225098\n",
      "train r2:  0.8853679858994667\n",
      "test loss:  6.781994819641113\n",
      "test r2:  -0.2553643552100029\n",
      "train loss:  1.6365302801132202\n",
      "train r2:  0.8853681269974406\n",
      "test loss:  6.781982421875\n",
      "test r2:  -0.2553670274230171\n",
      "train loss:  1.636529803276062\n",
      "train r2:  0.88536751032519\n",
      "test loss:  6.781947612762451\n",
      "test r2:  -0.25536337698931355\n",
      "train loss:  1.6365300416946411\n",
      "train r2:  0.885368235564982\n",
      "test loss:  6.781932353973389\n",
      "test r2:  -0.2553653049692517\n",
      "train loss:  1.636529803276062\n",
      "train r2:  0.8853677537297445\n",
      "test loss:  6.781908988952637\n",
      "test r2:  -0.25536476067492697\n",
      "train loss:  1.636529803276062\n",
      "train r2:  0.8853678298560169\n",
      "test loss:  6.7818827629089355\n",
      "test r2:  -0.2553632429936059\n",
      "train loss:  1.6365294456481934\n",
      "train r2:  0.8853680650814872\n",
      "test loss:  6.781865119934082\n",
      "test r2:  -0.25536450120801635\n",
      "train loss:  1.6365292072296143\n",
      "train r2:  0.8853677613997237\n",
      "test loss:  6.781839370727539\n",
      "test r2:  -0.2553632816918252\n",
      "train loss:  1.6365290880203247\n",
      "train r2:  0.8853679419618556\n",
      "test loss:  6.781817436218262\n",
      "test r2:  -0.25536324015893164\n",
      "train loss:  1.6365292072296143\n",
      "train r2:  0.8853679244586806\n",
      "test loss:  6.781795978546143\n",
      "test r2:  -0.2553630167153236\n",
      "train loss:  1.6365290880203247\n",
      "train r2:  0.8853679064441377\n",
      "test loss:  6.781773567199707\n",
      "test r2:  -0.25536311101330256\n",
      "train loss:  1.6365289688110352\n",
      "train r2:  0.8853678423415937\n",
      "test loss:  6.781750202178955\n",
      "test r2:  -0.2553621428573454\n",
      "train loss:  1.636528730392456\n",
      "train r2:  0.8853679749922656\n",
      "test loss:  6.781729221343994\n",
      "test r2:  -0.2553625112503013\n",
      "train loss:  1.6365286111831665\n",
      "train r2:  0.8853678868145161\n",
      "test loss:  6.7817063331604\n",
      "test r2:  -0.25536200186097546\n",
      "train loss:  1.636528491973877\n",
      "train r2:  0.8853678937308824\n",
      "test loss:  6.781682968139648\n",
      "test r2:  -0.25536129211507075\n",
      "train loss:  1.636528491973877\n",
      "train r2:  0.8853679900539697\n",
      "test loss:  6.78166389465332\n",
      "test r2:  -0.25536208756890844\n",
      "train loss:  1.6365281343460083\n",
      "train r2:  0.8853677520322123\n",
      "test loss:  6.7816362380981445\n",
      "test r2:  -0.25536026086303343\n",
      "train loss:  1.6365280151367188\n",
      "train r2:  0.8853680850799117\n",
      "test loss:  6.781619071960449\n",
      "test r2:  -0.2553612754019625\n",
      "train loss:  1.63652765750885\n",
      "train r2:  0.8853678379356373\n",
      "test loss:  6.7815961837768555\n",
      "test r2:  -0.25536090378927545\n",
      "train loss:  1.6365278959274292\n",
      "train r2:  0.8853678945055107\n",
      "test loss:  6.781570911407471\n",
      "test r2:  -0.25535973921742805\n",
      "train loss:  1.6365278959274292\n",
      "train r2:  0.8853680626485075\n",
      "test loss:  6.781553745269775\n",
      "test r2:  -0.2553609584141039\n",
      "train loss:  1.6365275382995605\n",
      "train r2:  0.885367765922856\n",
      "test loss:  6.781527519226074\n",
      "test r2:  -0.25535941100557036\n",
      "train loss:  1.636527419090271\n",
      "train r2:  0.8853680258552085\n",
      "test loss:  6.78150749206543\n",
      "test r2:  -0.25535952164388975\n",
      "train loss:  1.6365272998809814\n",
      "train r2:  0.8853679376108223\n",
      "test loss:  6.781486988067627\n",
      "test r2:  -0.25535992130018936\n",
      "train loss:  1.6365272998809814\n",
      "train r2:  0.8853677957697872\n",
      "test loss:  6.781460762023926\n",
      "test r2:  -0.2553580809125051\n",
      "train loss:  1.6365269422531128\n",
      "train r2:  0.8853681268563657\n",
      "test loss:  6.781444072723389\n",
      "test r2:  -0.25535962549455715\n",
      "train loss:  1.6365269422531128\n",
      "train r2:  0.8853677641728045\n",
      "test loss:  6.781418323516846\n",
      "test r2:  -0.2553581569284735\n",
      "train loss:  1.6365268230438232\n",
      "train r2:  0.8853679944548766\n",
      "test loss:  6.781396865844727\n",
      "test r2:  -0.2553578944507455\n",
      "train loss:  1.6365268230438232\n",
      "train r2:  0.8853679962135259\n",
      "test loss:  6.781379222869873\n",
      "test r2:  -0.2553588426206106\n",
      "train loss:  1.6365264654159546\n",
      "train r2:  0.8853677767498811\n",
      "test loss:  6.781352519989014\n",
      "test r2:  -0.255357105161915\n",
      "train loss:  1.636526346206665\n",
      "train r2:  0.8853680731922551\n",
      "test loss:  6.781332492828369\n",
      "test r2:  -0.2553573962813227\n",
      "train loss:  1.636526346206665\n",
      "train r2:  0.8853679615446535\n",
      "test loss:  6.781313896179199\n",
      "test r2:  -0.25535783103514986\n",
      "train loss:  1.6365262269973755\n",
      "train r2:  0.8853677917237245\n",
      "test loss:  6.781287670135498\n",
      "test r2:  -0.2553562524042361\n",
      "train loss:  1.6365258693695068\n",
      "train r2:  0.885368096415619\n",
      "test loss:  6.781269550323486\n",
      "test r2:  -0.25535698145214236\n",
      "train loss:  1.6365258693695068\n",
      "train r2:  0.8853679008746715\n",
      "test loss:  6.781248569488525\n",
      "test r2:  -0.2553569227596384\n",
      "train loss:  1.6365257501602173\n",
      "train r2:  0.8853678532172254\n",
      "test loss:  6.781223773956299\n",
      "test r2:  -0.25535551574121484\n",
      "train loss:  1.6365257501602173\n",
      "train r2:  0.8853680899145983\n",
      "test loss:  6.781206130981445\n",
      "test r2:  -0.25535645987617506\n",
      "train loss:  1.6365253925323486\n",
      "train r2:  0.885367856613825\n",
      "test loss:  6.781183242797852\n",
      "test r2:  -0.255355893908062\n",
      "train loss:  1.6365256309509277\n",
      "train r2:  0.8853679163512301\n",
      "test loss:  6.781158447265625\n",
      "test r2:  -0.2553544672394472\n",
      "train loss:  1.636525273323059\n",
      "train r2:  0.8853681368875936\n",
      "test loss:  6.781144618988037\n",
      "test r2:  -0.25535632957947163\n",
      "train loss:  1.6365249156951904\n",
      "train r2:  0.8853676929965786\n",
      "test loss:  6.781116008758545\n",
      "test r2:  -0.25535394935429134\n",
      "train loss:  1.6365249156951904\n",
      "train r2:  0.8853681224553154\n",
      "test loss:  6.781097888946533\n",
      "test r2:  -0.2553545625000684\n",
      "train loss:  1.6365247964859009\n",
      "train r2:  0.8853679614194327\n",
      "test loss:  6.781079292297363\n",
      "test r2:  -0.2553552161751331\n",
      "train loss:  1.6365246772766113\n",
      "train r2:  0.8853677998169933\n",
      "test loss:  6.781053066253662\n",
      "test r2:  -0.25535341120039545\n",
      "train loss:  1.6365245580673218\n",
      "train r2:  0.8853681150993952\n",
      "test loss:  6.78103494644165\n",
      "test r2:  -0.25535384911660475\n",
      "train loss:  1.6365246772766113\n",
      "train r2:  0.8853679351890826\n",
      "test loss:  6.781015396118164\n",
      "test r2:  -0.25535422293722454\n",
      "train loss:  1.6365243196487427\n",
      "train r2:  0.8853678045060237\n",
      "test loss:  6.780989170074463\n",
      "test r2:  -0.2553523674462974\n",
      "train loss:  1.6365243196487427\n",
      "train r2:  0.8853681638883915\n",
      "test loss:  6.7809739112854\n",
      "test r2:  -0.25535370587133865\n",
      "train loss:  1.6365240812301636\n",
      "train r2:  0.8853678083795399\n",
      "test loss:  6.780949592590332\n",
      "test r2:  -0.25535249710397023\n",
      "train loss:  1.6365240812301636\n",
      "train r2:  0.8853680087154197\n",
      "test loss:  6.7809295654296875\n",
      "test r2:  -0.25535256221955116\n",
      "train loss:  1.6365238428115845\n",
      "train r2:  0.8853679644322917\n",
      "test loss:  6.780908584594727\n",
      "test r2:  -0.2553525708014046\n",
      "train loss:  1.636523723602295\n",
      "train r2:  0.8853679480830852\n",
      "test loss:  6.780886650085449\n",
      "test r2:  -0.2553517066476798\n",
      "train loss:  1.6365236043930054\n",
      "train r2:  0.8853680463326286\n",
      "test loss:  6.780869007110596\n",
      "test r2:  -0.2553523785842733\n",
      "train loss:  1.6365234851837158\n",
      "train r2:  0.8853678657861376\n",
      "test loss:  6.780844211578369\n",
      "test r2:  -0.2553509718730762\n",
      "train loss:  1.6365234851837158\n",
      "train r2:  0.8853680931662461\n",
      "test loss:  6.780827522277832\n",
      "test r2:  -0.2553519266995101\n",
      "train loss:  1.6365231275558472\n",
      "train r2:  0.8853678224995168\n",
      "test loss:  6.7808027267456055\n",
      "test r2:  -0.25535044317355604\n",
      "train loss:  1.6365231275558472\n",
      "train r2:  0.8853680988161593\n",
      "test loss:  6.780785083770752\n",
      "test r2:  -0.2553513213245091\n",
      "train loss:  1.6365230083465576\n",
      "train r2:  0.8853678892533648\n",
      "test loss:  6.780763149261475\n",
      "test r2:  -0.25535050191521624\n",
      "train loss:  1.6365227699279785\n",
      "train r2:  0.8853680055676194\n",
      "test loss:  6.78074312210083\n",
      "test r2:  -0.255350258833706\n",
      "train loss:  1.636522650718689\n",
      "train r2:  0.8853680014185588\n",
      "test loss:  6.780723571777344\n",
      "test r2:  -0.25535036542892775\n",
      "train loss:  1.6365227699279785\n",
      "train r2:  0.8853679245552645\n",
      "test loss:  6.78070068359375\n",
      "test r2:  -0.2553494728711114\n",
      "train loss:  1.6365225315093994\n",
      "train r2:  0.8853680441991092\n",
      "test loss:  6.780683517456055\n",
      "test r2:  -0.2553500662274213\n",
      "train loss:  1.6365224123001099\n",
      "train r2:  0.8853679074224059\n",
      "test loss:  6.780660629272461\n",
      "test r2:  -0.2553489391289845\n",
      "train loss:  1.6365224123001099\n",
      "train r2:  0.8853680707975844\n",
      "test loss:  6.780642509460449\n",
      "test r2:  -0.2553495900717837\n",
      "train loss:  1.6365220546722412\n",
      "train r2:  0.8853678998459841\n",
      "test loss:  6.780618667602539\n",
      "test r2:  -0.2553484665330752\n",
      "train loss:  1.6365220546722412\n",
      "train r2:  0.8853680561644116\n",
      "test loss:  6.7806010246276855\n",
      "test r2:  -0.2553488937537147\n",
      "train loss:  1.6365220546722412\n",
      "train r2:  0.8853679442994551\n",
      "test loss:  6.780579090118408\n",
      "test r2:  -0.2553482278838157\n",
      "train loss:  1.6365219354629517\n",
      "train r2:  0.8853680356830294\n",
      "test loss:  6.780560493469238\n",
      "test r2:  -0.2553485897553822\n",
      "train loss:  1.636521577835083\n",
      "train r2:  0.8853679073529708\n",
      "test loss:  6.780538558959961\n",
      "test r2:  -0.25534748086522163\n",
      "train loss:  1.636521816253662\n",
      "train r2:  0.8853680732045446\n",
      "test loss:  6.780519485473633\n",
      "test r2:  -0.2553478567790761\n",
      "train loss:  1.636521339416504\n",
      "train r2:  0.8853679610145746\n",
      "test loss:  6.78049898147583\n",
      "test r2:  -0.2553473576470109\n",
      "train loss:  1.6365214586257935\n",
      "train r2:  0.8853679876086856\n",
      "test loss:  6.7804789543151855\n",
      "test r2:  -0.2553470570773235\n",
      "train loss:  1.636521339416504\n",
      "train r2:  0.8853680215065909\n",
      "test loss:  6.780459403991699\n",
      "test r2:  -0.2553471940019214\n",
      "train loss:  1.6365211009979248\n",
      "train r2:  0.8853679378056304\n",
      "test loss:  6.780436992645264\n",
      "test r2:  -0.2553462646138216\n",
      "train loss:  1.6365209817886353\n",
      "train r2:  0.8853680763626056\n",
      "test loss:  6.780419826507568\n",
      "test r2:  -0.25534674652073464\n",
      "train loss:  1.6365209817886353\n",
      "train r2:  0.8853679217284927\n",
      "test loss:  6.780398845672607\n",
      "test r2:  -0.2553460878317373\n",
      "train loss:  1.6365207433700562\n",
      "train r2:  0.8853680152518488\n",
      "test loss:  6.780378818511963\n",
      "test r2:  -0.2553458284385608\n",
      "train loss:  1.6365207433700562\n",
      "train r2:  0.8853680251658098\n",
      "test loss:  6.780360221862793\n",
      "test r2:  -0.25534601528947354\n",
      "train loss:  1.636520504951477\n",
      "train r2:  0.8853679281844249\n",
      "test loss:  6.780338764190674\n",
      "test r2:  -0.2553452920092283\n",
      "train loss:  1.636520504951477\n",
      "train r2:  0.8853680609693142\n",
      "test loss:  6.7803192138671875\n",
      "test r2:  -0.25534517340350793\n",
      "train loss:  1.6365203857421875\n",
      "train r2:  0.8853680108941402\n",
      "test loss:  6.780300617218018\n",
      "test r2:  -0.25534527254746897\n",
      "train loss:  1.6365200281143188\n",
      "train r2:  0.8853679561309579\n",
      "test loss:  6.780279159545898\n",
      "test r2:  -0.25534437203454075\n",
      "train loss:  1.636520266532898\n",
      "train r2:  0.8853680547545487\n",
      "test loss:  6.780259609222412\n",
      "test r2:  -0.2553444507745821\n",
      "train loss:  1.6365200281143188\n",
      "train r2:  0.8853679976877785\n",
      "test loss:  6.7802414894104\n",
      "test r2:  -0.2553447383178764\n",
      "train loss:  1.6365199089050293\n",
      "train r2:  0.8853679204072772\n",
      "test loss:  6.780218601226807\n",
      "test r2:  -0.255343379533975\n",
      "train loss:  1.6365197896957397\n",
      "train r2:  0.885368143183421\n",
      "test loss:  6.7802019119262695\n",
      "test r2:  -0.2553440916598593\n",
      "train loss:  1.6365196704864502\n",
      "train r2:  0.8853679367401011\n",
      "test loss:  6.780182361602783\n",
      "test r2:  -0.2553438659427769\n",
      "train loss:  1.6365193128585815\n",
      "train r2:  0.8853679544184967\n",
      "test loss:  6.780160427093506\n",
      "test r2:  -0.2553429074951694\n",
      "train loss:  1.636519432067871\n",
      "train r2:  0.8853680976880399\n",
      "test loss:  6.780142307281494\n",
      "test r2:  -0.2553429798571938\n",
      "train loss:  1.6365193128585815\n",
      "train r2:  0.8853680452146643\n",
      "test loss:  6.780125617980957\n",
      "test r2:  -0.25534367752705833\n",
      "train loss:  1.6365193128585815\n",
      "train r2:  0.8853678506145811\n",
      "test loss:  6.7801008224487305\n",
      "test r2:  -0.2553418469829034\n",
      "train loss:  1.636519193649292\n",
      "train r2:  0.885368200655597\n",
      "test loss:  6.780085563659668\n",
      "test r2:  -0.25534289262541865\n",
      "train loss:  1.6365188360214233\n",
      "train r2:  0.8853679086514088\n",
      "test loss:  6.780064105987549\n",
      "test r2:  -0.255342038687991\n",
      "train loss:  1.6365188360214233\n",
      "train r2:  0.8853680513919575\n",
      "test loss:  6.780045032501221\n",
      "test r2:  -0.2553418576702806\n",
      "train loss:  1.6365187168121338\n",
      "train r2:  0.8853680243573459\n",
      "test loss:  6.780025959014893\n",
      "test r2:  -0.25534160794858685\n",
      "train loss:  1.6365187168121338\n",
      "train r2:  0.8853680235222301\n",
      "test loss:  6.7800068855285645\n",
      "test r2:  -0.25534169570879106\n",
      "train loss:  1.6365185976028442\n",
      "train r2:  0.885367989612319\n",
      "test loss:  6.77998685836792\n",
      "test r2:  -0.25534109441375485\n",
      "train loss:  1.6365183591842651\n",
      "train r2:  0.88536804692084\n",
      "test loss:  6.77996826171875\n",
      "test r2:  -0.25534118268190653\n",
      "train loss:  1.6365182399749756\n",
      "train r2:  0.8853680158894318\n",
      "test loss:  6.779948711395264\n",
      "test r2:  -0.25534063145655717\n",
      "train loss:  1.6365182399749756\n",
      "train r2:  0.885368073650821\n",
      "test loss:  6.779930591583252\n",
      "test r2:  -0.2553409761808023\n",
      "train loss:  1.636518120765686\n",
      "train r2:  0.8853679570190405\n",
      "test loss:  6.779910087585449\n",
      "test r2:  -0.2553400970917852\n",
      "train loss:  1.6365180015563965\n",
      "train r2:  0.8853680962549513\n",
      "test loss:  6.779891490936279\n",
      "test r2:  -0.2553399922661863\n",
      "train loss:  1.6365177631378174\n",
      "train r2:  0.8853680376585924\n",
      "test loss:  6.779873847961426\n",
      "test r2:  -0.2553402742056736\n",
      "train loss:  1.6365177631378174\n",
      "train r2:  0.8853679516555049\n",
      "test loss:  6.779852390289307\n",
      "test r2:  -0.2553391554760802\n",
      "train loss:  1.6365176439285278\n",
      "train r2:  0.8853681322795529\n",
      "test loss:  6.779835224151611\n",
      "test r2:  -0.25533956722480533\n",
      "train loss:  1.6365175247192383\n",
      "train r2:  0.8853680260836608\n",
      "test loss:  6.779817581176758\n",
      "test r2:  -0.2553396989101715\n",
      "train loss:  1.6365175247192383\n",
      "train r2:  0.8853679067637578\n",
      "test loss:  6.779792785644531\n",
      "test r2:  -0.25533765658881324\n",
      "train loss:  1.6365171670913696\n",
      "train r2:  0.8853683161309168\n",
      "test loss:  6.779783248901367\n",
      "test r2:  -0.25534037572551793\n",
      "train loss:  1.6365171670913696\n",
      "train r2:  0.8853677067632653\n",
      "test loss:  6.779754638671875\n",
      "test r2:  -0.2553372079360703\n",
      "train loss:  1.6365171670913696\n",
      "train r2:  0.8853682982615403\n",
      "test loss:  6.779742240905762\n",
      "test r2:  -0.2553387302872303\n",
      "train loss:  1.63651704788208\n",
      "train r2:  0.8853679454079967\n",
      "test loss:  6.779722213745117\n",
      "test r2:  -0.2553382373816173\n",
      "train loss:  1.63651704788208\n",
      "train r2:  0.8853680101944733\n",
      "test loss:  6.779702663421631\n",
      "test r2:  -0.255337693582951\n",
      "train loss:  1.6365166902542114\n",
      "train r2:  0.8853680479761386\n",
      "test loss:  6.779682636260986\n",
      "test r2:  -0.25533709692907935\n",
      "train loss:  1.6365166902542114\n",
      "train r2:  0.8853681345654467\n",
      "test loss:  6.779669284820557\n",
      "test r2:  -0.2553384117509514\n",
      "train loss:  1.6365166902542114\n",
      "train r2:  0.885367812429928\n",
      "test loss:  6.779642105102539\n",
      "test r2:  -0.2553358390382807\n",
      "train loss:  1.6365164518356323\n",
      "train r2:  0.8853683089903671\n",
      "test loss:  6.7796311378479\n",
      "test r2:  -0.2553379067529131\n",
      "train loss:  1.6365164518356323\n",
      "train r2:  0.8853678476725515\n",
      "test loss:  6.779609203338623\n",
      "test r2:  -0.25533646491961015\n",
      "train loss:  1.6365164518356323\n",
      "train r2:  0.8853681117438037\n",
      "test loss:  6.779590129852295\n",
      "test r2:  -0.25533630003332664\n",
      "train loss:  1.6365160942077637\n",
      "train r2:  0.88536808694491\n",
      "test loss:  6.7795729637146\n",
      "test r2:  -0.25533646220782646\n",
      "train loss:  1.6365160942077637\n",
      "train r2:  0.8853680113236769\n",
      "test loss:  6.77955436706543\n",
      "test r2:  -0.25533619973009847\n",
      "train loss:  1.6365158557891846\n",
      "train r2:  0.8853680246826637\n",
      "test loss:  6.779533863067627\n",
      "test r2:  -0.25533532464731157\n",
      "train loss:  1.6365159749984741\n",
      "train r2:  0.8853681450244691\n",
      "test loss:  6.779519557952881\n",
      "test r2:  -0.25533629346278097\n",
      "train loss:  1.6365158557891846\n",
      "train r2:  0.8853679267990758\n",
      "test loss:  6.779496669769287\n",
      "test r2:  -0.2553348471726493\n",
      "train loss:  1.636515498161316\n",
      "train r2:  0.8853681591225475\n",
      "test loss:  6.779480457305908\n",
      "test r2:  -0.25533532357406785\n",
      "train loss:  1.6365156173706055\n",
      "train r2:  0.885368019009212\n",
      "test loss:  6.779462814331055\n",
      "test r2:  -0.25533516267762923\n",
      "train loss:  1.6365153789520264\n",
      "train r2:  0.8853680006340097\n",
      "test loss:  6.779441833496094\n",
      "test r2:  -0.25533413979853137\n",
      "train loss:  1.6365153789520264\n",
      "train r2:  0.8853681837757962\n",
      "test loss:  6.779428005218506\n",
      "test r2:  -0.25533497794452953\n",
      "train loss:  1.6365150213241577\n",
      "train r2:  0.8853679259786695\n",
      "test loss:  6.779406547546387\n",
      "test r2:  -0.25533401744874706\n",
      "train loss:  1.6365151405334473\n",
      "train r2:  0.8853681315634981\n",
      "test loss:  6.779388904571533\n",
      "test r2:  -0.2553339134710928\n",
      "train loss:  1.6365150213241577\n",
      "train r2:  0.8853680614223559\n",
      "test loss:  6.779371738433838\n",
      "test r2:  -0.25533404716776675\n",
      "train loss:  1.6365150213241577\n",
      "train r2:  0.8853680092493825\n",
      "test loss:  6.779352188110352\n",
      "test r2:  -0.2553333699468818\n",
      "train loss:  1.6365149021148682\n",
      "train r2:  0.885368124567226\n",
      "test loss:  6.779334545135498\n",
      "test r2:  -0.255333241366549\n",
      "train loss:  1.6365145444869995\n",
      "train r2:  0.8853680832779588\n",
      "test loss:  6.779318332672119\n",
      "test r2:  -0.2553336475237562\n",
      "train loss:  1.6365145444869995\n",
      "train r2:  0.8853679579276545\n",
      "test loss:  6.779296398162842\n",
      "test r2:  -0.2553322288020605\n",
      "train loss:  1.63651442527771\n",
      "train r2:  0.8853682152302533\n",
      "test loss:  6.779283046722412\n",
      "test r2:  -0.25533344135445657\n",
      "train loss:  1.6365145444869995\n",
      "train r2:  0.8853679365408588\n",
      "test loss:  6.779260635375977\n",
      "test r2:  -0.2553320200889275\n",
      "train loss:  1.6365143060684204\n",
      "train r2:  0.8853681552076185\n",
      "test loss:  6.779245376586914\n",
      "test r2:  -0.2553324880641539\n",
      "train loss:  1.6365143060684204\n",
      "train r2:  0.8853680401790678\n",
      "test loss:  6.7792277336120605\n",
      "test r2:  -0.2553322931475277\n",
      "train loss:  1.6365141868591309\n",
      "train r2:  0.8853680291577147\n",
      "test loss:  6.779208183288574\n",
      "test r2:  -0.25533160485830475\n",
      "train loss:  1.6365139484405518\n",
      "train r2:  0.8853681463311446\n",
      "test loss:  6.779191493988037\n",
      "test r2:  -0.255331842028782\n",
      "train loss:  1.6365138292312622\n",
      "train r2:  0.8853680316638212\n",
      "test loss:  6.7791748046875\n",
      "test r2:  -0.25533180561632607\n",
      "train loss:  1.6365138292312622\n",
      "train r2:  0.8853680139032871\n",
      "test loss:  6.7791523933410645\n",
      "test r2:  -0.2553304414457245\n",
      "train loss:  1.6365137100219727\n",
      "train r2:  0.8853682479490492\n",
      "test loss:  6.779140949249268\n",
      "test r2:  -0.2553320121747791\n",
      "train loss:  1.6365137100219727\n",
      "train r2:  0.8853678694269704\n",
      "test loss:  6.779116630554199\n",
      "test r2:  -0.2553297234456744\n",
      "train loss:  1.636513352394104\n",
      "train r2:  0.8853682848781935\n",
      "test loss:  6.779106140136719\n",
      "test r2:  -0.2553316042848157\n",
      "train loss:  1.636513352394104\n",
      "train r2:  0.8853678548605902\n",
      "test loss:  6.77908182144165\n",
      "test r2:  -0.25532955167752247\n",
      "train loss:  1.636513352394104\n",
      "train r2:  0.8853682473952892\n",
      "test loss:  6.779069423675537\n",
      "test r2:  -0.2553309011872873\n",
      "train loss:  1.6365132331848145\n",
      "train r2:  0.8853679324718645\n",
      "test loss:  6.779047012329102\n",
      "test r2:  -0.2553291074570303\n",
      "train loss:  1.636513113975525\n",
      "train r2:  0.8853682825324946\n",
      "test loss:  6.779036998748779\n",
      "test r2:  -0.2553313240739883\n",
      "train loss:  1.636513113975525\n",
      "train r2:  0.8853677667422704\n",
      "test loss:  6.7790069580078125\n",
      "test r2:  -0.2553272018759345\n",
      "train loss:  1.6365127563476562\n",
      "train r2:  0.8853685599276676\n",
      "test loss:  6.779006481170654\n",
      "test r2:  -0.25533209823499803\n",
      "train loss:  1.6365127563476562\n",
      "train r2:  0.8853674951387528\n",
      "test loss:  6.778970718383789\n",
      "test r2:  -0.2553264501875012\n",
      "train loss:  1.6365127563476562\n",
      "train r2:  0.8853686721163744\n",
      "test loss:  6.778970241546631\n",
      "test r2:  -0.2553314341715893\n",
      "train loss:  1.6365126371383667\n",
      "train r2:  0.8853675408635087\n",
      "test loss:  6.778937816619873\n",
      "test r2:  -0.2553263939569035\n",
      "train loss:  1.6365123987197876\n",
      "train r2:  0.8853685572946347\n",
      "test loss:  6.778934955596924\n",
      "test r2:  -0.25533073287235863\n",
      "train loss:  1.6365126371383667\n",
      "train r2:  0.885367590079345\n",
      "test loss:  6.778900146484375\n",
      "test r2:  -0.25532535297603465\n",
      "train loss:  1.636512279510498\n",
      "train r2:  0.8853687087274555\n",
      "test loss:  6.778905868530273\n",
      "test r2:  -0.2553320589346153\n",
      "train loss:  1.6365121603012085\n",
      "train r2:  0.8853672400131192\n",
      "test loss:  6.778857707977295\n",
      "test r2:  -0.25532249249067407\n",
      "train loss:  1.636512041091919\n",
      "train r2:  0.8853692305031747\n",
      "test loss:  6.778880596160889\n",
      "test r2:  -0.2553344154869883\n",
      "train loss:  1.636512041091919\n",
      "train r2:  0.8853666479697722\n",
      "test loss:  6.778814315795898\n",
      "test r2:  -0.2553193309235824\n",
      "train loss:  1.636512041091919\n",
      "train r2:  0.8853698161576516\n",
      "test loss:  6.778853893280029\n",
      "test r2:  -0.2553363494926575\n",
      "train loss:  1.6365118026733398\n",
      "train r2:  0.8853661717141704\n",
      "test loss:  6.778773784637451\n",
      "test r2:  -0.25531713827846514\n",
      "train loss:  1.6365118026733398\n",
      "train r2:  0.8853701879840352\n",
      "test loss:  6.778825283050537\n",
      "test r2:  -0.2553378075761812\n",
      "train loss:  1.6365116834640503\n",
      "train r2:  0.8853657527910781\n",
      "test loss:  6.778728008270264\n",
      "test r2:  -0.25531341437672284\n",
      "train loss:  1.6365118026733398\n",
      "train r2:  0.8853709160566887\n",
      "test loss:  6.778810024261475\n",
      "test r2:  -0.2553429013137771\n",
      "train loss:  1.6365115642547607\n",
      "train r2:  0.885364567298579\n",
      "test loss:  6.778669357299805\n",
      "test r2:  -0.25530542943523704\n",
      "train loss:  1.6365115642547607\n",
      "train r2:  0.8853725484948478\n",
      "test loss:  6.778808116912842\n",
      "test r2:  -0.2553521311032829\n",
      "train loss:  1.6365115642547607\n",
      "train r2:  0.8853625150430982\n",
      "test loss:  6.778596878051758\n",
      "test r2:  -0.25529349237615295\n",
      "train loss:  1.6365113258361816\n",
      "train r2:  0.8853750101099829\n",
      "test loss:  6.7788190841674805\n",
      "test r2:  -0.255365388014557\n",
      "train loss:  1.6365116834640503\n",
      "train r2:  0.8853595821865683\n",
      "test loss:  6.778509140014648\n",
      "test r2:  -0.25527674446931337\n",
      "train loss:  1.6365118026733398\n",
      "train r2:  0.8853784980441681\n",
      "test loss:  6.778851509094238\n",
      "test r2:  -0.25538516695419666\n",
      "train loss:  1.6365121603012085\n",
      "train r2:  0.8853552580679147\n",
      "test loss:  6.7783894538879395\n",
      "test r2:  -0.255250279835737\n",
      "train loss:  1.6365128755569458\n",
      "train r2:  0.8853840351173565\n",
      "test loss:  6.7789306640625\n",
      "test r2:  -0.25541873878384425\n",
      "train loss:  1.6365139484405518\n",
      "train r2:  0.8853479692736048\n",
      "test loss:  6.7782087326049805\n",
      "test r2:  -0.25520544676693846\n",
      "train loss:  1.6365158557891846\n",
      "train r2:  0.8853934983457743\n",
      "test loss:  6.779088973999023\n",
      "test r2:  -0.2554761347070331\n",
      "train loss:  1.636519193649292\n",
      "train r2:  0.8853355497554427\n",
      "test loss:  6.777929306030273\n",
      "test r2:  -0.25513075775367744\n",
      "train loss:  1.6365242004394531\n",
      "train r2:  0.8854092824427138\n",
      "test loss:  6.779369831085205\n",
      "test r2:  -0.25557058253046927\n",
      "train loss:  1.6365324258804321\n",
      "train r2:  0.8853150751811232\n",
      "test loss:  6.777498245239258\n",
      "test r2:  -0.2550100209481565\n",
      "train loss:  1.6365464925765991\n",
      "train r2:  0.8854346682334636\n",
      "test loss:  6.779841899871826\n",
      "test r2:  -0.25572247049719365\n",
      "train loss:  1.636568307876587\n",
      "train r2:  0.885282019891632\n",
      "test loss:  6.776830673217773\n",
      "test r2:  -0.25481766936228234\n",
      "train loss:  1.6366041898727417\n",
      "train r2:  0.8854749306137972\n",
      "test loss:  6.78061056137085\n",
      "test r2:  -0.25596323852012626\n",
      "train loss:  1.6366581916809082\n",
      "train r2:  0.8852291810746957\n",
      "test loss:  6.775819778442383\n",
      "test r2:  -0.2545212036113411\n",
      "train loss:  1.6367417573928833\n",
      "train r2:  0.8855362235036655\n",
      "test loss:  6.781745910644531\n",
      "test r2:  -0.2563131000059897\n",
      "train loss:  1.6368488073349\n",
      "train r2:  0.8851515718297202\n",
      "test loss:  6.774518013000488\n",
      "test r2:  -0.25413762982788923\n",
      "train loss:  1.6369856595993042\n",
      "train r2:  0.8856146923314244\n",
      "test loss:  6.782943248748779\n",
      "test r2:  -0.2566789468385462\n",
      "train loss:  1.6370832920074463\n",
      "train r2:  0.8850698998369382\n",
      "test loss:  6.773370742797852\n",
      "test r2:  -0.25380583027194925\n",
      "train loss:  1.6371253728866577\n",
      "train r2:  0.8856833309528589\n",
      "test loss:  6.783296585083008\n",
      "test r2:  -0.2567877812687793\n",
      "train loss:  1.6369998455047607\n",
      "train r2:  0.8850476183832471\n",
      "test loss:  6.774146556854248\n",
      "test r2:  -0.2540592580238552\n",
      "train loss:  1.6367918252944946\n",
      "train r2:  0.8856336241074143\n",
      "test loss:  6.780821323394775\n",
      "test r2:  -0.2560565992255026\n",
      "train loss:  1.6365834474563599\n",
      "train r2:  0.8852098878450197\n",
      "test loss:  6.778262615203857\n",
      "test r2:  -0.2553030903701825\n",
      "train loss:  1.6365095376968384\n",
      "train r2:  0.885371996977469\n",
      "test loss:  6.776142597198486\n",
      "test r2:  -0.25467146835428434\n",
      "train loss:  1.636582612991333\n",
      "train r2:  0.8855058311782987\n",
      "test loss:  6.781857013702393\n",
      "test r2:  -0.2563782203714733\n",
      "train loss:  1.6367056369781494\n",
      "train r2:  0.8851392083786181\n",
      "test loss:  6.774623394012451\n",
      "test r2:  -0.2542208296556745\n",
      "train loss:  1.6367665529251099\n",
      "train r2:  0.885599413884615\n",
      "test loss:  6.781013011932373\n",
      "test r2:  -0.25614306683054466\n",
      "train loss:  1.6367042064666748\n",
      "train r2:  0.8851894836444958\n",
      "test loss:  6.777036666870117\n",
      "test r2:  -0.25494770702898295\n",
      "train loss:  1.636588454246521\n",
      "train r2:  0.8854467453327948\n",
      "test loss:  6.7780070304870605\n",
      "test r2:  -0.2552569562391518\n",
      "train loss:  1.636513352394104\n",
      "train r2:  0.8853815204530374\n",
      "test loss:  6.779446601867676\n",
      "test r2:  -0.2556847798612698\n",
      "train loss:  1.6365307569503784\n",
      "train r2:  0.88528984994279\n",
      "test loss:  6.776526927947998\n",
      "test r2:  -0.25481175926717414\n",
      "train loss:  1.6365998983383179\n",
      "train r2:  0.8854754467645884\n",
      "test loss:  6.779943466186523\n",
      "test r2:  -0.2558513675597913\n",
      "train loss:  1.6366386413574219\n",
      "train r2:  0.885252584948888\n",
      "test loss:  6.776609420776367\n",
      "test r2:  -0.2548435406149707\n",
      "train loss:  1.636611819267273\n",
      "train r2:  0.8854684449910628\n",
      "test loss:  6.779333114624023\n",
      "test r2:  -0.2556726861004097\n",
      "train loss:  1.6365466117858887\n",
      "train r2:  0.8852920267757082\n",
      "test loss:  6.777612686157227\n",
      "test r2:  -0.255163026038705\n",
      "train loss:  1.6365092992782593\n",
      "train r2:  0.8854014334220136\n",
      "test loss:  6.77780294418335\n",
      "test r2:  -0.25521593037956736\n",
      "train loss:  1.6365245580673218\n",
      "train r2:  0.8853899483754127\n",
      "test loss:  6.779316425323486\n",
      "test r2:  -0.2556824586849762\n",
      "train loss:  1.6365622282028198\n",
      "train r2:  0.885289582551506\n",
      "test loss:  6.776327610015869\n",
      "test r2:  -0.2547855446379399\n",
      "train loss:  1.6365787982940674\n",
      "train r2:  0.8854810197891785\n",
      "test loss:  6.779869556427002\n",
      "test r2:  -0.255850259140711\n",
      "train loss:  1.63655686378479\n",
      "train r2:  0.8852537275490332\n",
      "test loss:  6.776917934417725\n",
      "test r2:  -0.25497570152642557\n",
      "train loss:  1.6365221738815308\n",
      "train r2:  0.8854410727468262\n",
      "test loss:  6.77816915512085\n",
      "test r2:  -0.25535142740359085\n",
      "train loss:  1.636507511138916\n",
      "train r2:  0.8853609964021205\n",
      "test loss:  6.778947353363037\n",
      "test r2:  -0.25558952025184833\n",
      "train loss:  1.6365209817886353\n",
      "train r2:  0.8853098884056907\n",
      "test loss:  6.776504039764404\n",
      "test r2:  -0.2548645733080952\n",
      "train loss:  1.6365416049957275\n",
      "train r2:  0.8854644386280316\n",
      "test loss:  6.779521465301514\n",
      "test r2:  -0.2557698959575285\n",
      "train loss:  1.6365448236465454\n",
      "train r2:  0.8852708739835637\n",
      "test loss:  6.777010917663574\n",
      "test r2:  -0.2550232491153419\n",
      "train loss:  1.6365294456481934\n",
      "train r2:  0.8854306732454033\n",
      "test loss:  6.778185844421387\n",
      "test r2:  -0.2553829765620721\n",
      "train loss:  1.6365115642547607\n",
      "train r2:  0.8853539713316467\n",
      "test loss:  6.778411865234375\n",
      "test r2:  -0.25545016781276275\n",
      "train loss:  1.6365077495574951\n",
      "train r2:  0.8853396512129292\n",
      "test loss:  6.777130126953125\n",
      "test r2:  -0.25507353081721873\n",
      "train loss:  1.6365172863006592\n",
      "train r2:  0.885419936822333\n",
      "test loss:  6.778783798217773\n",
      "test r2:  -0.2555736042850363\n",
      "train loss:  1.6365270614624023\n",
      "train r2:  0.8853129164438324\n",
      "test loss:  6.7772369384765625\n",
      "test r2:  -0.25511027751890336\n",
      "train loss:  1.636526346206665\n",
      "train r2:  0.8854119334012027\n",
      "test loss:  6.7783203125\n",
      "test r2:  -0.25544449261056124\n",
      "train loss:  1.6365162134170532\n",
      "train r2:  0.8853405560185964\n",
      "test loss:  6.7777299880981445\n",
      "test r2:  -0.25526849381398287\n",
      "train loss:  1.6365078687667847\n",
      "train r2:  0.8853782572233144\n",
      "test loss:  6.77777099609375\n",
      "test r2:  -0.2552848542306827\n",
      "train loss:  1.636507511138916\n",
      "train r2:  0.8853747654961247\n",
      "test loss:  6.778198719024658\n",
      "test r2:  -0.25542069937892187\n",
      "train loss:  1.6365134716033936\n",
      "train r2:  0.8853455489424298\n",
      "test loss:  6.777293682098389\n",
      "test r2:  -0.2551496472364376\n",
      "train loss:  1.636518120765686\n",
      "train r2:  0.8854034316134184\n",
      "test loss:  6.778465747833252\n",
      "test r2:  -0.25550766247437395\n",
      "train loss:  1.6365162134170532\n",
      "train r2:  0.8853268690301064\n",
      "test loss:  6.777255058288574\n",
      "test r2:  -0.2551493733380856\n",
      "train loss:  1.6365106105804443\n",
      "train r2:  0.8854034941486818\n",
      "test loss:  6.778075695037842\n",
      "test r2:  -0.25539758925052625\n",
      "train loss:  1.6365063190460205\n",
      "train r2:  0.885350471168115\n",
      "test loss:  6.777886867523193\n",
      "test r2:  -0.2553475833559007\n",
      "train loss:  1.6365069150924683\n",
      "train r2:  0.8853611205449349\n",
      "test loss:  6.777304172515869\n",
      "test r2:  -0.2551761800455685\n",
      "train loss:  1.6365103721618652\n",
      "train r2:  0.8853976438984076\n",
      "test loss:  6.778395175933838\n",
      "test r2:  -0.2555067153736563\n",
      "train loss:  1.636512279510498\n",
      "train r2:  0.8853269639548076\n",
      "test loss:  6.77714729309082\n",
      "test r2:  -0.25513824522212003\n",
      "train loss:  1.636510968208313\n",
      "train r2:  0.8854056855749253\n",
      "test loss:  6.778062343597412\n",
      "test r2:  -0.25541580551863197\n",
      "train loss:  1.6365078687667847\n",
      "train r2:  0.8853463565339594\n",
      "test loss:  6.777693271636963\n",
      "test r2:  -0.2553089235030652\n",
      "train loss:  1.6365057229995728\n",
      "train r2:  0.8853691946218822\n",
      "test loss:  6.7774338722229\n",
      "test r2:  -0.25523696762373693\n",
      "train loss:  1.6365060806274414\n",
      "train r2:  0.8853845156025493\n",
      "test loss:  6.778072834014893\n",
      "test r2:  -0.2554313103675565\n",
      "train loss:  1.636507511138916\n",
      "train r2:  0.8853429558744199\n",
      "test loss:  6.777278423309326\n",
      "test r2:  -0.25519783610895996\n",
      "train loss:  1.636508584022522\n",
      "train r2:  0.8853928034610073\n",
      "test loss:  6.777923107147217\n",
      "test r2:  -0.25539662917666783\n",
      "train loss:  1.6365079879760742\n",
      "train r2:  0.8853502713326418\n",
      "test loss:  6.777496337890625\n",
      "test r2:  -0.2552711121395119\n",
      "train loss:  1.6365065574645996\n",
      "train r2:  0.8853771067416057\n",
      "test loss:  6.777632236480713\n",
      "test r2:  -0.25531762596942453\n",
      "train loss:  1.636505126953125\n",
      "train r2:  0.8853671132594214\n",
      "test loss:  6.777679920196533\n",
      "test r2:  -0.25533558698986014\n",
      "train loss:  1.636505126953125\n",
      "train r2:  0.8853632497016907\n",
      "test loss:  6.777442455291748\n",
      "test r2:  -0.255267671115321\n",
      "train loss:  1.6365058422088623\n",
      "train r2:  0.885377713909763\n",
      "test loss:  6.777777194976807\n",
      "test r2:  -0.2553739416154579\n",
      "train loss:  1.6365065574645996\n",
      "train r2:  0.8853549534545161\n",
      "test loss:  6.777325630187988\n",
      "test r2:  -0.25524126766892596\n",
      "train loss:  1.6365063190460205\n",
      "train r2:  0.8853832631397607\n",
      "test loss:  6.7777628898620605\n",
      "test r2:  -0.25537675464869913\n",
      "train loss:  1.6365054845809937\n",
      "train r2:  0.8853542838126347\n",
      "test loss:  6.777392864227295\n",
      "test r2:  -0.25527082036059157\n",
      "train loss:  1.6365046501159668\n",
      "train r2:  0.8853768912534319\n",
      "test loss:  6.777525424957275\n",
      "test r2:  -0.25531365971532227\n",
      "train loss:  1.6365041732788086\n",
      "train r2:  0.8853677164686897\n",
      "test loss:  6.777632236480713\n",
      "test r2:  -0.2553504738429291\n",
      "train loss:  1.6365047693252563\n",
      "train r2:  0.8853597880490742\n",
      "test loss:  6.777259349822998\n",
      "test r2:  -0.2552426750068646\n",
      "train loss:  1.636505126953125\n",
      "train r2:  0.8853827971263826\n",
      "test loss:  6.7777252197265625\n",
      "test r2:  -0.2553861010367138\n",
      "train loss:  1.636505126953125\n",
      "train r2:  0.8853521114956953\n",
      "test loss:  6.777265548706055\n",
      "test r2:  -0.2552529982023277\n",
      "train loss:  1.6365047693252563\n",
      "train r2:  0.8853804969337586\n",
      "test loss:  6.77752685546875\n",
      "test r2:  -0.2553354088109203\n",
      "train loss:  1.636504054069519\n",
      "train r2:  0.8853628946754647\n",
      "test loss:  6.777465343475342\n",
      "test r2:  -0.25532070393001116\n",
      "train loss:  1.636504054069519\n",
      "train r2:  0.8853659936288407\n",
      "test loss:  6.777296543121338\n",
      "test r2:  -0.25527510940298437\n",
      "train loss:  1.636504054069519\n",
      "train r2:  0.8853757129885653\n",
      "test loss:  6.777551651000977\n",
      "test r2:  -0.2553549130575159\n",
      "train loss:  1.6365041732788086\n",
      "train r2:  0.8853585878758105\n",
      "test loss:  6.77725076675415\n",
      "test r2:  -0.2552688470545399\n",
      "train loss:  1.6365044116973877\n",
      "train r2:  0.8853769667494186\n",
      "test loss:  6.777471542358398\n",
      "test r2:  -0.2553397354168434\n",
      "train loss:  1.6365041732788086\n",
      "train r2:  0.8853617560532743\n",
      "test loss:  6.777302265167236\n",
      "test r2:  -0.25529237180729836\n",
      "train loss:  1.6365036964416504\n",
      "train r2:  0.8853718682545955\n",
      "test loss:  6.777361869812012\n",
      "test r2:  -0.25531482871942024\n",
      "train loss:  1.6365033388137817\n",
      "train r2:  0.8853670496972141\n",
      "test loss:  6.777347087860107\n",
      "test r2:  -0.25531438672734263\n",
      "train loss:  1.6365034580230713\n",
      "train r2:  0.8853670912022438\n",
      "test loss:  6.777267932891846\n",
      "test r2:  -0.25529432279233855\n",
      "train loss:  1.6365034580230713\n",
      "train r2:  0.8853713295768983\n",
      "test loss:  6.777378559112549\n",
      "test r2:  -0.25533221011451146\n",
      "train loss:  1.6365035772323608\n",
      "train r2:  0.8853632356997901\n",
      "test loss:  6.77719259262085\n",
      "test r2:  -0.25527997396208213\n",
      "train loss:  1.6365034580230713\n",
      "train r2:  0.8853743403356722\n",
      "test loss:  6.777369976043701\n",
      "test r2:  -0.25533734819100085\n",
      "train loss:  1.6365033388137817\n",
      "train r2:  0.8853620304408178\n",
      "test loss:  6.777186870574951\n",
      "test r2:  -0.25528685680105956\n",
      "train loss:  1.636502981185913\n",
      "train r2:  0.8853728126326917\n",
      "test loss:  6.777273178100586\n",
      "test r2:  -0.25531639927642824\n",
      "train loss:  1.6365028619766235\n",
      "train r2:  0.885366471900162\n",
      "test loss:  6.777256965637207\n",
      "test r2:  -0.2553158891620486\n",
      "train loss:  1.636502742767334\n",
      "train r2:  0.885366531044051\n",
      "test loss:  6.777148246765137\n",
      "test r2:  -0.2552872808429312\n",
      "train loss:  1.6365028619766235\n",
      "train r2:  0.8853726034539298\n",
      "test loss:  6.777292251586914\n",
      "test r2:  -0.25533431072283497\n",
      "train loss:  1.6365028619766235\n",
      "train r2:  0.8853625267318961\n",
      "test loss:  6.777106761932373\n",
      "test r2:  -0.2552827199462653\n",
      "train loss:  1.6365028619766235\n",
      "train r2:  0.8853734993168795\n",
      "test loss:  6.777232646942139\n",
      "test r2:  -0.2553246611311797\n",
      "train loss:  1.636502742767334\n",
      "train r2:  0.8853644957458072\n",
      "test loss:  6.7771382331848145\n",
      "test r2:  -0.2553002485150222\n",
      "train loss:  1.6365023851394653\n",
      "train r2:  0.8853697152411971\n",
      "test loss:  6.777139663696289\n",
      "test r2:  -0.2553046602881597\n",
      "train loss:  1.6365022659301758\n",
      "train r2:  0.8853686891986543\n",
      "test loss:  6.777162551879883\n",
      "test r2:  -0.25531540586647283\n",
      "train loss:  1.6365023851394653\n",
      "train r2:  0.885366364331672\n",
      "test loss:  6.777082443237305\n",
      "test r2:  -0.2552952687215\n",
      "train loss:  1.6365022659301758\n",
      "train r2:  0.8853706348790056\n",
      "test loss:  6.777145862579346\n",
      "test r2:  -0.2553186391811364\n",
      "train loss:  1.6365022659301758\n",
      "train r2:  0.8853656164560174\n",
      "test loss:  6.7770538330078125\n",
      "test r2:  -0.2552945702569436\n",
      "train loss:  1.6365020275115967\n",
      "train r2:  0.8853707257217096\n",
      "test loss:  6.777115345001221\n",
      "test r2:  -0.255317367239857\n",
      "train loss:  1.6365020275115967\n",
      "train r2:  0.8853658389167344\n",
      "test loss:  6.777035713195801\n",
      "test r2:  -0.2552972083678433\n",
      "train loss:  1.6365017890930176\n",
      "train r2:  0.885370110543688\n",
      "test loss:  6.7770676612854\n",
      "test r2:  -0.25531074312225455\n",
      "train loss:  1.6365017890930176\n",
      "train r2:  0.8853671788731268\n",
      "test loss:  6.777040004730225\n",
      "test r2:  -0.2553063662786941\n",
      "train loss:  1.636501669883728\n",
      "train r2:  0.8853680787579251\n",
      "test loss:  6.777003288269043\n",
      "test r2:  -0.25529925741950454\n",
      "train loss:  1.636501669883728\n",
      "train r2:  0.8853695398454705\n",
      "test loss:  6.777045726776123\n",
      "test r2:  -0.25531604938258945\n",
      "train loss:  1.636501431465149\n",
      "train r2:  0.8853659300763906\n",
      "test loss:  6.776954650878906\n",
      "test r2:  -0.255292735354272\n",
      "train loss:  1.636501431465149\n",
      "train r2:  0.8853708946569591\n",
      "test loss:  6.777021884918213\n",
      "test r2:  -0.255316549444526\n",
      "train loss:  1.636501431465149\n",
      "train r2:  0.8853657605530497\n",
      "test loss:  6.776943683624268\n",
      "test r2:  -0.2552969974713555\n",
      "train loss:  1.636501431465149\n",
      "train r2:  0.8853699106940724\n",
      "test loss:  6.776966571807861\n",
      "test r2:  -0.2553077952699394\n",
      "train loss:  1.6365011930465698\n",
      "train r2:  0.8853675565230208\n",
      "test loss:  6.77694845199585\n",
      "test r2:  -0.25530610750406657\n",
      "train loss:  1.6365011930465698\n",
      "train r2:  0.8853678885685186\n",
      "test loss:  6.776913642883301\n",
      "test r2:  -0.2552998334728316\n",
      "train loss:  1.6365009546279907\n",
      "train r2:  0.8853692201256844\n",
      "test loss:  6.776936054229736\n",
      "test r2:  -0.25531052549136724\n",
      "train loss:  1.6365011930465698\n",
      "train r2:  0.8853668927192652\n",
      "test loss:  6.776880264282227\n",
      "test r2:  -0.25529742319273074\n",
      "train loss:  1.6365008354187012\n",
      "train r2:  0.885369641176745\n",
      "test loss:  6.776910305023193\n",
      "test r2:  -0.25531025636526317\n",
      "train loss:  1.6365008354187012\n",
      "train r2:  0.8853668549767202\n",
      "test loss:  6.776857376098633\n",
      "test r2:  -0.2552983404515381\n",
      "train loss:  1.6365007162094116\n",
      "train r2:  0.8853693657278996\n",
      "test loss:  6.776875019073486\n",
      "test r2:  -0.25530749580217016\n",
      "train loss:  1.636500597000122\n",
      "train r2:  0.8853673830757346\n",
      "test loss:  6.776843070983887\n",
      "test r2:  -0.25530156747420785\n",
      "train loss:  1.636500597000122\n",
      "train r2:  0.8853686082979977\n",
      "test loss:  6.776834011077881\n",
      "test r2:  -0.2553029014424202\n",
      "train loss:  1.636500358581543\n",
      "train r2:  0.8853683095098926\n",
      "test loss:  6.776831150054932\n",
      "test r2:  -0.2553058157005683\n",
      "train loss:  1.636500358581543\n",
      "train r2:  0.8853676355336888\n",
      "test loss:  6.776793956756592\n",
      "test r2:  -0.2552983810422711\n",
      "train loss:  1.636500358581543\n",
      "train r2:  0.8853692299714141\n",
      "test loss:  6.776815414428711\n",
      "test r2:  -0.25530881735024913\n",
      "train loss:  1.6365002393722534\n",
      "train r2:  0.8853669507711559\n",
      "test loss:  6.77676248550415\n",
      "test r2:  -0.25529661856306896\n",
      "train loss:  1.6365002393722534\n",
      "train r2:  0.8853694979297994\n",
      "test loss:  6.776785373687744\n",
      "test r2:  -0.255307350590656\n",
      "train loss:  1.6365002393722534\n",
      "train r2:  0.8853671948813442\n",
      "test loss:  6.77674674987793\n",
      "test r2:  -0.2552995546793413\n",
      "train loss:  1.6365001201629639\n",
      "train r2:  0.8853688405609879\n",
      "test loss:  6.776745796203613\n",
      "test r2:  -0.25530308642539734\n",
      "train loss:  1.6364998817443848\n",
      "train r2:  0.8853680278194442\n",
      "test loss:  6.776731967926025\n",
      "test r2:  -0.2553026716207951\n",
      "train loss:  1.6364997625350952\n",
      "train r2:  0.8853680874888105\n",
      "test loss:  6.7767109870910645\n",
      "test r2:  -0.25530029789242614\n",
      "train loss:  1.6364997625350952\n",
      "train r2:  0.8853685822219358\n",
      "test loss:  6.776710510253906\n",
      "test r2:  -0.2553038016276403\n",
      "train loss:  1.6364997625350952\n",
      "train r2:  0.8853677538620603\n",
      "test loss:  6.7766828536987305\n",
      "test r2:  -0.25529908800675405\n",
      "train loss:  1.6364996433258057\n",
      "train r2:  0.8853687467545798\n",
      "test loss:  6.77668571472168\n",
      "test r2:  -0.2553038478508547\n",
      "train loss:  1.6364995241165161\n",
      "train r2:  0.8853676975466513\n",
      "test loss:  6.776656627655029\n",
      "test r2:  -0.25529875952863357\n",
      "train loss:  1.6364995241165161\n",
      "train r2:  0.8853687610749219\n",
      "test loss:  6.776657581329346\n",
      "test r2:  -0.25530311474346545\n",
      "train loss:  1.636499285697937\n",
      "train r2:  0.8853677936716002\n",
      "test loss:  6.776634693145752\n",
      "test r2:  -0.2552999380239749\n",
      "train loss:  1.636499285697937\n",
      "train r2:  0.8853684507093921\n",
      "test loss:  6.776625156402588\n",
      "test r2:  -0.2553007808070413\n",
      "train loss:  1.6364991664886475\n",
      "train r2:  0.8853682353317118\n",
      "test loss:  6.776615619659424\n",
      "test r2:  -0.25530152872273604\n",
      "train loss:  1.6364991664886475\n",
      "train r2:  0.8853680226659475\n",
      "test loss:  6.776593208312988\n",
      "test r2:  -0.2552985002788293\n",
      "train loss:  1.636499047279358\n",
      "train r2:  0.8853686698210629\n",
      "test loss:  6.7765960693359375\n",
      "test r2:  -0.25530327253487073\n",
      "train loss:  1.636499047279358\n",
      "train r2:  0.8853676345044695\n",
      "test loss:  6.776564121246338\n",
      "test r2:  -0.255297058896125\n",
      "train loss:  1.636499047279358\n",
      "train r2:  0.88536889018402\n",
      "test loss:  6.776569843292236\n",
      "test r2:  -0.25530266380495914\n",
      "train loss:  1.6364989280700684\n",
      "train r2:  0.885367646273547\n",
      "test loss:  6.7765421867370605\n",
      "test r2:  -0.25529790122859297\n",
      "train loss:  1.6364986896514893\n",
      "train r2:  0.8853686511921605\n",
      "test loss:  6.776539325714111\n",
      "test r2:  -0.25530086747352\n",
      "train loss:  1.6364986896514893\n",
      "train r2:  0.8853679942831477\n",
      "test loss:  6.7765212059021\n",
      "test r2:  -0.2552991599017944\n",
      "train loss:  1.6364986896514893\n",
      "train r2:  0.8853683312073549\n",
      "test loss:  6.776508808135986\n",
      "test r2:  -0.25529904587579355\n",
      "train loss:  1.6364985704421997\n",
      "train r2:  0.8853683092366317\n",
      "test loss:  6.776500225067139\n",
      "test r2:  -0.2553000713888445\n",
      "train loss:  1.6364984512329102\n",
      "train r2:  0.8853680556754164\n",
      "test loss:  6.776481628417969\n",
      "test r2:  -0.25529812251342454\n",
      "train loss:  1.6364985704421997\n",
      "train r2:  0.88536844805969\n",
      "test loss:  6.776474475860596\n",
      "test r2:  -0.2552997575674645\n",
      "train loss:  1.636498212814331\n",
      "train r2:  0.8853680722801075\n",
      "test loss:  6.7764573097229\n",
      "test r2:  -0.2552980936505418\n",
      "train loss:  1.636498212814331\n",
      "train r2:  0.8853683832980441\n",
      "test loss:  6.776449680328369\n",
      "test r2:  -0.2552994629702554\n",
      "train loss:  1.6364980936050415\n",
      "train r2:  0.8853680591146389\n",
      "test loss:  6.776429653167725\n",
      "test r2:  -0.2552971333063243\n",
      "train loss:  1.6364980936050415\n",
      "train r2:  0.8853685369294455\n",
      "test loss:  6.776427745819092\n",
      "test r2:  -0.25530009234577156\n",
      "train loss:  1.6364980936050415\n",
      "train r2:  0.8853678731448527\n",
      "test loss:  6.776403903961182\n",
      "test r2:  -0.25529660528270215\n",
      "train loss:  1.6364980936050415\n",
      "train r2:  0.8853685873947442\n",
      "test loss:  6.776399612426758\n",
      "test r2:  -0.2552991280649617\n",
      "train loss:  1.6364978551864624\n",
      "train r2:  0.8853680201558295\n",
      "test loss:  6.7763824462890625\n",
      "test r2:  -0.25529751425049674\n",
      "train loss:  1.636497974395752\n",
      "train r2:  0.8853683232314223\n",
      "test loss:  6.776369094848633\n",
      "test r2:  -0.25529705453351226\n",
      "train loss:  1.6364976167678833\n",
      "train r2:  0.8853683579697073\n",
      "test loss:  6.776362895965576\n",
      "test r2:  -0.2552987850120274\n",
      "train loss:  1.6364974975585938\n",
      "train r2:  0.8853679751058464\n",
      "test loss:  6.776342391967773\n",
      "test r2:  -0.2552961538813081\n",
      "train loss:  1.6364974975585938\n",
      "train r2:  0.885368496670842\n",
      "test loss:  6.7763352394104\n",
      "test r2:  -0.2552975330937073\n",
      "train loss:  1.6364974975585938\n",
      "train r2:  0.8853681983462982\n",
      "test loss:  6.776324272155762\n",
      "test r2:  -0.25529795295730184\n",
      "train loss:  1.6364974975585938\n",
      "train r2:  0.8853680667174535\n",
      "test loss:  6.776304721832275\n",
      "test r2:  -0.25529569309927247\n",
      "train loss:  1.6364973783493042\n",
      "train r2:  0.8853685118778761\n",
      "test loss:  6.776298522949219\n",
      "test r2:  -0.255297428599913\n",
      "train loss:  1.636497139930725\n",
      "train r2:  0.8853681182564889\n",
      "test loss:  6.7762861251831055\n",
      "test r2:  -0.2552972414417738\n",
      "train loss:  1.6364973783493042\n",
      "train r2:  0.8853681462774132\n",
      "test loss:  6.776266574859619\n",
      "test r2:  -0.2552950079724319\n",
      "train loss:  1.636497139930725\n",
      "train r2:  0.8853685661594708\n",
      "test loss:  6.776266098022461\n",
      "test r2:  -0.25529816013020734\n",
      "train loss:  1.6364970207214355\n",
      "train r2:  0.8853678727418983\n",
      "test loss:  6.776242256164551\n",
      "test r2:  -0.2552947243862118\n",
      "train loss:  1.6364970207214355\n",
      "train r2:  0.8853685602553396\n",
      "test loss:  6.776237487792969\n",
      "test r2:  -0.2552968364438337\n",
      "train loss:  1.6364970207214355\n",
      "train r2:  0.8853681044729705\n",
      "test loss:  6.776223659515381\n",
      "test r2:  -0.2552961715201916\n",
      "train loss:  1.6364967823028564\n",
      "train r2:  0.885368197741891\n",
      "test loss:  6.776206970214844\n",
      "test r2:  -0.2552948021267436\n",
      "train loss:  1.6364967823028564\n",
      "train r2:  0.885368491011552\n",
      "test loss:  6.7762041091918945\n",
      "test r2:  -0.2552971370708701\n",
      "train loss:  1.636496901512146\n",
      "train r2:  0.8853679390346386\n",
      "test loss:  6.776181221008301\n",
      "test r2:  -0.2552939650457966\n",
      "train loss:  1.6364965438842773\n",
      "train r2:  0.8853685990222309\n",
      "test loss:  6.776178359985352\n",
      "test r2:  -0.2552965150278206\n",
      "train loss:  1.6364965438842773\n",
      "train r2:  0.8853680129556278\n",
      "test loss:  6.776159763336182\n",
      "test r2:  -0.25529446918769794\n",
      "train loss:  1.6364963054656982\n",
      "train r2:  0.8853684136790033\n",
      "test loss:  6.77615213394165\n",
      "test r2:  -0.2552956534711819\n",
      "train loss:  1.6364964246749878\n",
      "train r2:  0.885368129685009\n",
      "test loss:  6.776134967803955\n",
      "test r2:  -0.2552939752784791\n",
      "train loss:  1.6364963054656982\n",
      "train r2:  0.885368454707677\n",
      "test loss:  6.776130676269531\n",
      "test r2:  -0.2552962160393244\n",
      "train loss:  1.6364963054656982\n",
      "train r2:  0.8853679478065385\n",
      "test loss:  6.7761077880859375\n",
      "test r2:  -0.2552927281856594\n",
      "train loss:  1.6364963054656982\n",
      "train r2:  0.8853686427774055\n",
      "test loss:  6.7761077880859375\n",
      "test r2:  -0.2552962348579566\n",
      "train loss:  1.6364960670471191\n",
      "train r2:  0.8853678904030824\n",
      "test loss:  6.7760844230651855\n",
      "test r2:  -0.2552928160564649\n",
      "train loss:  1.6364959478378296\n",
      "train r2:  0.8853685730647531\n",
      "test loss:  6.776081562042236\n",
      "test r2:  -0.2552953115734182\n",
      "train loss:  1.63649582862854\n",
      "train r2:  0.8853680389149351\n",
      "test loss:  6.776063442230225\n",
      "test r2:  -0.2552933599862146\n",
      "train loss:  1.6364959478378296\n",
      "train r2:  0.8853683984982121\n",
      "test loss:  6.776054859161377\n",
      "test r2:  -0.25529416453804576\n",
      "train loss:  1.6364957094192505\n",
      "train r2:  0.8853682037101134\n",
      "test loss:  6.776041030883789\n",
      "test r2:  -0.2552933703376914\n",
      "train loss:  1.63649582862854\n",
      "train r2:  0.885368340614858\n",
      "test loss:  6.776031494140625\n",
      "test r2:  -0.2552941160946096\n",
      "train loss:  1.6364957094192505\n",
      "train r2:  0.8853681759281431\n",
      "test loss:  6.776016712188721\n",
      "test r2:  -0.25529299691441754\n",
      "train loss:  1.6364953517913818\n",
      "train r2:  0.8853683837846403\n",
      "test loss:  6.776008605957031\n",
      "test r2:  -0.2552940625184468\n",
      "train loss:  1.6364953517913818\n",
      "train r2:  0.8853681321623508\n",
      "test loss:  6.7759928703308105\n",
      "test r2:  -0.25529273475620484\n",
      "train loss:  1.6364957094192505\n",
      "train r2:  0.885368371601063\n",
      "test loss:  6.775982856750488\n",
      "test r2:  -0.25529301564702656\n",
      "train loss:  1.6364953517913818\n",
      "train r2:  0.8853682801698881\n",
      "test loss:  6.775973320007324\n",
      "test r2:  -0.25529345892535815\n",
      "train loss:  1.6364952325820923\n",
      "train r2:  0.8853681641672866\n",
      "test loss:  6.775956630706787\n",
      "test r2:  -0.2552920380162116\n",
      "train loss:  1.6364952325820923\n",
      "train r2:  0.8853684329440993\n",
      "test loss:  6.775949478149414\n",
      "test r2:  -0.2552931859445886\n",
      "train loss:  1.6364951133728027\n",
      "train r2:  0.8853681437162869\n",
      "test loss:  6.775935173034668\n",
      "test r2:  -0.25529207791466146\n",
      "train loss:  1.6364951133728027\n",
      "train r2:  0.8853683674974436\n",
      "test loss:  6.775925159454346\n",
      "test r2:  -0.2552928679531241\n",
      "train loss:  1.6364948749542236\n",
      "train r2:  0.8853681871574863\n",
      "test loss:  6.7759108543396\n",
      "test r2:  -0.25529152215874906\n",
      "train loss:  1.636494755744934\n",
      "train r2:  0.8853683982437633\n",
      "test loss:  6.775903224945068\n",
      "test r2:  -0.2552928110916888\n",
      "train loss:  1.6364948749542236\n",
      "train r2:  0.8853681315365222\n",
      "test loss:  6.7758870124816895\n",
      "test r2:  -0.2552911825426527\n",
      "train loss:  1.636494755744934\n",
      "train r2:  0.8853684260204614\n",
      "test loss:  6.775880336761475\n",
      "test r2:  -0.2552925657448968\n",
      "train loss:  1.636494755744934\n",
      "train r2:  0.885368120565575\n",
      "test loss:  6.775862216949463\n",
      "test r2:  -0.25529065236435033\n",
      "train loss:  1.6364946365356445\n",
      "train r2:  0.8853684822042875\n",
      "test loss:  6.775857925415039\n",
      "test r2:  -0.25529268873780797\n",
      "train loss:  1.6364943981170654\n",
      "train r2:  0.8853680271239073\n",
      "test loss:  6.775838851928711\n",
      "test r2:  -0.25529005717697206\n",
      "train loss:  1.6364943981170654\n",
      "train r2:  0.8853685456000946\n",
      "test loss:  6.775834560394287\n",
      "test r2:  -0.2552920757272106\n",
      "train loss:  1.6364943981170654\n",
      "train r2:  0.8853680765109733\n",
      "test loss:  6.775818347930908\n",
      "test r2:  -0.25529062182606044\n",
      "train loss:  1.6364942789077759\n",
      "train r2:  0.8853683964249766\n",
      "test loss:  6.775808811187744\n",
      "test r2:  -0.25529115182002693\n",
      "train loss:  1.6364941596984863\n",
      "train r2:  0.8853682370159677\n",
      "test loss:  6.775796413421631\n",
      "test r2:  -0.25529069685071204\n",
      "train loss:  1.6364940404891968\n",
      "train r2:  0.8853683405988264\n",
      "test loss:  6.775787830352783\n",
      "test r2:  -0.25529145104611173\n",
      "train loss:  1.6364940404891968\n",
      "train r2:  0.8853681281440211\n",
      "test loss:  6.775768756866455\n",
      "test r2:  -0.25528891107556717\n",
      "train loss:  1.6364941596984863\n",
      "train r2:  0.8853686375369005\n",
      "test loss:  6.775771617889404\n",
      "test r2:  -0.25529297082886027\n",
      "train loss:  1.6364940404891968\n",
      "train r2:  0.8853677403332485\n",
      "test loss:  6.775740146636963\n",
      "test r2:  -0.25528707752469115\n",
      "train loss:  1.6364938020706177\n",
      "train r2:  0.8853689860506642\n",
      "test loss:  6.775752067565918\n",
      "test r2:  -0.25529368058295776\n",
      "train loss:  1.6364938020706177\n",
      "train r2:  0.8853675148166236\n",
      "test loss:  6.775716781616211\n",
      "test r2:  -0.2552862725959959\n",
      "train loss:  1.6364938020706177\n",
      "train r2:  0.88536907356144\n",
      "test loss:  6.775729179382324\n",
      "test r2:  -0.25529337044010014\n",
      "train loss:  1.6364935636520386\n",
      "train r2:  0.8853675405196966\n",
      "test loss:  6.775695323944092\n",
      "test r2:  -0.2552863306330839\n",
      "train loss:  1.6364935636520386\n",
      "train r2:  0.8853690007502886\n",
      "test loss:  6.7757062911987305\n",
      "test r2:  -0.2552930952145305\n",
      "train loss:  1.6364935636520386\n",
      "train r2:  0.885367552991126\n",
      "test loss:  6.775671005249023\n",
      "test r2:  -0.25528548496618697\n",
      "train loss:  1.6364935636520386\n",
      "train r2:  0.8853691350793438\n",
      "test loss:  6.775688171386719\n",
      "test r2:  -0.2552940460429267\n",
      "train loss:  1.6364933252334595\n",
      "train r2:  0.8853672980981262\n",
      "test loss:  6.775641918182373\n",
      "test r2:  -0.2552835418420425\n",
      "train loss:  1.6364935636520386\n",
      "train r2:  0.8853695171431452\n",
      "test loss:  6.775672435760498\n",
      "test r2:  -0.25529586884498023\n",
      "train loss:  1.63649320602417\n",
      "train r2:  0.8853668312985083\n",
      "test loss:  6.775611877441406\n",
      "test r2:  -0.25528062427814\n",
      "train loss:  1.63649320602417\n",
      "train r2:  0.8853700533332971\n",
      "test loss:  6.775659561157227\n",
      "test r2:  -0.2552986199496008\n",
      "train loss:  1.6364930868148804\n",
      "train r2:  0.8853662127042636\n",
      "test loss:  6.775578022003174\n",
      "test r2:  -0.2552770715014223\n",
      "train loss:  1.6364929676055908\n",
      "train r2:  0.8853707692716563\n",
      "test loss:  6.7756500244140625\n",
      "test r2:  -0.2553016919131308\n",
      "train loss:  1.6364930868148804\n",
      "train r2:  0.8853654651391325\n",
      "test loss:  6.775545120239258\n",
      "test r2:  -0.2552734907343448\n",
      "train loss:  1.6364930868148804\n",
      "train r2:  0.8853714611386567\n",
      "test loss:  6.775639057159424\n",
      "test r2:  -0.2553050597969908\n",
      "train loss:  1.6364929676055908\n",
      "train r2:  0.8853647255341341\n",
      "test loss:  6.775506973266602\n",
      "test r2:  -0.2552685568568107\n",
      "train loss:  1.6364929676055908\n",
      "train r2:  0.8853724970525152\n",
      "test loss:  6.775639057159424\n",
      "test r2:  -0.25531146743887656\n",
      "train loss:  1.6364927291870117\n",
      "train r2:  0.8853632748098776\n",
      "test loss:  6.775454521179199\n",
      "test r2:  -0.2552590222251243\n",
      "train loss:  1.6364929676055908\n",
      "train r2:  0.8853744496263024\n",
      "test loss:  6.775655746459961\n",
      "test r2:  -0.2553227937977045\n",
      "train loss:  1.6364929676055908\n",
      "train r2:  0.8853607955665691\n",
      "test loss:  6.775386333465576\n",
      "test r2:  -0.255245035295109\n",
      "train loss:  1.6364929676055908\n",
      "train r2:  0.8853774023600619\n",
      "test loss:  6.775689601898193\n",
      "test r2:  -0.25533914672217994\n",
      "train loss:  1.63649320602417\n",
      "train r2:  0.8853572263199806\n",
      "test loss:  6.775296211242676\n",
      "test r2:  -0.2552241101516559\n",
      "train loss:  1.6364935636520386\n",
      "train r2:  0.8853817988576975\n",
      "test loss:  6.775752067565918\n",
      "test r2:  -0.25536431967826223\n",
      "train loss:  1.6364940404891968\n",
      "train r2:  0.8853517707375507\n",
      "test loss:  6.775169849395752\n",
      "test r2:  -0.2551924608128371\n",
      "train loss:  1.6364948749542236\n",
      "train r2:  0.8853884899560412\n",
      "test loss:  6.775860786437988\n",
      "test r2:  -0.2554033981862691\n",
      "train loss:  1.6364960670471191\n",
      "train r2:  0.885343356095656\n",
      "test loss:  6.774984359741211\n",
      "test r2:  -0.25514285695858696\n",
      "train loss:  1.636498212814331\n",
      "train r2:  0.8853990083366394\n",
      "test loss:  6.776047229766846\n",
      "test r2:  -0.25546560359722514\n",
      "train loss:  1.636501431465149\n",
      "train r2:  0.8853299010561204\n",
      "test loss:  6.77470064163208\n",
      "test r2:  -0.25506357064030016\n",
      "train loss:  1.6365063190460205\n",
      "train r2:  0.8854157723796862\n",
      "test loss:  6.776357650756836\n",
      "test r2:  -0.2555648989799064\n",
      "train loss:  1.6365145444869995\n",
      "train r2:  0.8853084768293893\n",
      "test loss:  6.774264812469482\n",
      "test r2:  -0.2549386367267714\n",
      "train loss:  1.6365272998809814\n",
      "train r2:  0.8854421077194199\n",
      "test loss:  6.776854038238525\n",
      "test r2:  -0.2557201305841945\n",
      "train loss:  1.6365464925765991\n",
      "train r2:  0.8852747611242977\n",
      "test loss:  6.773605823516846\n",
      "test r2:  -0.25474617071345396\n",
      "train loss:  1.6365771293640137\n",
      "train r2:  0.8854824907622159\n",
      "test loss:  6.777621269226074\n",
      "test r2:  -0.2559559701367753\n",
      "train loss:  1.636621356010437\n",
      "train r2:  0.8852232073538834\n",
      "test loss:  6.772644519805908\n",
      "test r2:  -0.2544624680710732\n",
      "train loss:  1.6366885900497437\n",
      "train r2:  0.8855414877245809\n",
      "test loss:  6.778698921203613\n",
      "test r2:  -0.2562842916784831\n",
      "train loss:  1.6367720365524292\n",
      "train r2:  0.8851507916553738\n",
      "test loss:  6.771450519561768\n",
      "test r2:  -0.25410840967382686\n",
      "train loss:  1.6368800401687622\n",
      "train r2:  0.885614321368729\n",
      "test loss:  6.779809951782227\n",
      "test r2:  -0.25662115792381957\n",
      "train loss:  1.6369644403457642\n",
      "train r2:  0.8850759272110398\n",
      "test loss:  6.770380020141602\n",
      "test r2:  -0.25379521560069573\n",
      "train loss:  1.637020230293274\n",
      "train r2:  0.8856790636418539\n",
      "test loss:  6.780271530151367\n",
      "test r2:  -0.2567603432604959\n",
      "train loss:  1.6369547843933105\n",
      "train r2:  0.8850461797475496\n",
      "test loss:  6.770758152008057\n",
      "test r2:  -0.2539227865354954\n",
      "train loss:  1.6368156671524048\n",
      "train r2:  0.8856545070854146\n",
      "test loss:  6.7784953117370605\n",
      "test r2:  -0.25623538009101177\n",
      "train loss:  1.6366276741027832\n",
      "train r2:  0.8851630545377361\n",
      "test loss:  6.7742018699646\n",
      "test r2:  -0.2549619683980686\n",
      "train loss:  1.636507272720337\n",
      "train r2:  0.8854370167471383\n",
      "test loss:  6.774171352386475\n",
      "test r2:  -0.25495606153907713\n",
      "train loss:  1.636504054069519\n",
      "train r2:  0.8854382756966496\n",
      "test loss:  6.778003215789795\n",
      "test r2:  -0.2560967416088791\n",
      "train loss:  1.6365876197814941\n",
      "train r2:  0.8851932462357304\n",
      "test loss:  6.771871566772461\n",
      "test r2:  -0.2542696861472371\n",
      "train loss:  1.6366775035858154\n",
      "train r2:  0.8855823474187653\n",
      "test loss:  6.778357982635498\n",
      "test r2:  -0.2562132643515993\n",
      "train loss:  1.636695146560669\n",
      "train r2:  0.8851667643812748\n",
      "test loss:  6.773149013519287\n",
      "test r2:  -0.25465084738530663\n",
      "train loss:  1.6366379261016846\n",
      "train r2:  0.8855016593412972\n",
      "test loss:  6.776095390319824\n",
      "test r2:  -0.25555069393563445\n",
      "train loss:  1.6365456581115723\n",
      "train r2:  0.8853104997645691\n",
      "test loss:  6.7754106521606445\n",
      "test r2:  -0.25533689080893573\n",
      "train loss:  1.6364930868148804\n",
      "train r2:  0.885356965825711\n",
      "test loss:  6.774297714233398\n",
      "test r2:  -0.25501135030797495\n",
      "train loss:  1.6365071535110474\n",
      "train r2:  0.8854262727664447\n",
      "test loss:  6.776516437530518\n",
      "test r2:  -0.2556837074245286\n",
      "train loss:  1.636558175086975\n",
      "train r2:  0.8852818255524098\n",
      "test loss:  6.773656845092773\n",
      "test r2:  -0.25481796735126916\n",
      "train loss:  1.6365935802459717\n",
      "train r2:  0.8854664293562035\n",
      "test loss:  6.776759624481201\n",
      "test r2:  -0.25576197295285596\n",
      "train loss:  1.6365792751312256\n",
      "train r2:  0.8852647221614977\n",
      "test loss:  6.773777961730957\n",
      "test r2:  -0.2548656374702094\n",
      "train loss:  1.6365342140197754\n",
      "train r2:  0.8854569662390934\n",
      "test loss:  6.7760419845581055\n",
      "test r2:  -0.25554491295748094\n",
      "train loss:  1.6364964246749878\n",
      "train r2:  0.885312288489346\n",
      "test loss:  6.7750654220581055\n",
      "test r2:  -0.25526259279229024\n",
      "train loss:  1.6364936828613281\n",
      "train r2:  0.8853726045480922\n",
      "test loss:  6.774316787719727\n",
      "test r2:  -0.25503312471492023\n",
      "train loss:  1.6365177631378174\n",
      "train r2:  0.8854213678059537\n",
      "test loss:  6.776677131652832\n",
      "test r2:  -0.25574618755720313\n",
      "train loss:  1.636540174484253\n",
      "train r2:  0.8852685394050087\n",
      "test loss:  6.773316860198975\n",
      "test r2:  -0.2547435210713287\n",
      "train loss:  1.6365405321121216\n",
      "train r2:  0.8854827774136153\n",
      "test loss:  6.776601791381836\n",
      "test r2:  -0.255726614057713\n",
      "train loss:  1.6365182399749756\n",
      "train r2:  0.885273009751796\n",
      "test loss:  6.774393081665039\n",
      "test r2:  -0.2550723997043589\n",
      "train loss:  1.63649582862854\n",
      "train r2:  0.8854130976316188\n",
      "test loss:  6.774844646453857\n",
      "test r2:  -0.2552103244712238\n",
      "train loss:  1.636489987373352\n",
      "train r2:  0.885383669190483\n",
      "test loss:  6.776077747344971\n",
      "test r2:  -0.25557957103266604\n",
      "train loss:  1.6365009546279907\n",
      "train r2:  0.8853046109233361\n",
      "test loss:  6.773737907409668\n",
      "test r2:  -0.2548851592000272\n",
      "train loss:  1.6365145444869995\n",
      "train r2:  0.8854527559279493\n",
      "test loss:  6.776263236999512\n",
      "test r2:  -0.25564258069641976\n",
      "train loss:  1.6365169286727905\n",
      "train r2:  0.885290876177234\n",
      "test loss:  6.774287223815918\n",
      "test r2:  -0.25505194664886766\n",
      "train loss:  1.636507272720337\n",
      "train r2:  0.8854172071791031\n",
      "test loss:  6.775263786315918\n",
      "test r2:  -0.25535197805954746\n",
      "train loss:  1.6364946365356445\n",
      "train r2:  0.8853532381027533\n",
      "test loss:  6.7752485275268555\n",
      "test r2:  -0.2553451135271587\n",
      "train loss:  1.6364892721176147\n",
      "train r2:  0.8853547828823227\n",
      "test loss:  6.774534702301025\n",
      "test r2:  -0.2551358946422253\n",
      "train loss:  1.63649320602417\n",
      "train r2:  0.8853993988216989\n",
      "test loss:  6.7756028175354\n",
      "test r2:  -0.25546018174198726\n",
      "train loss:  1.6365007162094116\n",
      "train r2:  0.8853299476608023\n",
      "test loss:  6.774412631988525\n",
      "test r2:  -0.25510216410358977\n",
      "train loss:  1.6365039348602295\n",
      "train r2:  0.8854064402271795\n",
      "test loss:  6.775520324707031\n",
      "test r2:  -0.255441428880695\n",
      "train loss:  1.636500358581543\n",
      "train r2:  0.8853339149745044\n",
      "test loss:  6.774568557739258\n",
      "test r2:  -0.2551564642183948\n",
      "train loss:  1.63649320602417\n",
      "train r2:  0.8853948925977728\n",
      "test loss:  6.775198459625244\n",
      "test r2:  -0.25534769063111673\n",
      "train loss:  1.636488914489746\n",
      "train r2:  0.8853540619719089\n",
      "test loss:  6.775001525878906\n",
      "test r2:  -0.25529425871313416\n",
      "train loss:  1.6364898681640625\n",
      "train r2:  0.885365416287799\n",
      "test loss:  6.774616718292236\n",
      "test r2:  -0.25517844723196825\n",
      "train loss:  1.6364935636520386\n",
      "train r2:  0.8853901543388112\n",
      "test loss:  6.775516986846924\n",
      "test r2:  -0.25545269960289607\n",
      "train loss:  1.6364959478378296\n",
      "train r2:  0.8853314456403203\n",
      "test loss:  6.774278163909912\n",
      "test r2:  -0.2550843564545979\n",
      "train loss:  1.6364954710006714\n",
      "train r2:  0.885410118234346\n",
      "test loss:  6.775468826293945\n",
      "test r2:  -0.25544226891101407\n",
      "train loss:  1.636492133140564\n",
      "train r2:  0.8853336864114368\n",
      "test loss:  6.774645805358887\n",
      "test r2:  -0.2552000454426073\n",
      "train loss:  1.6364891529083252\n",
      "train r2:  0.8853854718847112\n",
      "test loss:  6.774837017059326\n",
      "test r2:  -0.2552593428996981\n",
      "train loss:  1.636488437652588\n",
      "train r2:  0.8853727875300745\n",
      "test loss:  6.775253772735596\n",
      "test r2:  -0.2553861857697153\n",
      "train loss:  1.6364898681640625\n",
      "train r2:  0.8853456252055784\n",
      "test loss:  6.774383544921875\n",
      "test r2:  -0.2551296772676084\n",
      "train loss:  1.6364918947219849\n",
      "train r2:  0.8854004106602975\n",
      "test loss:  6.775362968444824\n",
      "test r2:  -0.2554247767792912\n",
      "train loss:  1.6364920139312744\n",
      "train r2:  0.8853372983035934\n",
      "test loss:  6.774530410766602\n",
      "test r2:  -0.2551780113926081\n",
      "train loss:  1.6364909410476685\n",
      "train r2:  0.8853900271342596\n",
      "test loss:  6.774997234344482\n",
      "test r2:  -0.25532203557968924\n",
      "train loss:  1.6364891529083252\n",
      "train r2:  0.8853592562900566\n",
      "test loss:  6.7748870849609375\n",
      "test r2:  -0.25529011921619404\n",
      "train loss:  1.6364878416061401\n",
      "train r2:  0.8853660843843512\n",
      "test loss:  6.774684429168701\n",
      "test r2:  -0.25523334176813384\n",
      "train loss:  1.6364880800247192\n",
      "train r2:  0.8853781969374842\n",
      "test loss:  6.775038242340088\n",
      "test r2:  -0.25534200463503276\n",
      "train loss:  1.636488914489746\n",
      "train r2:  0.8853549143361591\n",
      "test loss:  6.774600028991699\n",
      "test r2:  -0.25521225664992087\n",
      "train loss:  1.636489748954773\n",
      "train r2:  0.8853826403894153\n",
      "test loss:  6.775022506713867\n",
      "test r2:  -0.255343234719807\n",
      "train loss:  1.6364895105361938\n",
      "train r2:  0.8853545737939679\n",
      "test loss:  6.774612903594971\n",
      "test r2:  -0.255221726092292\n",
      "train loss:  1.6364887952804565\n",
      "train r2:  0.8853805718191846\n",
      "test loss:  6.774939060211182\n",
      "test r2:  -0.25532242265609795\n",
      "train loss:  1.6364878416061401\n",
      "train r2:  0.8853590335092726\n",
      "test loss:  6.774712085723877\n",
      "test r2:  -0.25525761506742506\n",
      "train loss:  1.6364872455596924\n",
      "train r2:  0.8853728369154178\n",
      "test loss:  6.774743556976318\n",
      "test r2:  -0.2552686201454195\n",
      "train loss:  1.636487603187561\n",
      "train r2:  0.8853704877948292\n",
      "test loss:  6.774906635284424\n",
      "test r2:  -0.25532114890423174\n",
      "train loss:  1.6364878416061401\n",
      "train r2:  0.8853592267703617\n",
      "test loss:  6.774530410766602\n",
      "test r2:  -0.2552108656400336\n",
      "train loss:  1.6364880800247192\n",
      "train r2:  0.8853827554647773\n",
      "test loss:  6.774997234344482\n",
      "test r2:  -0.25535288711336546\n",
      "train loss:  1.6364880800247192\n",
      "train r2:  0.8853523795660331\n",
      "test loss:  6.774530410766602\n",
      "test r2:  -0.2552163999646593\n",
      "train loss:  1.636487603187561\n",
      "train r2:  0.8853815273964706\n",
      "test loss:  6.774837017059326\n",
      "test r2:  -0.25531052269356014\n",
      "train loss:  1.6364870071411133\n",
      "train r2:  0.8853614095651099\n",
      "test loss:  6.774726390838623\n",
      "test r2:  -0.2552800670966977\n",
      "train loss:  1.6364867687225342\n",
      "train r2:  0.8853679185401623\n",
      "test loss:  6.774604320526123\n",
      "test r2:  -0.2552463610951994\n",
      "train loss:  1.6364867687225342\n",
      "train r2:  0.8853750596010643\n",
      "test loss:  6.77485990524292\n",
      "test r2:  -0.25532499381215557\n",
      "train loss:  1.6364870071411133\n",
      "train r2:  0.8853582530282231\n",
      "test loss:  6.774529933929443\n",
      "test r2:  -0.255229112704499\n",
      "train loss:  1.6364872455596924\n",
      "train r2:  0.8853787316875135\n",
      "test loss:  6.774810791015625\n",
      "test r2:  -0.25531601931537984\n",
      "train loss:  1.6364871263504028\n",
      "train r2:  0.8853601044566214\n",
      "test loss:  6.774592876434326\n",
      "test r2:  -0.25525287511929684\n",
      "train loss:  1.6364867687225342\n",
      "train r2:  0.8853735959322782\n",
      "test loss:  6.774701118469238\n",
      "test r2:  -0.255288741421132\n",
      "train loss:  1.6364866495132446\n",
      "train r2:  0.8853659043248905\n",
      "test loss:  6.774649143218994\n",
      "test r2:  -0.25527533887232345\n",
      "train loss:  1.636486530303955\n",
      "train r2:  0.8853687716049095\n",
      "test loss:  6.774627685546875\n",
      "test r2:  -0.255271368300668\n",
      "train loss:  1.6364861726760864\n",
      "train r2:  0.885369560854598\n",
      "test loss:  6.774677753448486\n",
      "test r2:  -0.2552893970419632\n",
      "train loss:  1.6364864110946655\n",
      "train r2:  0.8853656692660651\n",
      "test loss:  6.774561882019043\n",
      "test r2:  -0.2552565530190276\n",
      "train loss:  1.636486530303955\n",
      "train r2:  0.8853726773479379\n",
      "test loss:  6.774707317352295\n",
      "test r2:  -0.2553034255294502\n",
      "train loss:  1.636486530303955\n",
      "train r2:  0.8853626359933501\n",
      "test loss:  6.774509906768799\n",
      "test r2:  -0.25524670313223874\n",
      "train loss:  1.6364864110946655\n",
      "train r2:  0.8853747406897555\n",
      "test loss:  6.7746901512146\n",
      "test r2:  -0.25530291867986143\n",
      "train loss:  1.6364861726760864\n",
      "train r2:  0.885362686248414\n",
      "test loss:  6.7745361328125\n",
      "test r2:  -0.2552596841912016\n",
      "train loss:  1.6364860534667969\n",
      "train r2:  0.8853719411029193\n",
      "test loss:  6.774591445922852\n",
      "test r2:  -0.25527867150709094\n",
      "train loss:  1.6364859342575073\n",
      "train r2:  0.8853678562869991\n",
      "test loss:  6.774613857269287\n",
      "test r2:  -0.2552880397819042\n",
      "train loss:  1.6364860534667969\n",
      "train r2:  0.8853658278460004\n",
      "test loss:  6.7744903564453125\n",
      "test r2:  -0.2552537239239978\n",
      "train loss:  1.6364859342575073\n",
      "train r2:  0.8853731383436623\n",
      "test loss:  6.774643421173096\n",
      "test r2:  -0.2553017972466769\n",
      "train loss:  1.6364859342575073\n",
      "train r2:  0.8853628148326267\n",
      "test loss:  6.774470329284668\n",
      "test r2:  -0.2552526013110643\n",
      "train loss:  1.6364856958389282\n",
      "train r2:  0.8853733123531444\n",
      "test loss:  6.774591445922852\n",
      "test r2:  -0.2552915838948413\n",
      "train loss:  1.6364855766296387\n",
      "train r2:  0.8853649652450932\n",
      "test loss:  6.774505615234375\n",
      "test r2:  -0.25526807437231236\n",
      "train loss:  1.6364855766296387\n",
      "train r2:  0.8853700083848747\n",
      "test loss:  6.774522304534912\n",
      "test r2:  -0.2552759140572243\n",
      "train loss:  1.6364854574203491\n",
      "train r2:  0.8853682964966645\n",
      "test loss:  6.774527072906494\n",
      "test r2:  -0.25527971205784317\n",
      "train loss:  1.6364853382110596\n",
      "train r2:  0.8853674501699896\n",
      "test loss:  6.774479866027832\n",
      "test r2:  -0.2552681706611175\n",
      "train loss:  1.6364854574203491\n",
      "train r2:  0.885369895485224\n",
      "test loss:  6.77452278137207\n",
      "test r2:  -0.2552837238674548\n",
      "train loss:  1.6364854574203491\n",
      "train r2:  0.8853665635766566\n",
      "test loss:  6.774453639984131\n",
      "test r2:  -0.25526520169621403\n",
      "train loss:  1.6364850997924805\n",
      "train r2:  0.8853704791690554\n",
      "test loss:  6.7745137214660645\n",
      "test r2:  -0.25528600416627123\n",
      "train loss:  1.6364850997924805\n",
      "train r2:  0.8853660195396169\n",
      "test loss:  6.7744293212890625\n",
      "test r2:  -0.25526287371588285\n",
      "train loss:  1.636484980583191\n",
      "train r2:  0.8853709197085833\n",
      "test loss:  6.7744975090026855\n",
      "test r2:  -0.25528575893417704\n",
      "train loss:  1.636484980583191\n",
      "train r2:  0.8853660363099098\n",
      "test loss:  6.774425029754639\n",
      "test r2:  -0.25526688133083186\n",
      "train loss:  1.636484980583191\n",
      "train r2:  0.8853700571154289\n",
      "test loss:  6.774451732635498\n",
      "test r2:  -0.25527702761722404\n",
      "train loss:  1.6364848613739014\n",
      "train r2:  0.8853678535708067\n",
      "test loss:  6.774444580078125\n",
      "test r2:  -0.2552778221166119\n",
      "train loss:  1.6364848613739014\n",
      "train r2:  0.8853676753966679\n",
      "test loss:  6.774398326873779\n",
      "test r2:  -0.2552661672059289\n",
      "train loss:  1.6364846229553223\n",
      "train r2:  0.8853701544757016\n",
      "test loss:  6.774453639984131\n",
      "test r2:  -0.25528516719182903\n",
      "train loss:  1.6364846229553223\n",
      "train r2:  0.8853660794772822\n",
      "test loss:  6.77437162399292\n",
      "test r2:  -0.2552632821547569\n",
      "train loss:  1.6364846229553223\n",
      "train r2:  0.885370716835427\n",
      "test loss:  6.7744293212890625\n",
      "test r2:  -0.25528285435980047\n",
      "train loss:  1.6364843845367432\n",
      "train r2:  0.885366511233613\n",
      "test loss:  6.774371147155762\n",
      "test r2:  -0.2552679937028901\n",
      "train loss:  1.6364845037460327\n",
      "train r2:  0.8853696675352486\n",
      "test loss:  6.774393081665039\n",
      "test r2:  -0.25527692690845716\n",
      "train loss:  1.6364843845367432\n",
      "train r2:  0.8853677267909698\n",
      "test loss:  6.774370193481445\n",
      "test r2:  -0.25527263535909817\n",
      "train loss:  1.6364843845367432\n",
      "train r2:  0.8853686176791076\n",
      "test loss:  6.774363994598389\n",
      "test r2:  -0.2552731290143433\n",
      "train loss:  1.6364840269088745\n",
      "train r2:  0.8853684903090787\n",
      "test loss:  6.7743611335754395\n",
      "test r2:  -0.2552747508125943\n",
      "train loss:  1.6364842653274536\n",
      "train r2:  0.8853681569782603\n",
      "test loss:  6.774343490600586\n",
      "test r2:  -0.2552716325807902\n",
      "train loss:  1.6364840269088745\n",
      "train r2:  0.885368792267376\n",
      "test loss:  6.774350166320801\n",
      "test r2:  -0.2552763612352813\n",
      "train loss:  1.636483907699585\n",
      "train r2:  0.8853677576259\n",
      "test loss:  6.774316787719727\n",
      "test r2:  -0.25526868771061784\n",
      "train loss:  1.636483907699585\n",
      "train r2:  0.8853693761944333\n",
      "test loss:  6.7743425369262695\n",
      "test r2:  -0.25527890540458453\n",
      "train loss:  1.636483907699585\n",
      "train r2:  0.88536717378213\n",
      "test loss:  6.774294853210449\n",
      "test r2:  -0.2552667715322643\n",
      "train loss:  1.6364840269088745\n",
      "train r2:  0.8853697201364102\n",
      "test loss:  6.774325370788574\n",
      "test r2:  -0.2552783472400184\n",
      "train loss:  1.6364837884902954\n",
      "train r2:  0.8853672323737047\n",
      "test loss:  6.774286270141602\n",
      "test r2:  -0.2552692286950917\n",
      "train loss:  1.6364836692810059\n",
      "train r2:  0.8853691651870432\n",
      "test loss:  6.774293422698975\n",
      "test r2:  -0.25527374439672745\n",
      "train loss:  1.6364836692810059\n",
      "train r2:  0.8853681662180231\n",
      "test loss:  6.774286270141602\n",
      "test r2:  -0.25527387706112115\n",
      "train loss:  1.6364834308624268\n",
      "train r2:  0.8853681277156454\n",
      "test loss:  6.774264335632324\n",
      "test r2:  -0.25526958018241075\n",
      "train loss:  1.6364834308624268\n",
      "train r2:  0.8853690330367477\n",
      "test loss:  6.774277210235596\n",
      "test r2:  -0.25527603128247467\n",
      "train loss:  1.6364834308624268\n",
      "train r2:  0.8853676383192024\n",
      "test loss:  6.774245738983154\n",
      "test r2:  -0.25526879767303945\n",
      "train loss:  1.6364833116531372\n",
      "train r2:  0.8853691482835102\n",
      "test loss:  6.774258613586426\n",
      "test r2:  -0.25527508487404016\n",
      "train loss:  1.6364831924438477\n",
      "train r2:  0.8853677753438866\n",
      "test loss:  6.774232387542725\n",
      "test r2:  -0.2552697723749642\n",
      "train loss:  1.6364831924438477\n",
      "train r2:  0.8853688965837334\n",
      "test loss:  6.774238586425781\n",
      "test r2:  -0.25527387907652543\n",
      "train loss:  1.6364833116531372\n",
      "train r2:  0.8853680080582597\n",
      "test loss:  6.77421760559082\n",
      "test r2:  -0.25526986603391233\n",
      "train loss:  1.6364831924438477\n",
      "train r2:  0.8853688156956556\n",
      "test loss:  6.7742228507995605\n",
      "test r2:  -0.25527397890457704\n",
      "train loss:  1.6364831924438477\n",
      "train r2:  0.8853679567813757\n",
      "test loss:  6.774200439453125\n",
      "test r2:  -0.2552696342460392\n",
      "train loss:  1.6364829540252686\n",
      "train r2:  0.8853688448183331\n",
      "test loss:  6.774204730987549\n",
      "test r2:  -0.25527296498010044\n",
      "train loss:  1.636482834815979\n",
      "train r2:  0.8853681062701799\n",
      "test loss:  6.774189472198486\n",
      "test r2:  -0.2552709238753583\n",
      "train loss:  1.636482834815979\n",
      "train r2:  0.8853685387650736\n",
      "test loss:  6.77418327331543\n",
      "test r2:  -0.25527123605000557\n",
      "train loss:  1.6364829540252686\n",
      "train r2:  0.8853684541136263\n",
      "test loss:  6.774177551269531\n",
      "test r2:  -0.25527202615401\n",
      "train loss:  1.6364827156066895\n",
      "train r2:  0.8853682432201326\n",
      "test loss:  6.774163722991943\n",
      "test r2:  -0.2552701121467218\n",
      "train loss:  1.6364825963974\n",
      "train r2:  0.8853686514219664\n",
      "test loss:  6.774163722991943\n",
      "test r2:  -0.25527243102086694\n",
      "train loss:  1.6364825963974\n",
      "train r2:  0.885368132073862\n",
      "test loss:  6.774146556854248\n",
      "test r2:  -0.2552695208222018\n",
      "train loss:  1.6364825963974\n",
      "train r2:  0.8853687517541966\n",
      "test loss:  6.7741475105285645\n",
      "test r2:  -0.2552722706487611\n",
      "train loss:  1.6364825963974\n",
      "train r2:  0.8853681115881227\n",
      "test loss:  6.774131774902344\n",
      "test r2:  -0.25526970395772497\n",
      "train loss:  1.6364823579788208\n",
      "train r2:  0.8853686640073586\n",
      "test loss:  6.7741312980651855\n",
      "test r2:  -0.25527178279804397\n",
      "train loss:  1.6364822387695312\n",
      "train r2:  0.8853681833025056\n",
      "test loss:  6.774116039276123\n",
      "test r2:  -0.2552695606182429\n",
      "train loss:  1.6364822387695312\n",
      "train r2:  0.8853686412552983\n",
      "test loss:  6.774115085601807\n",
      "test r2:  -0.25527154046616585\n",
      "train loss:  1.6364822387695312\n",
      "train r2:  0.8853682137180413\n",
      "test loss:  6.774101257324219\n",
      "test r2:  -0.2552698295313369\n",
      "train loss:  1.6364821195602417\n",
      "train r2:  0.8853685699551683\n",
      "test loss:  6.77409553527832\n",
      "test r2:  -0.25527044209543215\n",
      "train loss:  1.6364821195602417\n",
      "train r2:  0.8853684017363634\n",
      "test loss:  6.774089336395264\n",
      "test r2:  -0.2552706524880688\n",
      "train loss:  1.6364818811416626\n",
      "train r2:  0.8853683605935352\n",
      "test loss:  6.774078369140625\n",
      "test r2:  -0.25526964029225185\n",
      "train loss:  1.6364818811416626\n",
      "train r2:  0.8853685150198184\n",
      "test loss:  6.774072647094727\n",
      "test r2:  -0.25527047662766345\n",
      "train loss:  1.6364818811416626\n",
      "train r2:  0.8853683491440156\n",
      "test loss:  6.774062633514404\n",
      "test r2:  -0.25526947898617824\n",
      "train loss:  1.6364818811416626\n",
      "train r2:  0.8853685152220053\n",
      "test loss:  6.7740583419799805\n",
      "test r2:  -0.25527047382166357\n",
      "train loss:  1.6364816427230835\n",
      "train r2:  0.8853683082753406\n",
      "test loss:  6.774046421051025\n",
      "test r2:  -0.2552692296618304\n",
      "train loss:  1.6364816427230835\n",
      "train r2:  0.885368545092966\n",
      "test loss:  6.774040699005127\n",
      "test r2:  -0.25526981428472184\n",
      "train loss:  1.6364812850952148\n",
      "train r2:  0.8853683728031372\n",
      "test loss:  6.774033069610596\n",
      "test r2:  -0.255269713330174\n",
      "train loss:  1.6364816427230835\n",
      "train r2:  0.8853683863102956\n",
      "test loss:  6.774024486541748\n",
      "test r2:  -0.25526931476350345\n",
      "train loss:  1.6364812850952148\n",
      "train r2:  0.8853684729909078\n",
      "test loss:  6.774017333984375\n",
      "test r2:  -0.25526946156849784\n",
      "train loss:  1.6364812850952148\n",
      "train r2:  0.8853684315930233\n",
      "test loss:  6.774010181427002\n",
      "test r2:  -0.2552696696057333\n",
      "train loss:  1.6364812850952148\n",
      "train r2:  0.8853683788787303\n",
      "test loss:  6.774000644683838\n",
      "test r2:  -0.25526871690530495\n",
      "train loss:  1.6364812850952148\n",
      "train r2:  0.885368530331148\n",
      "test loss:  6.773995876312256\n",
      "test r2:  -0.25526958851848325\n",
      "train loss:  1.6364810466766357\n",
      "train r2:  0.8853683235862155\n",
      "test loss:  6.773984909057617\n",
      "test r2:  -0.2552685408359856\n",
      "train loss:  1.6364811658859253\n",
      "train r2:  0.8853685327436491\n",
      "test loss:  6.773979663848877\n",
      "test r2:  -0.25526936004046097\n",
      "train loss:  1.6364811658859253\n",
      "train r2:  0.885368352529187\n",
      "test loss:  6.773970127105713\n",
      "test r2:  -0.255268616442319\n",
      "train loss:  1.6364810466766357\n",
      "train r2:  0.8853685050465786\n",
      "test loss:  6.773963928222656\n",
      "test r2:  -0.25526883555198876\n",
      "train loss:  1.6364808082580566\n",
      "train r2:  0.885368413810557\n",
      "test loss:  6.7739577293396\n",
      "test r2:  -0.25526911044575384\n",
      "train loss:  1.6364810466766357\n",
      "train r2:  0.88536833981453\n",
      "test loss:  6.77394437789917\n",
      "test r2:  -0.25526749679923944\n",
      "train loss:  1.6364808082580566\n",
      "train r2:  0.8853686434877801\n",
      "test loss:  6.773946762084961\n",
      "test r2:  -0.25527008978065036\n",
      "train loss:  1.6364808082580566\n",
      "train r2:  0.8853680994919435\n",
      "test loss:  6.773927688598633\n",
      "test r2:  -0.2552666555277263\n",
      "train loss:  1.636480689048767\n",
      "train r2:  0.8853688165917781\n",
      "test loss:  6.773931503295898\n",
      "test r2:  -0.2552698775815234\n",
      "train loss:  1.636480689048767\n",
      "train r2:  0.885368130161001\n",
      "test loss:  6.7739152908325195\n",
      "test r2:  -0.2552672904906639\n",
      "train loss:  1.636480689048767\n",
      "train r2:  0.8853686326759664\n",
      "test loss:  6.773911952972412\n",
      "test r2:  -0.25526854300705115\n",
      "train loss:  1.636480450630188\n",
      "train r2:  0.8853683495328678\n",
      "test loss:  6.7739033699035645\n",
      "test r2:  -0.2552680952473123\n",
      "train loss:  1.6364802122116089\n",
      "train r2:  0.8853684380586351\n",
      "test loss:  6.773895263671875\n",
      "test r2:  -0.2552677715209579\n",
      "train loss:  1.636480450630188\n",
      "train r2:  0.8853684792307406\n",
      "test loss:  6.773889064788818\n",
      "test r2:  -0.2552679652373535\n",
      "train loss:  1.6364802122116089\n",
      "train r2:  0.8853684238944272\n",
      "test loss:  6.773880481719971\n",
      "test r2:  -0.25526782743204013\n",
      "train loss:  1.6364800930023193\n",
      "train r2:  0.8853684474496635\n",
      "test loss:  6.7738728523254395\n",
      "test r2:  -0.2552674845142855\n",
      "train loss:  1.6364800930023193\n",
      "train r2:  0.8853684887083162\n",
      "test loss:  6.773866653442383\n",
      "test r2:  -0.2552679369438633\n",
      "train loss:  1.6364800930023193\n",
      "train r2:  0.8853683822759676\n",
      "test loss:  6.773859024047852\n",
      "test r2:  -0.2552676051763736\n",
      "train loss:  1.6364800930023193\n",
      "train r2:  0.8853684169916324\n",
      "test loss:  6.773849010467529\n",
      "test r2:  -0.2552665482402212\n",
      "train loss:  1.6364799737930298\n",
      "train r2:  0.8853686260025846\n",
      "test loss:  6.773849010467529\n",
      "test r2:  -0.25526865189213277\n",
      "train loss:  1.6364799737930298\n",
      "train r2:  0.8853681480210098\n",
      "test loss:  6.773831367492676\n",
      "test r2:  -0.255265775373658\n",
      "train loss:  1.6364798545837402\n",
      "train r2:  0.8853687482117054\n",
      "test loss:  6.77383279800415\n",
      "test r2:  -0.2552681959601757\n",
      "train loss:  1.6364798545837402\n",
      "train r2:  0.8853682044449355\n",
      "test loss:  6.773819446563721\n",
      "test r2:  -0.25526621675128336\n",
      "train loss:  1.6364796161651611\n",
      "train r2:  0.8853686129380761\n",
      "test loss:  6.773817539215088\n",
      "test r2:  -0.2552676675678818\n",
      "train loss:  1.6364798545837402\n",
      "train r2:  0.8853682897487604\n",
      "test loss:  6.773804187774658\n",
      "test r2:  -0.25526578399237865\n",
      "train loss:  1.6364794969558716\n",
      "train r2:  0.8853686790826688\n",
      "test loss:  6.773804187774658\n",
      "test r2:  -0.25526814265027564\n",
      "train loss:  1.6364794969558716\n",
      "train r2:  0.8853681514394193\n",
      "test loss:  6.773787021636963\n",
      "test r2:  -0.2552649474767277\n",
      "train loss:  1.6364794969558716\n",
      "train r2:  0.8853688417104304\n",
      "test loss:  6.7737932205200195\n",
      "test r2:  -0.2552688053250214\n",
      "train loss:  1.6364794969558716\n",
      "train r2:  0.8853679924589278\n",
      "test loss:  6.773771286010742\n",
      "test r2:  -0.25526421958808854\n",
      "train loss:  1.636479377746582\n",
      "train r2:  0.8853689305644714\n",
      "test loss:  6.773779392242432\n",
      "test r2:  -0.2552688326804473\n",
      "train loss:  1.636479377746582\n",
      "train r2:  0.8853679510626621\n",
      "test loss:  6.773756504058838\n",
      "test r2:  -0.2552639536284629\n",
      "train loss:  1.636479377746582\n",
      "train r2:  0.8853689924559839\n",
      "test loss:  6.773766040802002\n",
      "test r2:  -0.2552690849664563\n",
      "train loss:  1.636479139328003\n",
      "train r2:  0.8853678576085509\n",
      "test loss:  6.773738384246826\n",
      "test r2:  -0.25526292100414816\n",
      "train loss:  1.636479139328003\n",
      "train r2:  0.88536915451865\n",
      "test loss:  6.773755073547363\n",
      "test r2:  -0.25526981326063436\n",
      "train loss:  1.636479139328003\n",
      "train r2:  0.8853676484073703\n",
      "test loss:  6.7737202644348145\n",
      "test r2:  -0.25526151829098853\n",
      "train loss:  1.6364790201187134\n",
      "train r2:  0.8853694202794031\n",
      "test loss:  6.773746013641357\n",
      "test r2:  -0.25527116052969534\n",
      "train loss:  1.6364789009094238\n",
      "train r2:  0.8853673420129852\n",
      "test loss:  6.773701190948486\n",
      "test r2:  -0.2552598292388619\n",
      "train loss:  1.6364789009094238\n",
      "train r2:  0.8853697702390149\n",
      "test loss:  6.773738384246826\n",
      "test r2:  -0.2552727526007339\n",
      "train loss:  1.6364787817001343\n",
      "train r2:  0.8853669741003829\n",
      "test loss:  6.773681640625\n",
      "test r2:  -0.2552578516480277\n",
      "train loss:  1.6364789009094238\n",
      "train r2:  0.8853701684688823\n",
      "test loss:  6.773731708526611\n",
      "test r2:  -0.25527476828762374\n",
      "train loss:  1.6364785432815552\n",
      "train r2:  0.8853665227966551\n",
      "test loss:  6.773658275604248\n",
      "test r2:  -0.255254931765591\n",
      "train loss:  1.6364785432815552\n",
      "train r2:  0.8853707331153032\n",
      "test loss:  6.773730278015137\n",
      "test r2:  -0.2552784237639343\n",
      "train loss:  1.6364785432815552\n",
      "train r2:  0.885365682765361\n",
      "test loss:  6.773626804351807\n",
      "test r2:  -0.2552493069362065\n",
      "train loss:  1.6364787817001343\n",
      "train r2:  0.8853718872464791\n",
      "test loss:  6.773737907409668\n",
      "test r2:  -0.25528466665471594\n",
      "train loss:  1.636478304862976\n",
      "train r2:  0.8853643127679217\n",
      "test loss:  6.77358865737915\n",
      "test r2:  -0.2552422010100037\n",
      "train loss:  1.6364784240722656\n",
      "train r2:  0.8853734033575369\n",
      "test loss:  6.7737507820129395\n",
      "test r2:  -0.2552926751502147\n",
      "train loss:  1.6364785432815552\n",
      "train r2:  0.8853625694423445\n",
      "test loss:  6.773540019989014\n",
      "test r2:  -0.2552314829386815\n",
      "train loss:  1.6364784240722656\n",
      "train r2:  0.8853756194301988\n",
      "test loss:  6.7737812995910645\n",
      "test r2:  -0.2553058810045814\n",
      "train loss:  1.6364787817001343\n",
      "train r2:  0.8853597114927038\n",
      "test loss:  6.773470878601074\n",
      "test r2:  -0.25521463570764125\n",
      "train loss:  1.6364785432815552\n",
      "train r2:  0.8853792079303326\n",
      "test loss:  6.773837089538574\n",
      "test r2:  -0.25532655682368666\n",
      "train loss:  1.6364789009094238\n",
      "train r2:  0.8853552408020458\n",
      "test loss:  6.773370742797852\n",
      "test r2:  -0.25518840122749453\n",
      "train loss:  1.6364794969558716\n",
      "train r2:  0.8853847659458556\n",
      "test loss:  6.7739338874816895\n",
      "test r2:  -0.25535967152933936\n",
      "train loss:  1.6364802122116089\n",
      "train r2:  0.8853481234372785\n",
      "test loss:  6.773214340209961\n",
      "test r2:  -0.25514527961376143\n",
      "train loss:  1.636481761932373\n",
      "train r2:  0.8853938892444355\n",
      "test loss:  6.774103164672852\n",
      "test r2:  -0.2554143799806097\n",
      "train loss:  1.636483907699585\n",
      "train r2:  0.8853363271137193\n",
      "test loss:  6.77296781539917\n",
      "test r2:  -0.2550751140606229\n",
      "train loss:  1.6364872455596924\n",
      "train r2:  0.8854088140467844\n",
      "test loss:  6.774389266967773\n",
      "test r2:  -0.2555041695658129\n",
      "train loss:  1.63649320602417\n",
      "train r2:  0.8853169876253076\n",
      "test loss:  6.7725725173950195\n",
      "test r2:  -0.2549600476973446\n",
      "train loss:  1.6365028619766235\n",
      "train r2:  0.8854331135365889\n",
      "test loss:  6.774864196777344\n",
      "test r2:  -0.255650393591202\n",
      "train loss:  1.6365176439285278\n",
      "train r2:  0.8852853226990371\n",
      "test loss:  6.77194356918335\n",
      "test r2:  -0.2547743118479404\n",
      "train loss:  1.6365426778793335\n",
      "train r2:  0.8854721984760475\n",
      "test loss:  6.775631427764893\n",
      "test r2:  -0.2558839373402815\n",
      "train loss:  1.636579990386963\n",
      "train r2:  0.885234442958318\n",
      "test loss:  6.770971298217773\n",
      "test r2:  -0.2544852196869094\n",
      "train loss:  1.6366407871246338\n",
      "train r2:  0.8855325614194847\n",
      "test loss:  6.7767839431762695\n",
      "test r2:  -0.256232115459752\n",
      "train loss:  1.6367241144180298\n",
      "train r2:  0.8851578934810876\n",
      "test loss:  6.7696380615234375\n",
      "test r2:  -0.25408681723904136\n",
      "train loss:  1.6368436813354492\n",
      "train r2:  0.8856147425252529\n",
      "test loss:  6.778177261352539\n",
      "test r2:  -0.2566509848907015\n",
      "train loss:  1.6369645595550537\n",
      "train r2:  0.8850648347208057\n",
      "test loss:  6.768067836761475\n",
      "test r2:  -0.2536202445578719\n",
      "train loss:  1.6370849609375\n",
      "train r2:  0.8857107890566471\n",
      "test loss:  6.779332160949707\n",
      "test r2:  -0.2569930881107074\n",
      "train loss:  1.6370822191238403\n",
      "train r2:  0.8849898151313318\n",
      "test loss:  6.767489910125732\n",
      "test r2:  -0.2534598617585333\n",
      "train loss:  1.6369820833206177\n",
      "train r2:  0.8857461122054213\n",
      "test loss:  6.778304576873779\n",
      "test r2:  -0.25668594884854024\n",
      "train loss:  1.6367466449737549\n",
      "train r2:  0.8850602533633722\n",
      "test loss:  6.770956516265869\n",
      "test r2:  -0.25450761361355245\n",
      "train loss:  1.6365433931350708\n",
      "train r2:  0.885528824117245\n",
      "test loss:  6.773153781890869\n",
      "test r2:  -0.2551634534887399\n",
      "train loss:  1.6364779472351074\n",
      "train r2:  0.8853897232671603\n",
      "test loss:  6.776295185089111\n",
      "test r2:  -0.25609560787025876\n",
      "train loss:  1.6365594863891602\n",
      "train r2:  0.8851892560856764\n",
      "test loss:  6.769460678100586\n",
      "test r2:  -0.2540606425656058\n",
      "train loss:  1.636685848236084\n",
      "train r2:  0.8856221575229096\n",
      "test loss:  6.77728271484375\n",
      "test r2:  -0.25639699709400476\n",
      "train loss:  1.6367297172546387\n",
      "train r2:  0.8851223284137368\n",
      "test loss:  6.7710957527160645\n",
      "test r2:  -0.25454215864176444\n",
      "train loss:  1.6366673707962036\n",
      "train r2:  0.8855198822507713\n",
      "test loss:  6.774074077606201\n",
      "test r2:  -0.25545709756723767\n",
      "train loss:  1.6365481615066528\n",
      "train r2:  0.8853258661906858\n",
      "test loss:  6.7742390632629395\n",
      "test r2:  -0.2554869762464431\n",
      "train loss:  1.6364805698394775\n",
      "train r2:  0.8853205566021685\n",
      "test loss:  6.772005081176758\n",
      "test r2:  -0.25483145535813323\n",
      "train loss:  1.6365036964416504\n",
      "train r2:  0.8854601792869282\n",
      "test loss:  6.7749552726745605\n",
      "test r2:  -0.2557215930958725\n",
      "train loss:  1.636573076248169\n",
      "train r2:  0.8852689428498542\n",
      "test loss:  6.772122383117676\n",
      "test r2:  -0.2548560378376399\n",
      "train loss:  1.6366102695465088\n",
      "train r2:  0.8854536467606958\n",
      "test loss:  6.774562358856201\n",
      "test r2:  -0.25561120385500136\n",
      "train loss:  1.6365739107131958\n",
      "train r2:  0.8852924955259625\n",
      "test loss:  6.7724833488464355\n",
      "test r2:  -0.25497606444256116\n",
      "train loss:  1.636508822441101\n",
      "train r2:  0.8854292321981424\n",
      "test loss:  6.774006366729736\n",
      "test r2:  -0.2554332303186486\n",
      "train loss:  1.6364766359329224\n",
      "train r2:  0.8853319797570338\n",
      "test loss:  6.773490905761719\n",
      "test r2:  -0.2552930829910218\n",
      "train loss:  1.6364970207214355\n",
      "train r2:  0.8853615343863761\n",
      "test loss:  6.772481918334961\n",
      "test r2:  -0.25497572845583094\n",
      "train loss:  1.6365346908569336\n",
      "train r2:  0.8854289804046016\n",
      "test loss:  6.7750654220581055\n",
      "test r2:  -0.2557609405210697\n",
      "train loss:  1.6365455389022827\n",
      "train r2:  0.8852608528742392\n",
      "test loss:  6.771543979644775\n",
      "test r2:  -0.2547078220562382\n",
      "train loss:  1.6365214586257935\n",
      "train r2:  0.8854862335570343\n",
      "test loss:  6.774744987487793\n",
      "test r2:  -0.2556613704535371\n",
      "train loss:  1.6364877223968506\n",
      "train r2:  0.8852829658032977\n",
      "test loss:  6.773110866546631\n",
      "test r2:  -0.2551831972243468\n",
      "train loss:  1.6364763975143433\n",
      "train r2:  0.885385239992502\n",
      "test loss:  6.772466659545898\n",
      "test r2:  -0.25498795672444263\n",
      "train loss:  1.6364920139312744\n",
      "train r2:  0.8854267941189333\n",
      "test loss:  6.7750701904296875\n",
      "test r2:  -0.25576690528196977\n",
      "train loss:  1.6365113258361816\n",
      "train r2:  0.8852599758938807\n",
      "test loss:  6.771618366241455\n",
      "test r2:  -0.25474047344831097\n",
      "train loss:  1.6365127563476562\n",
      "train r2:  0.8854792688319504\n",
      "test loss:  6.774480819702148\n",
      "test r2:  -0.2555962419936657\n",
      "train loss:  1.6364951133728027\n",
      "train r2:  0.8852966696557263\n",
      "test loss:  6.773198127746582\n",
      "test r2:  -0.25521277021342725\n",
      "train loss:  1.636478066444397\n",
      "train r2:  0.8853788830095473\n",
      "test loss:  6.77265739440918\n",
      "test r2:  -0.2550577925623627\n",
      "train loss:  1.636476993560791\n",
      "train r2:  0.8854119318200763\n",
      "test loss:  6.774450778961182\n",
      "test r2:  -0.2555901013068187\n",
      "train loss:  1.6364877223968506\n",
      "train r2:  0.8852980676276143\n",
      "test loss:  6.772308349609375\n",
      "test r2:  -0.25495189152842523\n",
      "train loss:  1.6364964246749878\n",
      "train r2:  0.8854342985858675\n",
      "test loss:  6.773972988128662\n",
      "test r2:  -0.2554560993031074\n",
      "train loss:  1.6364936828613281\n",
      "train r2:  0.8853265819255647\n",
      "test loss:  6.773143291473389\n",
      "test r2:  -0.25520164631670217\n",
      "train loss:  1.6364834308624268\n",
      "train r2:  0.8853811693984504\n",
      "test loss:  6.773180961608887\n",
      "test r2:  -0.2552215354317737\n",
      "train loss:  1.636475682258606\n",
      "train r2:  0.88537690069471\n",
      "test loss:  6.773608207702637\n",
      "test r2:  -0.2553488166235389\n",
      "train loss:  1.6364766359329224\n",
      "train r2:  0.8853497060102645\n",
      "test loss:  6.772970676422119\n",
      "test r2:  -0.25515629971307163\n",
      "train loss:  1.6364831924438477\n",
      "train r2:  0.88539076270874\n",
      "test loss:  6.773674488067627\n",
      "test r2:  -0.255375803435246\n",
      "train loss:  1.6364871263504028\n",
      "train r2:  0.885343741561643\n",
      "test loss:  6.772887706756592\n",
      "test r2:  -0.2551348983443431\n",
      "train loss:  1.6364840269088745\n",
      "train r2:  0.8853953100033618\n",
      "test loss:  6.773701190948486\n",
      "test r2:  -0.2553833190538062\n",
      "train loss:  1.636478066444397\n",
      "train r2:  0.8853422649973872\n",
      "test loss:  6.7730021476745605\n",
      "test r2:  -0.2551772717474441\n",
      "train loss:  1.636474609375\n",
      "train r2:  0.8853862872263469\n",
      "test loss:  6.7733001708984375\n",
      "test r2:  -0.2552634930430522\n",
      "train loss:  1.6364760398864746\n",
      "train r2:  0.8853678773410666\n",
      "test loss:  6.7735915184021\n",
      "test r2:  -0.2553570111056207\n",
      "train loss:  1.6364794969558716\n",
      "train r2:  0.8853478104918218\n",
      "test loss:  6.772692680358887\n",
      "test r2:  -0.2550869713596744\n",
      "train loss:  1.6364808082580566\n",
      "train r2:  0.8854054707922802\n",
      "test loss:  6.7739057540893555\n",
      "test r2:  -0.2554509793816415\n",
      "train loss:  1.636479139328003\n",
      "train r2:  0.8853276895556048\n",
      "test loss:  6.772799968719482\n",
      "test r2:  -0.2551240118065272\n",
      "train loss:  1.6364760398864746\n",
      "train r2:  0.885397580142764\n",
      "test loss:  6.7733612060546875\n",
      "test r2:  -0.25529204059691213\n",
      "train loss:  1.6364742517471313\n",
      "train r2:  0.8853617438853474\n",
      "test loss:  6.773509502410889\n",
      "test r2:  -0.25533835523360926\n",
      "train loss:  1.6364750862121582\n",
      "train r2:  0.8853517806273805\n",
      "test loss:  6.772739887237549\n",
      "test r2:  -0.2551109907221276\n",
      "train loss:  1.6364768743515015\n",
      "train r2:  0.8854003368199164\n",
      "test loss:  6.773763656616211\n",
      "test r2:  -0.25541732775919046\n",
      "train loss:  1.6364777088165283\n",
      "train r2:  0.8853348333033569\n",
      "test loss:  6.772864818572998\n",
      "test r2:  -0.25515055191945035\n",
      "train loss:  1.636476755142212\n",
      "train r2:  0.8853918653604123\n",
      "test loss:  6.773336410522461\n",
      "test r2:  -0.2552943853026408\n",
      "train loss:  1.6364747285842896\n",
      "train r2:  0.8853610945820728\n",
      "test loss:  6.773332118988037\n",
      "test r2:  -0.25529233978203325\n",
      "train loss:  1.6364740133285522\n",
      "train r2:  0.8853615603920163\n",
      "test loss:  6.772976875305176\n",
      "test r2:  -0.25518976761012513\n",
      "train loss:  1.6364742517471313\n",
      "train r2:  0.8853834739988526\n",
      "test loss:  6.773458480834961\n",
      "test r2:  -0.25533479928631686\n",
      "train loss:  1.6364750862121582\n",
      "train r2:  0.8853524360037573\n",
      "test loss:  6.773005962371826\n",
      "test r2:  -0.2551994712203487\n",
      "train loss:  1.636475682258606\n",
      "train r2:  0.8853813406140606\n",
      "test loss:  6.773327827453613\n",
      "test r2:  -0.2553001339810739\n",
      "train loss:  1.6364752054214478\n",
      "train r2:  0.885359806941457\n",
      "test loss:  6.7731099128723145\n",
      "test r2:  -0.2552340124471477\n",
      "train loss:  1.6364742517471313\n",
      "train r2:  0.8853739840961321\n",
      "test loss:  6.773233413696289\n",
      "test r2:  -0.2552735672541644\n",
      "train loss:  1.6364734172821045\n",
      "train r2:  0.8853655040547437\n",
      "test loss:  6.773176670074463\n",
      "test r2:  -0.2552590243306483\n",
      "train loss:  1.6364736557006836\n",
      "train r2:  0.8853686110135558\n",
      "test loss:  6.773112773895264\n",
      "test r2:  -0.2552396268144541\n",
      "train loss:  1.6364740133285522\n",
      "train r2:  0.88537273800289\n",
      "test loss:  6.773310661315918\n",
      "test r2:  -0.2553022533220062\n",
      "train loss:  1.6364742517471313\n",
      "train r2:  0.8853592897023103\n",
      "test loss:  6.772963047027588\n",
      "test r2:  -0.25519887104361616\n",
      "train loss:  1.6364740133285522\n",
      "train r2:  0.8853814172654548\n",
      "test loss:  6.773364067077637\n",
      "test r2:  -0.2553202362456255\n",
      "train loss:  1.6364736557006836\n",
      "train r2:  0.8853554637712088\n",
      "test loss:  6.773013591766357\n",
      "test r2:  -0.2552178483971821\n",
      "train loss:  1.6364730596542358\n",
      "train r2:  0.8853773012819508\n",
      "test loss:  6.773168563842773\n",
      "test r2:  -0.2552647694985093\n",
      "train loss:  1.6364729404449463\n",
      "train r2:  0.8853672933091165\n",
      "test loss:  6.773248672485352\n",
      "test r2:  -0.2552906740504275\n",
      "train loss:  1.6364731788635254\n",
      "train r2:  0.8853617551289301\n",
      "test loss:  6.772946357727051\n",
      "test r2:  -0.2552018536534617\n",
      "train loss:  1.6364734172821045\n",
      "train r2:  0.8853806790581696\n",
      "test loss:  6.7733378410339355\n",
      "test r2:  -0.255320009262771\n",
      "train loss:  1.6364734172821045\n",
      "train r2:  0.8853554189338909\n",
      "test loss:  6.772974967956543\n",
      "test r2:  -0.25521331487232723\n",
      "train loss:  1.6364730596542358\n",
      "train r2:  0.8853782143543619\n",
      "test loss:  6.773178577423096\n",
      "test r2:  -0.25527624568953433\n",
      "train loss:  1.6364728212356567\n",
      "train r2:  0.8853647458686869\n",
      "test loss:  6.773149013519287\n",
      "test r2:  -0.2552679773543569\n",
      "train loss:  1.6364725828170776\n",
      "train r2:  0.8853665285476169\n",
      "test loss:  6.773019313812256\n",
      "test r2:  -0.2552316000942938\n",
      "train loss:  1.6364725828170776\n",
      "train r2:  0.8853742715557186\n",
      "test loss:  6.773210525512695\n",
      "test r2:  -0.2552899678560583\n",
      "train loss:  1.6364728212356567\n",
      "train r2:  0.8853617689371694\n",
      "test loss:  6.773011684417725\n",
      "test r2:  -0.2552316533017851\n",
      "train loss:  1.6364728212356567\n",
      "train r2:  0.8853742458425199\n",
      "test loss:  6.773153781890869\n",
      "test r2:  -0.2552764668228009\n",
      "train loss:  1.6364725828170776\n",
      "train r2:  0.8853646411397665\n",
      "test loss:  6.773054599761963\n",
      "test r2:  -0.25524736595854947\n",
      "train loss:  1.636472463607788\n",
      "train r2:  0.8853708685915357\n",
      "test loss:  6.773104667663574\n",
      "test r2:  -0.25526456697086464\n",
      "train loss:  1.636472463607788\n",
      "train r2:  0.8853671603272015\n",
      "test loss:  6.773069381713867\n",
      "test r2:  -0.25525516561392836\n",
      "train loss:  1.636472225189209\n",
      "train r2:  0.8853691655912223\n",
      "test loss:  6.773067951202393\n",
      "test r2:  -0.2552558558489175\n",
      "train loss:  1.636472225189209\n",
      "train r2:  0.88536901646189\n",
      "test loss:  6.77310037612915\n",
      "test r2:  -0.25526774243277606\n",
      "train loss:  1.636472225189209\n",
      "train r2:  0.8853664432933479\n",
      "test loss:  6.773005962371826\n",
      "test r2:  -0.2552403442287263\n",
      "train loss:  1.636472225189209\n",
      "train r2:  0.885372322018682\n",
      "test loss:  6.773134231567383\n",
      "test r2:  -0.2552805864852141\n",
      "train loss:  1.636472225189209\n",
      "train r2:  0.885363695993379\n",
      "test loss:  6.772979736328125\n",
      "test r2:  -0.25523597071549853\n",
      "train loss:  1.6364718675613403\n",
      "train r2:  0.8853732144758547\n",
      "test loss:  6.773097515106201\n",
      "test r2:  -0.2552722217301484\n",
      "train loss:  1.6364718675613403\n",
      "train r2:  0.8853654612896799\n",
      "test loss:  6.773036003112793\n",
      "test r2:  -0.2552554917202623\n",
      "train loss:  1.6364718675613403\n",
      "train r2:  0.8853690009805465\n",
      "test loss:  6.773003101348877\n",
      "test r2:  -0.25524706138263165\n",
      "train loss:  1.6364717483520508\n",
      "train r2:  0.8853708140488785\n",
      "test loss:  6.773098945617676\n",
      "test r2:  -0.2552772298130641\n",
      "train loss:  1.6364718675613403\n",
      "train r2:  0.8853643673067699\n",
      "test loss:  6.772954940795898\n",
      "test r2:  -0.25523564583806957\n",
      "train loss:  1.6364717483520508\n",
      "train r2:  0.8853732400812294\n",
      "test loss:  6.773083209991455\n",
      "test r2:  -0.25527536311861954\n",
      "train loss:  1.6364715099334717\n",
      "train r2:  0.8853647156982747\n",
      "test loss:  6.772985458374023\n",
      "test r2:  -0.2552474505932387\n",
      "train loss:  1.6364715099334717\n",
      "train r2:  0.8853706602174825\n",
      "test loss:  6.773017406463623\n",
      "test r2:  -0.25525860626535146\n",
      "train loss:  1.6364713907241821\n",
      "train r2:  0.8853682590743516\n",
      "test loss:  6.773025989532471\n",
      "test r2:  -0.25526241600610966\n",
      "train loss:  1.6364712715148926\n",
      "train r2:  0.885367460677123\n",
      "test loss:  6.772974967956543\n",
      "test r2:  -0.2552487482104404\n",
      "train loss:  1.6364712715148926\n",
      "train r2:  0.8853703234652274\n",
      "test loss:  6.773027420043945\n",
      "test r2:  -0.25526592265792525\n",
      "train loss:  1.6364712715148926\n",
      "train r2:  0.8853666971664058\n",
      "test loss:  6.7729692459106445\n",
      "test r2:  -0.25524979516378776\n",
      "train loss:  1.6364712715148926\n",
      "train r2:  0.8853701393577698\n",
      "test loss:  6.773008346557617\n",
      "test r2:  -0.25526306858744907\n",
      "train loss:  1.636471152305603\n",
      "train r2:  0.8853672423717237\n",
      "test loss:  6.772965908050537\n",
      "test r2:  -0.25525149016791127\n",
      "train loss:  1.636471152305603\n",
      "train r2:  0.8853697434721495\n",
      "test loss:  6.772996425628662\n",
      "test r2:  -0.2552621095171963\n",
      "train loss:  1.636470913887024\n",
      "train r2:  0.8853674211291349\n",
      "test loss:  6.772961139678955\n",
      "test r2:  -0.2552528755371244\n",
      "train loss:  1.636470913887024\n",
      "train r2:  0.8853694068871057\n",
      "test loss:  6.772974014282227\n",
      "test r2:  -0.2552580356028211\n",
      "train loss:  1.636471152305603\n",
      "train r2:  0.8853682796815199\n",
      "test loss:  6.772972106933594\n",
      "test r2:  -0.2552591804507427\n",
      "train loss:  1.6364707946777344\n",
      "train r2:  0.8853680288090428\n",
      "test loss:  6.772939682006836\n",
      "test r2:  -0.2552506056594228\n",
      "train loss:  1.6364707946777344\n",
      "train r2:  0.8853698817912676\n",
      "test loss:  6.772984504699707\n",
      "test r2:  -0.2552654043549418\n",
      "train loss:  1.6364706754684448\n",
      "train r2:  0.8853666892612149\n",
      "test loss:  6.772918701171875\n",
      "test r2:  -0.2552472473077694\n",
      "train loss:  1.6364706754684448\n",
      "train r2:  0.8853705366609663\n",
      "test loss:  6.772970676422119\n",
      "test r2:  -0.2552640613174102\n",
      "train loss:  1.6364706754684448\n",
      "train r2:  0.8853669536841833\n",
      "test loss:  6.772928237915039\n",
      "test r2:  -0.25525276965466737\n",
      "train loss:  1.6364706754684448\n",
      "train r2:  0.8853693658893877\n",
      "test loss:  6.7729339599609375\n",
      "test r2:  -0.2552558309103383\n",
      "train loss:  1.6364704370498657\n",
      "train r2:  0.8853686730022915\n",
      "test loss:  6.772944450378418\n",
      "test r2:  -0.25526029256473093\n",
      "train loss:  1.6364704370498657\n",
      "train r2:  0.8853677164938886\n",
      "test loss:  6.772907733917236\n",
      "test r2:  -0.25525056068969154\n",
      "train loss:  1.6364704370498657\n",
      "train r2:  0.8853697689729381\n",
      "test loss:  6.7729411125183105\n",
      "test r2:  -0.2552619366921862\n",
      "train loss:  1.6364703178405762\n",
      "train r2:  0.8853673591457436\n",
      "test loss:  6.772902965545654\n",
      "test r2:  -0.25525190879440807\n",
      "train loss:  1.6364703178405762\n",
      "train r2:  0.8853694864971572\n",
      "test loss:  6.772922039031982\n",
      "test r2:  -0.2552590659618543\n",
      "train loss:  1.6364703178405762\n",
      "train r2:  0.8853679401314769\n",
      "test loss:  6.772902011871338\n",
      "test r2:  -0.2552542524432784\n",
      "train loss:  1.636470079421997\n",
      "train r2:  0.8853689468263348\n",
      "test loss:  6.77290678024292\n",
      "test r2:  -0.25525723030135783\n",
      "train loss:  1.6364701986312866\n",
      "train r2:  0.8853682912363732\n",
      "test loss:  6.772895812988281\n",
      "test r2:  -0.2552550473523014\n",
      "train loss:  1.636470079421997\n",
      "train r2:  0.8853687389006325\n",
      "test loss:  6.772894382476807\n",
      "test r2:  -0.2552558828397684\n",
      "train loss:  1.636470079421997\n",
      "train r2:  0.8853685770087327\n",
      "test loss:  6.772893905639648\n",
      "test r2:  -0.25525733808042506\n",
      "train loss:  1.636470079421997\n",
      "train r2:  0.8853682624745667\n",
      "test loss:  6.772875785827637\n",
      "test r2:  -0.25525298096898297\n",
      "train loss:  1.6364697217941284\n",
      "train r2:  0.8853691838822383\n",
      "test loss:  6.772893905639648\n",
      "test r2:  -0.2552597077738892\n",
      "train loss:  1.6364697217941284\n",
      "train r2:  0.885367705753198\n",
      "test loss:  6.772860527038574\n",
      "test r2:  -0.2552511170682492\n",
      "train loss:  1.6364697217941284\n",
      "train r2:  0.8853695435106355\n",
      "test loss:  6.772885322570801\n",
      "test r2:  -0.255259868871049\n",
      "train loss:  1.6364696025848389\n",
      "train r2:  0.8853676600887685\n",
      "test loss:  6.77285623550415\n",
      "test r2:  -0.2552525093029452\n",
      "train loss:  1.6364696025848389\n",
      "train r2:  0.8853692354978422\n",
      "test loss:  6.772867202758789\n",
      "test r2:  -0.25525705368722407\n",
      "train loss:  1.6364696025848389\n",
      "train r2:  0.8853682535544815\n",
      "test loss:  6.772858142852783\n",
      "test r2:  -0.25525551819087644\n",
      "train loss:  1.6364693641662598\n",
      "train r2:  0.8853685440288661\n",
      "test loss:  6.772850036621094\n",
      "test r2:  -0.2552541985639858\n",
      "train loss:  1.6364693641662598\n",
      "train r2:  0.8853688359504066\n",
      "test loss:  6.772854804992676\n",
      "test r2:  -0.25525713288605645\n",
      "train loss:  1.6364692449569702\n",
      "train r2:  0.8853681998305156\n",
      "test loss:  6.772839069366455\n",
      "test r2:  -0.2552534744685666\n",
      "train loss:  1.6364693641662598\n",
      "train r2:  0.8853689764793138\n",
      "test loss:  6.772846698760986\n",
      "test r2:  -0.25525709430663146\n",
      "train loss:  1.6364692449569702\n",
      "train r2:  0.8853681744348568\n",
      "test loss:  6.772829055786133\n",
      "test r2:  -0.2552530507462103\n",
      "train loss:  1.6364691257476807\n",
      "train r2:  0.8853690099312275\n",
      "test loss:  6.772839546203613\n",
      "test r2:  -0.25525757590631826\n",
      "train loss:  1.6364691257476807\n",
      "train r2:  0.8853680435735608\n",
      "test loss:  6.772818088531494\n",
      "test r2:  -0.25525237591349725\n",
      "train loss:  1.6364691257476807\n",
      "train r2:  0.8853691339024332\n",
      "test loss:  6.772830486297607\n",
      "test r2:  -0.2552574259553271\n",
      "train loss:  1.6364690065383911\n",
      "train r2:  0.8853680554545448\n",
      "test loss:  6.7728118896484375\n",
      "test r2:  -0.2552531111509886\n",
      "train loss:  1.636468768119812\n",
      "train r2:  0.8853690035340815\n",
      "test loss:  6.772818088531494\n",
      "test r2:  -0.255256103506051\n",
      "train loss:  1.6364690065383911\n",
      "train r2:  0.885368351579702\n",
      "test loss:  6.772810459136963\n",
      "test r2:  -0.2552551907450362\n",
      "train loss:  1.636468768119812\n",
      "train r2:  0.885368534106438\n",
      "test loss:  6.772799968719482\n",
      "test r2:  -0.25525322727022437\n",
      "train loss:  1.636468768119812\n",
      "train r2:  0.885368934755543\n",
      "test loss:  6.772811412811279\n",
      "test r2:  -0.2552575757547533\n",
      "train loss:  1.636468768119812\n",
      "train r2:  0.8853679783461412\n",
      "test loss:  6.772787094116211\n",
      "test r2:  -0.2552513973446182\n",
      "train loss:  1.636468768119812\n",
      "train r2:  0.8853692826192803\n",
      "test loss:  6.772803783416748\n",
      "test r2:  -0.2552579710361511\n",
      "train loss:  1.6364686489105225\n",
      "train r2:  0.8853679031319323\n",
      "test loss:  6.772780895233154\n",
      "test r2:  -0.2552521680319233\n",
      "train loss:  1.6364686489105225\n",
      "train r2:  0.8853691052252998\n",
      "test loss:  6.772789478302002\n",
      "test r2:  -0.25525611132598347\n",
      "train loss:  1.636468529701233\n",
      "train r2:  0.8853682672295556\n",
      "test loss:  6.77277946472168\n",
      "test r2:  -0.25525394372595067\n",
      "train loss:  1.6364684104919434\n",
      "train r2:  0.885368700679176\n",
      "test loss:  6.7727766036987305\n",
      "test r2:  -0.25525448069190504\n",
      "train loss:  1.6364684104919434\n",
      "train r2:  0.8853685907861271\n",
      "test loss:  6.772773265838623\n",
      "test r2:  -0.2552547031441965\n",
      "train loss:  1.6364684104919434\n",
      "train r2:  0.8853685404684671\n",
      "test loss:  6.772768020629883\n",
      "test r2:  -0.25525439904345526\n",
      "train loss:  1.6364684104919434\n",
      "train r2:  0.8853685714502372\n",
      "test loss:  6.772763252258301\n",
      "test r2:  -0.25525407173689074\n",
      "train loss:  1.6364684104919434\n",
      "train r2:  0.8853686509815655\n",
      "test loss:  6.772761344909668\n",
      "test r2:  -0.25525460415589674\n",
      "train loss:  1.6364681720733643\n",
      "train r2:  0.8853685310703696\n",
      "test loss:  6.772756576538086\n",
      "test r2:  -0.2552545033160467\n",
      "train loss:  1.6364681720733643\n",
      "train r2:  0.885368552093482\n",
      "test loss:  6.772748947143555\n",
      "test r2:  -0.25525320994675993\n",
      "train loss:  1.6364681720733643\n",
      "train r2:  0.8853687987382514\n",
      "test loss:  6.77275276184082\n",
      "test r2:  -0.25525572632642435\n",
      "train loss:  1.6364680528640747\n",
      "train r2:  0.885368249028796\n",
      "test loss:  6.772737503051758\n",
      "test r2:  -0.2552523275356029\n",
      "train loss:  1.6364679336547852\n",
      "train r2:  0.885368953796354\n",
      "test loss:  6.772744655609131\n",
      "test r2:  -0.2552555583228182\n",
      "train loss:  1.6364679336547852\n",
      "train r2:  0.8853682753925615\n",
      "test loss:  6.772732257843018\n",
      "test r2:  -0.2552529594549522\n",
      "train loss:  1.636467695236206\n",
      "train r2:  0.8853688175042291\n",
      "test loss:  6.772733688354492\n",
      "test r2:  -0.25525446725178047\n",
      "train loss:  1.6364679336547852\n",
      "train r2:  0.8853684952705311\n",
      "test loss:  6.772728443145752\n",
      "test r2:  -0.2552541982444705\n",
      "train loss:  1.636467695236206\n",
      "train r2:  0.8853685471678724\n",
      "test loss:  6.772721767425537\n",
      "test r2:  -0.25525323531545596\n",
      "train loss:  1.636467695236206\n",
      "train r2:  0.8853687131606003\n",
      "test loss:  6.772721767425537\n",
      "test r2:  -0.2552544005713939\n",
      "train loss:  1.6364675760269165\n",
      "train r2:  0.8853684652034645\n",
      "test loss:  6.772714138031006\n",
      "test r2:  -0.2552531773766804\n",
      "train loss:  1.6364675760269165\n",
      "train r2:  0.8853687025050007\n",
      "test loss:  6.772714138031006\n",
      "test r2:  -0.2552542112872491\n",
      "train loss:  1.6364675760269165\n",
      "train r2:  0.8853684952281102\n",
      "test loss:  6.772706985473633\n",
      "test r2:  -0.255253395220578\n",
      "train loss:  1.636467456817627\n",
      "train r2:  0.8853686686095452\n",
      "test loss:  6.772705078125\n",
      "test r2:  -0.25525387694315516\n",
      "train loss:  1.6364670991897583\n",
      "train r2:  0.8853685668273479\n",
      "test loss:  6.772700786590576\n",
      "test r2:  -0.25525356383044384\n",
      "train loss:  1.6364673376083374\n",
      "train r2:  0.8853686054174233\n",
      "test loss:  6.772697448730469\n",
      "test r2:  -0.25525382102797645\n",
      "train loss:  1.6364673376083374\n",
      "train r2:  0.8853685626773261\n",
      "test loss:  6.77269172668457\n",
      "test r2:  -0.25525313782642045\n",
      "train loss:  1.6364670991897583\n",
      "train r2:  0.8853687019470825\n",
      "test loss:  6.77269172668457\n",
      "test r2:  -0.25525405754303776\n",
      "train loss:  1.6364670991897583\n",
      "train r2:  0.8853684480349852\n",
      "test loss:  6.7726826667785645\n",
      "test r2:  -0.255252473308317\n",
      "train loss:  1.6364669799804688\n",
      "train r2:  0.8853687743193731\n",
      "test loss:  6.772684097290039\n",
      "test r2:  -0.25525419035490016\n",
      "train loss:  1.6364670991897583\n",
      "train r2:  0.8853684287193531\n",
      "test loss:  6.772677421569824\n",
      "test r2:  -0.2552530088405489\n",
      "train loss:  1.6364669799804688\n",
      "train r2:  0.8853686941386935\n",
      "test loss:  6.7726731300354\n",
      "test r2:  -0.2552530222765772\n",
      "train loss:  1.6364669799804688\n",
      "train r2:  0.8853686378461655\n",
      "test loss:  6.772672653198242\n",
      "test r2:  -0.25525383085512043\n",
      "train loss:  1.6364669799804688\n",
      "train r2:  0.8853684472555285\n",
      "test loss:  6.7726640701293945\n",
      "test r2:  -0.25525225359648385\n",
      "train loss:  1.6364668607711792\n",
      "train r2:  0.8853687625840764\n",
      "test loss:  6.7726664543151855\n",
      "test r2:  -0.2552540352384116\n",
      "train loss:  1.6364668607711792\n",
      "train r2:  0.8853684001378618\n",
      "test loss:  6.772655963897705\n",
      "test r2:  -0.2552520890624863\n",
      "train loss:  1.6364666223526\n",
      "train r2:  0.8853688060437417\n",
      "test loss:  6.772657871246338\n",
      "test r2:  -0.25525386206111533\n",
      "train loss:  1.6364666223526\n",
      "train r2:  0.8853684491970121\n",
      "test loss:  6.772651195526123\n",
      "test r2:  -0.2552527067920791\n",
      "train loss:  1.6364666223526\n",
      "train r2:  0.8853686795010416\n",
      "test loss:  6.772647380828857\n",
      "test r2:  -0.25525270240898457\n",
      "train loss:  1.6364666223526\n",
      "train r2:  0.8853686600932733\n",
      "test loss:  6.772646903991699\n",
      "test r2:  -0.2552534907064985\n",
      "train loss:  1.6364665031433105\n",
      "train r2:  0.8853684780624308\n",
      "test loss:  6.772639274597168\n",
      "test r2:  -0.2552522538709392\n",
      "train loss:  1.636466383934021\n",
      "train r2:  0.8853687142188938\n",
      "test loss:  6.772638320922852\n",
      "test r2:  -0.2552531061862122\n",
      "train loss:  1.6364665031433105\n",
      "train r2:  0.885368552205583\n",
      "test loss:  6.772634506225586\n",
      "test r2:  -0.2552527905624382\n",
      "train loss:  1.636466383934021\n",
      "train r2:  0.8853685993309952\n",
      "test loss:  6.7726287841796875\n",
      "test r2:  -0.25525239613717776\n",
      "train loss:  1.6364662647247314\n",
      "train r2:  0.8853686967789736\n",
      "test loss:  6.772629261016846\n",
      "test r2:  -0.255253292217855\n",
      "train loss:  1.6364662647247314\n",
      "train r2:  0.8853684726749885\n",
      "test loss:  6.772622585296631\n",
      "test r2:  -0.25525235242912236\n",
      "train loss:  1.6364662647247314\n",
      "train r2:  0.8853686832862412\n",
      "test loss:  6.772619247436523\n",
      "test r2:  -0.2552523218252909\n",
      "train loss:  1.6364662647247314\n",
      "train r2:  0.8853686861100764\n",
      "test loss:  6.772621154785156\n",
      "test r2:  -0.2552537524755578\n",
      "train loss:  1.6364659070968628\n",
      "train r2:  0.8853683619838888\n",
      "test loss:  6.772607803344727\n",
      "test r2:  -0.2552509517436561\n",
      "train loss:  1.6364660263061523\n",
      "train r2:  0.8853689571376021\n",
      "test loss:  6.7726149559021\n",
      "test r2:  -0.25525400987381186\n",
      "train loss:  1.6364659070968628\n",
      "train r2:  0.8853682936316091\n",
      "test loss:  6.7726030349731445\n",
      "test r2:  -0.25525139600101543\n",
      "train loss:  1.6364657878875732\n",
      "train r2:  0.8853688584355806\n",
      "test loss:  6.772605895996094\n",
      "test r2:  -0.2552532671809633\n",
      "train loss:  1.6364657878875732\n",
      "train r2:  0.885368450463325\n",
      "test loss:  6.772597789764404\n",
      "test r2:  -0.2552517526046758\n",
      "train loss:  1.6364657878875732\n",
      "train r2:  0.8853687336580844\n",
      "test loss:  6.7725982666015625\n",
      "test r2:  -0.25525288125972545\n",
      "train loss:  1.6364655494689941\n",
      "train r2:  0.8853684984457575\n",
      "test loss:  6.772590160369873\n",
      "test r2:  -0.25525131755591124\n",
      "train loss:  1.6364657878875732\n",
      "train r2:  0.8853688136591337\n",
      "test loss:  6.772595405578613\n",
      "test r2:  -0.2552539725314844\n",
      "train loss:  1.6364655494689941\n",
      "train r2:  0.8853682669816103\n",
      "test loss:  6.772578239440918\n",
      "test r2:  -0.25524978971973855\n",
      "train loss:  1.6364654302597046\n",
      "train r2:  0.8853691284486764\n",
      "test loss:  6.7725911140441895\n",
      "test r2:  -0.25525458990059846\n",
      "train loss:  1.6364655494689941\n",
      "train r2:  0.8853680690271891\n",
      "test loss:  6.772573471069336\n",
      "test r2:  -0.25525023279325265\n",
      "train loss:  1.6364654302597046\n",
      "train r2:  0.8853690497943759\n",
      "test loss:  6.772579669952393\n",
      "test r2:  -0.2552532035482611\n",
      "train loss:  1.636465311050415\n",
      "train r2:  0.8853684062439242\n",
      "test loss:  6.7725725173950195\n",
      "test r2:  -0.255251951326811\n",
      "train loss:  1.636465311050415\n",
      "train r2:  0.8853686552757061\n",
      "test loss:  6.772569179534912\n",
      "test r2:  -0.25525191807264114\n",
      "train loss:  1.6364654302597046\n",
      "train r2:  0.8853686479732582\n",
      "test loss:  6.772567272186279\n",
      "test r2:  -0.2552519766258692\n",
      "train loss:  1.636465311050415\n",
      "train r2:  0.8853686093261386\n",
      "test loss:  6.772563457489014\n",
      "test r2:  -0.25525223964021904\n",
      "train loss:  1.6364651918411255\n",
      "train r2:  0.8853685603837179\n",
      "test loss:  6.772556781768799\n",
      "test r2:  -0.2552509178832263\n",
      "train loss:  1.636465311050415\n",
      "train r2:  0.8853688231579792\n",
      "test loss:  6.772562026977539\n",
      "test r2:  -0.255253576668405\n",
      "train loss:  1.6364651918411255\n",
      "train r2:  0.8853682700420127\n",
      "test loss:  6.772545337677002\n",
      "test r2:  -0.25524942318242916\n",
      "train loss:  1.6364651918411255\n",
      "train r2:  0.8853691115260889\n",
      "test loss:  6.772559642791748\n",
      "test r2:  -0.25525450353724954\n",
      "train loss:  1.6364651918411255\n",
      "train r2:  0.8853680504720788\n",
      "test loss:  6.772538661956787\n",
      "test r2:  -0.25524893388979697\n",
      "train loss:  1.6364648342132568\n",
      "train r2:  0.885369222597281\n",
      "test loss:  6.772552967071533\n",
      "test r2:  -0.2552543932061564\n",
      "train loss:  1.6364648342132568\n",
      "train r2:  0.8853680646097957\n",
      "test loss:  6.7725324630737305\n",
      "test r2:  -0.25524893899794554\n",
      "train loss:  1.6364649534225464\n",
      "train r2:  0.8853691908640039\n",
      "test loss:  6.772548198699951\n",
      "test r2:  -0.2552546681244996\n",
      "train loss:  1.6364648342132568\n",
      "train r2:  0.8853679513652499\n",
      "test loss:  6.77252197265625\n",
      "test r2:  -0.2552475852361695\n",
      "train loss:  1.6364648342132568\n",
      "train r2:  0.8853694811767907\n",
      "test loss:  6.772549629211426\n",
      "test r2:  -0.25525667521315065\n",
      "train loss:  1.6364645957946777\n",
      "train r2:  0.8853675411947715\n",
      "test loss:  6.77250862121582\n",
      "test r2:  -0.25524540128760376\n",
      "train loss:  1.6364645957946777\n",
      "train r2:  0.8853699507668029\n",
      "test loss:  6.7725510597229\n",
      "test r2:  -0.25525905225137047\n",
      "train loss:  1.6364647150039673\n",
      "train r2:  0.8853670059800218\n",
      "test loss:  6.772491455078125\n",
      "test r2:  -0.2552420487691527\n",
      "train loss:  1.6364645957946777\n",
      "train r2:  0.8853706406179938\n",
      "test loss:  6.772558212280273\n",
      "test r2:  -0.25526286732967307\n",
      "train loss:  1.6364643573760986\n",
      "train r2:  0.8853661942080598\n",
      "test loss:  6.772472858428955\n",
      "test r2:  -0.2552379342312736\n",
      "train loss:  1.6364643573760986\n",
      "train r2:  0.8853715246238963\n",
      "test loss:  6.772567272186279\n",
      "test r2:  -0.2552673512026684\n",
      "train loss:  1.6364645957946777\n",
      "train r2:  0.8853652136590516\n",
      "test loss:  6.772447109222412\n",
      "test r2:  -0.25523195807842414\n",
      "train loss:  1.636464238166809\n",
      "train r2:  0.8853727529708655\n",
      "test loss:  6.772587299346924\n",
      "test r2:  -0.25527510987816093\n",
      "train loss:  1.6364645957946777\n",
      "train r2:  0.8853635419206969\n",
      "test loss:  6.772407531738281\n",
      "test r2:  -0.2552218440384999\n",
      "train loss:  1.6364643573760986\n",
      "train r2:  0.8853749169454703\n",
      "test loss:  6.7726216316223145\n",
      "test r2:  -0.2552872285530223\n",
      "train loss:  1.6364645957946777\n",
      "train r2:  0.8853609133848355\n",
      "test loss:  6.772352695465088\n",
      "test r2:  -0.2552069630882714\n",
      "train loss:  1.6364647150039673\n",
      "train r2:  0.8853780575766779\n",
      "test loss:  6.772676467895508\n",
      "test r2:  -0.2553053172566899\n",
      "train loss:  1.6364648342132568\n",
      "train r2:  0.8853570195787615\n",
      "test loss:  6.772270679473877\n",
      "test r2:  -0.25518382936899564\n",
      "train loss:  1.636465311050415\n",
      "train r2:  0.885383026079071\n",
      "test loss:  6.772771835327148\n",
      "test r2:  -0.2553355368792094\n",
      "train loss:  1.6364662647247314\n",
      "train r2:  0.8853505155402418\n",
      "test loss:  6.772134780883789\n",
      "test r2:  -0.2551443625270007\n",
      "train loss:  1.6364673376083374\n",
      "train r2:  0.885391414995007\n",
      "test loss:  6.772934436798096\n",
      "test r2:  -0.25538624102128504\n",
      "train loss:  1.6364691257476807\n",
      "train r2:  0.8853396477076221\n",
      "test loss:  6.771914482116699\n",
      "test r2:  -0.25507950818668435\n",
      "train loss:  1.6364723443984985\n",
      "train r2:  0.8854051918238165\n",
      "test loss:  6.773202419281006\n",
      "test r2:  -0.25546837622406904\n",
      "train loss:  1.6364772319793701\n",
      "train r2:  0.8853219461690339\n",
      "test loss:  6.771563529968262\n",
      "test r2:  -0.2549753220979025\n",
      "train loss:  1.6364854574203491\n",
      "train r2:  0.885427250115831\n",
      "test loss:  6.773637294769287\n",
      "test r2:  -0.25560060042822896\n",
      "train loss:  1.6364984512329102\n",
      "train r2:  0.885293364401548\n",
      "test loss:  6.771001815795898\n",
      "test r2:  -0.2548073748084989\n",
      "train loss:  1.6365200281143188\n",
      "train r2:  0.8854626479630218\n",
      "test loss:  6.774341106414795\n",
      "test r2:  -0.25581359554987326\n",
      "train loss:  1.6365532875061035\n",
      "train r2:  0.8852470440691269\n",
      "test loss:  6.770112991333008\n",
      "test r2:  -0.254540406337896\n",
      "train loss:  1.6366075277328491\n",
      "train r2:  0.8855184263010054\n",
      "test loss:  6.775430202484131\n",
      "test r2:  -0.2561415512301697\n",
      "train loss:  1.6366842985153198\n",
      "train r2:  0.8851750220423739\n",
      "test loss:  6.768832683563232\n",
      "test r2:  -0.25415482213546037\n",
      "train loss:  1.6367982625961304\n",
      "train r2:  0.8855980941060957\n",
      "test loss:  6.7768449783325195\n",
      "test r2:  -0.25656552305020663\n",
      "train loss:  1.636922001838684\n",
      "train r2:  0.885080915610472\n",
      "test loss:  6.767271518707275\n",
      "test r2:  -0.2536871174791495\n",
      "train loss:  1.6370582580566406\n",
      "train r2:  0.8856942122512594\n",
      "test loss:  6.7781147956848145\n",
      "test r2:  -0.25694170432270735\n",
      "train loss:  1.637089490890503\n",
      "train r2:  0.8849979628229939\n",
      "test loss:  6.766315937042236\n",
      "test r2:  -0.25341047666781114\n",
      "train loss:  1.6370298862457275\n",
      "train r2:  0.8857532754628383\n",
      "test loss:  6.777729511260986\n",
      "test r2:  -0.25682000133567007\n",
      "train loss:  1.6368060111999512\n",
      "train r2:  0.8850279095669902\n",
      "test loss:  6.7688751220703125\n",
      "test r2:  -0.2541898549447512\n",
      "train loss:  1.6365808248519897\n",
      "train r2:  0.8855933323979147\n",
      "test loss:  6.773242473602295\n",
      "test r2:  -0.2554886358867763\n",
      "train loss:  1.6364659070968628\n",
      "train r2:  0.8853176915330592\n",
      "test loss:  6.774462699890137\n",
      "test r2:  -0.25585428863016957\n",
      "train loss:  1.6365143060684204\n",
      "train r2:  0.8852388139576362\n",
      "test loss:  6.768537521362305\n",
      "test r2:  -0.25408461623737\n",
      "train loss:  1.636645793914795\n",
      "train r2:  0.8856148888592932\n",
      "test loss:  6.776737689971924\n",
      "test r2:  -0.2565298346610483\n",
      "train loss:  1.636721134185791\n",
      "train r2:  0.8850912873400594\n",
      "test loss:  6.769140243530273\n",
      "test r2:  -0.25425783335007446\n",
      "train loss:  1.636685848236084\n",
      "train r2:  0.8855775431734546\n",
      "test loss:  6.773852348327637\n",
      "test r2:  -0.255684640642716\n",
      "train loss:  1.636565089225769\n",
      "train r2:  0.8852743243486956\n",
      "test loss:  6.772915840148926\n",
      "test r2:  -0.2553854158771023\n",
      "train loss:  1.636475682258606\n",
      "train r2:  0.8853397017544191\n",
      "test loss:  6.770730495452881\n",
      "test r2:  -0.25474911133161493\n",
      "train loss:  1.6364785432815552\n",
      "train r2:  0.885475413657629\n",
      "test loss:  6.774415493011475\n",
      "test r2:  -0.25584857537287586\n",
      "train loss:  1.6365444660186768\n",
      "train r2:  0.885239525305713\n",
      "test loss:  6.770794868469238\n",
      "test r2:  -0.25475250331020605\n",
      "train loss:  1.6365965604782104\n",
      "train r2:  0.8854732779737357\n",
      "test loss:  6.773473739624023\n",
      "test r2:  -0.2555800401999304\n",
      "train loss:  1.6365761756896973\n",
      "train r2:  0.8852964718836438\n",
      "test loss:  6.77183198928833\n",
      "test r2:  -0.25506549406919343\n",
      "train loss:  1.636511206626892\n",
      "train r2:  0.8854075243450535\n",
      "test loss:  6.772662162780762\n",
      "test r2:  -0.25532571163196627\n",
      "train loss:  1.6364651918411255\n",
      "train r2:  0.8853524807305346\n",
      "test loss:  6.772518634796143\n",
      "test r2:  -0.2552882724668779\n",
      "train loss:  1.636475682258606\n",
      "train r2:  0.8853602704631304\n",
      "test loss:  6.771825790405273\n",
      "test r2:  -0.2550633202222268\n",
      "train loss:  1.6365164518356323\n",
      "train r2:  0.8854079777317004\n",
      "test loss:  6.773550033569336\n",
      "test r2:  -0.25559895619017214\n",
      "train loss:  1.6365355253219604\n",
      "train r2:  0.8852929976597982\n",
      "test loss:  6.7709245681762695\n",
      "test r2:  -0.2548019971979383\n",
      "train loss:  1.6365158557891846\n",
      "train r2:  0.8854636914876302\n",
      "test loss:  6.773778915405273\n",
      "test r2:  -0.25565763010494913\n",
      "train loss:  1.6364796161651611\n",
      "train r2:  0.8852812714227792\n",
      "test loss:  6.77170991897583\n",
      "test r2:  -0.2550485838731562\n",
      "train loss:  1.6364630460739136\n",
      "train r2:  0.8854116396605819\n",
      "test loss:  6.772058010101318\n",
      "test r2:  -0.2551431843757528\n",
      "train loss:  1.6364752054214478\n",
      "train r2:  0.8853913583179834\n",
      "test loss:  6.773696422576904\n",
      "test r2:  -0.2556403197282795\n",
      "train loss:  1.6364964246749878\n",
      "train r2:  0.885284694906443\n",
      "test loss:  6.770649433135986\n",
      "test r2:  -0.254728504003483\n",
      "train loss:  1.636501669883728\n",
      "train r2:  0.8854794561087492\n",
      "test loss:  6.77387809753418\n",
      "test r2:  -0.2556919781847453\n",
      "train loss:  1.6364855766296387\n",
      "train r2:  0.8852738307030659\n",
      "test loss:  6.771743297576904\n",
      "test r2:  -0.2550568849955197\n",
      "train loss:  1.6364666223526\n",
      "train r2:  0.8854098109129315\n",
      "test loss:  6.772026538848877\n",
      "test r2:  -0.2551425213241427\n",
      "train loss:  1.636462688446045\n",
      "train r2:  0.8853915618886884\n",
      "test loss:  6.773494243621826\n",
      "test r2:  -0.2555782608724404\n",
      "train loss:  1.6364734172821045\n",
      "train r2:  0.8852983316695386\n",
      "test loss:  6.771078109741211\n",
      "test r2:  -0.2548586019930352\n",
      "train loss:  1.6364833116531372\n",
      "train r2:  0.8854519123314366\n",
      "test loss:  6.773382663726807\n",
      "test r2:  -0.25554899508094175\n",
      "train loss:  1.6364816427230835\n",
      "train r2:  0.8853044229375429\n",
      "test loss:  6.771993637084961\n",
      "test r2:  -0.2551293808884869\n",
      "train loss:  1.6364713907241821\n",
      "train r2:  0.885394288514082\n",
      "test loss:  6.772190570831299\n",
      "test r2:  -0.2551962080023298\n",
      "train loss:  1.6364628076553345\n",
      "train r2:  0.8853800791457749\n",
      "test loss:  6.772915363311768\n",
      "test r2:  -0.25540790429834903\n",
      "train loss:  1.6364631652832031\n",
      "train r2:  0.8853348345529612\n",
      "test loss:  6.771783828735352\n",
      "test r2:  -0.2550709097758097\n",
      "train loss:  1.6364696025848389\n",
      "train r2:  0.8854067754533658\n",
      "test loss:  6.772845268249512\n",
      "test r2:  -0.2553936641934167\n",
      "train loss:  1.6364740133285522\n",
      "train r2:  0.8853376655829848\n",
      "test loss:  6.772071838378906\n",
      "test r2:  -0.25515498449385365\n",
      "train loss:  1.6364717483520508\n",
      "train r2:  0.8853887874833078\n",
      "test loss:  6.772548198699951\n",
      "test r2:  -0.2553052016781723\n",
      "train loss:  1.6364655494689941\n",
      "train r2:  0.8853566994066687\n",
      "test loss:  6.772283554077148\n",
      "test r2:  -0.25522350309305497\n",
      "train loss:  1.6364614963531494\n",
      "train r2:  0.8853742387106748\n",
      "test loss:  6.772348403930664\n",
      "test r2:  -0.2552410747267406\n",
      "train loss:  1.6364628076553345\n",
      "train r2:  0.8853704910662025\n",
      "test loss:  6.772548198699951\n",
      "test r2:  -0.25530700036910914\n",
      "train loss:  1.636466383934021\n",
      "train r2:  0.8853562822962562\n",
      "test loss:  6.7720046043396\n",
      "test r2:  -0.25513870991616994\n",
      "train loss:  1.6364681720733643\n",
      "train r2:  0.885392301946934\n",
      "test loss:  6.7728424072265625\n",
      "test r2:  -0.2553935968617105\n",
      "train loss:  1.6364660263061523\n",
      "train r2:  0.885337778534971\n",
      "test loss:  6.771916389465332\n",
      "test r2:  -0.2551170919365453\n",
      "train loss:  1.6364630460739136\n",
      "train r2:  0.8853969255586133\n",
      "test loss:  6.772597789764404\n",
      "test r2:  -0.2553188784858118\n",
      "train loss:  1.6364611387252808\n",
      "train r2:  0.8853538254141367\n",
      "test loss:  6.772437572479248\n",
      "test r2:  -0.25527479159585575\n",
      "train loss:  1.6364619731903076\n",
      "train r2:  0.8853632408121748\n",
      "test loss:  6.771974563598633\n",
      "test r2:  -0.2551350143488811\n",
      "train loss:  1.6364638805389404\n",
      "train r2:  0.8853930837285926\n",
      "test loss:  6.772891521453857\n",
      "test r2:  -0.255409936530397\n",
      "train loss:  1.6364648342132568\n",
      "train r2:  0.8853343249296338\n",
      "test loss:  6.771865367889404\n",
      "test r2:  -0.2551042444800402\n",
      "train loss:  1.6364636421203613\n",
      "train r2:  0.8853996590482337\n",
      "test loss:  6.772613525390625\n",
      "test r2:  -0.2553280186799487\n",
      "train loss:  1.6364619731903076\n",
      "train r2:  0.8853518648454213\n",
      "test loss:  6.7723774909973145\n",
      "test r2:  -0.25525744152555374\n",
      "train loss:  1.636460781097412\n",
      "train r2:  0.8853669645224602\n",
      "test loss:  6.772082328796387\n",
      "test r2:  -0.25517056957798734\n",
      "train loss:  1.6364611387252808\n",
      "train r2:  0.8853854915230119\n",
      "test loss:  6.7727155685424805\n",
      "test r2:  -0.2553592133812568\n",
      "train loss:  1.6364622116088867\n",
      "train r2:  0.885345169690933\n",
      "test loss:  6.7720184326171875\n",
      "test r2:  -0.2551511833882012\n",
      "train loss:  1.6364625692367554\n",
      "train r2:  0.8853896364923454\n",
      "test loss:  6.772535800933838\n",
      "test r2:  -0.25530789156284084\n",
      "train loss:  1.6364622116088867\n",
      "train r2:  0.885356126387379\n",
      "test loss:  6.772302627563477\n",
      "test r2:  -0.25523592382867544\n",
      "train loss:  1.6364611387252808\n",
      "train r2:  0.8853715370868536\n",
      "test loss:  6.772271633148193\n",
      "test r2:  -0.2552295073263844\n",
      "train loss:  1.636460542678833\n",
      "train r2:  0.885372868249098\n",
      "test loss:  6.772454738616943\n",
      "test r2:  -0.25528398848757394\n",
      "train loss:  1.636460781097412\n",
      "train r2:  0.8853612628619019\n",
      "test loss:  6.772218227386475\n",
      "test r2:  -0.255212811889693\n",
      "train loss:  1.6364611387252808\n",
      "train r2:  0.8853764780838911\n",
      "test loss:  6.772444248199463\n",
      "test r2:  -0.2552832656456381\n",
      "train loss:  1.6364614963531494\n",
      "train r2:  0.8853613917949201\n",
      "test loss:  6.772227764129639\n",
      "test r2:  -0.2552163993174359\n",
      "train loss:  1.6364610195159912\n",
      "train r2:  0.8853756855314248\n",
      "test loss:  6.772437572479248\n",
      "test r2:  -0.2552811237952619\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8853618461096282\n",
      "test loss:  6.772243022918701\n",
      "test r2:  -0.25522304368329674\n",
      "train loss:  1.636460304260254\n",
      "train r2:  0.8853742420269485\n",
      "test loss:  6.77236795425415\n",
      "test r2:  -0.25525996483624236\n",
      "train loss:  1.6364604234695435\n",
      "train r2:  0.8853663929260549\n",
      "test loss:  6.772368907928467\n",
      "test r2:  -0.2552619929883255\n",
      "train loss:  1.6364604234695435\n",
      "train r2:  0.8853659069291531\n",
      "test loss:  6.7722015380859375\n",
      "test r2:  -0.2552112276754539\n",
      "train loss:  1.636460781097412\n",
      "train r2:  0.8853767635090483\n",
      "test loss:  6.772503852844238\n",
      "test r2:  -0.2553026191260688\n",
      "train loss:  1.636460542678833\n",
      "train r2:  0.8853572270705249\n",
      "test loss:  6.7721476554870605\n",
      "test r2:  -0.25519661510169755\n",
      "train loss:  1.6364604234695435\n",
      "train r2:  0.8853798664219715\n",
      "test loss:  6.772435188293457\n",
      "test r2:  -0.2552826312889602\n",
      "train loss:  1.6364600658416748\n",
      "train r2:  0.8853614985199639\n",
      "test loss:  6.7723069190979\n",
      "test r2:  -0.2552449856432497\n",
      "train loss:  1.6364599466323853\n",
      "train r2:  0.8853695342536086\n",
      "test loss:  6.77223539352417\n",
      "test r2:  -0.25522401686547536\n",
      "train loss:  1.6364600658416748\n",
      "train r2:  0.8853740264919557\n",
      "test loss:  6.772463798522949\n",
      "test r2:  -0.2552921966965249\n",
      "train loss:  1.6364600658416748\n",
      "train r2:  0.8853594575378695\n",
      "test loss:  6.772164821624756\n",
      "test r2:  -0.25520348151431094\n",
      "train loss:  1.6364600658416748\n",
      "train r2:  0.8853784040979775\n",
      "test loss:  6.772427558898926\n",
      "test r2:  -0.25528250581366074\n",
      "train loss:  1.6364600658416748\n",
      "train r2:  0.885361537483649\n",
      "test loss:  6.772268772125244\n",
      "test r2:  -0.25523494474365616\n",
      "train loss:  1.6364598274230957\n",
      "train r2:  0.8853716803887902\n",
      "test loss:  6.7722978591918945\n",
      "test r2:  -0.25524460994650155\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.8853696189439093\n",
      "test loss:  6.772366523742676\n",
      "test r2:  -0.25526491703675025\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.8853652763453892\n",
      "test loss:  6.772246837615967\n",
      "test r2:  -0.25522951698967433\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.8853728174738744\n",
      "test loss:  6.772366523742676\n",
      "test r2:  -0.2552663112581761\n",
      "train loss:  1.6364598274230957\n",
      "train r2:  0.8853649776348635\n",
      "test loss:  6.772264003753662\n",
      "test r2:  -0.2552351807261919\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.8853716464946294\n",
      "test loss:  6.772343635559082\n",
      "test r2:  -0.25526000784382186\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.8853662883843554\n",
      "test loss:  6.772274971008301\n",
      "test r2:  -0.2552393756139779\n",
      "train loss:  1.6364593505859375\n",
      "train r2:  0.8853707300774345\n",
      "test loss:  6.7723307609558105\n",
      "test r2:  -0.2552562878336122\n",
      "train loss:  1.6364593505859375\n",
      "train r2:  0.885367127473185\n",
      "test loss:  6.7722930908203125\n",
      "test r2:  -0.25524579605286135\n",
      "train loss:  1.6364593505859375\n",
      "train r2:  0.8853693179246804\n",
      "test loss:  6.77229118347168\n",
      "test r2:  -0.2552447945608072\n",
      "train loss:  1.6364593505859375\n",
      "train r2:  0.8853695417981476\n",
      "test loss:  6.772340774536133\n",
      "test r2:  -0.2552608296412868\n",
      "train loss:  1.6364593505859375\n",
      "train r2:  0.8853661230594108\n",
      "test loss:  6.772240161895752\n",
      "test r2:  -0.255230572651862\n",
      "train loss:  1.636459231376648\n",
      "train r2:  0.8853725757455136\n",
      "test loss:  6.772366523742676\n",
      "test r2:  -0.2552686639190165\n",
      "train loss:  1.636459231376648\n",
      "train r2:  0.8853644493708757\n",
      "test loss:  6.77224588394165\n",
      "test r2:  -0.25523296063962553\n",
      "train loss:  1.6364589929580688\n",
      "train r2:  0.8853720546656406\n",
      "test loss:  6.772320747375488\n",
      "test r2:  -0.25525535674143063\n",
      "train loss:  1.636459231376648\n",
      "train r2:  0.8853672677533856\n",
      "test loss:  6.772310256958008\n",
      "test r2:  -0.25525285181106483\n",
      "train loss:  1.6364589929580688\n",
      "train r2:  0.8853678287583517\n",
      "test loss:  6.772253513336182\n",
      "test r2:  -0.25523621057727763\n",
      "train loss:  1.6364588737487793\n",
      "train r2:  0.8853713970050161\n",
      "test loss:  6.7723493576049805\n",
      "test r2:  -0.25526499224164145\n",
      "train loss:  1.6364588737487793\n",
      "train r2:  0.8853652188500998\n",
      "test loss:  6.772244453430176\n",
      "test r2:  -0.25523403522285415\n",
      "train loss:  1.636459231376648\n",
      "train r2:  0.8853718342215708\n",
      "test loss:  6.772325038909912\n",
      "test r2:  -0.25525834509845535\n",
      "train loss:  1.6364588737487793\n",
      "train r2:  0.8853666332393825\n",
      "test loss:  6.772281169891357\n",
      "test r2:  -0.25524525720258584\n",
      "train loss:  1.6364588737487793\n",
      "train r2:  0.885369440382365\n",
      "test loss:  6.772284984588623\n",
      "test r2:  -0.25524683734095643\n",
      "train loss:  1.6364588737487793\n",
      "train r2:  0.8853690769914117\n",
      "test loss:  6.7723069190979\n",
      "test r2:  -0.25525340912359007\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.8853676865732248\n",
      "test loss:  6.772273540496826\n",
      "test r2:  -0.2552437111335588\n",
      "train loss:  1.6364588737487793\n",
      "train r2:  0.8853697717100462\n",
      "test loss:  6.772302150726318\n",
      "test r2:  -0.2552527484314777\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.8853678335954264\n",
      "test loss:  6.772276401519775\n",
      "test r2:  -0.2552449876463647\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.8853694655022731\n",
      "test loss:  6.772301197052002\n",
      "test r2:  -0.2552530536546189\n",
      "train loss:  1.6364587545394897\n",
      "train r2:  0.8853677810901784\n",
      "test loss:  6.772268295288086\n",
      "test r2:  -0.255243113775115\n",
      "train loss:  1.6364587545394897\n",
      "train r2:  0.8853698700298089\n",
      "test loss:  6.772305488586426\n",
      "test r2:  -0.2552544964669494\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.8853674565475285\n",
      "test loss:  6.7722697257995605\n",
      "test r2:  -0.2552440257373416\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.8853696584394208\n",
      "test loss:  6.772290229797363\n",
      "test r2:  -0.2552503014316947\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.8853683324755848\n",
      "test loss:  6.772289752960205\n",
      "test r2:  -0.2552505927886908\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.8853682917430812\n",
      "test loss:  6.772264003753662\n",
      "test r2:  -0.25524300375944065\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.8853699012706964\n",
      "test loss:  6.77230978012085\n",
      "test r2:  -0.255256694687199\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.8853669616180014\n",
      "test loss:  6.772253036499023\n",
      "test r2:  -0.2552399985623208\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8853705162381873\n",
      "test loss:  6.772302627563477\n",
      "test r2:  -0.25525503265459726\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8853673285613625\n",
      "test loss:  6.772270679473877\n",
      "test r2:  -0.25524566888986566\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.8853693075920225\n",
      "test loss:  6.772276401519775\n",
      "test r2:  -0.25524784315465987\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.8853688491044228\n",
      "test loss:  6.772288799285889\n",
      "test r2:  -0.2552514497615139\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.8853680828071462\n",
      "test loss:  6.772266864776611\n",
      "test r2:  -0.255245056800947\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8853694613881561\n",
      "test loss:  6.7722883224487305\n",
      "test r2:  -0.25525171432838056\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853680506056164\n",
      "test loss:  6.7722697257995605\n",
      "test r2:  -0.25524599567619366\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.8853692364365401\n",
      "test loss:  6.772282600402832\n",
      "test r2:  -0.25525052784106017\n",
      "train loss:  1.636457920074463\n",
      "train r2:  0.8853682786523451\n",
      "test loss:  6.772270202636719\n",
      "test r2:  -0.25524666443401944\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853690966523352\n",
      "test loss:  6.772281169891357\n",
      "test r2:  -0.25525028398533967\n",
      "train loss:  1.636457920074463\n",
      "train r2:  0.8853683041644195\n",
      "test loss:  6.772268295288086\n",
      "test r2:  -0.25524655566363563\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853691329892173\n",
      "test loss:  6.772280693054199\n",
      "test r2:  -0.25525028093355884\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.885368313272395\n",
      "test loss:  6.772270202636719\n",
      "test r2:  -0.2552472257118117\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853689555941903\n",
      "test loss:  6.772273540496826\n",
      "test r2:  -0.2552483434582813\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853687555520924\n",
      "test loss:  6.772279262542725\n",
      "test r2:  -0.2552502429153338\n",
      "train loss:  1.6364576816558838\n",
      "train r2:  0.8853683218180565\n",
      "test loss:  6.772262096405029\n",
      "test r2:  -0.2552450904483665\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853694023749635\n",
      "test loss:  6.772285461425781\n",
      "test r2:  -0.25525234751350223\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853678831259614\n",
      "test loss:  6.772259712219238\n",
      "test r2:  -0.25524477917901267\n",
      "train loss:  1.6364576816558838\n",
      "train r2:  0.8853694765631583\n",
      "test loss:  6.772280693054199\n",
      "test r2:  -0.2552511017478998\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853681509812767\n",
      "test loss:  6.7722673416137695\n",
      "test r2:  -0.25524719012272223\n",
      "train loss:  1.6364576816558838\n",
      "train r2:  0.8853689589886204\n",
      "test loss:  6.772270202636719\n",
      "test r2:  -0.25524814404795904\n",
      "train loss:  1.6364576816558838\n",
      "train r2:  0.885368777993346\n",
      "test loss:  6.772275924682617\n",
      "test r2:  -0.255249900161433\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853684114241239\n",
      "test loss:  6.772263050079346\n",
      "test r2:  -0.255246487778922\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853691538820025\n",
      "test loss:  6.772276401519775\n",
      "test r2:  -0.255250450846064\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853682958827364\n",
      "test loss:  6.77226448059082\n",
      "test r2:  -0.25524684623003613\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853690397885088\n",
      "test loss:  6.772273540496826\n",
      "test r2:  -0.2552495260622616\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853684761776137\n",
      "test loss:  6.772266864776611\n",
      "test r2:  -0.2552474313731641\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853688974241296\n",
      "test loss:  6.772271633148193\n",
      "test r2:  -0.2552492406449731\n",
      "train loss:  1.6364572048187256\n",
      "train r2:  0.8853685546789223\n",
      "test loss:  6.772266864776611\n",
      "test r2:  -0.255247711940374\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853688594989946\n",
      "test loss:  6.772270679473877\n",
      "test r2:  -0.25524890604280914\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.885368618655681\n",
      "test loss:  6.772268772125244\n",
      "test r2:  -0.255248365885798\n",
      "train loss:  1.6364572048187256\n",
      "train r2:  0.8853687170801129\n",
      "test loss:  6.772266864776611\n",
      "test r2:  -0.2552477281086678\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853688514106554\n",
      "test loss:  6.772272109985352\n",
      "test r2:  -0.25524949483578485\n",
      "train loss:  1.6364572048187256\n",
      "train r2:  0.8853685064104164\n",
      "test loss:  6.772264003753662\n",
      "test r2:  -0.25524711415590984\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853689899441631\n",
      "test loss:  6.772272109985352\n",
      "test r2:  -0.2552496029507527\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8853684412685344\n",
      "test loss:  6.772265434265137\n",
      "test r2:  -0.2552474170605168\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.885368918214868\n",
      "test loss:  6.7722697257995605\n",
      "test r2:  -0.2552488561328796\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8853686341286282\n",
      "test loss:  6.772266864776611\n",
      "test r2:  -0.2552482689784439\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8853687696577942\n",
      "test loss:  6.772268772125244\n",
      "test r2:  -0.2552486858639922\n",
      "train loss:  1.6364567279815674\n",
      "train r2:  0.8853686542710102\n",
      "test loss:  6.772265434265137\n",
      "test r2:  -0.2552476553247196\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8853688726323984\n",
      "test loss:  6.772271633148193\n",
      "test r2:  -0.25524954615485873\n",
      "train loss:  1.6364567279815674\n",
      "train r2:  0.885368474360281\n",
      "test loss:  6.7722625732421875\n",
      "test r2:  -0.255247045869754\n",
      "train loss:  1.6364567279815674\n",
      "train r2:  0.8853690308583355\n",
      "test loss:  6.772272109985352\n",
      "test r2:  -0.2552498196067088\n",
      "train loss:  1.6364567279815674\n",
      "train r2:  0.8853684345125679\n",
      "test loss:  6.77226448059082\n",
      "test r2:  -0.25524738024252236\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853689350440297\n",
      "test loss:  6.772268772125244\n",
      "test r2:  -0.2552486510040528\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853686836974463\n",
      "test loss:  6.772270679473877\n",
      "test r2:  -0.2552491817107845\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853685803625062\n",
      "test loss:  6.772264003753662\n",
      "test r2:  -0.25524707166856686\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853690159067287\n",
      "test loss:  6.772273540496826\n",
      "test r2:  -0.2552498801425702\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853684180894665\n",
      "test loss:  6.772265434265137\n",
      "test r2:  -0.2552474162944993\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853689009433411\n",
      "test loss:  6.772268772125244\n",
      "test r2:  -0.2552483725423669\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853687288176506\n",
      "test loss:  6.772270679473877\n",
      "test r2:  -0.2552489635105044\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853685872059291\n",
      "test loss:  6.772266864776611\n",
      "test r2:  -0.25524764526818\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.885368910876136\n",
      "test loss:  6.772272109985352\n",
      "test r2:  -0.25524919905882704\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853685698940323\n",
      "test loss:  6.772268772125244\n",
      "test r2:  -0.25524807504494196\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853688208507668\n",
      "test loss:  6.772270679473877\n",
      "test r2:  -0.25524868309895576\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.885368680985795\n",
      "test loss:  6.7722697257995605\n",
      "test r2:  -0.2552482979928916\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853687643860978\n",
      "test loss:  6.772270202636719\n",
      "test r2:  -0.2552483864617645\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853687326802119\n",
      "test loss:  6.772271633148193\n",
      "test r2:  -0.2552486847497848\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853686790601014\n",
      "test loss:  6.772270202636719\n",
      "test r2:  -0.2552481360477874\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.885368798164064\n",
      "test loss:  6.772272109985352\n",
      "test r2:  -0.2552486993450802\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853686905312596\n",
      "test loss:  6.772271633148193\n",
      "test r2:  -0.25524841328466485\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853687193685297\n",
      "test loss:  6.772271633148193\n",
      "test r2:  -0.2552481670571576\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853687777766734\n",
      "test loss:  6.772273540496826\n",
      "test r2:  -0.25524871238376257\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.885368680551263\n",
      "test loss:  6.772273540496826\n",
      "test r2:  -0.25524866890919906\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853687021288554\n",
      "test loss:  6.772272109985352\n",
      "test r2:  -0.2552480724601449\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853688372002795\n",
      "test loss:  6.772276401519775\n",
      "test r2:  -0.2552493073253599\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853685512951314\n",
      "test loss:  6.772270679473877\n",
      "test r2:  -0.2552474857276332\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853689256509851\n",
      "test loss:  6.772276401519775\n",
      "test r2:  -0.25524901198261496\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853686096946528\n",
      "test loss:  6.772274971008301\n",
      "test r2:  -0.2552484009382656\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853687579866453\n",
      "test loss:  6.772276401519775\n",
      "test r2:  -0.2552486900217874\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853687173655513\n",
      "test loss:  6.772274971008301\n",
      "test r2:  -0.25524820645994906\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853688009503489\n",
      "test loss:  6.77227783203125\n",
      "test r2:  -0.25524879508497444\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853686572267379\n",
      "test loss:  6.772277355194092\n",
      "test r2:  -0.255248472214757\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853687356319817\n",
      "test loss:  6.772275924682617\n",
      "test r2:  -0.2552478262244451\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853688898737956\n",
      "test loss:  6.772282600402832\n",
      "test r2:  -0.2552497299130272\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853684678237186\n",
      "test loss:  6.772273540496826\n",
      "test r2:  -0.2552469645735902\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853690500891254\n",
      "test loss:  6.772284984588623\n",
      "test r2:  -0.2552499894782503\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853684459964587\n",
      "test loss:  6.772277355194092\n",
      "test r2:  -0.25524750640600846\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853689638198622\n",
      "test loss:  6.772282600402832\n",
      "test r2:  -0.25524910360567743\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853686136817431\n",
      "test loss:  6.772281169891357\n",
      "test r2:  -0.25524847301764164\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853687806348404\n",
      "test loss:  6.772281169891357\n",
      "test r2:  -0.25524823201298075\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853688160216916\n",
      "test loss:  6.7722859382629395\n",
      "test r2:  -0.2552494346194387\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853685504794504\n",
      "test loss:  6.772281169891357\n",
      "test r2:  -0.2552478173845216\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853689238941038\n",
      "test loss:  6.7722859382629395\n",
      "test r2:  -0.2552490364460178\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853686599101339\n",
      "test loss:  6.7722859382629395\n",
      "test r2:  -0.25524889241015614\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853686743344958\n",
      "test loss:  6.772282600402832\n",
      "test r2:  -0.2552475818607771\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853689612782498\n",
      "test loss:  6.772291660308838\n",
      "test r2:  -0.25525009173953395\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853684341608266\n",
      "test loss:  6.772282600402832\n",
      "test r2:  -0.25524729315002315\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.885369050098576\n",
      "test loss:  6.772291660308838\n",
      "test r2:  -0.2552497311009687\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.8853685198468983\n",
      "test loss:  6.7722883224487305\n",
      "test r2:  -0.25524830527210574\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.8853688353000679\n",
      "test loss:  6.772288799285889\n",
      "test r2:  -0.2552482808455703\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.885368853821013\n",
      "test loss:  6.772295951843262\n",
      "test r2:  -0.25525015307828003\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853684287781383\n",
      "test loss:  6.772285461425781\n",
      "test r2:  -0.2552467432641805\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.885369186901547\n",
      "test loss:  6.772300720214844\n",
      "test r2:  -0.2552509759203143\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.885368260957478\n",
      "test loss:  6.772286891937256\n",
      "test r2:  -0.2552464580312277\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853692244416116\n",
      "test loss:  6.772301197052002\n",
      "test r2:  -0.2552507762027658\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853683061281382\n",
      "test loss:  6.772288799285889\n",
      "test r2:  -0.2552468094407161\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853691762721732\n",
      "test loss:  6.772302627563477\n",
      "test r2:  -0.2552507553769221\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853683418298525\n",
      "test loss:  6.772291660308838\n",
      "test r2:  -0.255246854639843\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853691665354806\n",
      "test loss:  6.772306442260742\n",
      "test r2:  -0.25525103293331464\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.885368273324251\n",
      "test loss:  6.77229118347168\n",
      "test r2:  -0.25524621549862836\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853693116388712\n",
      "test loss:  6.772311687469482\n",
      "test r2:  -0.25525205042161603\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853680569517167\n",
      "test loss:  6.772289752960205\n",
      "test r2:  -0.2552450807850766\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853695480316033\n",
      "test loss:  6.7723164558410645\n",
      "test r2:  -0.25525302014237883\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853678465120798\n",
      "test loss:  6.772287368774414\n",
      "test r2:  -0.2552439752948865\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853697828429761\n",
      "test loss:  6.7723236083984375\n",
      "test r2:  -0.2552541959013581\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853676012996189\n",
      "test loss:  6.772287368774414\n",
      "test r2:  -0.25524303516615676\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853699952989909\n",
      "test loss:  6.772327899932861\n",
      "test r2:  -0.25525511622423536\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853674343140069\n",
      "test loss:  6.772285461425781\n",
      "test r2:  -0.2552418750716201\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853702395615538\n",
      "test loss:  6.772337436676025\n",
      "test r2:  -0.2552573779215259\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853669282086749\n",
      "test loss:  6.772275924682617\n",
      "test r2:  -0.2552379861279328\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853710592342577\n",
      "test loss:  6.7723588943481445\n",
      "test r2:  -0.2552630328795653\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853657506951541\n",
      "test loss:  6.772254467010498\n",
      "test r2:  -0.25523093165188704\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853726039689888\n",
      "test loss:  6.772390365600586\n",
      "test r2:  -0.2552719032430255\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853638554910302\n",
      "test loss:  6.772221565246582\n",
      "test r2:  -0.2552204129417308\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.885374853900428\n",
      "test loss:  6.772435188293457\n",
      "test r2:  -0.255284549318864\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853611551828883\n",
      "test loss:  6.772172451019287\n",
      "test r2:  -0.25520500352137754\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853781733507973\n",
      "test loss:  6.7725019454956055\n",
      "test r2:  -0.25530404687202357\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.885356993930573\n",
      "test loss:  6.772092819213867\n",
      "test r2:  -0.2551800042464427\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853834887831915\n",
      "test loss:  6.772610664367676\n",
      "test r2:  -0.2553362546949238\n",
      "train loss:  1.6364567279815674\n",
      "train r2:  0.8853500541058567\n",
      "test loss:  6.771955966949463\n",
      "test r2:  -0.2551379063433665\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.8853924588796664\n",
      "test loss:  6.772796154022217\n",
      "test r2:  -0.2553912384823651\n",
      "train loss:  1.6364600658416748\n",
      "train r2:  0.8853382724904403\n",
      "test loss:  6.771723747253418\n",
      "test r2:  -0.255066815846668\n",
      "train loss:  1.6364641189575195\n",
      "train r2:  0.8854075685976824\n",
      "test loss:  6.773103713989258\n",
      "test r2:  -0.2554831301137106\n",
      "train loss:  1.636469841003418\n",
      "train r2:  0.8853184966680505\n",
      "test loss:  6.771336078643799\n",
      "test r2:  -0.254948822497882\n",
      "train loss:  1.6364800930023193\n",
      "train r2:  0.8854325829180638\n",
      "test loss:  6.773609638214111\n",
      "test r2:  -0.2556346743843736\n",
      "train loss:  1.636496901512146\n",
      "train r2:  0.8852857039410985\n",
      "test loss:  6.770698070526123\n",
      "test r2:  -0.2547547913183532\n",
      "train loss:  1.6365246772766113\n",
      "train r2:  0.8854734457295276\n",
      "test loss:  6.7744364738464355\n",
      "test r2:  -0.25588287461188997\n",
      "train loss:  1.636568546295166\n",
      "train r2:  0.8852316023638747\n",
      "test loss:  6.769671440124512\n",
      "test r2:  -0.25444277165240603\n",
      "train loss:  1.6366404294967651\n",
      "train r2:  0.8855384874354877\n",
      "test loss:  6.77571439743042\n",
      "test r2:  -0.25626574767369625\n",
      "train loss:  1.6367411613464355\n",
      "train r2:  0.8851472852974183\n",
      "test loss:  6.7682085037231445\n",
      "test r2:  -0.25399863529919964\n",
      "train loss:  1.6368881464004517\n",
      "train r2:  0.885629890218392\n",
      "test loss:  6.777297496795654\n",
      "test r2:  -0.2567378117784169\n",
      "train loss:  1.637031078338623\n",
      "train r2:  0.885042143164625\n",
      "test loss:  6.766334533691406\n",
      "test r2:  -0.25343594301472727\n",
      "train loss:  1.637168526649475\n",
      "train r2:  0.8857458629257045\n",
      "test loss:  6.778750896453857\n",
      "test r2:  -0.25716169965604796\n",
      "train loss:  1.6371335983276367\n",
      "train r2:  0.8849498233082528\n",
      "test loss:  6.765661239624023\n",
      "test r2:  -0.25324752881597656\n",
      "train loss:  1.6369775533676147\n",
      "train r2:  0.885788321989981\n",
      "test loss:  6.777398586273193\n",
      "test r2:  -0.25674955380208075\n",
      "train loss:  1.6366859674453735\n",
      "train r2:  0.8850443802984712\n",
      "test loss:  6.770104885101318\n",
      "test r2:  -0.25458762372822474\n",
      "train loss:  1.6364836692810059\n",
      "train r2:  0.8855095817147595\n",
      "test loss:  6.771121025085449\n",
      "test r2:  -0.2548837449310639\n",
      "train loss:  1.6364773511886597\n",
      "train r2:  0.8854465318427829\n",
      "test loss:  6.776290416717529\n",
      "test r2:  -0.2564208245793236\n",
      "train loss:  1.6366190910339355\n",
      "train r2:  0.8851157774281803\n",
      "test loss:  6.7674784660339355\n",
      "test r2:  -0.25378707575573145\n",
      "train loss:  1.6367472410202026\n",
      "train r2:  0.8856767060125484\n",
      "test loss:  6.7762770652771\n",
      "test r2:  -0.256422996517391\n",
      "train loss:  1.6367231607437134\n",
      "train r2:  0.8851139044889307\n",
      "test loss:  6.7707366943359375\n",
      "test r2:  -0.2547504261698723\n",
      "train loss:  1.6365935802459717\n",
      "train r2:  0.8854736090075647\n",
      "test loss:  6.7716217041015625\n",
      "test r2:  -0.255044927639021\n",
      "train loss:  1.6364768743515015\n",
      "train r2:  0.8854120056689214\n",
      "test loss:  6.774508476257324\n",
      "test r2:  -0.2558825198188164\n",
      "train loss:  1.6364712715148926\n",
      "train r2:  0.8852332085145882\n",
      "test loss:  6.770083427429199\n",
      "test r2:  -0.25456383793555704\n",
      "train loss:  1.6365491151809692\n",
      "train r2:  0.8855139323914689\n",
      "test loss:  6.773909091949463\n",
      "test r2:  -0.2557277841637293\n",
      "train loss:  1.6366080045700073\n",
      "train r2:  0.8852643100132157\n",
      "test loss:  6.771710395812988\n",
      "test r2:  -0.2550341050575189\n",
      "train loss:  1.6365857124328613\n",
      "train r2:  0.8854132319043018\n",
      "test loss:  6.772486686706543\n",
      "test r2:  -0.25530063169170547\n",
      "train loss:  1.636502981185913\n",
      "train r2:  0.8853570827087811\n",
      "test loss:  6.772386074066162\n",
      "test r2:  -0.25525293641298297\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853680726946318\n",
      "test loss:  6.772284030914307\n",
      "test r2:  -0.2552127427474\n",
      "train loss:  1.6364790201187134\n",
      "train r2:  0.8853764084547429\n",
      "test loss:  6.772777080535889\n",
      "test r2:  -0.25538550323586406\n",
      "train loss:  1.636528730392456\n",
      "train r2:  0.8853386083091339\n",
      "test loss:  6.7714385986328125\n",
      "test r2:  -0.2549546584039937\n",
      "train loss:  1.6365399360656738\n",
      "train r2:  0.8854307887827821\n",
      "test loss:  6.773776531219482\n",
      "test r2:  -0.25567132448593055\n",
      "train loss:  1.636501431465149\n",
      "train r2:  0.8852779312990424\n",
      "test loss:  6.771044731140137\n",
      "test r2:  -0.254853971720584\n",
      "train loss:  1.6364624500274658\n",
      "train r2:  0.8854531567705868\n",
      "test loss:  6.77299165725708\n",
      "test r2:  -0.25542276225166827\n",
      "train loss:  1.6364589929580688\n",
      "train r2:  0.8853317721921375\n",
      "test loss:  6.772935390472412\n",
      "test r2:  -0.2554232119612698\n",
      "train loss:  1.636483907699585\n",
      "train r2:  0.8853312040705196\n",
      "test loss:  6.770797252655029\n",
      "test r2:  -0.25477152523206104\n",
      "train loss:  1.6365028619766235\n",
      "train r2:  0.8854702785776887\n",
      "test loss:  6.774332046508789\n",
      "test r2:  -0.25582975287772847\n",
      "train loss:  1.6364926099777222\n",
      "train r2:  0.8852442111246337\n",
      "test loss:  6.770988464355469\n",
      "test r2:  -0.2548344339371704\n",
      "train loss:  1.6364666223526\n",
      "train r2:  0.8854572713446914\n",
      "test loss:  6.772617816925049\n",
      "test r2:  -0.2553161881259667\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853545991861516\n",
      "test loss:  6.773366928100586\n",
      "test r2:  -0.25554044967274114\n",
      "train loss:  1.6364637613296509\n",
      "train r2:  0.885306524482898\n",
      "test loss:  6.7707743644714355\n",
      "test r2:  -0.25476540483853216\n",
      "train loss:  1.6364798545837402\n",
      "train r2:  0.8854719020207774\n",
      "test loss:  6.773888111114502\n",
      "test r2:  -0.25569416748724083\n",
      "train loss:  1.6364802122116089\n",
      "train r2:  0.8852734211087084\n",
      "test loss:  6.7716779708862305\n",
      "test r2:  -0.25503052329912457\n",
      "train loss:  1.6364665031433105\n",
      "train r2:  0.8854155185919267\n",
      "test loss:  6.772207736968994\n",
      "test r2:  -0.2551950171728783\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853804677330775\n",
      "test loss:  6.773244857788086\n",
      "test r2:  -0.2554967862143005\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853159968817365\n",
      "test loss:  6.771441459655762\n",
      "test r2:  -0.25496047089127183\n",
      "train loss:  1.6364645957946777\n",
      "train r2:  0.8854305100501574\n",
      "test loss:  6.773089408874512\n",
      "test r2:  -0.2554564875469758\n",
      "train loss:  1.6364692449569702\n",
      "train r2:  0.8853244067533995\n",
      "test loss:  6.7721848487854\n",
      "test r2:  -0.2551761653929243\n",
      "train loss:  1.6364649534225464\n",
      "train r2:  0.8853844728542899\n",
      "test loss:  6.772301197052002\n",
      "test r2:  -0.2552211861564837\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8853748613418769\n",
      "test loss:  6.772655010223389\n",
      "test r2:  -0.255319888473696\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853538899674294\n",
      "test loss:  6.772209644317627\n",
      "test r2:  -0.25518484739391867\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8853827463484288\n",
      "test loss:  6.7725934982299805\n",
      "test r2:  -0.25530654979517786\n",
      "train loss:  1.6364617347717285\n",
      "train r2:  0.8853565986633661\n",
      "test loss:  6.772220134735107\n",
      "test r2:  -0.2551838295000788\n",
      "train loss:  1.6364617347717285\n",
      "train r2:  0.8853829028467838\n",
      "test loss:  6.7727155685424805\n",
      "test r2:  -0.25533862153732834\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853498222496796\n",
      "test loss:  6.77212381362915\n",
      "test r2:  -0.2551597014491689\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853881311970125\n",
      "test loss:  6.772605895996094\n",
      "test r2:  -0.25529920879173273\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853583601190238\n",
      "test loss:  6.77253532409668\n",
      "test r2:  -0.2552840235277527\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853615322272321\n",
      "test loss:  6.772037982940674\n",
      "test r2:  -0.2551292756163861\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.885394615440426\n",
      "test loss:  6.772997856140137\n",
      "test r2:  -0.2554179270879786\n",
      "train loss:  1.6364572048187256\n",
      "train r2:  0.8853329256069877\n",
      "test loss:  6.771957874298096\n",
      "test r2:  -0.25510747470605577\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853992872774294\n",
      "test loss:  6.7726287841796875\n",
      "test r2:  -0.25530499801174256\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853571729990155\n",
      "test loss:  6.772636413574219\n",
      "test r2:  -0.25530822816402376\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853564416300375\n",
      "test loss:  6.771978378295898\n",
      "test r2:  -0.2551102031783421\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853987347774915\n",
      "test loss:  6.7729811668396\n",
      "test r2:  -0.2554086072156383\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853349887120069\n",
      "test loss:  6.772091865539551\n",
      "test r2:  -0.25514216495397446\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853919339234716\n",
      "test loss:  6.7725300788879395\n",
      "test r2:  -0.2552735758401141\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.885363901425612\n",
      "test loss:  6.772651195526123\n",
      "test r2:  -0.25530700138910034\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853567761234645\n",
      "test loss:  6.772138595581055\n",
      "test r2:  -0.2551546650604739\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853892630461819\n",
      "test loss:  6.772761821746826\n",
      "test r2:  -0.2553403355444199\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853496257366504\n",
      "test loss:  6.772295951843262\n",
      "test r2:  -0.25519841074085337\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853799585002377\n",
      "test loss:  6.772497177124023\n",
      "test r2:  -0.25526105801690036\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853665515797803\n",
      "test loss:  6.7725324630737305\n",
      "test r2:  -0.2552678561474544\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853651399320456\n",
      "test loss:  6.772390842437744\n",
      "test r2:  -0.25522628691522375\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853740296591595\n",
      "test loss:  6.7725419998168945\n",
      "test r2:  -0.25527166604797036\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853643471677727\n",
      "test loss:  6.772426128387451\n",
      "test r2:  -0.255233369021151\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853725505001658\n",
      "test loss:  6.772549629211426\n",
      "test r2:  -0.25527267525754804\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853640960814828\n",
      "test loss:  6.772388935089111\n",
      "test r2:  -0.25522162660423753\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853750742538289\n",
      "test loss:  6.772592067718506\n",
      "test r2:  -0.25528191643081066\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853621640870608\n",
      "test loss:  6.772426128387451\n",
      "test r2:  -0.25523280840696727\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853726716185512\n",
      "test loss:  6.772471904754639\n",
      "test r2:  -0.2552438856421686\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853703146194405\n",
      "test loss:  6.77261209487915\n",
      "test r2:  -0.25528670126674324\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853611781535785\n",
      "test loss:  6.772320747375488\n",
      "test r2:  -0.25519810922490915\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853801055559389\n",
      "test loss:  6.772670269012451\n",
      "test r2:  -0.25530170083498116\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853580058678355\n",
      "test loss:  6.7724103927612305\n",
      "test r2:  -0.25522366639814753\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853746601022314\n",
      "test loss:  6.772488594055176\n",
      "test r2:  -0.25524582323624045\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853699366288024\n",
      "test loss:  6.772623062133789\n",
      "test r2:  -0.25528520973242474\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853615133734812\n",
      "test loss:  6.772356986999512\n",
      "test r2:  -0.2552049150647939\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853787206914666\n",
      "test loss:  6.772649765014648\n",
      "test r2:  -0.2552915729944536\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853601879121984\n",
      "test loss:  6.772449970245361\n",
      "test r2:  -0.25523072613800335\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853732158595065\n",
      "test loss:  6.772516250610352\n",
      "test r2:  -0.2552503623894804\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.885369017895926\n",
      "test loss:  6.772580146789551\n",
      "test r2:  -0.2552680751506189\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853652616813004\n",
      "test loss:  6.772454738616943\n",
      "test r2:  -0.25522994284213274\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853733974639647\n",
      "test loss:  6.772590160369873\n",
      "test r2:  -0.25526994703513894\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853648759457182\n",
      "test loss:  6.772496223449707\n",
      "test r2:  -0.2552400668361876\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853712330052942\n",
      "test loss:  6.772552490234375\n",
      "test r2:  -0.25525733039157594\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853675603494959\n",
      "test loss:  6.772529602050781\n",
      "test r2:  -0.25524866798342405\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853694095590545\n",
      "test loss:  6.772549629211426\n",
      "test r2:  -0.2552539827272997\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.885368308911084\n",
      "test loss:  6.772541522979736\n",
      "test r2:  -0.25525103129477467\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853689421629208\n",
      "test loss:  6.772538661956787\n",
      "test r2:  -0.2552487171478177\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853694328014434\n",
      "test loss:  6.772580146789551\n",
      "test r2:  -0.25526086005258986\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853668525738576\n",
      "test loss:  6.7725067138671875\n",
      "test r2:  -0.25523762398191097\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853718139270891\n",
      "test loss:  6.772610187530518\n",
      "test r2:  -0.255267609637299\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853654131493309\n",
      "test loss:  6.772520065307617\n",
      "test r2:  -0.2552400656728242\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853713202973373\n",
      "test loss:  6.772575855255127\n",
      "test r2:  -0.2552555249580468\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853680266775903\n",
      "test loss:  6.772587299346924\n",
      "test r2:  -0.2552583467451881\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.885367414024606\n",
      "test loss:  6.772522449493408\n",
      "test r2:  -0.25523804445586173\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853717854963875\n",
      "test loss:  6.7726287841796875\n",
      "test r2:  -0.2552687318938498\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853652231337996\n",
      "test loss:  6.772531509399414\n",
      "test r2:  -0.2552387236757656\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853716483245725\n",
      "test loss:  6.772600173950195\n",
      "test r2:  -0.2552584493997212\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853674389606965\n",
      "test loss:  6.772588729858398\n",
      "test r2:  -0.2552538847057386\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853684490696099\n",
      "test loss:  6.772562026977539\n",
      "test r2:  -0.2552451966831095\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.885370286294773\n",
      "test loss:  6.772619247436523\n",
      "test r2:  -0.2552612608067113\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853668870708684\n",
      "test loss:  6.7725677490234375\n",
      "test r2:  -0.25524497236697896\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853703830638872\n",
      "test loss:  6.772610664367676\n",
      "test r2:  -0.25525714690376655\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853677508566955\n",
      "test loss:  6.772590637207031\n",
      "test r2:  -0.2552499640767836\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853692947738259\n",
      "test loss:  6.7726054191589355\n",
      "test r2:  -0.2552535853813416\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853685469464067\n",
      "test loss:  6.7726030349731445\n",
      "test r2:  -0.2552518397217529\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.88536890703603\n",
      "test loss:  6.772609233856201\n",
      "test r2:  -0.2552527421190023\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853687646942667\n",
      "test loss:  6.772614002227783\n",
      "test r2:  -0.25525346633321533\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853685804166429\n",
      "test loss:  6.772607326507568\n",
      "test r2:  -0.25525008266611837\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853693479993198\n",
      "test loss:  6.772633075714111\n",
      "test r2:  -0.25525715010301586\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853678286240749\n",
      "test loss:  6.772603988647461\n",
      "test r2:  -0.2552471780999346\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853699738591226\n",
      "test loss:  6.772642612457275\n",
      "test r2:  -0.25525781142187\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853676984314814\n",
      "test loss:  6.772619724273682\n",
      "test r2:  -0.2552499592021269\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853693754010223\n",
      "test loss:  6.772631645202637\n",
      "test r2:  -0.255252678474011\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853688427724246\n",
      "test loss:  6.772645473480225\n",
      "test r2:  -0.2552558180396063\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853681440737327\n",
      "test loss:  6.772624492645264\n",
      "test r2:  -0.2552485711948642\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853697392823298\n",
      "test loss:  6.772657871246338\n",
      "test r2:  -0.2552576199789487\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853678072525839\n",
      "test loss:  6.772634506225586\n",
      "test r2:  -0.2552493394858044\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853695629814272\n",
      "test loss:  6.772656440734863\n",
      "test r2:  -0.25525508977410283\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853683466628187\n",
      "test loss:  6.7726521492004395\n",
      "test r2:  -0.25525275194204977\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853688737523226\n",
      "test loss:  6.772653579711914\n",
      "test r2:  -0.25525236988366995\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853689644323066\n",
      "test loss:  6.772665500640869\n",
      "test r2:  -0.25525487417500514\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853684354476636\n",
      "test loss:  6.772656440734863\n",
      "test r2:  -0.2552509333264661\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853692843804167\n",
      "test loss:  6.772676467895508\n",
      "test r2:  -0.25525598282757755\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853681928673425\n",
      "test loss:  6.772662162780762\n",
      "test r2:  -0.25525045179232086\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853694154366816\n",
      "test loss:  6.772684097290039\n",
      "test r2:  -0.25525623082061166\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853681770282753\n",
      "test loss:  6.772670269012451\n",
      "test r2:  -0.255251090728718\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853692908501113\n",
      "test loss:  6.772686958312988\n",
      "test r2:  -0.25525496727275354\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853684447994774\n",
      "test loss:  6.772684097290039\n",
      "test r2:  -0.2552531885720053\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853688433940083\n",
      "test loss:  6.7726850509643555\n",
      "test r2:  -0.25525229340071753\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853690490715466\n",
      "test loss:  6.772700786590576\n",
      "test r2:  -0.2552559472712588\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853682618394321\n",
      "test loss:  6.772686958312988\n",
      "test r2:  -0.2552507481468642\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853694116342842\n",
      "test loss:  6.772709369659424\n",
      "test r2:  -0.2552563405659267\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853682226859136\n",
      "test loss:  6.772697925567627\n",
      "test r2:  -0.25525188828807965\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853691606082675\n",
      "test loss:  6.772711277008057\n",
      "test r2:  -0.2552546421003876\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853685989516431\n",
      "test loss:  6.772711277008057\n",
      "test r2:  -0.2552537460115174\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853687874025282\n",
      "test loss:  6.7727131843566895\n",
      "test r2:  -0.25525320912339367\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853689129175456\n",
      "test loss:  6.772721767425537\n",
      "test r2:  -0.2552547383400363\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853686084174254\n",
      "test loss:  6.7727203369140625\n",
      "test r2:  -0.25525319900950527\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.885368953012305\n",
      "test loss:  6.772728443145752\n",
      "test r2:  -0.2552547758175434\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853686357864408\n",
      "test loss:  6.772728443145752\n",
      "test r2:  -0.25525336641504404\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.885368935963053\n",
      "test loss:  6.7727370262146\n",
      "test r2:  -0.2552549186204036\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853686196970578\n",
      "test loss:  6.772735118865967\n",
      "test r2:  -0.25525306151141836\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853690172384925\n",
      "test loss:  6.772746562957764\n",
      "test r2:  -0.2552555989381293\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853685049001973\n",
      "test loss:  6.772742748260498\n",
      "test r2:  -0.25525299618282715\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853690487055834\n",
      "test loss:  6.77275276184082\n",
      "test r2:  -0.255255067485862\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853686348059586\n",
      "test loss:  6.772754192352295\n",
      "test r2:  -0.2552545321420623\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853687738562719\n",
      "test loss:  6.772755146026611\n",
      "test r2:  -0.25525336702540025\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853689927847065\n",
      "test loss:  6.772767543792725\n",
      "test r2:  -0.25525610783589303\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853684469375064\n",
      "test loss:  6.772760391235352\n",
      "test r2:  -0.2552528862572727\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853691262170847\n",
      "test loss:  6.772773265838623\n",
      "test r2:  -0.2552553578597341\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.885368628536432\n",
      "test loss:  6.7727766036987305\n",
      "test r2:  -0.2552551283043718\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853686574810558\n",
      "test loss:  6.772771835327148\n",
      "test r2:  -0.25525278904678883\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853691849441743\n",
      "test loss:  6.772789478302002\n",
      "test r2:  -0.25525700068864654\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853682881371853\n",
      "test loss:  6.772779941558838\n",
      "test r2:  -0.25525282042483033\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853692028917073\n",
      "test loss:  6.772793769836426\n",
      "test r2:  -0.2552558535918288\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853685858009371\n",
      "test loss:  6.7727952003479\n",
      "test r2:  -0.25525502733343863\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853687625607567\n",
      "test loss:  6.772796154022217\n",
      "test r2:  -0.25525416384741884\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853689549824034\n",
      "test loss:  6.7728047370910645\n",
      "test r2:  -0.25525571227184707\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853686387386057\n",
      "test loss:  6.772806167602539\n",
      "test r2:  -0.25525491799775835\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853688079107248\n",
      "test loss:  6.772807598114014\n",
      "test r2:  -0.2552542548601249\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853689669304852\n",
      "test loss:  6.772820949554443\n",
      "test r2:  -0.25525675313392204\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853684494730202\n",
      "test loss:  6.77281379699707\n",
      "test r2:  -0.255253547498296\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853691196337042\n",
      "test loss:  6.772825717926025\n",
      "test r2:  -0.2552557480493689\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853686701801888\n",
      "test loss:  6.772831439971924\n",
      "test r2:  -0.2552563164548103\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.885368592425095\n",
      "test loss:  6.772824287414551\n",
      "test r2:  -0.2552530920128411\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853692474903903\n",
      "test loss:  6.772843837738037\n",
      "test r2:  -0.25525770464231234\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.885368269536795\n",
      "test loss:  6.772834300994873\n",
      "test r2:  -0.2552535095333235\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853692038381142\n",
      "test loss:  6.772848129272461\n",
      "test r2:  -0.2552565427003217\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853685850622424\n",
      "test loss:  6.772848606109619\n",
      "test r2:  -0.25525544475970485\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853687958598844\n",
      "test loss:  6.772850036621094\n",
      "test r2:  -0.2552545653184015\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853689902941566\n",
      "test loss:  6.772862434387207\n",
      "test r2:  -0.2552570698432288\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853684956488771\n",
      "test loss:  6.772857666015625\n",
      "test r2:  -0.25525458235921783\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853690320412826\n",
      "test loss:  6.772866725921631\n",
      "test r2:  -0.255255974069581\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853687550658561\n",
      "test loss:  6.7728729248046875\n",
      "test r2:  -0.2552565626126795\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853686484160426\n",
      "test loss:  6.772871017456055\n",
      "test r2:  -0.2552547453079279\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853690220335496\n",
      "test loss:  6.772881031036377\n",
      "test r2:  -0.25525665251937113\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853686424934525\n",
      "test loss:  6.772883415222168\n",
      "test r2:  -0.25525590033937595\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853687864673616\n",
      "test loss:  6.772885322570801\n",
      "test r2:  -0.25525529706170613\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853689372777599\n",
      "test loss:  6.7728962898254395\n",
      "test r2:  -0.25525718277140785\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853685562865661\n",
      "test loss:  6.772892951965332\n",
      "test r2:  -0.2552550173670187\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853690374831846\n",
      "test loss:  6.7729034423828125\n",
      "test r2:  -0.2552567185033783\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853686588616058\n",
      "test loss:  6.772905349731445\n",
      "test r2:  -0.2552561718659412\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853687957859124\n",
      "test loss:  6.7729082107543945\n",
      "test r2:  -0.2552558650902834\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.885368901278632\n",
      "test loss:  6.7729172706604\n",
      "test r2:  -0.25525710436726734\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853686395064163\n",
      "test loss:  6.7729172706604\n",
      "test r2:  -0.2552557268835278\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853689169439061\n",
      "test loss:  6.772924423217773\n",
      "test r2:  -0.255256683467296\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.885368747180279\n",
      "test loss:  6.772929668426514\n",
      "test r2:  -0.25525692134644173\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853687156638513\n",
      "test loss:  6.77293062210083\n",
      "test r2:  -0.2552558833067522\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853689200625974\n",
      "test loss:  6.7729387283325195\n",
      "test r2:  -0.25525711041348\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853686817178662\n",
      "test loss:  6.7729411125183105\n",
      "test r2:  -0.2552563542968922\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.885368853691906\n",
      "test loss:  6.772946357727051\n",
      "test r2:  -0.25525689971771337\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853687775811909\n",
      "test loss:  6.772952079772949\n",
      "test r2:  -0.2552570680080639\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853687314137484\n",
      "test loss:  6.772953510284424\n",
      "test r2:  -0.25525617426640235\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853689112666226\n",
      "test loss:  6.77296257019043\n",
      "test r2:  -0.2552573933770548\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853686997174998\n",
      "test loss:  6.7729644775390625\n",
      "test r2:  -0.25525685453087554\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853688174243024\n",
      "test loss:  6.772968769073486\n",
      "test r2:  -0.25525687350516924\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853688367781035\n",
      "test loss:  6.772976398468018\n",
      "test r2:  -0.25525761139709524\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853686738629051\n",
      "test loss:  6.772975444793701\n",
      "test r2:  -0.25525613344627374\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853689926262518\n",
      "test loss:  6.7729878425598145\n",
      "test r2:  -0.25525832848775587\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853685508651915\n",
      "test loss:  6.772985458374023\n",
      "test r2:  -0.25525622571655937\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853689829353883\n",
      "test loss:  6.7729949951171875\n",
      "test r2:  -0.25525775551898033\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853687157871325\n",
      "test loss:  6.772999286651611\n",
      "test r2:  -0.25525778380427777\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853687137870554\n",
      "test loss:  6.772999286651611\n",
      "test r2:  -0.25525634000063047\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853690282725574\n",
      "test loss:  6.773013114929199\n",
      "test r2:  -0.2552591566181779\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.885368455288908\n",
      "test loss:  6.773006916046143\n",
      "test r2:  -0.25525592845262657\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853691416393936\n",
      "test loss:  6.7730207443237305\n",
      "test r2:  -0.25525872523564686\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853685515500935\n",
      "test loss:  6.773019790649414\n",
      "test r2:  -0.25525726709887064\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853689102375423\n",
      "test loss:  6.773025989532471\n",
      "test r2:  -0.25525769805538134\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853687862515167\n",
      "test loss:  6.773031234741211\n",
      "test r2:  -0.25525771746388815\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853688016844241\n",
      "test loss:  6.773037433624268\n",
      "test r2:  -0.25525814060456287\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853687331147126\n",
      "test loss:  6.773038864135742\n",
      "test r2:  -0.2552571463630484\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853689664765468\n",
      "test loss:  6.773051738739014\n",
      "test r2:  -0.2552596285177078\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.885368468704757\n",
      "test loss:  6.773043632507324\n",
      "test r2:  -0.255255736747539\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853692868227376\n",
      "test loss:  6.773065567016602\n",
      "test r2:  -0.2552609716658407\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853681971988052\n",
      "test loss:  6.773050308227539\n",
      "test r2:  -0.2552550993390803\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853694381105871\n",
      "test loss:  6.773074626922607\n",
      "test r2:  -0.2552608867935633\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853682348495414\n",
      "test loss:  6.773065090179443\n",
      "test r2:  -0.2552564384195377\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853691718396862\n",
      "test loss:  6.773078918457031\n",
      "test r2:  -0.25525921939064666\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.88536859618501\n",
      "test loss:  6.773078918457031\n",
      "test r2:  -0.2552577013324615\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.885368954441666\n",
      "test loss:  6.773089408874512\n",
      "test r2:  -0.25525965390688543\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853685318454327\n",
      "test loss:  6.773083686828613\n",
      "test r2:  -0.25525633094769673\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853692415194655\n",
      "test loss:  6.773105144500732\n",
      "test r2:  -0.25526148716282426\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853681751880038\n",
      "test loss:  6.773089408874512\n",
      "test r2:  -0.25525517727623703\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.885369557693061\n",
      "test loss:  6.773118495941162\n",
      "test r2:  -0.2552625942956508\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853679634155973\n",
      "test loss:  6.773097515106201\n",
      "test r2:  -0.25525470018663166\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853696740291238\n",
      "test loss:  6.773129463195801\n",
      "test r2:  -0.25526296419196703\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853679253636956\n",
      "test loss:  6.773107528686523\n",
      "test r2:  -0.2552548103702563\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853696890463276\n",
      "test loss:  6.7731404304504395\n",
      "test r2:  -0.25526337861970516\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.885367880707205\n",
      "test loss:  6.773115158081055\n",
      "test r2:  -0.2552541527176355\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853698392498192\n",
      "test loss:  6.773155689239502\n",
      "test r2:  -0.25526501424313786\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853675397105096\n",
      "test loss:  6.773117542266846\n",
      "test r2:  -0.255252040078332\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853703377953701\n",
      "test loss:  6.77317476272583\n",
      "test r2:  -0.255267605577816\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853670196127708\n",
      "test loss:  6.773120403289795\n",
      "test r2:  -0.25524988477144595\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853708106229945\n",
      "test loss:  6.773193359375\n",
      "test r2:  -0.25527021338801426\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853664748478532\n",
      "test loss:  6.773119926452637\n",
      "test r2:  -0.2552465238841517\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853715721401487\n",
      "test loss:  6.773219585418701\n",
      "test r2:  -0.25527513609480157\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853654490621286\n",
      "test loss:  6.7731099128723145\n",
      "test r2:  -0.25524037315715065\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853728831449399\n",
      "test loss:  6.773254871368408\n",
      "test r2:  -0.2552831300810283\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.885363778033365\n",
      "test loss:  6.773088455200195\n",
      "test r2:  -0.25523106534036843\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853749398414011\n",
      "test loss:  6.773304462432861\n",
      "test r2:  -0.2552948037366092\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853612731048449\n",
      "test loss:  6.7730512619018555\n",
      "test r2:  -0.2552166781477936\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853780211549103\n",
      "test loss:  6.773375034332275\n",
      "test r2:  -0.25531314278461603\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853573953253211\n",
      "test loss:  6.772986888885498\n",
      "test r2:  -0.25519387342687483\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853829018487144\n",
      "test loss:  6.773481369018555\n",
      "test r2:  -0.2553422792830169\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.885351157509098\n",
      "test loss:  6.77287483215332\n",
      "test r2:  -0.25515700473588465\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853907951685105\n",
      "test loss:  6.773648262023926\n",
      "test r2:  -0.2553899075987043\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853409668428437\n",
      "test loss:  6.772685527801514\n",
      "test r2:  -0.25509644353431105\n",
      "train loss:  1.6364588737487793\n",
      "train r2:  0.885403692869842\n",
      "test loss:  6.773913860321045\n",
      "test r2:  -0.25546735107968943\n",
      "train loss:  1.6364638805389404\n",
      "train r2:  0.8853243288179214\n",
      "test loss:  6.772372245788574\n",
      "test r2:  -0.254998123365598\n",
      "train loss:  1.636472225189209\n",
      "train r2:  0.8854245895924466\n",
      "test loss:  6.774341106414795\n",
      "test r2:  -0.2555936009047195\n",
      "train loss:  1.6364848613739014\n",
      "train r2:  0.8852970560339376\n",
      "test loss:  6.771853446960449\n",
      "test r2:  -0.2548372813060178\n",
      "train loss:  1.6365063190460205\n",
      "train r2:  0.8854585055354599\n",
      "test loss:  6.775028705596924\n",
      "test r2:  -0.255798276728495\n",
      "train loss:  1.6365394592285156\n",
      "train r2:  0.885252520721628\n",
      "test loss:  6.771020412445068\n",
      "test r2:  -0.254580712743226\n",
      "train loss:  1.6365928649902344\n",
      "train r2:  0.8855121723879658\n",
      "test loss:  6.776089191436768\n",
      "test r2:  -0.25611510135574256\n",
      "train loss:  1.6366685628890991\n",
      "train r2:  0.885182959476632\n",
      "test loss:  6.769798278808594\n",
      "test r2:  -0.25420601477547633\n",
      "train loss:  1.6367818117141724\n",
      "train r2:  0.8855895852341507\n",
      "test loss:  6.7774882316589355\n",
      "test r2:  -0.25653249056239646\n",
      "train loss:  1.6369050741195679\n",
      "train r2:  0.8850903308762634\n",
      "test loss:  6.768322467803955\n",
      "test r2:  -0.25375678103687416\n",
      "train loss:  1.6370431184768677\n",
      "train r2:  0.8856818206495126\n",
      "test loss:  6.778741836547852\n",
      "test r2:  -0.2569019254412448\n",
      "train loss:  1.637078881263733\n",
      "train r2:  0.8850087386063079\n",
      "test loss:  6.767283916473389\n",
      "test r2:  -0.2534507984733694\n",
      "train loss:  1.6370280981063843\n",
      "train r2:  0.88574701767072\n",
      "test loss:  6.77865743637085\n",
      "test r2:  -0.25686338222378535\n",
      "train loss:  1.6368095874786377\n",
      "train r2:  0.8850207289308468\n",
      "test loss:  6.769317626953125\n",
      "test r2:  -0.25407453489451215\n",
      "train loss:  1.6365872621536255\n",
      "train r2:  0.8856200389544339\n",
      "test loss:  6.774682998657227\n",
      "test r2:  -0.25567314219622084\n",
      "train loss:  1.6364600658416748\n",
      "train r2:  0.8852805810036786\n",
      "test loss:  6.774831771850586\n",
      "test r2:  -0.2557208719866928\n",
      "train loss:  1.6364942789077759\n",
      "train r2:  0.8852698804267384\n",
      "test loss:  6.769571304321289\n",
      "test r2:  -0.2541408211549643\n",
      "train loss:  1.6366195678710938\n",
      "train r2:  0.88560564804606\n",
      "test loss:  6.777866840362549\n",
      "test r2:  -0.2566165550805286\n",
      "train loss:  1.6367024183273315\n",
      "train r2:  0.8850752411577507\n",
      "test loss:  6.7693867683410645\n",
      "test r2:  -0.25407445164848586\n",
      "train loss:  1.6366811990737915\n",
      "train r2:  0.8856190594111562\n",
      "test loss:  6.7754225730896\n",
      "test r2:  -0.2558956078826362\n",
      "train loss:  1.636567234992981\n",
      "train r2:  0.8852315130979342\n",
      "test loss:  6.773529529571533\n",
      "test r2:  -0.2553051367223491\n",
      "train loss:  1.6364779472351074\n",
      "train r2:  0.8853592785668545\n",
      "test loss:  6.771453380584717\n",
      "test r2:  -0.254706751049123\n",
      "train loss:  1.6364679336547852\n",
      "train r2:  0.8854869750869171\n",
      "test loss:  6.775845527648926\n",
      "test r2:  -0.2560047998545938\n",
      "train loss:  1.6365246772766113\n",
      "train r2:  0.8852088449417598\n",
      "test loss:  6.771295547485352\n",
      "test r2:  -0.25463702053655624\n",
      "train loss:  1.6365737915039062\n",
      "train r2:  0.8855006532532229\n",
      "test loss:  6.774476528167725\n",
      "test r2:  -0.25561164087820654\n",
      "train loss:  1.6365630626678467\n",
      "train r2:  0.8852924018923669\n",
      "test loss:  6.773141860961914\n",
      "test r2:  -0.2551772781254613\n",
      "train loss:  1.636509895324707\n",
      "train r2:  0.8853862685393892\n",
      "test loss:  6.773097038269043\n",
      "test r2:  -0.25518828113889547\n",
      "train loss:  1.6364628076553345\n",
      "train r2:  0.8853843343538803\n",
      "test loss:  6.773830890655518\n",
      "test r2:  -0.2553948005250266\n",
      "train loss:  1.6364675760269165\n",
      "train r2:  0.8853402630716346\n",
      "test loss:  6.772906303405762\n",
      "test r2:  -0.2551084570353841\n",
      "train loss:  1.6364984512329102\n",
      "train r2:  0.8854011002353616\n",
      "test loss:  6.7740159034729\n",
      "test r2:  -0.2554598697762538\n",
      "train loss:  1.6365182399749756\n",
      "train r2:  0.8853255576381224\n",
      "test loss:  6.772549629211426\n",
      "test r2:  -0.2549980918400878\n",
      "train loss:  1.6365036964416504\n",
      "train r2:  0.8854246655796956\n",
      "test loss:  6.77439546585083\n",
      "test r2:  -0.255562436049418\n",
      "train loss:  1.6364719867706299\n",
      "train r2:  0.8853043436979223\n",
      "test loss:  6.772608757019043\n",
      "test r2:  -0.25502525513894203\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8854193738506478\n",
      "test loss:  6.773615837097168\n",
      "test r2:  -0.255317597774247\n",
      "train loss:  1.6364648342132568\n",
      "train r2:  0.8853568834751053\n",
      "test loss:  6.7740478515625\n",
      "test r2:  -0.25545479741750876\n",
      "train loss:  1.6364837884902954\n",
      "train r2:  0.8853272272303713\n",
      "test loss:  6.772111415863037\n",
      "test r2:  -0.2548679119153414\n",
      "train loss:  1.6364871263504028\n",
      "train r2:  0.8854526488086184\n",
      "test loss:  6.774943828582764\n",
      "test r2:  -0.2557130661171507\n",
      "train loss:  1.6364742517471313\n",
      "train r2:  0.8852721973357368\n",
      "test loss:  6.772356986999512\n",
      "test r2:  -0.25494087454234093\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8854375010214466\n",
      "test loss:  6.77366304397583\n",
      "test r2:  -0.2553262739133644\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853552682139982\n",
      "test loss:  6.774167060852051\n",
      "test r2:  -0.2554734316771772\n",
      "train loss:  1.6364622116088867\n",
      "train r2:  0.8853236952418503\n",
      "test loss:  6.772186279296875\n",
      "test r2:  -0.2548830596321765\n",
      "train loss:  1.636471152305603\n",
      "train r2:  0.8854497025137891\n",
      "test loss:  6.774767875671387\n",
      "test r2:  -0.2556478544317349\n",
      "train loss:  1.6364715099334717\n",
      "train r2:  0.8852863068217408\n",
      "test loss:  6.772680759429932\n",
      "test r2:  -0.2550250122171893\n",
      "train loss:  1.6364611387252808\n",
      "train r2:  0.885419569150774\n",
      "test loss:  6.773553848266602\n",
      "test r2:  -0.25528696318736754\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853637134447854\n",
      "test loss:  6.774035453796387\n",
      "test r2:  -0.255423527154927\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853346317363805\n",
      "test loss:  6.7726731300354\n",
      "test r2:  -0.25501998337397125\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8854207341159446\n",
      "test loss:  6.774232864379883\n",
      "test r2:  -0.2554817590940117\n",
      "train loss:  1.6364628076553345\n",
      "train r2:  0.8853220026564246\n",
      "test loss:  6.773101806640625\n",
      "test r2:  -0.25513992416445475\n",
      "train loss:  1.636461615562439\n",
      "train r2:  0.8853951185277196\n",
      "test loss:  6.773576736450195\n",
      "test r2:  -0.2552852047021068\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853641085147635\n",
      "test loss:  6.773681640625\n",
      "test r2:  -0.2553099854531502\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853589731517831\n",
      "test loss:  6.7733001708984375\n",
      "test r2:  -0.255196048871418\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853833545720973\n",
      "test loss:  6.773735046386719\n",
      "test r2:  -0.2553266786327526\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853553586059761\n",
      "test loss:  6.7733659744262695\n",
      "test r2:  -0.2552090683787229\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853805275283194\n",
      "test loss:  6.7737345695495605\n",
      "test r2:  -0.255323385335235\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853560845015789\n",
      "test loss:  6.773324489593506\n",
      "test r2:  -0.255196077013343\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.885383340158804\n",
      "test loss:  6.773776531219482\n",
      "test r2:  -0.2553285784502841\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853550712434127\n",
      "test loss:  6.773445129394531\n",
      "test r2:  -0.2552326648708605\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853755730883144\n",
      "test loss:  6.773487567901611\n",
      "test r2:  -0.25523757183127804\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853745725741847\n",
      "test loss:  6.773872375488281\n",
      "test r2:  -0.25535536022328387\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853493338394824\n",
      "test loss:  6.7731475830078125\n",
      "test r2:  -0.25513498787826694\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853965114953095\n",
      "test loss:  6.774000644683838\n",
      "test r2:  -0.2553870825836393\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853426563813236\n",
      "test loss:  6.773364067077637\n",
      "test r2:  -0.2551971457305984\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853832600208145\n",
      "test loss:  6.773565292358398\n",
      "test r2:  -0.25525279687081737\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853713966222294\n",
      "test loss:  6.773887634277344\n",
      "test r2:  -0.2553494667880316\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853507024308941\n",
      "test loss:  6.773210048675537\n",
      "test r2:  -0.25514391841711004\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853946588498501\n",
      "test loss:  6.773991584777832\n",
      "test r2:  -0.2553768794317155\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853448917036655\n",
      "test loss:  6.773408889770508\n",
      "test r2:  -0.2551998542495635\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.885382755856143\n",
      "test loss:  6.773645401000977\n",
      "test r2:  -0.2552706407807004\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853676529902859\n",
      "test loss:  6.773785591125488\n",
      "test r2:  -0.25530895703988343\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853595087414992\n",
      "test loss:  6.773420810699463\n",
      "test r2:  -0.2551993099757204\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853829419358603\n",
      "test loss:  6.773853778839111\n",
      "test r2:  -0.25532751532454645\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.885355557314683\n",
      "test loss:  6.773521900177002\n",
      "test r2:  -0.2552243905877827\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853776147545747\n",
      "test loss:  6.773717880249023\n",
      "test r2:  -0.25528409748735337\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853648483401251\n",
      "test loss:  6.773663520812988\n",
      "test r2:  -0.25526329831485817\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853693661398033\n",
      "test loss:  6.773656845092773\n",
      "test r2:  -0.2552614927789203\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853697554431774\n",
      "test loss:  6.773702621459961\n",
      "test r2:  -0.25527285118759147\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853673169600058\n",
      "test loss:  6.773651599884033\n",
      "test r2:  -0.2552549867795728\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853711715838322\n",
      "test loss:  6.773753643035889\n",
      "test r2:  -0.2552853073607364\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853647027523587\n",
      "test loss:  6.773605823516846\n",
      "test r2:  -0.2552377100789971\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853748666168156\n",
      "test loss:  6.7738142013549805\n",
      "test r2:  -0.25529918634783066\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853617595224821\n",
      "test loss:  6.773617744445801\n",
      "test r2:  -0.2552386665603563\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853747444999216\n",
      "test loss:  6.773759365081787\n",
      "test r2:  -0.255278479470199\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853662402264391\n",
      "test loss:  6.773756504058838\n",
      "test r2:  -0.2552763197720256\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853667086469539\n",
      "test loss:  6.7736310958862305\n",
      "test r2:  -0.25523675138151214\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853751944058604\n",
      "test loss:  6.773874282836914\n",
      "test r2:  -0.25530723248469034\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853601214638418\n",
      "test loss:  6.773616313934326\n",
      "test r2:  -0.25522914054739054\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853768480132382\n",
      "test loss:  6.773827075958252\n",
      "test r2:  -0.255289769064285\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853639344153108\n",
      "test loss:  6.773748397827148\n",
      "test r2:  -0.25526445329715\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853693159183542\n",
      "test loss:  6.773709297180176\n",
      "test r2:  -0.25525107701004157\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853722317563091\n",
      "test loss:  6.773858547210693\n",
      "test r2:  -0.25529367130882097\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853631251597197\n",
      "test loss:  6.773684978485107\n",
      "test r2:  -0.2552400759915301\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853746072847574\n",
      "test loss:  6.773848056793213\n",
      "test r2:  -0.25528706974572235\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.885364577911329\n",
      "test loss:  6.773759365081787\n",
      "test r2:  -0.255258101631888\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853707835054627\n",
      "test loss:  6.773794174194336\n",
      "test r2:  -0.2552673778412331\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853687849601897\n",
      "test loss:  6.773820400238037\n",
      "test r2:  -0.25527276506183094\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853676917083193\n",
      "test loss:  6.773786544799805\n",
      "test r2:  -0.2552608970672092\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.885370233890559\n",
      "test loss:  6.773834705352783\n",
      "test r2:  -0.2552738981696132\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853674834791727\n",
      "test loss:  6.773802280426025\n",
      "test r2:  -0.2552613449375494\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853701780921229\n",
      "test loss:  6.773853778839111\n",
      "test r2:  -0.25527593277344773\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.885367064439951\n",
      "test loss:  6.773800849914551\n",
      "test r2:  -0.255257456133138\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853710600087946\n",
      "test loss:  6.773878574371338\n",
      "test r2:  -0.2552794018412512\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853663739026795\n",
      "test loss:  6.773816108703613\n",
      "test r2:  -0.25525866626049476\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853708190107621\n",
      "test loss:  6.773869037628174\n",
      "test r2:  -0.25527233052101383\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853679074026395\n",
      "test loss:  6.773870468139648\n",
      "test r2:  -0.25527121711667555\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853681623258892\n",
      "test loss:  6.773833751678467\n",
      "test r2:  -0.2552581838702124\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853709928322868\n",
      "test loss:  6.773923873901367\n",
      "test r2:  -0.2552832205038602\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853656587436979\n",
      "test loss:  6.773832321166992\n",
      "test r2:  -0.25525382627949744\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853719560412658\n",
      "test loss:  6.773922920227051\n",
      "test r2:  -0.2552790746493847\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853665769421472\n",
      "test loss:  6.773881912231445\n",
      "test r2:  -0.2552649409389529\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853696235204186\n",
      "test loss:  6.773892402648926\n",
      "test r2:  -0.25526618813827784\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853693690932144\n",
      "test loss:  6.773932933807373\n",
      "test r2:  -0.25527606607687225\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853672788330065\n",
      "test loss:  6.7738847732543945\n",
      "test r2:  -0.25526009838135155\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853706929010403\n",
      "test loss:  6.773947238922119\n",
      "test r2:  -0.25527684450627874\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853671443977892\n",
      "test loss:  6.7739105224609375\n",
      "test r2:  -0.25526383564948407\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853699339600145\n",
      "test loss:  6.773942947387695\n",
      "test r2:  -0.25527183592360836\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853682518524353\n",
      "test loss:  6.773938179016113\n",
      "test r2:  -0.25526828283147185\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853690019756337\n",
      "test loss:  6.773948669433594\n",
      "test r2:  -0.25526960163089996\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853687694105841\n",
      "test loss:  6.77395486831665\n",
      "test r2:  -0.2552696104503416\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853687896704059\n",
      "test loss:  6.773959636688232\n",
      "test r2:  -0.2552688299809527\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853689629663373\n",
      "test loss:  6.773974418640137\n",
      "test r2:  -0.25527165486083825\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853683803135137\n",
      "test loss:  6.773963451385498\n",
      "test r2:  -0.2552659800764645\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.885369613550375\n",
      "test loss:  6.773999214172363\n",
      "test r2:  -0.25527512345346515\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853676478712007\n",
      "test loss:  6.773967266082764\n",
      "test r2:  -0.25526343655028816\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853701806586945\n",
      "test loss:  6.774015426635742\n",
      "test r2:  -0.25527618353561454\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853674997695632\n",
      "test loss:  6.773987293243408\n",
      "test r2:  -0.2552657981002082\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853697163762584\n",
      "test loss:  6.774013042449951\n",
      "test r2:  -0.2552715822939964\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853685023329063\n",
      "test loss:  6.774019241333008\n",
      "test r2:  -0.2552713593829139\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853685652551262\n",
      "test loss:  6.774011611938477\n",
      "test r2:  -0.25526727126649296\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853694398055278\n",
      "test loss:  6.774042129516602\n",
      "test r2:  -0.25527427165842864\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853679858192378\n",
      "test loss:  6.774023532867432\n",
      "test r2:  -0.25526675397121146\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853696134876735\n",
      "test loss:  6.774052619934082\n",
      "test r2:  -0.25527346009364615\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853681998029322\n",
      "test loss:  6.774044990539551\n",
      "test r2:  -0.25526930094651457\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853691159346747\n",
      "test loss:  6.774057388305664\n",
      "test r2:  -0.255271005871998\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853687543600128\n",
      "test loss:  6.774064540863037\n",
      "test r2:  -0.25527137537096833\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853686751813638\n",
      "test loss:  6.774067401885986\n",
      "test r2:  -0.2552698907799633\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853690255178817\n",
      "test loss:  6.774081230163574\n",
      "test r2:  -0.25527241927663114\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853685220976619\n",
      "test loss:  6.774080276489258\n",
      "test r2:  -0.2552697387357372\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853691258864544\n",
      "test loss:  6.774095058441162\n",
      "test r2:  -0.25527284536258166\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853684632056105\n",
      "test loss:  6.774093151092529\n",
      "test r2:  -0.2552694457811646\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853691916394293\n",
      "test loss:  6.774111747741699\n",
      "test r2:  -0.25527361633663115\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.885368338360816\n",
      "test loss:  6.774104118347168\n",
      "test r2:  -0.2552689159387629\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853693620091355\n",
      "test loss:  6.774127006530762\n",
      "test r2:  -0.2552744121755255\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853682084424084\n",
      "test loss:  6.774117946624756\n",
      "test r2:  -0.2552690844134491\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853693767420523\n",
      "test loss:  6.774136543273926\n",
      "test r2:  -0.25527370599344534\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853684020361183\n",
      "test loss:  6.774137496948242\n",
      "test r2:  -0.2552705948524232\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853690479658662\n",
      "test loss:  6.774146556854248\n",
      "test r2:  -0.25527275406722727\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853686123360079\n",
      "test loss:  6.774151802062988\n",
      "test r2:  -0.2552709115248628\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853690449064843\n",
      "test loss:  6.774162292480469\n",
      "test r2:  -0.2552737483660905\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853684276305296\n",
      "test loss:  6.774162292480469\n",
      "test r2:  -0.25526968435668973\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853693414943963\n",
      "test loss:  6.774180889129639\n",
      "test r2:  -0.2552757592438655\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853680157182927\n",
      "test loss:  6.774169445037842\n",
      "test r2:  -0.2552675186327855\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.885369840003964\n",
      "test loss:  6.774202346801758\n",
      "test r2:  -0.2552789404160887\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853673429475793\n",
      "test loss:  6.774171829223633\n",
      "test r2:  -0.25526399913071973\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.885370590699416\n",
      "test loss:  6.774227619171143\n",
      "test r2:  -0.2552833110004262\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853664502622731\n",
      "test loss:  6.774172782897949\n",
      "test r2:  -0.25525990571362156\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853714914628723\n",
      "test loss:  6.774252414703369\n",
      "test r2:  -0.25528818719725455\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853654120325656\n",
      "test loss:  6.774169445037842\n",
      "test r2:  -0.2552549496625447\n",
      "train loss:  1.636459231376648\n",
      "train r2:  0.8853725407678514\n",
      "test loss:  6.774280071258545\n",
      "test r2:  -0.25529385765588275\n",
      "train loss:  1.6364567279815674\n",
      "train r2:  0.8853641873412005\n",
      "test loss:  6.77415657043457\n",
      "test r2:  -0.2552485436059464\n",
      "train loss:  1.6364589929580688\n",
      "train r2:  0.8853739240182659\n",
      "test loss:  6.774313449859619\n",
      "test r2:  -0.2553006296476268\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853627981731742\n",
      "test loss:  6.774144172668457\n",
      "test r2:  -0.25524192319144445\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853753974722102\n",
      "test loss:  6.774345397949219\n",
      "test r2:  -0.2553062100316128\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.885361683051073\n",
      "test loss:  6.774145126342773\n",
      "test r2:  -0.2552387038412385\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853761989706921\n",
      "test loss:  6.7743682861328125\n",
      "test r2:  -0.25530742586518507\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853614903571044\n",
      "test loss:  6.774166584014893\n",
      "test r2:  -0.2552401983454107\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853759406337633\n",
      "test loss:  6.774380683898926\n",
      "test r2:  -0.25530465485230325\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853621649702987\n",
      "test loss:  6.774203300476074\n",
      "test r2:  -0.25524557032348993\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.885374852322287\n",
      "test loss:  6.7743821144104\n",
      "test r2:  -0.2552983327012437\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853635710846298\n",
      "test loss:  6.774251937866211\n",
      "test r2:  -0.25525406296250885\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853731047713935\n",
      "test loss:  6.774376392364502\n",
      "test r2:  -0.2552903934504467\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853653552414236\n",
      "test loss:  6.774299144744873\n",
      "test r2:  -0.25526266449480217\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853713264919257\n",
      "test loss:  6.774368762969971\n",
      "test r2:  -0.2552827987887152\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853670067391213\n",
      "test loss:  6.7743377685546875\n",
      "test r2:  -0.2552699434385437\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853697680862843\n",
      "test loss:  6.774362564086914\n",
      "test r2:  -0.2552769042597376\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853682922347647\n",
      "test loss:  6.77436637878418\n",
      "test r2:  -0.2552749750672796\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.885368760691074\n",
      "test loss:  6.7743611335754395\n",
      "test r2:  -0.25527337247271786\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853691140132713\n",
      "test loss:  6.77438497543335\n",
      "test r2:  -0.2552775816239947\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853681999280739\n",
      "test loss:  6.774363994598389\n",
      "test r2:  -0.25527170404571375\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853694925875724\n",
      "test loss:  6.774396896362305\n",
      "test r2:  -0.2552782233786808\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.885368120506535\n",
      "test loss:  6.774376392364502\n",
      "test r2:  -0.2552727587534518\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853692511308878\n",
      "test loss:  6.774397373199463\n",
      "test r2:  -0.2552749920056874\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853688482881465\n",
      "test loss:  6.774405002593994\n",
      "test r2:  -0.25527839909571415\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853680811687032\n",
      "test loss:  6.774389266967773\n",
      "test r2:  -0.25526853196738775\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853702346356161\n",
      "test loss:  6.774439811706543\n",
      "test r2:  -0.25528553098048756\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853665630323118\n",
      "test loss:  6.774380207061768\n",
      "test r2:  -0.2552611837912335\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853718371241753\n",
      "test loss:  6.774482250213623\n",
      "test r2:  -0.2552946523600883\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853646473408148\n",
      "test loss:  6.7743635177612305\n",
      "test r2:  -0.25525134791805804\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853739572272306\n",
      "test loss:  6.774531841278076\n",
      "test r2:  -0.2553063141813139\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853621802259126\n",
      "test loss:  6.774334907531738\n",
      "test r2:  -0.2552385388607388\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.885376708668951\n",
      "test loss:  6.774592876434326\n",
      "test r2:  -0.25532103494377245\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853590624894827\n",
      "test loss:  6.774293422698975\n",
      "test r2:  -0.25522247433979106\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8853801501534094\n",
      "test loss:  6.774662971496582\n",
      "test r2:  -0.2553385281036793\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853553452841161\n",
      "test loss:  6.774243354797363\n",
      "test r2:  -0.2552040005996974\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853841804820525\n",
      "test loss:  6.774742126464844\n",
      "test r2:  -0.25535805714957815\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853512350936673\n",
      "test loss:  6.7741899490356445\n",
      "test r2:  -0.25518406605200705\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853884722380396\n",
      "test loss:  6.774827480316162\n",
      "test r2:  -0.25537888613940574\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853467795203483\n",
      "test loss:  6.774135112762451\n",
      "test r2:  -0.2551629450538637\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.885393034541651\n",
      "test loss:  6.774919033050537\n",
      "test r2:  -0.25540114892959376\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853420988406978\n",
      "test loss:  6.7740797996521\n",
      "test r2:  -0.2551409401985516\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853977716171446\n",
      "test loss:  6.775014877319336\n",
      "test r2:  -0.2554245291344468\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.8853371038599621\n",
      "test loss:  6.77401876449585\n",
      "test r2:  -0.2551171566793584\n",
      "train loss:  1.636459469795227\n",
      "train r2:  0.8854028951565174\n",
      "test loss:  6.775115966796875\n",
      "test r2:  -0.2554501719910398\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8853316090277514\n",
      "test loss:  6.773947238922119\n",
      "test r2:  -0.2550902382316378\n",
      "train loss:  1.6364630460739136\n",
      "train r2:  0.8854086282781377\n",
      "test loss:  6.775228977203369\n",
      "test r2:  -0.25548033139311666\n",
      "train loss:  1.6364647150039673\n",
      "train r2:  0.8853251754282772\n",
      "test loss:  6.7738542556762695\n",
      "test r2:  -0.2550576316864057\n",
      "train loss:  1.6364680528640747\n",
      "train r2:  0.8854156016464377\n",
      "test loss:  6.77536153793335\n",
      "test r2:  -0.25551708148248276\n",
      "train loss:  1.6364707946777344\n",
      "train r2:  0.8853172551579466\n",
      "test loss:  6.773733615875244\n",
      "test r2:  -0.2550170415883506\n",
      "train loss:  1.6364758014678955\n",
      "train r2:  0.8854242022812377\n",
      "test loss:  6.7755208015441895\n",
      "test r2:  -0.25556289390256337\n",
      "train loss:  1.636479377746582\n",
      "train r2:  0.88530735658537\n",
      "test loss:  6.773571968078613\n",
      "test r2:  -0.25496513140707555\n",
      "train loss:  1.636486530303955\n",
      "train r2:  0.8854351565593463\n",
      "test loss:  6.775721549987793\n",
      "test r2:  -0.2556215028000719\n",
      "train loss:  1.6364905834197998\n",
      "train r2:  0.8852946974527299\n",
      "test loss:  6.773366928100586\n",
      "test r2:  -0.25490047624358936\n",
      "train loss:  1.6364996433258057\n",
      "train r2:  0.885448826848378\n",
      "test loss:  6.775960922241211\n",
      "test r2:  -0.2556912885068596\n",
      "train loss:  1.636505126953125\n",
      "train r2:  0.8852795664200154\n",
      "test loss:  6.773131847381592\n",
      "test r2:  -0.2548270296655981\n",
      "train loss:  1.6365153789520264\n",
      "train r2:  0.8854643501423451\n",
      "test loss:  6.776219367980957\n",
      "test r2:  -0.25576622839698526\n",
      "train loss:  1.6365221738815308\n",
      "train r2:  0.8852633551955104\n",
      "test loss:  6.7729034423828125\n",
      "test r2:  -0.25475456143528286\n",
      "train loss:  1.6365324258804321\n",
      "train r2:  0.8854796178498984\n",
      "test loss:  6.776455402374268\n",
      "test r2:  -0.25583280704261724\n",
      "train loss:  1.6365387439727783\n",
      "train r2:  0.8852489097585621\n",
      "test loss:  6.772736072540283\n",
      "test r2:  -0.25469966477311146\n",
      "train loss:  1.6365466117858887\n",
      "train r2:  0.8854911847610069\n",
      "test loss:  6.776598930358887\n",
      "test r2:  -0.2558708900802047\n",
      "train loss:  1.6365478038787842\n",
      "train r2:  0.8852406745327435\n",
      "test loss:  6.772707939147949\n",
      "test r2:  -0.25468602056422607\n",
      "train loss:  1.6365485191345215\n",
      "train r2:  0.8854941123089386\n",
      "test loss:  6.776568412780762\n",
      "test r2:  -0.25585593200799295\n",
      "train loss:  1.6365406513214111\n",
      "train r2:  0.8852440372154222\n",
      "test loss:  6.772888660430908\n",
      "test r2:  -0.2547358542237159\n",
      "train loss:  1.6365317106246948\n",
      "train r2:  0.885483769417654\n",
      "test loss:  6.776300430297852\n",
      "test r2:  -0.2557701845535847\n",
      "train loss:  1.636515498161316\n",
      "train r2:  0.8852627775313676\n",
      "test loss:  6.773304462432861\n",
      "test r2:  -0.25485720017287994\n",
      "train loss:  1.6365007162094116\n",
      "train r2:  0.8854582837657414\n",
      "test loss:  6.775813579559326\n",
      "test r2:  -0.2556188953790268\n",
      "train loss:  1.6364833116531372\n",
      "train r2:  0.8852956264595905\n",
      "test loss:  6.773889541625977\n",
      "test r2:  -0.25503069471908657\n",
      "train loss:  1.6364706754684448\n",
      "train r2:  0.885421642283723\n",
      "test loss:  6.775213241577148\n",
      "test r2:  -0.2554342986836178\n",
      "train loss:  1.6364598274230957\n",
      "train r2:  0.8853355078559408\n",
      "test loss:  6.77450704574585\n",
      "test r2:  -0.25521512062537166\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853824920056438\n",
      "test loss:  6.7746500968933105\n",
      "test r2:  -0.25526095405153537\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853727144811433\n",
      "test loss:  6.775022983551025\n",
      "test r2:  -0.25536918895225913\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853495881874787\n",
      "test loss:  6.774233818054199\n",
      "test r2:  -0.2551313669669584\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8854003693664464\n",
      "test loss:  6.77537202835083\n",
      "test r2:  -0.25547235933874823\n",
      "train loss:  1.636459469795227\n",
      "train r2:  0.8853274253144744\n",
      "test loss:  6.773993968963623\n",
      "test r2:  -0.2550548035908855\n",
      "train loss:  1.6364630460739136\n",
      "train r2:  0.8854166879415563\n",
      "test loss:  6.775550365447998\n",
      "test r2:  -0.2555239691264788\n",
      "train loss:  1.6364655494689941\n",
      "train r2:  0.8853163295351588\n",
      "test loss:  6.773916721343994\n",
      "test r2:  -0.2550270215137729\n",
      "train loss:  1.6364669799804688\n",
      "train r2:  0.885422608759782\n",
      "test loss:  6.775584697723389\n",
      "test r2:  -0.25553161127310053\n",
      "train loss:  1.6364670991897583\n",
      "train r2:  0.8853147180514646\n",
      "test loss:  6.773965835571289\n",
      "test r2:  -0.2550374886795561\n",
      "train loss:  1.6364673376083374\n",
      "train r2:  0.8854204213569975\n",
      "test loss:  6.775510787963867\n",
      "test r2:  -0.25550658325407705\n",
      "train loss:  1.6364657878875732\n",
      "train r2:  0.8853201071247095\n",
      "test loss:  6.774106025695801\n",
      "test r2:  -0.2550762941904079\n",
      "train loss:  1.636465311050415\n",
      "train r2:  0.8854122017601608\n",
      "test loss:  6.775353908538818\n",
      "test r2:  -0.25545739646561416\n",
      "train loss:  1.6364624500274658\n",
      "train r2:  0.8853306779738274\n",
      "test loss:  6.774301052093506\n",
      "test r2:  -0.2551330354226369\n",
      "train loss:  1.6364620923995972\n",
      "train r2:  0.8854001138302652\n",
      "test loss:  6.775156021118164\n",
      "test r2:  -0.25539705124409884\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.8853436873155555\n",
      "test loss:  6.774500846862793\n",
      "test r2:  -0.25519338457255203\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853872842678303\n",
      "test loss:  6.774966239929199\n",
      "test r2:  -0.2553390492167589\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853561326025533\n",
      "test loss:  6.7746734619140625\n",
      "test r2:  -0.2552459489245502\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853760899999331\n",
      "test loss:  6.774816513061523\n",
      "test r2:  -0.2552927147004749\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853661070897166\n",
      "test loss:  6.774801731109619\n",
      "test r2:  -0.25528503673536806\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853677628287847\n",
      "test loss:  6.774714469909668\n",
      "test r2:  -0.25526014455950596\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853731260531468\n",
      "test loss:  6.774893283843994\n",
      "test r2:  -0.25531233885543014\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853619361326784\n",
      "test loss:  6.774648666381836\n",
      "test r2:  -0.2552375404655254\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853779789426232\n",
      "test loss:  6.774961948394775\n",
      "test r2:  -0.25533209172589766\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853577332730889\n",
      "test loss:  6.774600028991699\n",
      "test r2:  -0.2552209675383761\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853815294831714\n",
      "test loss:  6.775012016296387\n",
      "test r2:  -0.2553468387500566\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853545976052262\n",
      "test loss:  6.774560451507568\n",
      "test r2:  -0.2552083547617674\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853841890105301\n",
      "test loss:  6.775045871734619\n",
      "test r2:  -0.25535835503206017\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853520942748295\n",
      "test loss:  6.774520397186279\n",
      "test r2:  -0.25519776937941696\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853864205824284\n",
      "test loss:  6.775064468383789\n",
      "test r2:  -0.25536796924763583\n",
      "train loss:  1.6364543437957764\n",
      "train r2:  0.8853499736976512\n",
      "test loss:  6.77447509765625\n",
      "test r2:  -0.2551885182888909\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853883649444412\n",
      "test loss:  6.77507209777832\n",
      "test r2:  -0.2553767393037716\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853480118775112\n",
      "test loss:  6.774415969848633\n",
      "test r2:  -0.25517818268148695\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8853904692577877\n",
      "test loss:  6.775075912475586\n",
      "test r2:  -0.2553872602423424\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853456944368431\n",
      "test loss:  6.7743377685546875\n",
      "test r2:  -0.25516501929602975\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853932223497608\n",
      "test loss:  6.775084018707275\n",
      "test r2:  -0.2554021816604135\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853424081828852\n",
      "test loss:  6.774224758148193\n",
      "test r2:  -0.25514540806915553\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.8853972367126859\n",
      "test loss:  6.7751007080078125\n",
      "test r2:  -0.255423315201581\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853377129950522\n",
      "test loss:  6.774075031280518\n",
      "test r2:  -0.2551197216335419\n",
      "train loss:  1.6364589929580688\n",
      "train r2:  0.8854025572393223\n",
      "test loss:  6.775113105773926\n",
      "test r2:  -0.2554497189080942\n",
      "train loss:  1.6364593505859375\n",
      "train r2:  0.8853318217565227\n",
      "test loss:  6.773881435394287\n",
      "test r2:  -0.25508891289443514\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8854088657081283\n",
      "test loss:  6.775103569030762\n",
      "test r2:  -0.2554803659089626\n",
      "train loss:  1.6364619731903076\n",
      "train r2:  0.8853249454793176\n",
      "test loss:  6.773623466491699\n",
      "test r2:  -0.255053005618858\n",
      "train loss:  1.6364641189575195\n",
      "train r2:  0.8854161608368822\n",
      "test loss:  6.775045871734619\n",
      "test r2:  -0.2555157443191174\n",
      "train loss:  1.6364660263061523\n",
      "train r2:  0.8853168387810337\n",
      "test loss:  6.773255825042725\n",
      "test r2:  -0.255009102775863\n",
      "train loss:  1.6364693641662598\n",
      "train r2:  0.8854248431561922\n",
      "test loss:  6.774890422821045\n",
      "test r2:  -0.25555750513968967\n",
      "train loss:  1.636472463607788\n",
      "train r2:  0.8853070300435569\n",
      "test loss:  6.772687911987305\n",
      "test r2:  -0.2549540505240746\n",
      "train loss:  1.6364772319793701\n",
      "train r2:  0.8854354486858611\n",
      "test loss:  6.7745361328125\n",
      "test r2:  -0.25560721354917937\n",
      "train loss:  1.6364818811416626\n",
      "train r2:  0.8852948912658339\n",
      "test loss:  6.771759510040283\n",
      "test r2:  -0.2548832394240541\n",
      "train loss:  1.636488914489746\n",
      "train r2:  0.8854485618171124\n",
      "test loss:  6.773818492889404\n",
      "test r2:  -0.2556639567230785\n",
      "train loss:  1.6364954710006714\n",
      "train r2:  0.8852801190074183\n",
      "test loss:  6.770541191101074\n",
      "test r2:  -0.25479795377762526\n",
      "train loss:  1.636505126953125\n",
      "train r2:  0.8854640414491283\n",
      "test loss:  6.7743449211120605\n",
      "test r2:  -0.2557447315832999\n",
      "train loss:  1.636513113975525\n",
      "train r2:  0.8852632965584071\n",
      "test loss:  6.7793779373168945\n",
      "test r2:  -0.25482895511808823\n",
      "train loss:  1.636525273323059\n",
      "train r2:  0.8854806707990064\n",
      "test loss:  6.804548263549805\n",
      "test r2:  -0.2561929265714957\n",
      "train loss:  1.6365327835083008\n",
      "train r2:  0.8852464113917962\n",
      "test loss:  6.8135600090026855\n",
      "test r2:  -0.2552309313651424\n",
      "train loss:  1.6365443468093872\n",
      "train r2:  0.885495591616135\n",
      "test loss:  6.819585800170898\n",
      "test r2:  -0.2564947668894093\n",
      "train loss:  1.6365492343902588\n",
      "train r2:  0.885232458148527\n",
      "test loss:  6.811678886413574\n",
      "test r2:  -0.25517058910119195\n",
      "train loss:  1.6365536451339722\n",
      "train r2:  0.8855017420911306\n",
      "test loss:  6.803779602050781\n",
      "test r2:  -0.2562325415088351\n",
      "train loss:  1.6365493535995483\n",
      "train r2:  0.8852348738049558\n",
      "test loss:  6.780542373657227\n",
      "test r2:  -0.2547684575696987\n",
      "train loss:  1.6365444660186768\n",
      "train r2:  0.8854969766258367\n",
      "test loss:  6.774641513824463\n",
      "test r2:  -0.2558263588059022\n",
      "train loss:  1.636531114578247\n",
      "train r2:  0.8852456140669801\n",
      "test loss:  6.770306587219238\n",
      "test r2:  -0.2547191888304241\n",
      "train loss:  1.6365166902542114\n",
      "train r2:  0.8854807702670252\n",
      "test loss:  6.774587631225586\n",
      "test r2:  -0.25571780089670937\n",
      "train loss:  1.6364984512329102\n",
      "train r2:  0.8852701197672497\n",
      "test loss:  6.7726335525512695\n",
      "test r2:  -0.2548899353435048\n",
      "train loss:  1.6364818811416626\n",
      "train r2:  0.8854494959224535\n",
      "test loss:  6.775241374969482\n",
      "test r2:  -0.25555487683545186\n",
      "train loss:  1.636467456817627\n",
      "train r2:  0.8853086130589053\n",
      "test loss:  6.773916244506836\n",
      "test r2:  -0.2551002258704873\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8854064681578835\n",
      "test loss:  6.7747344970703125\n",
      "test r2:  -0.2553470772108841\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853537344374172\n",
      "test loss:  6.774477958679199\n",
      "test r2:  -0.2553046182104517\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853624660131292\n",
      "test loss:  6.773736476898193\n",
      "test r2:  -0.25515907271677984\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853928228296\n",
      "test loss:  6.7743306159973145\n",
      "test r2:  -0.25544947371901183\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.885329612561851\n",
      "test loss:  6.772429943084717\n",
      "test r2:  -0.2550312451538401\n",
      "train loss:  1.6364611387252808\n",
      "train r2:  0.8854175372606317\n",
      "test loss:  6.773394584655762\n",
      "test r2:  -0.25551485182274636\n",
      "train loss:  1.6364648342132568\n",
      "train r2:  0.8853123223301665\n",
      "test loss:  6.770798206329346\n",
      "test r2:  -0.25496582070809715\n",
      "train loss:  1.636467456817627\n",
      "train r2:  0.8854275583409422\n",
      "test loss:  6.771713733673096\n",
      "test r2:  -0.25551197474307163\n",
      "train loss:  1.6364686489105225\n",
      "train r2:  0.8853083598981092\n",
      "test loss:  6.768857002258301\n",
      "test r2:  -0.2549447097050479\n",
      "train loss:  1.636468529701233\n",
      "train r2:  0.8854269734306173\n",
      "test loss:  6.769531726837158\n",
      "test r2:  -0.25546557748299326\n",
      "train loss:  1.6364670991897583\n",
      "train r2:  0.8853128192343831\n",
      "test loss:  6.7667460441589355\n",
      "test r2:  -0.25494986781268913\n",
      "train loss:  1.636465311050415\n",
      "train r2:  0.8854202213550538\n",
      "test loss:  6.767114639282227\n",
      "test r2:  -0.25539402639269126\n",
      "train loss:  1.6364628076553345\n",
      "train r2:  0.8853223165777458\n",
      "test loss:  6.764649868011475\n",
      "test r2:  -0.25497514973168367\n",
      "train loss:  1.6364613771438599\n",
      "train r2:  0.8854089779455238\n",
      "test loss:  6.764679431915283\n",
      "test r2:  -0.2553045384340338\n",
      "train loss:  1.6364588737487793\n",
      "train r2:  0.8853357256016534\n",
      "test loss:  6.762732028961182\n",
      "test r2:  -0.2550176351126108\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8853944072409361\n",
      "test loss:  6.762404918670654\n",
      "test r2:  -0.2552083164363159\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853511114881303\n",
      "test loss:  6.761064052581787\n",
      "test r2:  -0.25506599705182764\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853791772364367\n",
      "test loss:  6.760414123535156\n",
      "test r2:  -0.2551199796257666\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853654431295326\n",
      "test loss:  6.759638786315918\n",
      "test r2:  -0.25510624528079395\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853664067179552\n",
      "test loss:  6.758771896362305\n",
      "test r2:  -0.25505331385076824\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853758862362661\n",
      "test loss:  6.758419513702393\n",
      "test r2:  -0.25512763529034355\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853583780362149\n",
      "test loss:  6.757476329803467\n",
      "test r2:  -0.2550133453738386\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853812845121999\n",
      "test loss:  6.757379055023193\n",
      "test r2:  -0.25513079242518466\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853548823624834\n",
      "test loss:  6.756464958190918\n",
      "test r2:  -0.2549921475732273\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.885383281751126\n",
      "test loss:  6.756515026092529\n",
      "test r2:  -0.25512584704100316\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853536454844888\n",
      "test loss:  6.755665302276611\n",
      "test r2:  -0.25497886559638716\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853840915174895\n",
      "test loss:  6.755819320678711\n",
      "test r2:  -0.25512107002500306\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853528465852961\n",
      "test loss:  6.755018711090088\n",
      "test r2:  -0.25496645143540864\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853851054773\n",
      "test loss:  6.7552714347839355\n",
      "test r2:  -0.2551194213997552\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.885351726333929\n",
      "test loss:  6.754498481750488\n",
      "test r2:  -0.2549552226885068\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.885386203746837\n",
      "test loss:  6.754831314086914\n",
      "test r2:  -0.25511728953628054\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853510101268245\n",
      "test loss:  6.754092693328857\n",
      "test r2:  -0.2549482769050142\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853866578590833\n",
      "test loss:  6.7544779777526855\n",
      "test r2:  -0.2551136896064772\n",
      "train loss:  1.6364543437957764\n",
      "train r2:  0.8853508227008582\n",
      "test loss:  6.753775119781494\n",
      "test r2:  -0.2549432573646071\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853868518902039\n",
      "test loss:  6.754204273223877\n",
      "test r2:  -0.25511244808878986\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853503573421082\n",
      "test loss:  6.75351095199585\n",
      "test r2:  -0.25493485543926075\n",
      "train loss:  1.6364567279815674\n",
      "train r2:  0.8853880115823385\n",
      "test loss:  6.754021167755127\n",
      "test r2:  -0.2551203044540393\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853481273948808\n",
      "test loss:  6.753265380859375\n",
      "test r2:  -0.25491671790710013\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853914043411206\n",
      "test loss:  6.753924369812012\n",
      "test r2:  -0.25513916552451543\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853436620824808\n",
      "test loss:  6.753030776977539\n",
      "test r2:  -0.25488986122414636\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853967245603265\n",
      "test loss:  6.7538909912109375\n",
      "test r2:  -0.2551661603241051\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853375256606577\n",
      "test loss:  6.752810478210449\n",
      "test r2:  -0.2548574786796258\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.8854033289298952\n",
      "test loss:  6.753904342651367\n",
      "test r2:  -0.2551985383831221\n",
      "train loss:  1.6364589929580688\n",
      "train r2:  0.8853303215193455\n",
      "test loss:  6.752598762512207\n",
      "test r2:  -0.2548203540937424\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8854110173800351\n",
      "test loss:  6.7539591789245605\n",
      "test r2:  -0.25523728050705263\n",
      "train loss:  1.6364622116088867\n",
      "train r2:  0.8853217815620598\n",
      "test loss:  6.752381801605225\n",
      "test r2:  -0.2547758371279909\n",
      "train loss:  1.6364649534225464\n",
      "train r2:  0.885420276037658\n",
      "test loss:  6.754060745239258\n",
      "test r2:  -0.2552852861416428\n",
      "train loss:  1.6364679336547852\n",
      "train r2:  0.88531129670895\n",
      "test loss:  6.752142429351807\n",
      "test r2:  -0.2547204319080527\n",
      "train loss:  1.636472225189209\n",
      "train r2:  0.8854318444224499\n",
      "test loss:  6.754220485687256\n",
      "test r2:  -0.2553465906628065\n",
      "train loss:  1.6364763975143433\n",
      "train r2:  0.8852979352361773\n",
      "test loss:  6.751864910125732\n",
      "test r2:  -0.2546502620414577\n",
      "train loss:  1.6364833116531372\n",
      "train r2:  0.8854465838093877\n",
      "test loss:  6.754443168640137\n",
      "test r2:  -0.2554239817432813\n",
      "train loss:  1.6364903450012207\n",
      "train r2:  0.885281112791807\n",
      "test loss:  6.751542568206787\n",
      "test r2:  -0.25456387132081026\n",
      "train loss:  1.636500358581543\n",
      "train r2:  0.8854646928220143\n",
      "test loss:  6.754728317260742\n",
      "test r2:  -0.2555170199921717\n",
      "train loss:  1.6365101337432861\n",
      "train r2:  0.8852608550655006\n",
      "test loss:  6.751184463500977\n",
      "test r2:  -0.254464239066587\n",
      "train loss:  1.6365242004394531\n",
      "train r2:  0.8854855928709096\n",
      "test loss:  6.755051136016846\n",
      "test r2:  -0.2556193043422339\n",
      "train loss:  1.6365360021591187\n",
      "train r2:  0.8852385498666413\n",
      "test loss:  6.75082540512085\n",
      "test r2:  -0.25436258533733125\n",
      "train loss:  1.6365526914596558\n",
      "train r2:  0.8855068613210653\n",
      "test loss:  6.755355358123779\n",
      "test r2:  -0.25571338260935117\n",
      "train loss:  1.636562705039978\n",
      "train r2:  0.8852180026566278\n",
      "test loss:  6.750547885894775\n",
      "test r2:  -0.25428347773050985\n",
      "train loss:  1.6365760564804077\n",
      "train r2:  0.8855233303155332\n",
      "test loss:  6.755527973175049\n",
      "test r2:  -0.2557669566624887\n",
      "train loss:  1.6365779638290405\n",
      "train r2:  0.8852063557698738\n",
      "test loss:  6.750479221343994\n",
      "test r2:  -0.2542654242636455\n",
      "train loss:  1.6365790367126465\n",
      "train r2:  0.8855271488747564\n",
      "test loss:  6.755431652069092\n",
      "test r2:  -0.25573904365783484\n",
      "train loss:  1.6365662813186646\n",
      "train r2:  0.8852124466880313\n",
      "test loss:  6.750750541687012\n",
      "test r2:  -0.2543466180637346\n",
      "train loss:  1.6365505456924438\n",
      "train r2:  0.8855102012943766\n",
      "test loss:  6.754966735839844\n",
      "test r2:  -0.2556008358249866\n",
      "train loss:  1.636525273323059\n",
      "train r2:  0.8852425816789099\n",
      "test loss:  6.751396656036377\n",
      "test r2:  -0.2545381865544596\n",
      "train loss:  1.636501431465149\n",
      "train r2:  0.8854700104054861\n",
      "test loss:  6.75417947769165\n",
      "test r2:  -0.2553659475554968\n",
      "train loss:  1.636478066444397\n",
      "train r2:  0.8852934722723742\n",
      "test loss:  6.7522873878479\n",
      "test r2:  -0.25480063802078745\n",
      "train loss:  1.6364620923995972\n",
      "train r2:  0.8854145523837827\n",
      "test loss:  6.7532758712768555\n",
      "test r2:  -0.25509529108766005\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853517092490851\n",
      "test loss:  6.753175258636475\n",
      "test r2:  -0.25506157322313183\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.885358965653709\n",
      "test loss:  6.752495288848877\n",
      "test r2:  -0.2548606671679303\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8854018073314875\n",
      "test loss:  6.753847122192383\n",
      "test r2:  -0.2552583162724398\n",
      "train loss:  1.6364622116088867\n",
      "train r2:  0.885316782011675\n",
      "test loss:  6.752000331878662\n",
      "test r2:  -0.2547102521544806\n",
      "train loss:  1.6364692449569702\n",
      "train r2:  0.8854337731271895\n",
      "test loss:  6.754197597503662\n",
      "test r2:  -0.2553602326883375\n",
      "train loss:  1.6364744901657104\n",
      "train r2:  0.8852948709182402\n",
      "test loss:  6.751832485198975\n",
      "test r2:  -0.25465709661314206\n",
      "train loss:  1.6364773511886597\n",
      "train r2:  0.8854450616511833\n",
      "test loss:  6.7542314529418945\n",
      "test r2:  -0.25536850431288394\n",
      "train loss:  1.636476755142212\n",
      "train r2:  0.8852930780914638\n",
      "test loss:  6.751951694488525\n",
      "test r2:  -0.2546890066477765\n",
      "train loss:  1.6364742517471313\n",
      "train r2:  0.8854383102095336\n",
      "test loss:  6.7540178298950195\n",
      "test r2:  -0.25530340732936674\n",
      "train loss:  1.636470079421997\n",
      "train r2:  0.8853071130239094\n",
      "test loss:  6.752269268035889\n",
      "test r2:  -0.25478003439575625\n",
      "train loss:  1.6364659070968628\n",
      "train r2:  0.8854190348944777\n",
      "test loss:  6.753658771514893\n",
      "test r2:  -0.25519498912107297\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8853304183169659\n",
      "test loss:  6.752676486968994\n",
      "test r2:  -0.254897932049708\n",
      "train loss:  1.6364589929580688\n",
      "train r2:  0.8853939699919271\n",
      "test loss:  6.753262042999268\n",
      "test r2:  -0.25507510925970056\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853561291006714\n",
      "test loss:  6.753072738647461\n",
      "test r2:  -0.25501290719136627\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853694941384803\n",
      "test loss:  6.7529215812683105\n",
      "test r2:  -0.2549712242321682\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853783792659597\n",
      "test loss:  6.75337553024292\n",
      "test r2:  -0.2551006673259433\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.885350748046609\n",
      "test loss:  6.7527008056640625\n",
      "test r2:  -0.254901785011056\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853932609645332\n",
      "test loss:  6.753555774688721\n",
      "test r2:  -0.2551512597318777\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853399909223447\n",
      "test loss:  6.752612113952637\n",
      "test r2:  -0.2548702134250582\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.885400026672136\n",
      "test loss:  6.753618240356445\n",
      "test r2:  -0.2551657727479417\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853369123684559\n",
      "test loss:  6.752636909484863\n",
      "test r2:  -0.25487138215879734\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853998273076459\n",
      "test loss:  6.753593444824219\n",
      "test r2:  -0.25515381896346034\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853395070985086\n",
      "test loss:  6.752729892730713\n",
      "test r2:  -0.2548925618248665\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853953325311763\n",
      "test loss:  6.753521919250488\n",
      "test r2:  -0.2551279495049732\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853450644965453\n",
      "test loss:  6.752847671508789\n",
      "test r2:  -0.2549221437357976\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853890924968719\n",
      "test loss:  6.753435134887695\n",
      "test r2:  -0.2550983870230308\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853514237500117\n",
      "test loss:  6.752959728240967\n",
      "test r2:  -0.2549511446613961\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853829092652856\n",
      "test loss:  6.753355503082275\n",
      "test r2:  -0.2550715337728182\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853571988380675\n",
      "test loss:  6.7530517578125\n",
      "test r2:  -0.2549756959758711\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853777252374918\n",
      "test loss:  6.753291130065918\n",
      "test r2:  -0.2550493718347695\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853619644918111\n",
      "test loss:  6.753124713897705\n",
      "test r2:  -0.2549949866019061\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853736447896161\n",
      "test loss:  6.753246784210205\n",
      "test r2:  -0.2550327965399297\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853655685062395\n",
      "test loss:  6.753178119659424\n",
      "test r2:  -0.25500781451882126\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853709437318195\n",
      "test loss:  6.753232002258301\n",
      "test r2:  -0.2550239054120709\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853675004450046\n",
      "test loss:  6.753209114074707\n",
      "test r2:  -0.2550132198329975\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.885369836537445\n",
      "test loss:  6.753242492675781\n",
      "test r2:  -0.2550217014118712\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853680329103576\n",
      "test loss:  6.753229141235352\n",
      "test r2:  -0.25501450697583206\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853696395000783\n",
      "test loss:  6.753262519836426\n",
      "test r2:  -0.2550216594283792\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853681142889431\n",
      "test loss:  6.753252029418945\n",
      "test r2:  -0.2550159625687747\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853693582531188\n",
      "test loss:  6.75327730178833\n",
      "test r2:  -0.25502005376565107\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853685365304378\n",
      "test loss:  6.753282070159912\n",
      "test r2:  -0.25501961185550037\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853686173232477\n",
      "test loss:  6.753281116485596\n",
      "test r2:  -0.25501582206806317\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853694492017959\n",
      "test loss:  6.753316879272461\n",
      "test r2:  -0.2550251869920619\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853674761095073\n",
      "test loss:  6.753278732299805\n",
      "test r2:  -0.25501021416889347\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853706853209322\n",
      "test loss:  6.753352165222168\n",
      "test r2:  -0.2550317112939018\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853661163018036\n",
      "test loss:  6.753270149230957\n",
      "test r2:  -0.2550036868931036\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853721472712129\n",
      "test loss:  6.753387451171875\n",
      "test r2:  -0.25503881460663336\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853646233547365\n",
      "test loss:  6.753258228302002\n",
      "test r2:  -0.2549963414819858\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.885373723862579\n",
      "test loss:  6.7534260749816895\n",
      "test r2:  -0.25504712341784597\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853628782311402\n",
      "test loss:  6.753236293792725\n",
      "test r2:  -0.25498611130234394\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853759497723729\n",
      "test loss:  6.753482341766357\n",
      "test r2:  -0.2550603152667916\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853600637030237\n",
      "test loss:  6.753195285797119\n",
      "test r2:  -0.25496969143941195\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853794522946574\n",
      "test loss:  6.753563404083252\n",
      "test r2:  -0.2550805239299403\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853557708244449\n",
      "test loss:  6.753129959106445\n",
      "test r2:  -0.2549458985231914\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853845585541166\n",
      "test loss:  6.753674030303955\n",
      "test r2:  -0.25510885537265904\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853497337367716\n",
      "test loss:  6.753037929534912\n",
      "test r2:  -0.254913732446195\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853914682123954\n",
      "test loss:  6.753815174102783\n",
      "test r2:  -0.2551458004728673\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853418539110439\n",
      "test loss:  6.752917289733887\n",
      "test r2:  -0.2548727069184147\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.8854002439629798\n",
      "test loss:  6.753992080688477\n",
      "test r2:  -0.25519324998697\n",
      "train loss:  1.6364599466323853\n",
      "train r2:  0.8853317108610866\n",
      "test loss:  6.752749919891357\n",
      "test r2:  -0.25481806097744664\n",
      "train loss:  1.6364630460739136\n",
      "train r2:  0.8854119188198839\n",
      "test loss:  6.754228115081787\n",
      "test r2:  -0.25525824681882403\n",
      "train loss:  1.6364655494689941\n",
      "train r2:  0.8853177980260637\n",
      "test loss:  6.752511978149414\n",
      "test r2:  -0.2547422263666319\n",
      "train loss:  1.6364712715148926\n",
      "train r2:  0.8854280221417543\n",
      "test loss:  6.75454568862915\n",
      "test r2:  -0.25534759572278154\n",
      "train loss:  1.6364763975143433\n",
      "train r2:  0.8852985998045716\n",
      "test loss:  6.752179145812988\n",
      "test r2:  -0.2546385802955853\n",
      "train loss:  1.6364859342575073\n",
      "train r2:  0.8854499976686295\n",
      "test loss:  6.754968643188477\n",
      "test r2:  -0.2554682095886438\n",
      "train loss:  1.6364960670471191\n",
      "train r2:  0.8852725495966468\n",
      "test loss:  6.751732349395752\n",
      "test r2:  -0.254500797549178\n",
      "train loss:  1.636512279510498\n",
      "train r2:  0.8854790643212126\n",
      "test loss:  6.755509853363037\n",
      "test r2:  -0.2556237120640814\n",
      "train loss:  1.6365303993225098\n",
      "train r2:  0.8852388797995154\n",
      "test loss:  6.751177787780762\n",
      "test r2:  -0.25433086772054936\n",
      "train loss:  1.63655686378479\n",
      "train r2:  0.8855147730291316\n",
      "test loss:  6.756138324737549\n",
      "test r2:  -0.2558051615132386\n",
      "train loss:  1.6365829706192017\n",
      "train r2:  0.8851994027385127\n",
      "test loss:  6.75058126449585\n",
      "test r2:  -0.25414817785152666\n",
      "train loss:  1.6366180181503296\n",
      "train r2:  0.8855529437268993\n",
      "test loss:  6.756733417510986\n",
      "test r2:  -0.25597681369732017\n",
      "train loss:  1.6366448402404785\n",
      "train r2:  0.8851618318145322\n",
      "test loss:  6.750131607055664\n",
      "test r2:  -0.2540096184617213\n",
      "train loss:  1.6366733312606812\n",
      "train r2:  0.8855817603565334\n",
      "test loss:  6.757017135620117\n",
      "test r2:  -0.25605621146909985\n",
      "train loss:  1.6366757154464722\n",
      "train r2:  0.8851444077467182\n",
      "test loss:  6.750179767608643\n",
      "test r2:  -0.25401981105735105\n",
      "train loss:  1.6366662979125977\n",
      "train r2:  0.8855797186911923\n",
      "test loss:  6.756608486175537\n",
      "test r2:  -0.2559316299563763\n",
      "train loss:  1.6366232633590698\n",
      "train r2:  0.8851718818261317\n",
      "test loss:  6.751031875610352\n",
      "test r2:  -0.25426982743035165\n",
      "train loss:  1.6365723609924316\n",
      "train r2:  0.8855277528517506\n",
      "test loss:  6.755387783050537\n",
      "test r2:  -0.25556570184404115\n",
      "train loss:  1.6365139484405518\n",
      "train r2:  0.8852517358905947\n",
      "test loss:  6.752557277679443\n",
      "test r2:  -0.25471900278572424\n",
      "train loss:  1.6364729404449463\n",
      "train r2:  0.8854332954610877\n",
      "test loss:  6.753770351409912\n",
      "test r2:  -0.25507986183687614\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853564768859092\n",
      "test loss:  6.754162788391113\n",
      "test r2:  -0.25519008810036303\n",
      "train loss:  1.6364567279815674\n",
      "train r2:  0.8853329364915243\n",
      "test loss:  6.752415657043457\n",
      "test r2:  -0.2546699976171354\n",
      "train loss:  1.6364749670028687\n",
      "train r2:  0.8854437630252346\n",
      "test loss:  6.755249500274658\n",
      "test r2:  -0.25550647748631783\n",
      "train loss:  1.6364963054656982\n",
      "train r2:  0.8852647936162202\n",
      "test loss:  6.75177001953125\n",
      "test r2:  -0.25447020357760963\n",
      "train loss:  1.636512041091919\n",
      "train r2:  0.8854859810852435\n",
      "test loss:  6.7555251121521\n",
      "test r2:  -0.255583334783702\n",
      "train loss:  1.6365145444869995\n",
      "train r2:  0.8852481610822102\n",
      "test loss:  6.7519450187683105\n",
      "test r2:  -0.2545149011514365\n",
      "train loss:  1.6365063190460205\n",
      "train r2:  0.8854765949145117\n",
      "test loss:  6.755037307739258\n",
      "test r2:  -0.2554346826590894\n",
      "train loss:  1.6364891529083252\n",
      "train r2:  0.8852803206337734\n",
      "test loss:  6.752732753753662\n",
      "test r2:  -0.2547429246714308\n",
      "train loss:  1.6364741325378418\n",
      "train r2:  0.8854284445007936\n",
      "test loss:  6.754127025604248\n",
      "test r2:  -0.2551605612853407\n",
      "train loss:  1.6364604234695435\n",
      "train r2:  0.8853393746170375\n",
      "test loss:  6.753713607788086\n",
      "test r2:  -0.2550299973974117\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.8853673669670166\n",
      "test loss:  6.753238201141357\n",
      "test r2:  -0.25489232250790206\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853967351097406\n",
      "test loss:  6.754473686218262\n",
      "test r2:  -0.2552528710516211\n",
      "train loss:  1.6364637613296509\n",
      "train r2:  0.8853196674812716\n",
      "test loss:  6.752714157104492\n",
      "test r2:  -0.2547316152755885\n",
      "train loss:  1.636468529701233\n",
      "train r2:  0.8854309845048554\n",
      "test loss:  6.7547831535339355\n",
      "test r2:  -0.25534237152053163\n",
      "train loss:  1.6364706754684448\n",
      "train r2:  0.8853004554304312\n",
      "test loss:  6.75267219543457\n",
      "test r2:  -0.25471369064712723\n",
      "train loss:  1.6364697217941284\n",
      "train r2:  0.8854348278116668\n",
      "test loss:  6.754634380340576\n",
      "test r2:  -0.25529498461094735\n",
      "train loss:  1.6364659070968628\n",
      "train r2:  0.8853106849373726\n",
      "test loss:  6.7530364990234375\n",
      "test r2:  -0.2548149282978158\n",
      "train loss:  1.6364614963531494\n",
      "train r2:  0.8854133729557369\n",
      "test loss:  6.754188060760498\n",
      "test r2:  -0.25515776868879003\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853402051189866\n",
      "test loss:  6.753586292266846\n",
      "test r2:  -0.2549712614147379\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853801224640578\n",
      "test loss:  6.753684997558594\n",
      "test r2:  -0.2550023170449609\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853734847152928\n",
      "test loss:  6.754081726074219\n",
      "test r2:  -0.25511202791796905\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853501043383437\n",
      "test loss:  6.753329277038574\n",
      "test r2:  -0.25489016315382207\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853975059104962\n",
      "test loss:  6.754356861114502\n",
      "test r2:  -0.255188892887817\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853336979219247\n",
      "test loss:  6.753222465515137\n",
      "test r2:  -0.2548519459361913\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8854057198527274\n",
      "test loss:  6.754374980926514\n",
      "test r2:  -0.2551902822304899\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.885333462426122\n",
      "test loss:  6.7533488273620605\n",
      "test r2:  -0.2548829436317348\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.885399162377738\n",
      "test loss:  6.754202365875244\n",
      "test r2:  -0.2551350051075154\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853453536856174\n",
      "test loss:  6.753610610961914\n",
      "test r2:  -0.2549543064619797\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853840270595635\n",
      "test loss:  6.753960132598877\n",
      "test r2:  -0.25505854903533276\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853617449851924\n",
      "test loss:  6.753882884979248\n",
      "test r2:  -0.2550288722242595\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853681093519866\n",
      "test loss:  6.753756523132324\n",
      "test r2:  -0.25499297293861334\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853757781477367\n",
      "test loss:  6.754080295562744\n",
      "test r2:  -0.2550823839964904\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853567442081389\n",
      "test loss:  6.753645420074463\n",
      "test r2:  -0.25495481835007894\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.885383975888212\n",
      "test loss:  6.754169940948486\n",
      "test r2:  -0.25510475144842304\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853519926443013\n",
      "test loss:  6.753641128540039\n",
      "test r2:  -0.25494803783383047\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853854821408356\n",
      "test loss:  6.754159927368164\n",
      "test r2:  -0.2550975951494032\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853536022721851\n",
      "test loss:  6.753726005554199\n",
      "test r2:  -0.2549670904824073\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853815011964616\n",
      "test loss:  6.754086017608643\n",
      "test r2:  -0.2550708035656448\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853594064667817\n",
      "test loss:  6.753854751586914\n",
      "test r2:  -0.2549988998738164\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853747583613355\n",
      "test loss:  6.753994941711426\n",
      "test r2:  -0.25503835486507054\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853663657956342\n",
      "test loss:  6.753984451293945\n",
      "test r2:  -0.2550304326059336\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853680848632604\n",
      "test loss:  6.753924369812012\n",
      "test r2:  -0.2550113232229081\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853721757641045\n",
      "test loss:  6.754083633422852\n",
      "test r2:  -0.25505331742688186\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.885363280709156\n",
      "test loss:  6.753889560699463\n",
      "test r2:  -0.25499527651698695\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853756320287748\n",
      "test loss:  6.75413703918457\n",
      "test r2:  -0.25506326428247017\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853611784171245\n",
      "test loss:  6.7538981437683105\n",
      "test r2:  -0.2549924451075194\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853763132768234\n",
      "test loss:  6.754144191741943\n",
      "test r2:  -0.2550601586018826\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853618975403451\n",
      "test loss:  6.753946304321289\n",
      "test r2:  -0.2550016945021567\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853743860558445\n",
      "test loss:  6.754114151000977\n",
      "test r2:  -0.2550465375865312\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.885364845992117\n",
      "test loss:  6.7540202140808105\n",
      "test r2:  -0.2550182519369102\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853708870660235\n",
      "test loss:  6.754072189331055\n",
      "test r2:  -0.2550290856031354\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853686402295016\n",
      "test loss:  6.7540974617004395\n",
      "test r2:  -0.2550358691138157\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853671767181861\n",
      "test loss:  6.754034519195557\n",
      "test r2:  -0.2550126935175532\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853721644567096\n",
      "test loss:  6.75416898727417\n",
      "test r2:  -0.2550511712016039\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853640012614935\n",
      "test loss:  6.754011631011963\n",
      "test r2:  -0.2550001972902971\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.885374909756349\n",
      "test loss:  6.754227161407471\n",
      "test r2:  -0.2550620038314526\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853617454146426\n",
      "test loss:  6.754004955291748\n",
      "test r2:  -0.2549921984294137\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853766746695042\n",
      "test loss:  6.754271030426025\n",
      "test r2:  -0.2550686589666178\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853603660319893\n",
      "test loss:  6.754012584686279\n",
      "test r2:  -0.2549882873572433\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.885377557595493\n",
      "test loss:  6.754300117492676\n",
      "test r2:  -0.2550710877048721\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853599057148246\n",
      "test loss:  6.754032611846924\n",
      "test r2:  -0.2549881681288777\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853776486199313\n",
      "test loss:  6.754317760467529\n",
      "test r2:  -0.2550703909362044\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853601145373907\n",
      "test loss:  6.7540602684021\n",
      "test r2:  -0.25499064841969776\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853771488087997\n",
      "test loss:  6.7543253898620605\n",
      "test r2:  -0.25506673279316994\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853609233592195\n",
      "test loss:  6.7540974617004395\n",
      "test r2:  -0.25499621759607005\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853760426932284\n",
      "test loss:  6.754323959350586\n",
      "test r2:  -0.25506095326512446\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.885362210130201\n",
      "test loss:  6.754137992858887\n",
      "test r2:  -0.25500227268148934\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.885374781427382\n",
      "test loss:  6.754324436187744\n",
      "test r2:  -0.255055697930614\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853633952563142\n",
      "test loss:  6.754173755645752\n",
      "test r2:  -0.2550074625809038\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853737304979893\n",
      "test loss:  6.754329204559326\n",
      "test r2:  -0.2550516441211248\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853643010487399\n",
      "test loss:  6.754205226898193\n",
      "test r2:  -0.2550108999306686\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853730622758847\n",
      "test loss:  6.754343032836914\n",
      "test r2:  -0.25505010150532104\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853646697361385\n",
      "test loss:  6.754228115081787\n",
      "test r2:  -0.25501146627154947\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.885373002641636\n",
      "test loss:  6.754365921020508\n",
      "test r2:  -0.2550513020922782\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853644721896082\n",
      "test loss:  6.754243850708008\n",
      "test r2:  -0.2550099208825165\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853733871991316\n",
      "test loss:  6.754395961761475\n",
      "test r2:  -0.2550544953978904\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853638433022568\n",
      "test loss:  6.754251480102539\n",
      "test r2:  -0.2550057258800327\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.885374292953484\n",
      "test loss:  6.754437446594238\n",
      "test r2:  -0.2550611860033509\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853624165733559\n",
      "test loss:  6.754245281219482\n",
      "test r2:  -0.25499726057186156\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853761212215323\n",
      "test loss:  6.754495143890381\n",
      "test r2:  -0.2550728422248658\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853600112234921\n",
      "test loss:  6.754219055175781\n",
      "test r2:  -0.2549831412396186\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853791861381661\n",
      "test loss:  6.754576206207275\n",
      "test r2:  -0.2550915636179969\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853559988954125\n",
      "test loss:  6.754159927368164\n",
      "test r2:  -0.2549598841669529\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.8853841747558266\n",
      "test loss:  6.7546916007995605\n",
      "test r2:  -0.25512061162294675\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853498330184849\n",
      "test loss:  6.754061698913574\n",
      "test r2:  -0.25492516099257223\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.8853916260753381\n",
      "test loss:  6.754849433898926\n",
      "test r2:  -0.2551620290731176\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.8853410234738438\n",
      "test loss:  6.753920078277588\n",
      "test r2:  -0.25487758523305626\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8854018339840816\n",
      "test loss:  6.755054950714111\n",
      "test r2:  -0.25521663946186335\n",
      "train loss:  1.6364610195159912\n",
      "train r2:  0.8853293614087472\n",
      "test loss:  6.7537312507629395\n",
      "test r2:  -0.2548156845536793\n",
      "train loss:  1.6364638805389404\n",
      "train r2:  0.8854150648162399\n",
      "test loss:  6.755319118499756\n",
      "test r2:  -0.2552878087108923\n",
      "train loss:  1.636466383934021\n",
      "train r2:  0.885314113877286\n",
      "test loss:  6.753483772277832\n",
      "test r2:  -0.25473488953327106\n",
      "train loss:  1.6364712715148926\n",
      "train r2:  0.885432260444201\n",
      "test loss:  6.755659580230713\n",
      "test r2:  -0.2553811097488332\n",
      "train loss:  1.6364772319793701\n",
      "train r2:  0.8852941143695006\n",
      "test loss:  6.753157138824463\n",
      "test r2:  -0.25463013323255734\n",
      "train loss:  1.6364861726760864\n",
      "train r2:  0.8854544898816267\n",
      "test loss:  6.756087779998779\n",
      "test r2:  -0.25550033177734544\n",
      "train loss:  1.6364970207214355\n",
      "train r2:  0.8852684228457033\n",
      "test loss:  6.752739429473877\n",
      "test r2:  -0.25449763838664374\n",
      "train loss:  1.6365123987197876\n",
      "train r2:  0.8854824856087811\n",
      "test loss:  6.756611347198486\n",
      "test r2:  -0.2556485076234303\n",
      "train loss:  1.6365302801132202\n",
      "train r2:  0.8852363326603625\n",
      "test loss:  6.752228260040283\n",
      "test r2:  -0.25433782545719175\n",
      "train loss:  1.6365548372268677\n",
      "train r2:  0.8855160684318893\n",
      "test loss:  6.757201671600342\n",
      "test r2:  -0.25581716196334026\n",
      "train loss:  1.6365793943405151\n",
      "train r2:  0.8851996130938841\n",
      "test loss:  6.751695156097412\n",
      "test r2:  -0.25417156922302997\n",
      "train loss:  1.6366114616394043\n",
      "train r2:  0.8855508468909203\n",
      "test loss:  6.757731914520264\n",
      "test r2:  -0.25596907944017033\n",
      "train loss:  1.6366342306137085\n",
      "train r2:  0.885166384824651\n",
      "test loss:  6.751324653625488\n",
      "test r2:  -0.2540550957307268\n",
      "train loss:  1.636658787727356\n",
      "train r2:  0.885575083162837\n",
      "test loss:  6.757945537567139\n",
      "test r2:  -0.25602756433706575\n",
      "train loss:  1.6366571187973022\n",
      "train r2:  0.8851535829484382\n",
      "test loss:  6.751420497894287\n",
      "test r2:  -0.2540794197387357\n",
      "train loss:  1.636647343635559\n",
      "train r2:  0.8855700869287023\n",
      "test loss:  6.757532119750977\n",
      "test r2:  -0.255900597675349\n",
      "train loss:  1.6366066932678223\n",
      "train r2:  0.8851815384009619\n",
      "test loss:  6.75222635269165\n",
      "test r2:  -0.2543157034626524\n",
      "train loss:  1.6365611553192139\n",
      "train r2:  0.8855208809354203\n",
      "test loss:  6.756414413452148\n",
      "test r2:  -0.2555630330269012\n",
      "train loss:  1.6365094184875488\n",
      "train r2:  0.885255165537866\n",
      "test loss:  6.7536234855651855\n",
      "test r2:  -0.25472608405599595\n",
      "train loss:  1.636472225189209\n",
      "train r2:  0.8854345899063105\n",
      "test loss:  6.754947185516357\n",
      "test r2:  -0.25511908083740176\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853509183568467\n",
      "test loss:  6.7551116943359375\n",
      "test r2:  -0.25516114295886005\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853419614438134\n",
      "test loss:  6.753685474395752\n",
      "test r2:  -0.25473355443856227\n",
      "train loss:  1.6364679336547852\n",
      "train r2:  0.8854331370893662\n",
      "test loss:  6.7561798095703125\n",
      "test r2:  -0.25546941808974943\n",
      "train loss:  1.6364870071411133\n",
      "train r2:  0.8852756686256759\n",
      "test loss:  6.753021240234375\n",
      "test r2:  -0.25452532960671137\n",
      "train loss:  1.6365022659301758\n",
      "train r2:  0.885477233195144\n",
      "test loss:  6.756551742553711\n",
      "test r2:  -0.25557197707141044\n",
      "train loss:  1.6365078687667847\n",
      "train r2:  0.8852535337518459\n",
      "test loss:  6.753073215484619\n",
      "test r2:  -0.2545308714112724\n",
      "train loss:  1.6365041732788086\n",
      "train r2:  0.8854761154007359\n",
      "test loss:  6.756233215332031\n",
      "test r2:  -0.2554710079118918\n",
      "train loss:  1.6364915370941162\n",
      "train r2:  0.885275397783275\n",
      "test loss:  6.753705024719238\n",
      "test r2:  -0.25471108593786584\n",
      "train loss:  1.6364785432815552\n",
      "train r2:  0.8854380863076449\n",
      "test loss:  6.755466938018799\n",
      "test r2:  -0.2552378841165266\n",
      "train loss:  1.6364643573760986\n",
      "train r2:  0.8853256751876667\n",
      "test loss:  6.754591464996338\n",
      "test r2:  -0.2549691069353146\n",
      "train loss:  1.6364593505859375\n",
      "train r2:  0.8853832796687873\n",
      "test loss:  6.754629135131836\n",
      "test r2:  -0.25498355127197314\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853802132757527\n",
      "test loss:  6.755363464355469\n",
      "test r2:  -0.25519492015082657\n",
      "train loss:  1.6364589929580688\n",
      "train r2:  0.8853350635455041\n",
      "test loss:  6.754043102264404\n",
      "test r2:  -0.2548035627942662\n",
      "train loss:  1.6364625692367554\n",
      "train r2:  0.8854185971892392\n",
      "test loss:  6.755785942077637\n",
      "test r2:  -0.25531695116128983\n",
      "train loss:  1.6364657878875732\n",
      "train r2:  0.8853088877928471\n",
      "test loss:  6.753861904144287\n",
      "test r2:  -0.25474292922657216\n",
      "train loss:  1.6364673376083374\n",
      "train r2:  0.8854315337313299\n",
      "test loss:  6.755805492401123\n",
      "test r2:  -0.255318088000847\n",
      "train loss:  1.6364659070968628\n",
      "train r2:  0.8853087127485328\n",
      "test loss:  6.754064559936523\n",
      "test r2:  -0.25479480829197176\n",
      "train loss:  1.6364631652832031\n",
      "train r2:  0.8854206027285805\n",
      "test loss:  6.755518913269043\n",
      "test r2:  -0.25522590665923817\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.8853285468632902\n",
      "test loss:  6.754504203796387\n",
      "test r2:  -0.2549157977890404\n",
      "train loss:  1.6364576816558838\n",
      "train r2:  0.8853949327190307\n",
      "test loss:  6.755099773406982\n",
      "test r2:  -0.25509325318216725\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.8853570453898705\n",
      "test loss:  6.754983901977539\n",
      "test r2:  -0.25504912228512233\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853665706151134\n",
      "test loss:  6.754728317260742\n",
      "test r2:  -0.25497401145021126\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.885382586228512\n",
      "test loss:  6.755338668823242\n",
      "test r2:  -0.2551470204806203\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853456912641684\n",
      "test loss:  6.754521369934082\n",
      "test r2:  -0.2549045735727018\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853975273901804\n",
      "test loss:  6.755491733551025\n",
      "test r2:  -0.2551869646620979\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853372211664595\n",
      "test loss:  6.754510879516602\n",
      "test r2:  -0.2548937024002951\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853999342198303\n",
      "test loss:  6.755462646484375\n",
      "test r2:  -0.255172899364809\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.885340323653274\n",
      "test loss:  6.7546539306640625\n",
      "test r2:  -0.25492833919084523\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853926071192946\n",
      "test loss:  6.755319595336914\n",
      "test r2:  -0.25512434904264425\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853507545790769\n",
      "test loss:  6.754873752593994\n",
      "test r2:  -0.25498556813041917\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853804602270225\n",
      "test loss:  6.755144119262695\n",
      "test r2:  -0.25506560187693506\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853633757196689\n",
      "test loss:  6.755092144012451\n",
      "test r2:  -0.25504259203538204\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853683328100402\n",
      "test loss:  6.755000591278076\n",
      "test r2:  -0.2550159424925631\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853740205557694\n",
      "test loss:  6.755250930786133\n",
      "test r2:  -0.25508264675277026\n",
      "train loss:  1.6364543437957764\n",
      "train r2:  0.8853598123155939\n",
      "test loss:  6.75493049621582\n",
      "test r2:  -0.2549880804506004\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853800487805442\n",
      "test loss:  6.75532865524292\n",
      "test r2:  -0.25509924402043205\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853563500337136\n",
      "test loss:  6.754938125610352\n",
      "test r2:  -0.25498290364721754\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853812340581247\n",
      "test loss:  6.755336284637451\n",
      "test r2:  -0.2550952615857467\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853572899559012\n",
      "test loss:  6.755006313323975\n",
      "test r2:  -0.2549950676727706\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853787275160446\n",
      "test loss:  6.755302429199219\n",
      "test r2:  -0.2550780085661708\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853610314352479\n",
      "test loss:  6.755107402801514\n",
      "test r2:  -0.2550166290981861\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853742095999932\n",
      "test loss:  6.755251884460449\n",
      "test r2:  -0.25505535210854724\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853659690192183\n",
      "test loss:  6.755216598510742\n",
      "test r2:  -0.2550399776177712\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853692885452473\n",
      "test loss:  6.7552103996276855\n",
      "test r2:  -0.2550352588764473\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853703332290197\n",
      "test loss:  6.755303859710693\n",
      "test r2:  -0.25505745792333157\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853656263081755\n",
      "test loss:  6.755194187164307\n",
      "test r2:  -0.2550226955223025\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853730694053382\n",
      "test loss:  6.755362033843994\n",
      "test r2:  -0.25506674607353697\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.885363739929177\n",
      "test loss:  6.755202770233154\n",
      "test r2:  -0.2550180428673945\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.885374109055914\n",
      "test loss:  6.755392074584961\n",
      "test r2:  -0.25506824268323314\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853634665048572\n",
      "test loss:  6.755234241485596\n",
      "test r2:  -0.255020532874757\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853736495473193\n",
      "test loss:  6.755398273468018\n",
      "test r2:  -0.25506292124182495\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853646308666456\n",
      "test loss:  6.755285263061523\n",
      "test r2:  -0.2550289035490485\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853719480396081\n",
      "test loss:  6.755387783050537\n",
      "test r2:  -0.25505284842347176\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853668837189006\n",
      "test loss:  6.75535249710083\n",
      "test r2:  -0.255041616813221\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853692837758287\n",
      "test loss:  6.755364894866943\n",
      "test r2:  -0.25503888156966803\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853699140502618\n",
      "test loss:  6.755429267883301\n",
      "test r2:  -0.25505685433024294\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853660939415087\n",
      "test loss:  6.75534200668335\n",
      "test r2:  -0.2550243972813071\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853731029723089\n",
      "test loss:  6.755505084991455\n",
      "test r2:  -0.25507142586676435\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853630362075486\n",
      "test loss:  6.75532341003418\n",
      "test r2:  -0.2550107867812865\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853760842591798\n",
      "test loss:  6.755581855773926\n",
      "test r2:  -0.2550859956623368\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853600343240627\n",
      "test loss:  6.755305767059326\n",
      "test r2:  -0.25499723655905737\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853790265162451\n",
      "test loss:  6.755656719207764\n",
      "test r2:  -0.25509995819039477\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853571219238702\n",
      "test loss:  6.755291938781738\n",
      "test r2:  -0.2549847864034507\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853817793242398\n",
      "test loss:  6.755726337432861\n",
      "test r2:  -0.2551122280533451\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853545323731989\n",
      "test loss:  6.755285263061523\n",
      "test r2:  -0.2549742777948938\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853840771950213\n",
      "test loss:  6.7557878494262695\n",
      "test r2:  -0.25512259657901826\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853524024518074\n",
      "test loss:  6.755280017852783\n",
      "test r2:  -0.25496464208576897\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853862063543109\n",
      "test loss:  6.7558512687683105\n",
      "test r2:  -0.2551339860789865\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853500434961032\n",
      "test loss:  6.755265712738037\n",
      "test r2:  -0.2549523175734121\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853888769276089\n",
      "test loss:  6.755925178527832\n",
      "test r2:  -0.25514857452933737\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853469538612081\n",
      "test loss:  6.755237102508545\n",
      "test r2:  -0.25493601890099726\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853924146748338\n",
      "test loss:  6.756016731262207\n",
      "test r2:  -0.2551683189162639\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853427602648417\n",
      "test loss:  6.75518798828125\n",
      "test r2:  -0.254913574249251\n",
      "train loss:  1.6364576816558838\n",
      "train r2:  0.8853972617819427\n",
      "test loss:  6.756131172180176\n",
      "test r2:  -0.25519495369174106\n",
      "train loss:  1.636457920074463\n",
      "train r2:  0.8853371377369443\n",
      "test loss:  6.755115985870361\n",
      "test r2:  -0.2548841908187707\n",
      "train loss:  1.636460304260254\n",
      "train r2:  0.8854036067823678\n",
      "test loss:  6.756270885467529\n",
      "test r2:  -0.2552287275820495\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.885329923524174\n",
      "test loss:  6.755016803741455\n",
      "test r2:  -0.2548464300656226\n",
      "train loss:  1.6364632844924927\n",
      "train r2:  0.885411665622603\n",
      "test loss:  6.756444931030273\n",
      "test r2:  -0.2552722547098629\n",
      "train loss:  1.636464238166809\n",
      "train r2:  0.8853206748622928\n",
      "test loss:  6.754881381988525\n",
      "test r2:  -0.2547976749710137\n",
      "train loss:  1.636467695236206\n",
      "train r2:  0.8854221096417553\n",
      "test loss:  6.756662368774414\n",
      "test r2:  -0.255328651942901\n",
      "train loss:  1.636470079421997\n",
      "train r2:  0.8853086221274007\n",
      "test loss:  6.754698276519775\n",
      "test r2:  -0.2547344733686805\n",
      "train loss:  1.6364747285842896\n",
      "train r2:  0.8854355774775824\n",
      "test loss:  6.7569355964660645\n",
      "test r2:  -0.25540071572828316\n",
      "train loss:  1.6364789009094238\n",
      "train r2:  0.8852931391681831\n",
      "test loss:  6.754461288452148\n",
      "test r2:  -0.2546548988148165\n",
      "train loss:  1.6364859342575073\n",
      "train r2:  0.885452491167075\n",
      "test loss:  6.757263660430908\n",
      "test r2:  -0.2554892681256411\n",
      "train loss:  1.6364929676055908\n",
      "train r2:  0.8852740913997359\n",
      "test loss:  6.7541728019714355\n",
      "test r2:  -0.2545597086180469\n",
      "train loss:  1.6365033388137817\n",
      "train r2:  0.8854726678484617\n",
      "test loss:  6.757640361785889\n",
      "test r2:  -0.25559242136480886\n",
      "train loss:  1.6365132331848145\n",
      "train r2:  0.8852518514039659\n",
      "test loss:  6.75384521484375\n",
      "test r2:  -0.2544528642397448\n",
      "train loss:  1.6365269422531128\n",
      "train r2:  0.885495212578299\n",
      "test loss:  6.758035659790039\n",
      "test r2:  -0.2557010036237308\n",
      "train loss:  1.6365389823913574\n",
      "train r2:  0.8852283260456217\n",
      "test loss:  6.753530979156494\n",
      "test r2:  -0.2543502849770545\n",
      "train loss:  1.6365547180175781\n",
      "train r2:  0.885516816905194\n",
      "test loss:  6.7583699226379395\n",
      "test r2:  -0.2557920849437769\n",
      "train loss:  1.6365649700164795\n",
      "train r2:  0.8852085554220551\n",
      "test loss:  6.753330707550049\n",
      "test r2:  -0.2542816937249881\n",
      "train loss:  1.636576533317566\n",
      "train r2:  0.8855312370110617\n",
      "test loss:  6.758523464202881\n",
      "test r2:  -0.2558297349193297\n",
      "train loss:  1.6365770101547241\n",
      "train r2:  0.8852004015435793\n",
      "test loss:  6.753375053405762\n",
      "test r2:  -0.2542866437380449\n",
      "train loss:  1.6365755796432495\n",
      "train r2:  0.8855302277303515\n",
      "test loss:  6.758363246917725\n",
      "test r2:  -0.2557741635964921\n",
      "train loss:  1.6365602016448975\n",
      "train r2:  0.8852126076276948\n",
      "test loss:  6.753774642944336\n",
      "test r2:  -0.2543980189499\n",
      "train loss:  1.6365431547164917\n",
      "train r2:  0.8855069973231338\n",
      "test loss:  6.757833480834961\n",
      "test r2:  -0.2556087247848935\n",
      "train loss:  1.6365169286727905\n",
      "train r2:  0.8852486703711372\n",
      "test loss:  6.754514694213867\n",
      "test r2:  -0.2546110293468338\n",
      "train loss:  1.6364938020706177\n",
      "train r2:  0.8854623186556528\n",
      "test loss:  6.757032871246338\n",
      "test r2:  -0.2553610918117444\n",
      "train loss:  1.636472225189209\n",
      "train r2:  0.8853023364683821\n",
      "test loss:  6.755439281463623\n",
      "test r2:  -0.2548779687866036\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.8854058775227895\n",
      "test loss:  6.756169319152832\n",
      "test r2:  -0.25509372721179924\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853598723710119\n",
      "test loss:  6.756319046020508\n",
      "test r2:  -0.25513073811167875\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853520241916886\n",
      "test loss:  6.755459308624268\n",
      "test r2:  -0.2548710013620934\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8854074828119312\n",
      "test loss:  6.756973743438721\n",
      "test r2:  -0.2553159796012656\n",
      "train loss:  1.6364635229110718\n",
      "train r2:  0.8853123640568725\n",
      "test loss:  6.755030632019043\n",
      "test r2:  -0.2547318276631476\n",
      "train loss:  1.6364703178405762\n",
      "train r2:  0.8854371157494408\n",
      "test loss:  6.757316589355469\n",
      "test r2:  -0.25540867410084234\n",
      "train loss:  1.6364752054214478\n",
      "train r2:  0.8852924699623201\n",
      "test loss:  6.754919052124023\n",
      "test r2:  -0.2546877268374086\n",
      "train loss:  1.6364777088165283\n",
      "train r2:  0.8854465559831302\n",
      "test loss:  6.757349967956543\n",
      "test r2:  -0.2554099942725476\n",
      "train loss:  1.636476993560791\n",
      "train r2:  0.8852922522897014\n",
      "test loss:  6.7550811767578125\n",
      "test r2:  -0.2547262585236425\n",
      "train loss:  1.6364749670028687\n",
      "train r2:  0.885438463999555\n",
      "test loss:  6.75714111328125\n",
      "test r2:  -0.2553400273555213\n",
      "train loss:  1.6364703178405762\n",
      "train r2:  0.8853073559437267\n",
      "test loss:  6.755427837371826\n",
      "test r2:  -0.2548209115291582\n",
      "train loss:  1.6364670991897583\n",
      "train r2:  0.8854184074449759\n",
      "test loss:  6.756796360015869\n",
      "test r2:  -0.2552300982289806\n",
      "train loss:  1.6364613771438599\n",
      "train r2:  0.885331034516186\n",
      "test loss:  6.755846977233887\n",
      "test r2:  -0.25493834798734305\n",
      "train loss:  1.6364593505859375\n",
      "train r2:  0.8853935329935714\n",
      "test loss:  6.7564287185668945\n",
      "test r2:  -0.25511315626988895\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853561869825964\n",
      "test loss:  6.756242275238037\n",
      "test r2:  -0.25504920649379104\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853699721894994\n",
      "test loss:  6.756120204925537\n",
      "test r2:  -0.25501291345878196\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853776949813394\n",
      "test loss:  6.756555557250977\n",
      "test r2:  -0.25513531835540637\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853516429124393\n",
      "test loss:  6.755923271179199\n",
      "test r2:  -0.2549439534860516\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853925382732696\n",
      "test loss:  6.756762504577637\n",
      "test r2:  -0.2551877405230929\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853405206465779\n",
      "test loss:  6.755847454071045\n",
      "test r2:  -0.2549096640045434\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853999676876942\n",
      "test loss:  6.756863594055176\n",
      "test r2:  -0.25520737595939624\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853363594431267\n",
      "test loss:  6.7558746337890625\n",
      "test r2:  -0.2549053135046102\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8854009821752129\n",
      "test loss:  6.7568817138671875\n",
      "test r2:  -0.2552020067750278\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853376048635005\n",
      "test loss:  6.755966663360596\n",
      "test r2:  -0.2549207411291432\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853977880572158\n",
      "test loss:  6.756846904754639\n",
      "test r2:  -0.25518186060989234\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.885342005756095\n",
      "test loss:  6.756086349487305\n",
      "test r2:  -0.2549459540860839\n",
      "train loss:  1.6364572048187256\n",
      "train r2:  0.8853924724681626\n",
      "test loss:  6.75678825378418\n",
      "test r2:  -0.2551555191371777\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853477141314734\n",
      "test loss:  6.756206035614014\n",
      "test r2:  -0.2549732479274225\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853867394605526\n",
      "test loss:  6.7567291259765625\n",
      "test r2:  -0.25512983890548635\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.885353270224655\n",
      "test loss:  6.756310939788818\n",
      "test r2:  -0.2549969709230433\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.885381752211889\n",
      "test loss:  6.756685256958008\n",
      "test r2:  -0.2551086971101735\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853578790352676\n",
      "test loss:  6.756396770477295\n",
      "test r2:  -0.2550150852329953\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853779976268393\n",
      "test loss:  6.756667613983154\n",
      "test r2:  -0.25509413016156435\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853611471433851\n",
      "test loss:  6.756469249725342\n",
      "test r2:  -0.25502790554708477\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853753532095082\n",
      "test loss:  6.756668567657471\n",
      "test r2:  -0.25508374010957136\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853634488813628\n",
      "test loss:  6.756536960601807\n",
      "test r2:  -0.25503797568232867\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.885373303126637\n",
      "test loss:  6.756679058074951\n",
      "test r2:  -0.2550754712910248\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853653464352954\n",
      "test loss:  6.75660514831543\n",
      "test r2:  -0.255047220865918\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853714357158536\n",
      "test loss:  6.756694316864014\n",
      "test r2:  -0.2550677720617647\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853670896244664\n",
      "test loss:  6.756672382354736\n",
      "test r2:  -0.2550558529119231\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853696759023733\n",
      "test loss:  6.756710529327393\n",
      "test r2:  -0.2550610746194959\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853686081804435\n",
      "test loss:  6.75673246383667\n",
      "test r2:  -0.25506327942258\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853681854453983\n",
      "test loss:  6.756724834442139\n",
      "test r2:  -0.2550547962215517\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853700631896384\n",
      "test loss:  6.7567901611328125\n",
      "test r2:  -0.2550706970441572\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853666897293417\n",
      "test loss:  6.7567338943481445\n",
      "test r2:  -0.25504768981197934\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853716440729531\n",
      "test loss:  6.756847858428955\n",
      "test r2:  -0.2550789596731189\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853650058073775\n",
      "test loss:  6.756737232208252\n",
      "test r2:  -0.255039483540602\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.88537351535741\n",
      "test loss:  6.756909370422363\n",
      "test r2:  -0.25508878913550626\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853629609571649\n",
      "test loss:  6.756731986999512\n",
      "test r2:  -0.25502871778366853\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853758474971484\n",
      "test loss:  6.756981372833252\n",
      "test r2:  -0.25510150263726716\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853603175947902\n",
      "test loss:  6.756716728210449\n",
      "test r2:  -0.25501452054703977\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.885378979717382\n",
      "test loss:  6.757072925567627\n",
      "test r2:  -0.25511922764649264\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853565974489032\n",
      "test loss:  6.756683349609375\n",
      "test r2:  -0.25499442276799145\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853833468750264\n",
      "test loss:  6.757188320159912\n",
      "test r2:  -0.25514348526085917\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853515186657379\n",
      "test loss:  6.7566304206848145\n",
      "test r2:  -0.2549678593550291\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.885389105616664\n",
      "test loss:  6.757329940795898\n",
      "test r2:  -0.25517508749984463\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853448277509864\n",
      "test loss:  6.75654935836792\n",
      "test r2:  -0.2549325726416709\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853967194337183\n",
      "test loss:  6.757505893707275\n",
      "test r2:  -0.25521676580149255\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8853359761187147\n",
      "test loss:  6.756429672241211\n",
      "test r2:  -0.2548856384934688\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.885406769478602\n",
      "test loss:  6.757728099822998\n",
      "test r2:  -0.255272122713174\n",
      "train loss:  1.636462688446045\n",
      "train r2:  0.8853241706936236\n",
      "test loss:  6.756252765655518\n",
      "test r2:  -0.2548219121773643\n",
      "train loss:  1.6364668607711792\n",
      "train r2:  0.8854204151588547\n",
      "test loss:  6.7580180168151855\n",
      "test r2:  -0.2553480670774968\n",
      "train loss:  1.6364704370498657\n",
      "train r2:  0.8853079241388855\n",
      "test loss:  6.755993843078613\n",
      "test r2:  -0.25473407345431087\n",
      "train loss:  1.6364772319793701\n",
      "train r2:  0.885439131891783\n",
      "test loss:  6.758401870727539\n",
      "test r2:  -0.2554518030961983\n",
      "train loss:  1.6364843845367432\n",
      "train r2:  0.8852856646975118\n",
      "test loss:  6.7556304931640625\n",
      "test r2:  -0.2546147990416736\n",
      "train loss:  1.6364960670471191\n",
      "train r2:  0.8854644206293875\n",
      "test loss:  6.758898735046387\n",
      "test r2:  -0.2555890256667317\n",
      "train loss:  1.6365090608596802\n",
      "train r2:  0.8852560354551358\n",
      "test loss:  6.755154132843018\n",
      "test r2:  -0.25446146494457533\n",
      "train loss:  1.6365289688110352\n",
      "train r2:  0.8854967994134405\n",
      "test loss:  6.759504795074463\n",
      "test r2:  -0.2557587100994121\n",
      "train loss:  1.6365498304367065\n",
      "train r2:  0.8852192709451921\n",
      "test loss:  6.7545928955078125\n",
      "test r2:  -0.25428252283443786\n",
      "train loss:  1.6365793943405151\n",
      "train r2:  0.8855343925144692\n",
      "test loss:  6.760154724121094\n",
      "test r2:  -0.25594107476329797\n",
      "train loss:  1.6366064548492432\n",
      "train r2:  0.8851795767370161\n",
      "test loss:  6.754065990447998\n",
      "test r2:  -0.25411321967773426\n",
      "train loss:  1.6366395950317383\n",
      "train r2:  0.885569779100506\n",
      "test loss:  6.760658264160156\n",
      "test r2:  -0.2560800915433612\n",
      "train loss:  1.6366580724716187\n",
      "train r2:  0.8851491657211017\n",
      "test loss:  6.753835678100586\n",
      "test r2:  -0.25403301353222885\n",
      "train loss:  1.6366724967956543\n",
      "train r2:  0.8855865257777058\n",
      "test loss:  6.760679244995117\n",
      "test r2:  -0.2560757027302658\n",
      "train loss:  1.6366559267044067\n",
      "train r2:  0.8851502377276868\n",
      "test loss:  6.754251480102539\n",
      "test r2:  -0.25414715707795277\n",
      "train loss:  1.6366273164749146\n",
      "train r2:  0.885562902092757\n",
      "test loss:  6.759927272796631\n",
      "test r2:  -0.2558416792576279\n",
      "train loss:  1.636573314666748\n",
      "train r2:  0.8852015671246106\n",
      "test loss:  6.755443096160889\n",
      "test r2:  -0.25449342903054917\n",
      "train loss:  1.6365221738815308\n",
      "train r2:  0.8854905754117169\n",
      "test loss:  6.758520603179932\n",
      "test r2:  -0.2554117001647698\n",
      "train loss:  1.6364774703979492\n",
      "train r2:  0.8852950117022924\n",
      "test loss:  6.757056713104248\n",
      "test r2:  -0.25496437057558907\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853909936219028\n",
      "test loss:  6.757013320922852\n",
      "test r2:  -0.2549487660747558\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853943689857146\n",
      "test loss:  6.758481025695801\n",
      "test r2:  -0.25537744629692916\n",
      "train loss:  1.6364686489105225\n",
      "train r2:  0.885302641988676\n",
      "test loss:  6.755964756011963\n",
      "test r2:  -0.2546211708118218\n",
      "train loss:  1.636488914489746\n",
      "train r2:  0.8854639821142495\n",
      "test loss:  6.759271621704102\n",
      "test r2:  -0.25560135056414546\n",
      "train loss:  1.6365050077438354\n",
      "train r2:  0.8852543531488022\n",
      "test loss:  6.75565767288208\n",
      "test r2:  -0.2545148197979237\n",
      "train loss:  1.6365121603012085\n",
      "train r2:  0.8854865238990416\n",
      "test loss:  6.759282112121582\n",
      "test r2:  -0.25559337156646356\n",
      "train loss:  1.6365065574645996\n",
      "train r2:  0.8852561610780105\n",
      "test loss:  6.756086826324463\n",
      "test r2:  -0.25462949207593844\n",
      "train loss:  1.6364938020706177\n",
      "train r2:  0.8854624006588354\n",
      "test loss:  6.758654594421387\n",
      "test r2:  -0.2553958553884259\n",
      "train loss:  1.636476755142212\n",
      "train r2:  0.8852989041529329\n",
      "test loss:  6.756975173950195\n",
      "test r2:  -0.2548828357297772\n",
      "train loss:  1.6364657878875732\n",
      "train r2:  0.8854087962928343\n",
      "test loss:  6.757767200469971\n",
      "test r2:  -0.25512086380654697\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853580890015991\n",
      "test loss:  6.757904529571533\n",
      "test r2:  -0.25515071130843214\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853517707524541\n",
      "test loss:  6.757020473480225\n",
      "test r2:  -0.2548869029179457\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.8854081244827529\n",
      "test loss:  6.758539199829102\n",
      "test r2:  -0.2553319666725222\n",
      "train loss:  1.6364647150039673\n",
      "train r2:  0.8853130156920852\n",
      "test loss:  6.7566680908203125\n",
      "test r2:  -0.25476999468410444\n",
      "train loss:  1.6364681720733643\n",
      "train r2:  0.8854330539874705\n",
      "test loss:  6.7587361335754395\n",
      "test r2:  -0.25538143306145633\n",
      "train loss:  1.636468768119812\n",
      "train r2:  0.8853024577123688\n",
      "test loss:  6.756762981414795\n",
      "test r2:  -0.25478531831050133\n",
      "train loss:  1.6364668607711792\n",
      "train r2:  0.8854298953615848\n",
      "test loss:  6.758538722991943\n",
      "test r2:  -0.25531164882935475\n",
      "train loss:  1.6364631652832031\n",
      "train r2:  0.8853175354880282\n",
      "test loss:  6.757191181182861\n",
      "test r2:  -0.2548988849959173\n",
      "train loss:  1.6364600658416748\n",
      "train r2:  0.8854058847457908\n",
      "test loss:  6.758114814758301\n",
      "test r2:  -0.25517307672447864\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853473627872666\n",
      "test loss:  6.7577409744262695\n",
      "test r2:  -0.2550487737922351\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8853740271882979\n",
      "test loss:  6.757684707641602\n",
      "test r2:  -0.25503152286179787\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853777719781402\n",
      "test loss:  6.7581939697265625\n",
      "test r2:  -0.25517169938001527\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853478824249097\n",
      "test loss:  6.75741720199585\n",
      "test r2:  -0.25493845786374125\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853977757772182\n",
      "test loss:  6.758430480957031\n",
      "test r2:  -0.2552318338361259\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853351499393082\n",
      "test loss:  6.757378101348877\n",
      "test r2:  -0.25491365304664115\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.88540319363663\n",
      "test loss:  6.758445739746094\n",
      "test r2:  -0.2552258978193147\n",
      "train loss:  1.6364543437957764\n",
      "train r2:  0.8853365158603231\n",
      "test loss:  6.757530689239502\n",
      "test r2:  -0.25494600307843096\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853964088128187\n",
      "test loss:  6.7583160400390625\n",
      "test r2:  -0.2551760913186256\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853473023235825\n",
      "test loss:  6.757785320281982\n",
      "test r2:  -0.25500836951281247\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853832019946809\n",
      "test loss:  6.758134841918945\n",
      "test r2:  -0.2551102097693694\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853614720633116\n",
      "test loss:  6.758049488067627\n",
      "test r2:  -0.25507400999186625\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853693031764095\n",
      "test loss:  6.757981777191162\n",
      "test r2:  -0.25505229333936086\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853739233393911\n",
      "test loss:  6.758250713348389\n",
      "test r2:  -0.2551220796319267\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853591120804992\n",
      "test loss:  6.757908344268799\n",
      "test r2:  -0.25501817481492695\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853813717828803\n",
      "test loss:  6.75836181640625\n",
      "test r2:  -0.25514397718334836\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853545899220038\n",
      "test loss:  6.757922172546387\n",
      "test r2:  -0.2550097294764624\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853832918066873\n",
      "test loss:  6.758391857147217\n",
      "test r2:  -0.25514150080454256\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853552343405178\n",
      "test loss:  6.758011341094971\n",
      "test r2:  -0.25502273190198754\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853806487963278\n",
      "test loss:  6.758368968963623\n",
      "test r2:  -0.25512261298080396\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853594046743709\n",
      "test loss:  6.758141040802002\n",
      "test r2:  -0.2550472255275644\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853755559265971\n",
      "test loss:  6.758329391479492\n",
      "test r2:  -0.2550977000487362\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853648390716001\n",
      "test loss:  6.758275985717773\n",
      "test r2:  -0.25507297745357493\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853701754080074\n",
      "test loss:  6.758300304412842\n",
      "test r2:  -0.25507584640609116\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853696268828118\n",
      "test loss:  6.758386611938477\n",
      "test r2:  -0.2550923323677281\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853661551861898\n",
      "test loss:  6.758298873901367\n",
      "test r2:  -0.25506249565562933\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853725635825347\n",
      "test loss:  6.758462429046631\n",
      "test r2:  -0.2551016912618995\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853642561446736\n",
      "test loss:  6.758328437805176\n",
      "test r2:  -0.25505884788455324\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853734427344908\n",
      "test loss:  6.758503437042236\n",
      "test r2:  -0.2551018589541829\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853643657406851\n",
      "test loss:  6.758386135101318\n",
      "test r2:  -0.25506360219858126\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853725292920107\n",
      "test loss:  6.758520126342773\n",
      "test r2:  -0.2550945315014639\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853659998448502\n",
      "test loss:  6.758462905883789\n",
      "test r2:  -0.25507406034010516\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853704377675597\n",
      "test loss:  6.7585248947143555\n",
      "test r2:  -0.255083624592499\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853684753258232\n",
      "test loss:  6.758550643920898\n",
      "test r2:  -0.25508696857825286\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853678154875381\n",
      "test loss:  6.75852632522583\n",
      "test r2:  -0.2550710267388938\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.885371280509918\n",
      "test loss:  6.758643627166748\n",
      "test r2:  -0.2551007439235935\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853649866708838\n",
      "test loss:  6.758532524108887\n",
      "test r2:  -0.2550594566800064\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.885373882267822\n",
      "test loss:  6.758727550506592\n",
      "test r2:  -0.25511158239483755\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.885362792801609\n",
      "test loss:  6.758554458618164\n",
      "test r2:  -0.2550519594049019\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853755968101957\n",
      "test loss:  6.758798599243164\n",
      "test r2:  -0.2551184928800816\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853614408329711\n",
      "test loss:  6.758589267730713\n",
      "test r2:  -0.25504832228433605\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853765138044848\n",
      "test loss:  6.758857250213623\n",
      "test r2:  -0.2551218673017164\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853608484625937\n",
      "test loss:  6.758632183074951\n",
      "test r2:  -0.25504738852133424\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853768600415349\n",
      "test loss:  6.758908271789551\n",
      "test r2:  -0.255123390291907\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853606695337901\n",
      "test loss:  6.758679389953613\n",
      "test r2:  -0.255047676572576\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853769011751774\n",
      "test loss:  6.758954048156738\n",
      "test r2:  -0.2551236408001001\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853607299199422\n",
      "test loss:  6.75872802734375\n",
      "test r2:  -0.2550488014466945\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853767643978043\n",
      "test loss:  6.758996963500977\n",
      "test r2:  -0.25512317282077746\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853609505553298\n",
      "test loss:  6.758780002593994\n",
      "test r2:  -0.2550508778455891\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853764641532846\n",
      "test loss:  6.759037494659424\n",
      "test r2:  -0.25512177211892584\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853613538276122\n",
      "test loss:  6.758834362030029\n",
      "test r2:  -0.2550532809079209\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853760906302037\n",
      "test loss:  6.759080410003662\n",
      "test r2:  -0.25512113564033867\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853616243977886\n",
      "test loss:  6.758883476257324\n",
      "test r2:  -0.25505388863422684\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853760831296873\n",
      "test loss:  6.759133815765381\n",
      "test r2:  -0.25512319176230025\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853613004874169\n",
      "test loss:  6.758923530578613\n",
      "test r2:  -0.25505118978264796\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853767641009799\n",
      "test loss:  6.759200572967529\n",
      "test r2:  -0.25512889794929383\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853602006037283\n",
      "test loss:  6.758952617645264\n",
      "test r2:  -0.255045141558615\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.885378202322118\n",
      "test loss:  6.759277820587158\n",
      "test r2:  -0.2551380768047826\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853583661954791\n",
      "test loss:  6.758970260620117\n",
      "test r2:  -0.25503546448454717\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853803734006235\n",
      "test loss:  6.759368419647217\n",
      "test r2:  -0.2551509850716045\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853557042906334\n",
      "test loss:  6.75897216796875\n",
      "test r2:  -0.25502119835140635\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853835570656625\n",
      "test loss:  6.759477615356445\n",
      "test r2:  -0.2551703580752398\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.8853516518162902\n",
      "test loss:  6.758944988250732\n",
      "test r2:  -0.25499850664059376\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8853884925562021\n",
      "test loss:  6.759620666503906\n",
      "test r2:  -0.2551996493788067\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.8853455011607152\n",
      "test loss:  6.758877277374268\n",
      "test r2:  -0.2549637894059207\n",
      "train loss:  1.6364613771438599\n",
      "train r2:  0.8853959509418327\n",
      "test loss:  6.7598114013671875\n",
      "test r2:  -0.25524293333498993\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8853363231597676\n",
      "test loss:  6.758752346038818\n",
      "test r2:  -0.25491271625643663\n",
      "train loss:  1.6364643573760986\n",
      "train r2:  0.8854069866766974\n",
      "test loss:  6.760066032409668\n",
      "test r2:  -0.25530475474180014\n",
      "train loss:  1.6364645957946777\n",
      "train r2:  0.8853231885102458\n",
      "test loss:  6.758561611175537\n",
      "test r2:  -0.2548413651581385\n",
      "train loss:  1.636468768119812\n",
      "train r2:  0.885422281139401\n",
      "test loss:  6.760398864746094\n",
      "test r2:  -0.2553887020264891\n",
      "train loss:  1.6364719867706299\n",
      "train r2:  0.8853052900141237\n",
      "test loss:  6.758293628692627\n",
      "test r2:  -0.25474600413537773\n",
      "train loss:  1.6364787817001343\n",
      "train r2:  0.8854426544127786\n",
      "test loss:  6.7608256340026855\n",
      "test r2:  -0.25549947837653963\n",
      "train loss:  1.6364861726760864\n",
      "train r2:  0.8852815225539915\n",
      "test loss:  6.757933139801025\n",
      "test r2:  -0.25462162296284774\n",
      "train loss:  1.636498212814331\n",
      "train r2:  0.8854690819618901\n",
      "test loss:  6.761357307434082\n",
      "test r2:  -0.2556411478423162\n",
      "train loss:  1.636512279510498\n",
      "train r2:  0.8852509965394557\n",
      "test loss:  6.75747537612915\n",
      "test r2:  -0.2544668390199858\n",
      "train loss:  1.6365324258804321\n",
      "train r2:  0.8855017958339363\n",
      "test loss:  6.761983871459961\n",
      "test r2:  -0.25581102470923445\n",
      "train loss:  1.6365543603897095\n",
      "train r2:  0.8852142366298101\n",
      "test loss:  6.756948471069336\n",
      "test r2:  -0.254291477865358\n",
      "train loss:  1.6365840435028076\n",
      "train r2:  0.8855386845657651\n",
      "test loss:  6.7626237869262695\n",
      "test r2:  -0.255986133315687\n",
      "train loss:  1.636610746383667\n",
      "train r2:  0.8851761033958129\n",
      "test loss:  6.756486415863037\n",
      "test r2:  -0.25413616797981975\n",
      "train loss:  1.6366420984268188\n",
      "train r2:  0.885571152321133\n",
      "test loss:  6.763069152832031\n",
      "test r2:  -0.25610443502132196\n",
      "train loss:  1.6366567611694336\n",
      "train r2:  0.8851502611722812\n",
      "test loss:  6.756360054016113\n",
      "test r2:  -0.2540829610333839\n",
      "train loss:  1.6366673707962036\n",
      "train r2:  0.8855822654304863\n",
      "test loss:  6.762998580932617\n",
      "test r2:  -0.25607004105421227\n",
      "train loss:  1.6366448402404785\n",
      "train r2:  0.8851579366985376\n",
      "test loss:  6.756878852844238\n",
      "test r2:  -0.2542253776406451\n",
      "train loss:  1.636613368988037\n",
      "train r2:  0.8855527631593132\n",
      "test loss:  6.7621870040893555\n",
      "test r2:  -0.255814652969395\n",
      "train loss:  1.6365586519241333\n",
      "train r2:  0.8852139218125789\n",
      "test loss:  6.758106708526611\n",
      "test r2:  -0.25458074219598315\n",
      "train loss:  1.6365100145339966\n",
      "train r2:  0.8854784639193716\n",
      "test loss:  6.760815620422363\n",
      "test r2:  -0.2553894663275842\n",
      "train loss:  1.6364701986312866\n",
      "train r2:  0.8853062236964134\n",
      "test loss:  6.759669303894043\n",
      "test r2:  -0.2550340405481979\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853825440465533\n",
      "test loss:  6.759418964385986\n",
      "test r2:  -0.2549529065056637\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.885399935990706\n",
      "test loss:  6.761016368865967\n",
      "test r2:  -0.25541975565359665\n",
      "train loss:  1.636470079421997\n",
      "train r2:  0.885300022442274\n",
      "test loss:  6.758478164672852\n",
      "test r2:  -0.2546503095632151\n",
      "train loss:  1.636489748954773\n",
      "train r2:  0.8854642851722677\n",
      "test loss:  6.76176643371582\n",
      "test r2:  -0.2556257173339529\n",
      "train loss:  1.6365047693252563\n",
      "train r2:  0.885255652791357\n",
      "test loss:  6.7582316398620605\n",
      "test r2:  -0.2545556309964747\n",
      "train loss:  1.6365107297897339\n",
      "train r2:  0.885484382493545\n",
      "test loss:  6.761783123016357\n",
      "test r2:  -0.2556135062986862\n",
      "train loss:  1.6365047693252563\n",
      "train r2:  0.8852584190995194\n",
      "test loss:  6.7586750984191895\n",
      "test r2:  -0.25466925206913094\n",
      "train loss:  1.6364935636520386\n",
      "train r2:  0.8854605260395055\n",
      "test loss:  6.761195182800293\n",
      "test r2:  -0.25542188761128726\n",
      "train loss:  1.6364763975143433\n",
      "train r2:  0.8852999705477234\n",
      "test loss:  6.759552001953125\n",
      "test r2:  -0.254915730010832\n",
      "train loss:  1.6364662647247314\n",
      "train r2:  0.8854084282481697\n",
      "test loss:  6.760348320007324\n",
      "test r2:  -0.2551535230799973\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853577553084763\n",
      "test loss:  6.760471820831299\n",
      "test r2:  -0.25517773132924915\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853526855254721\n",
      "test loss:  6.759632587432861\n",
      "test r2:  -0.2549243440124149\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8854068224656674\n",
      "test loss:  6.7611083984375\n",
      "test r2:  -0.25535576065789023\n",
      "train loss:  1.6364628076553345\n",
      "train r2:  0.8853146673086365\n",
      "test loss:  6.759302139282227\n",
      "test r2:  -0.25480926048542973\n",
      "train loss:  1.6364668607711792\n",
      "train r2:  0.8854314510320519\n",
      "test loss:  6.761322021484375\n",
      "test r2:  -0.25540601340266833\n",
      "train loss:  1.6364679336547852\n",
      "train r2:  0.8853039560472206\n",
      "test loss:  6.759405136108398\n",
      "test r2:  -0.25482199548893236\n",
      "train loss:  1.6364668607711792\n",
      "train r2:  0.8854288796494351\n",
      "test loss:  6.7611613273620605\n",
      "test r2:  -0.25534194231725893\n",
      "train loss:  1.6364636421203613\n",
      "train r2:  0.885317852146811\n",
      "test loss:  6.759823799133301\n",
      "test r2:  -0.25492744924650035\n",
      "train loss:  1.6364611387252808\n",
      "train r2:  0.8854065964179539\n",
      "test loss:  6.7607951164245605\n",
      "test r2:  -0.25521448712892725\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853453642819084\n",
      "test loss:  6.760351181030273\n",
      "test r2:  -0.2550658588286867\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.885377251628415\n",
      "test loss:  6.760417461395264\n",
      "test r2:  -0.25508286969662364\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853737239452666\n",
      "test loss:  6.760803699493408\n",
      "test r2:  -0.25518385252156617\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853522338820516\n",
      "test loss:  6.7601704597473145\n",
      "test r2:  -0.2549900881291258\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853937024327637\n",
      "test loss:  6.761074542999268\n",
      "test r2:  -0.25524898591753953\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853384455952478\n",
      "test loss:  6.76011848449707\n",
      "test r2:  -0.25495603145957846\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.885401121107118\n",
      "test loss:  6.761149883270264\n",
      "test r2:  -0.25525575930613886\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853371383459098\n",
      "test loss:  6.760246276855469\n",
      "test r2:  -0.25497552961490144\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853971529788738\n",
      "test loss:  6.76107931137085\n",
      "test r2:  -0.2552182143732913\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853453344535813\n",
      "test loss:  6.760483264923096\n",
      "test r2:  -0.255027975615153\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853860912183014\n",
      "test loss:  6.760941982269287\n",
      "test r2:  -0.2551603973494103\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853578736082488\n",
      "test loss:  6.760749340057373\n",
      "test r2:  -0.25508890616413193\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.885373257598759\n",
      "test loss:  6.7608137130737305\n",
      "test r2:  -0.2551045436160051\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853699677063596\n",
      "test loss:  6.760973930358887\n",
      "test r2:  -0.25513870690944884\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853627534564774\n",
      "test loss:  6.760745048522949\n",
      "test r2:  -0.2550663017875032\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853782774378898\n",
      "test loss:  6.761120796203613\n",
      "test r2:  -0.2551661511810517\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853570558670788\n",
      "test loss:  6.760758876800537\n",
      "test r2:  -0.2550521417744076\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853814971231834\n",
      "test loss:  6.7611918449401855\n",
      "test r2:  -0.2551704477730177\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853563010709615\n",
      "test loss:  6.760843276977539\n",
      "test r2:  -0.25505836831665607\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853803584592974\n",
      "test loss:  6.761213302612305\n",
      "test r2:  -0.2551588394132571\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853589560900526\n",
      "test loss:  6.7609710693359375\n",
      "test r2:  -0.25507676747040753\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853766138225927\n",
      "test loss:  6.7612104415893555\n",
      "test r2:  -0.2551392921672746\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853633218627429\n",
      "test loss:  6.761114120483398\n",
      "test r2:  -0.25509915598986854\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853720258185234\n",
      "test loss:  6.761209487915039\n",
      "test r2:  -0.2551197859462382\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853676441151332\n",
      "test loss:  6.761244297027588\n",
      "test r2:  -0.2551182015271818\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853681016382178\n",
      "test loss:  6.761224746704102\n",
      "test r2:  -0.255105768686847\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853708168779149\n",
      "test loss:  6.761347770690918\n",
      "test r2:  -0.255129896401856\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853657406738802\n",
      "test loss:  6.761266708374023\n",
      "test r2:  -0.2550998409979153\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853722126407253\n",
      "test loss:  6.761417865753174\n",
      "test r2:  -0.2551328005584048\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853652977370464\n",
      "test loss:  6.761335849761963\n",
      "test r2:  -0.2551026991606451\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853717903512713\n",
      "test loss:  6.761460781097412\n",
      "test r2:  -0.25512771898287223\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853665451797336\n",
      "test loss:  6.761428356170654\n",
      "test r2:  -0.25511197113026784\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853699830962781\n",
      "test loss:  6.76148796081543\n",
      "test r2:  -0.25511769097449255\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853688662795973\n",
      "test loss:  6.761534214019775\n",
      "test r2:  -0.255124595941953\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853674680672248\n",
      "test loss:  6.7615132331848145\n",
      "test r2:  -0.25510630163837833\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853715006586678\n",
      "test loss:  6.761641025543213\n",
      "test r2:  -0.25513700889860447\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853649897662438\n",
      "test loss:  6.7615461349487305\n",
      "test r2:  -0.2550965920925432\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.885373749947337\n",
      "test loss:  6.761744499206543\n",
      "test r2:  -0.25514747663378046\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853629233503626\n",
      "test loss:  6.7615885734558105\n",
      "test r2:  -0.25508885592649455\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853755851649334\n",
      "test loss:  6.761842727661133\n",
      "test r2:  -0.25515624131140857\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853612457550242\n",
      "test loss:  6.761636734008789\n",
      "test r2:  -0.2550828737561066\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853770269718977\n",
      "test loss:  6.761935234069824\n",
      "test r2:  -0.2551634146471484\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853599189020714\n",
      "test loss:  6.76168966293335\n",
      "test r2:  -0.25507820357291666\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853782348112159\n",
      "test loss:  6.76202392578125\n",
      "test r2:  -0.2551694539083673\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853588075550145\n",
      "test loss:  6.761744499206543\n",
      "test r2:  -0.2550745314039795\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853791922343552\n",
      "test loss:  6.762104511260986\n",
      "test r2:  -0.2551738838037576\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853580427221318\n",
      "test loss:  6.761804580688477\n",
      "test r2:  -0.2550726172574156\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853797539644435\n",
      "test loss:  6.762179374694824\n",
      "test r2:  -0.25517658359749706\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853576088867219\n",
      "test loss:  6.761867046356201\n",
      "test r2:  -0.25507134868333603\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853802286906606\n",
      "test loss:  6.762257099151611\n",
      "test r2:  -0.25518036503247643\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853569769285816\n",
      "test loss:  6.761923313140869\n",
      "test r2:  -0.25506794911011155\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853811072114268\n",
      "test loss:  6.762345790863037\n",
      "test r2:  -0.2551869622206733\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853557616084563\n",
      "test loss:  6.761970043182373\n",
      "test r2:  -0.25506104650624506\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853827600578807\n",
      "test loss:  6.762448310852051\n",
      "test r2:  -0.2551975290916175\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853536731473638\n",
      "test loss:  6.762004375457764\n",
      "test r2:  -0.25505031406083045\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853852507498053\n",
      "test loss:  6.762566089630127\n",
      "test r2:  -0.25521231524820887\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853506767472086\n",
      "test loss:  6.762024402618408\n",
      "test r2:  -0.25503462886190076\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.885388727251812\n",
      "test loss:  6.762704849243164\n",
      "test r2:  -0.25523329453312105\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853463226468334\n",
      "test loss:  6.762017726898193\n",
      "test r2:  -0.25501096097038123\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.8853939631739062\n",
      "test loss:  6.762875556945801\n",
      "test r2:  -0.25526398910695103\n",
      "train loss:  1.6364587545394897\n",
      "train r2:  0.8853399275167791\n",
      "test loss:  6.761971950531006\n",
      "test r2:  -0.2549758730487963\n",
      "train loss:  1.6364614963531494\n",
      "train r2:  0.8854015989794896\n",
      "test loss:  6.763092517852783\n",
      "test r2:  -0.2553079645393177\n",
      "train loss:  1.636461615562439\n",
      "train r2:  0.8853306512409239\n",
      "test loss:  6.761874675750732\n",
      "test r2:  -0.25492558896693995\n",
      "train loss:  1.6364651918411255\n",
      "train r2:  0.8854125024028506\n",
      "test loss:  6.763367176055908\n",
      "test r2:  -0.2553688772404994\n",
      "train loss:  1.6364662647247314\n",
      "train r2:  0.8853177464486378\n",
      "test loss:  6.761715888977051\n",
      "test r2:  -0.2548565667133029\n",
      "train loss:  1.6364706754684448\n",
      "train r2:  0.8854273582393893\n",
      "test loss:  6.763711929321289\n",
      "test r2:  -0.2554497492845782\n",
      "train loss:  1.6364741325378418\n",
      "train r2:  0.8853005706344704\n",
      "test loss:  6.761491775512695\n",
      "test r2:  -0.25476722802564256\n",
      "train loss:  1.6364810466766357\n",
      "train r2:  0.8854465157178334\n",
      "test loss:  6.76413106918335\n",
      "test r2:  -0.2555522828401944\n",
      "train loss:  1.6364881992340088\n",
      "train r2:  0.8852786367481906\n",
      "test loss:  6.761197090148926\n",
      "test r2:  -0.2546553049146747\n",
      "train loss:  1.636499285697937\n",
      "train r2:  0.8854703701543868\n",
      "test loss:  6.764627456665039\n",
      "test r2:  -0.2556775711617396\n",
      "train loss:  1.6365113258361816\n",
      "train r2:  0.8852517252521144\n",
      "test loss:  6.760834217071533\n",
      "test r2:  -0.25452231627833655\n",
      "train loss:  1.6365286111831665\n",
      "train r2:  0.8854985589504987\n",
      "test loss:  6.765183925628662\n",
      "test r2:  -0.2558206146948996\n",
      "train loss:  1.6365461349487305\n",
      "train r2:  0.8852208520737646\n",
      "test loss:  6.760438919067383\n",
      "test r2:  -0.2543792394336577\n",
      "train loss:  1.6365692615509033\n",
      "train r2:  0.8855287594275232\n",
      "test loss:  6.765727519989014\n",
      "test r2:  -0.2559601690144062\n",
      "train loss:  1.6365880966186523\n",
      "train r2:  0.885190588136298\n",
      "test loss:  6.760122299194336\n",
      "test r2:  -0.2542599516218593\n",
      "train loss:  1.6366103887557983\n",
      "train r2:  0.8855538533855838\n",
      "test loss:  6.766096115112305\n",
      "test r2:  -0.2560483915040175\n",
      "train loss:  1.636619210243225\n",
      "train r2:  0.8851714836985813\n",
      "test loss:  6.760081768035889\n",
      "test r2:  -0.2542251726060343\n",
      "train loss:  1.636625051498413\n",
      "train r2:  0.8855612566002744\n",
      "test loss:  6.766056537628174\n",
      "test r2:  -0.25601541966676655\n",
      "train loss:  1.6366076469421387\n",
      "train r2:  0.8851788773022313\n",
      "test loss:  6.76054048538208\n",
      "test r2:  -0.254341887344683\n",
      "train loss:  1.636584758758545\n",
      "train r2:  0.8855371079672061\n",
      "test loss:  6.765453815460205\n",
      "test r2:  -0.25581338613216786\n",
      "train loss:  1.6365450620651245\n",
      "train r2:  0.8852232028581825\n",
      "test loss:  6.7615461349487305\n",
      "test r2:  -0.25462326204359975\n",
      "train loss:  1.636508584022522\n",
      "train r2:  0.8854782786694174\n",
      "test loss:  6.764400959014893\n",
      "test r2:  -0.2554746414522475\n",
      "train loss:  1.636475682258606\n",
      "train r2:  0.8852968562183949\n",
      "test loss:  6.762852191925049\n",
      "test r2:  -0.254992907478939\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8854002525332022\n",
      "test loss:  6.763267993927002\n",
      "test r2:  -0.2551087067488853\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853756631182891\n",
      "test loss:  6.764059066772461\n",
      "test r2:  -0.2553303991591025\n",
      "train loss:  1.6364572048187256\n",
      "train r2:  0.8853283127777113\n",
      "test loss:  6.76242208480835\n",
      "test r2:  -0.254826471197902\n",
      "train loss:  1.6364691257476807\n",
      "train r2:  0.8854359535769388\n",
      "test loss:  6.764869213104248\n",
      "test r2:  -0.2555480621494992\n",
      "train loss:  1.6364818811416626\n",
      "train r2:  0.885281657611966\n",
      "test loss:  6.7620530128479\n",
      "test r2:  -0.25468770604843183\n",
      "train loss:  1.6364914178848267\n",
      "train r2:  0.8854655644753257\n",
      "test loss:  6.765162467956543\n",
      "test r2:  -0.2556109512986331\n",
      "train loss:  1.6364942789077759\n",
      "train r2:  0.8852682473348776\n",
      "test loss:  6.762197971343994\n",
      "test r2:  -0.25470396281928176\n",
      "train loss:  1.6364920139312744\n",
      "train r2:  0.8854623312452448\n",
      "test loss:  6.764969348907471\n",
      "test r2:  -0.2555292696478271\n",
      "train loss:  1.6364834308624268\n",
      "train r2:  0.8852860815373736\n",
      "test loss:  6.7627410888671875\n",
      "test r2:  -0.2548422253179219\n",
      "train loss:  1.6364755630493164\n",
      "train r2:  0.8854332459840513\n",
      "test loss:  6.764463901519775\n",
      "test r2:  -0.2553550648682501\n",
      "train loss:  1.6364647150039673\n",
      "train r2:  0.8853238162128727\n",
      "test loss:  6.763467311859131\n",
      "test r2:  -0.2550378838585452\n",
      "train loss:  1.6364599466323853\n",
      "train r2:  0.8853918478516196\n",
      "test loss:  6.763883590698242\n",
      "test r2:  -0.2551586006615887\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853661679906041\n",
      "test loss:  6.76414680480957\n",
      "test r2:  -0.25522155873181296\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853528669440289\n",
      "test loss:  6.763440132141113\n",
      "test r2:  -0.25500229010736275\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853997794452557\n",
      "test loss:  6.764627456665039\n",
      "test r2:  -0.25534432724914535\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853267364613271\n",
      "test loss:  6.763251781463623\n",
      "test r2:  -0.25491984082512875\n",
      "train loss:  1.6364599466323853\n",
      "train r2:  0.8854175657875174\n",
      "test loss:  6.764855861663818\n",
      "test r2:  -0.25538888150397177\n",
      "train loss:  1.6364610195159912\n",
      "train r2:  0.885317382375549\n",
      "test loss:  6.763331890106201\n",
      "test r2:  -0.2549158124375883\n",
      "train loss:  1.6364613771438599\n",
      "train r2:  0.8854186601704305\n",
      "test loss:  6.7648539543151855\n",
      "test r2:  -0.25536183624963793\n",
      "train loss:  1.6364604234695435\n",
      "train r2:  0.8853234020867602\n",
      "test loss:  6.763619899749756\n",
      "test r2:  -0.25497280095827946\n",
      "train loss:  1.6364598274230957\n",
      "train r2:  0.8854067546772044\n",
      "test loss:  6.764701843261719\n",
      "test r2:  -0.255289025720117\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853392967462472\n",
      "test loss:  6.764004230499268\n",
      "test r2:  -0.2550594241959503\n",
      "train loss:  1.6364576816558838\n",
      "train r2:  0.8853885243899232\n",
      "test loss:  6.764503002166748\n",
      "test r2:  -0.25520239380637655\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853580791332291\n",
      "test loss:  6.764373302459717\n",
      "test r2:  -0.2551443567511471\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853706593389674\n",
      "test loss:  6.76434326171875\n",
      "test r2:  -0.25512859411481514\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853740986976572\n",
      "test loss:  6.764660358428955\n",
      "test r2:  -0.2552068407917396\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853575277627332\n",
      "test loss:  6.764274597167969\n",
      "test r2:  -0.25508216958123797\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853842689719592\n",
      "test loss:  6.7648515701293945\n",
      "test r2:  -0.25524080702206975\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853505102472905\n",
      "test loss:  6.764298915863037\n",
      "test r2:  -0.25506272391244855\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853886651612313\n",
      "test loss:  6.764968395233154\n",
      "test r2:  -0.25525048294096697\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853486453147681\n",
      "test loss:  6.764401435852051\n",
      "test r2:  -0.25506572681970896\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853882942413794\n",
      "test loss:  6.765026569366455\n",
      "test r2:  -0.25524154364003104\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853508183929721\n",
      "test loss:  6.764556407928467\n",
      "test r2:  -0.25508332895072083\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853847617902092\n",
      "test loss:  6.765056133270264\n",
      "test r2:  -0.25522268015270844\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.885355072628548\n",
      "test loss:  6.764730930328369\n",
      "test r2:  -0.2551068366790483\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853799976591205\n",
      "test loss:  6.765077114105225\n",
      "test r2:  -0.255201393420337\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853598992312406\n",
      "test loss:  6.764899730682373\n",
      "test r2:  -0.255129515486358\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853753854344057\n",
      "test loss:  6.765109539031982\n",
      "test r2:  -0.2551835346366069\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853639450782845\n",
      "test loss:  6.7650465965271\n",
      "test r2:  -0.25514671102185327\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853719955330668\n",
      "test loss:  6.765161037445068\n",
      "test r2:  -0.25517139494746965\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853667710849256\n",
      "test loss:  6.765173435211182\n",
      "test r2:  -0.2551575170541007\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853699231742402\n",
      "test loss:  6.7652363777160645\n",
      "test r2:  -0.25516621503905323\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853681565840857\n",
      "test loss:  6.76527738571167\n",
      "test r2:  -0.25516148078894796\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853693232836781\n",
      "test loss:  6.7653350830078125\n",
      "test r2:  -0.2551667352263578\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853683200139075\n",
      "test loss:  6.765373229980469\n",
      "test r2:  -0.2551620204748788\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853694823188742\n",
      "test loss:  6.765443325042725\n",
      "test r2:  -0.2551697727969324\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853679522797501\n",
      "test loss:  6.765466213226318\n",
      "test r2:  -0.25516086454633014\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853699698511226\n",
      "test loss:  6.765556812286377\n",
      "test r2:  -0.25517378480316877\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853673735102993\n",
      "test loss:  6.765561103820801\n",
      "test r2:  -0.25515986596678086\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853704782172442\n",
      "test loss:  6.765668869018555\n",
      "test r2:  -0.2551766367066759\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853670244341013\n",
      "test loss:  6.7656636238098145\n",
      "test r2:  -0.25516089859928837\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853705174260622\n",
      "test loss:  6.765770435333252\n",
      "test r2:  -0.2551772766794498\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853671626834085\n",
      "test loss:  6.765770435333252\n",
      "test r2:  -0.2551633927152901\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853702276594947\n",
      "test loss:  6.765867710113525\n",
      "test r2:  -0.25517644397340455\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853675949284332\n",
      "test loss:  6.76588249206543\n",
      "test r2:  -0.2551675693866071\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853696203058599\n",
      "test loss:  6.765957832336426\n",
      "test r2:  -0.25517402515651\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853683845525933\n",
      "test loss:  6.765995979309082\n",
      "test r2:  -0.25517249751286575\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853687956241005\n",
      "test loss:  6.766048908233643\n",
      "test r2:  -0.25517141128781007\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853691839385772\n",
      "test loss:  6.766111850738525\n",
      "test r2:  -0.2551778666685598\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853679432366889\n",
      "test loss:  6.766136169433594\n",
      "test r2:  -0.2551674566837274\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.88537031291487\n",
      "test loss:  6.766238212585449\n",
      "test r2:  -0.2551860612202794\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853664516794038\n",
      "test loss:  6.7662129402160645\n",
      "test r2:  -0.25515967553156194\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.885372226833201\n",
      "test loss:  6.766381740570068\n",
      "test r2:  -0.25519837534429235\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853640595706289\n",
      "test loss:  6.766278266906738\n",
      "test r2:  -0.2551477021255635\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853750827990878\n",
      "test loss:  6.766543388366699\n",
      "test r2:  -0.2552156781181363\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853606717614534\n",
      "test loss:  6.766329765319824\n",
      "test r2:  -0.2551311979310722\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853788702553068\n",
      "test loss:  6.766718864440918\n",
      "test r2:  -0.255236678609853\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853564365331196\n",
      "test loss:  6.766366958618164\n",
      "test r2:  -0.2551100870672989\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853836384991018\n",
      "test loss:  6.766915798187256\n",
      "test r2:  -0.25526435555004423\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853507978323822\n",
      "test loss:  6.766378402709961\n",
      "test r2:  -0.2550808314552302\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853901858258004\n",
      "test loss:  6.767146110534668\n",
      "test r2:  -0.2553014246467695\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853431424269541\n",
      "test loss:  6.766353130340576\n",
      "test r2:  -0.25504079140687175\n",
      "train loss:  1.6364588737487793\n",
      "train r2:  0.8853990058408012\n",
      "test loss:  6.7674174308776855\n",
      "test r2:  -0.2553507285990373\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.8853328084777295\n",
      "test loss:  6.766278266906738\n",
      "test r2:  -0.25498552413971565\n",
      "train loss:  1.6364630460739136\n",
      "train r2:  0.8854110574680459\n",
      "test loss:  6.7677531242370605\n",
      "test r2:  -0.2554189617727576\n",
      "train loss:  1.6364649534225464\n",
      "train r2:  0.8853184614939215\n",
      "test loss:  6.766134262084961\n",
      "test r2:  -0.2549085559090747\n",
      "train loss:  1.6364701986312866\n",
      "train r2:  0.8854276751246813\n",
      "test loss:  6.768172740936279\n",
      "test r2:  -0.2555113072837889\n",
      "train loss:  1.6364750862121582\n",
      "train r2:  0.8852988494311153\n",
      "test loss:  6.765902519226074\n",
      "test r2:  -0.2548046804219417\n",
      "train loss:  1.636483907699585\n",
      "train r2:  0.885449975778133\n",
      "test loss:  6.7686967849731445\n",
      "test r2:  -0.25563459205592975\n",
      "train loss:  1.6364940404891968\n",
      "train r2:  0.8852725049522172\n",
      "test loss:  6.765559673309326\n",
      "test r2:  -0.25466653527144234\n",
      "train loss:  1.6365089416503906\n",
      "train r2:  0.8854794767839657\n",
      "test loss:  6.769343852996826\n",
      "test r2:  -0.2557944147346949\n",
      "train loss:  1.636526346206665\n",
      "train r2:  0.8852381919970046\n",
      "test loss:  6.7651047706604\n",
      "test r2:  -0.2544935384727345\n",
      "train loss:  1.636551856994629\n",
      "train r2:  0.8855161293185347\n",
      "test loss:  6.7700886726379395\n",
      "test r2:  -0.2559829626546981\n",
      "train loss:  1.63657808303833\n",
      "train r2:  0.8851974269297925\n",
      "test loss:  6.764596939086914\n",
      "test r2:  -0.254304129749821\n",
      "train loss:  1.6366126537322998\n",
      "train r2:  0.8855560385611648\n",
      "test loss:  6.770816326141357\n",
      "test r2:  -0.25616659428689426\n",
      "train loss:  1.6366407871246338\n",
      "train r2:  0.8851575310414558\n",
      "test loss:  6.764218330383301\n",
      "test r2:  -0.25415414409120896\n",
      "train loss:  1.6366714239120483\n",
      "train r2:  0.885587562280228\n",
      "test loss:  6.771247863769531\n",
      "test r2:  -0.256261817119285\n",
      "train loss:  1.6366777420043945\n",
      "train r2:  0.8851369245219023\n",
      "test loss:  6.764323711395264\n",
      "test r2:  -0.2541508036447018\n",
      "train loss:  1.6366734504699707\n",
      "train r2:  0.8855885204691116\n",
      "test loss:  6.770995616912842\n",
      "test r2:  -0.25615183798040597\n",
      "train loss:  1.6366336345672607\n",
      "train r2:  0.8851614214816036\n",
      "test loss:  6.765235424041748\n",
      "test r2:  -0.25439205615934424\n",
      "train loss:  1.6365845203399658\n",
      "train r2:  0.8855385703230295\n",
      "test loss:  6.7699127197265625\n",
      "test r2:  -0.2557913427220089\n",
      "train loss:  1.6365242004394531\n",
      "train r2:  0.8852404390332781\n",
      "test loss:  6.766852855682373\n",
      "test r2:  -0.2548451614587721\n",
      "train loss:  1.636479377746582\n",
      "train r2:  0.8854435960734091\n",
      "test loss:  6.768394470214844\n",
      "test r2:  -0.2552964743469679\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853476267304824\n",
      "test loss:  6.7686004638671875\n",
      "test r2:  -0.2553347896885687\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853396000457159\n",
      "test loss:  6.767100811004639\n",
      "test r2:  -0.2548656016599169\n",
      "train loss:  1.636471152305603\n",
      "train r2:  0.885439831587156\n",
      "test loss:  6.769867420196533\n",
      "test r2:  -0.25567777106362377\n",
      "train loss:  1.6364930868148804\n",
      "train r2:  0.8852660481301721\n",
      "test loss:  6.766497611999512\n",
      "test r2:  -0.25464134946101336\n",
      "train loss:  1.636510968208313\n",
      "train r2:  0.8854875452558191\n",
      "test loss:  6.770335674285889\n",
      "test r2:  -0.2557805915562743\n",
      "train loss:  1.6365158557891846\n",
      "train r2:  0.8852440935953994\n",
      "test loss:  6.766721725463867\n",
      "test r2:  -0.254667605946753\n",
      "train loss:  1.636509656906128\n",
      "train r2:  0.8854823296648604\n",
      "test loss:  6.770009994506836\n",
      "test r2:  -0.25564548042071755\n",
      "train loss:  1.63649320602417\n",
      "train r2:  0.885273636365447\n",
      "test loss:  6.767601490020752\n",
      "test r2:  -0.2548937087824086\n",
      "train loss:  1.6364774703979492\n",
      "train r2:  0.8854348534868143\n",
      "test loss:  6.76921272277832\n",
      "test r2:  -0.2553688872929425\n",
      "train loss:  1.6364620923995972\n",
      "train r2:  0.885333600819344\n",
      "test loss:  6.768709182739258\n",
      "test r2:  -0.2551911083618932\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8853718661145299\n",
      "test loss:  6.768409252166748\n",
      "test r2:  -0.25508947793677317\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8853937013300234\n",
      "test loss:  6.7696146965026855\n",
      "test r2:  -0.2554295981710517\n",
      "train loss:  1.6364625692367554\n",
      "train r2:  0.8853211277492106\n",
      "test loss:  6.767958164215088\n",
      "test r2:  -0.2549154993904186\n",
      "train loss:  1.6364675760269165\n",
      "train r2:  0.8854310813391231\n",
      "test loss:  6.770074844360352\n",
      "test r2:  -0.2555333525823653\n",
      "train loss:  1.6364707946777344\n",
      "train r2:  0.885299131115414\n",
      "test loss:  6.768003940582275\n",
      "test r2:  -0.2548890178593981\n",
      "train loss:  1.6364703178405762\n",
      "train r2:  0.8854370766229469\n",
      "test loss:  6.770068645477295\n",
      "test r2:  -0.2554940733204336\n",
      "train loss:  1.6364669799804688\n",
      "train r2:  0.8853079298699359\n",
      "test loss:  6.768474102020264\n",
      "test r2:  -0.2549882440342448\n",
      "train loss:  1.636462688446045\n",
      "train r2:  0.88541636044214\n",
      "test loss:  6.769757270812988\n",
      "test r2:  -0.2553594582201013\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.8853372130884025\n",
      "test loss:  6.769147872924805\n",
      "test r2:  -0.2551475560538159\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853827584896945\n",
      "test loss:  6.769376754760742\n",
      "test r2:  -0.25520202185369256\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.885371299311464\n",
      "test loss:  6.769775867462158\n",
      "test r2:  -0.2552949228748551\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853516291386366\n",
      "test loss:  6.769130229949951\n",
      "test r2:  -0.25508484066775594\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853966870354055\n",
      "test loss:  6.7701921463012695\n",
      "test r2:  -0.25538013655026925\n",
      "train loss:  1.6364567279815674\n",
      "train r2:  0.8853337856722177\n",
      "test loss:  6.769129753112793\n",
      "test r2:  -0.255041822540115\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8854062705022967\n",
      "test loss:  6.770351886749268\n",
      "test r2:  -0.2553885704107608\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853323386839473\n",
      "test loss:  6.769364833831787\n",
      "test r2:  -0.25506958207501307\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.885400762547239\n",
      "test loss:  6.770319938659668\n",
      "test r2:  -0.25533817184411234\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853434988746463\n",
      "test loss:  6.769749164581299\n",
      "test r2:  -0.2551413931770403\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853858102811767\n",
      "test loss:  6.770203113555908\n",
      "test r2:  -0.255261164595737\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853603719525207\n",
      "test loss:  6.7701640129089355\n",
      "test r2:  -0.2552222259903745\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853689210990249\n",
      "test loss:  6.770117282867432\n",
      "test r2:  -0.25519208254767767\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853755020225742\n",
      "test loss:  6.770504474639893\n",
      "test r2:  -0.25528156432084637\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853566386323833\n",
      "test loss:  6.770132064819336\n",
      "test r2:  -0.25515276022901023\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853843023235612\n",
      "test loss:  6.770728588104248\n",
      "test r2:  -0.25530645012278774\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853516586352841\n",
      "test loss:  6.770263195037842\n",
      "test r2:  -0.25514763284809083\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853858135113815\n",
      "test loss:  6.7708516120910645\n",
      "test r2:  -0.25530060486470885\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853533540328986\n",
      "test loss:  6.770486831665039\n",
      "test r2:  -0.25516895233897396\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853816975188729\n",
      "test loss:  6.770915508270264\n",
      "test r2:  -0.2552749663502467\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853592528441887\n",
      "test loss:  6.770758152008057\n",
      "test r2:  -0.2552030247180239\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853748565782112\n",
      "test loss:  6.770968437194824\n",
      "test r2:  -0.25524419068097415\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853662762233485\n",
      "test loss:  6.771029949188232\n",
      "test r2:  -0.2552365460929278\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853681106202247\n",
      "test loss:  6.771039009094238\n",
      "test r2:  -0.255218697959708\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853721157445202\n",
      "test loss:  6.771267890930176\n",
      "test r2:  -0.25526036298508514\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853634199419854\n",
      "test loss:  6.771152019500732\n",
      "test r2:  -0.2552055657618122\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853753187070139\n",
      "test loss:  6.771458625793457\n",
      "test r2:  -0.2552708748707222\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853615778680889\n",
      "test loss:  6.771305561065674\n",
      "test r2:  -0.25520497479367443\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853758576442112\n",
      "test loss:  6.771609783172607\n",
      "test r2:  -0.25526970430591467\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853622844675832\n",
      "test loss:  6.7714948654174805\n",
      "test r2:  -0.2552148986154861\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853741587776996\n",
      "test loss:  6.771731376647949\n",
      "test r2:  -0.2552592655933792\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853649156022992\n",
      "test loss:  6.771711826324463\n",
      "test r2:  -0.25523204504803276\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853709201647275\n",
      "test loss:  6.771841049194336\n",
      "test r2:  -0.25524401907667627\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853686590230757\n",
      "test loss:  6.771942138671875\n",
      "test r2:  -0.25525217926411514\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853671094144415\n",
      "test loss:  6.77195405960083\n",
      "test r2:  -0.25522850340929115\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853723912441399\n",
      "test loss:  6.772172451019287\n",
      "test r2:  -0.25527052376846004\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853636235923438\n",
      "test loss:  6.772082328796387\n",
      "test r2:  -0.2552167846160285\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853753658153174\n",
      "test loss:  6.772386074066162\n",
      "test r2:  -0.2552837557780221\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853612739566914\n",
      "test loss:  6.772233486175537\n",
      "test r2:  -0.2552113228213775\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853770117531354\n",
      "test loss:  6.772580146789551\n",
      "test r2:  -0.25529061174084644\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853602450603049\n",
      "test loss:  6.772405624389648\n",
      "test r2:  -0.2552119832963833\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853773240938152\n",
      "test loss:  6.772753715515137\n",
      "test r2:  -0.2552914739569976\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853605593649259\n",
      "test loss:  6.772595405578613\n",
      "test r2:  -0.2552181692397062\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853764414343821\n",
      "test loss:  6.772911548614502\n",
      "test r2:  -0.2552879321134385\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853617684399069\n",
      "test loss:  6.772792339324951\n",
      "test r2:  -0.25522637797298975\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853751542176328\n",
      "test loss:  6.773066997528076\n",
      "test r2:  -0.25528382147118833\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853631083264155\n",
      "test loss:  6.772989273071289\n",
      "test r2:  -0.25523491797400855\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853737867024576\n",
      "test loss:  6.773221015930176\n",
      "test r2:  -0.25527922283075255\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853645745513586\n",
      "test loss:  6.773190021514893\n",
      "test r2:  -0.25524430714839963\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853722790547499\n",
      "test loss:  6.773375034332275\n",
      "test r2:  -0.25527425545736393\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853661017483525\n",
      "test loss:  6.7733917236328125\n",
      "test r2:  -0.2552532801704894\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853708357435228\n",
      "test loss:  6.773533821105957\n",
      "test r2:  -0.2552701005458584\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853674945492158\n",
      "test loss:  6.773592948913574\n",
      "test r2:  -0.25526192203544573\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853694759968873\n",
      "test loss:  6.773695468902588\n",
      "test r2:  -0.2552663478918349\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.885368795167257\n",
      "test loss:  6.773791790008545\n",
      "test r2:  -0.25526958743704675\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853683151071126\n",
      "test loss:  6.773859977722168\n",
      "test r2:  -0.25526378609593703\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.885369819681902\n",
      "test loss:  6.77398681640625\n",
      "test r2:  -0.25527648587082896\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.885367319065779\n",
      "test loss:  6.774023056030273\n",
      "test r2:  -0.25526155558825625\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853707382817564\n",
      "test loss:  6.774175643920898\n",
      "test r2:  -0.25528281965961885\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853664573036211\n",
      "test loss:  6.77418327331543\n",
      "test r2:  -0.2552601211242871\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853715286800397\n",
      "test loss:  6.774354934692383\n",
      "test r2:  -0.2552887205911918\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853656640925012\n",
      "test loss:  6.774333477020264\n",
      "test r2:  -0.2552582683615292\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853723790832055\n",
      "test loss:  6.774525165557861\n",
      "test r2:  -0.25529487650417226\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853647902520896\n",
      "test loss:  6.774467468261719\n",
      "test r2:  -0.2552558562134928\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853733251855663\n",
      "test loss:  6.774675369262695\n",
      "test r2:  -0.25530157686918686\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853636957089204\n",
      "test loss:  6.77456521987915\n",
      "test r2:  -0.2552513948315074\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853746159732988\n",
      "test loss:  6.774789333343506\n",
      "test r2:  -0.25531019458206283\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853621204031887\n",
      "test loss:  6.774586200714111\n",
      "test r2:  -0.2552433358095785\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853764882884225\n",
      "test loss:  6.774801731109619\n",
      "test r2:  -0.2553210064905247\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853597795065162\n",
      "test loss:  6.774395942687988\n",
      "test r2:  -0.25522850017317444\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853792530385455\n",
      "test loss:  6.774466037750244\n",
      "test r2:  -0.25533280309190887\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853562205901703\n",
      "test loss:  6.7735676765441895\n",
      "test r2:  -0.25520113509835607\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.885383131463207\n",
      "test loss:  6.774162769317627\n",
      "test r2:  -0.2553549852289809\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853504383046198\n",
      "test loss:  6.773492336273193\n",
      "test r2:  -0.2551803782088984\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.8853874538840937\n",
      "test loss:  6.774476528167725\n",
      "test r2:  -0.25537523189302447\n",
      "train loss:  1.636459231376648\n",
      "train r2:  0.8853467250493268\n",
      "test loss:  6.773924350738525\n",
      "test r2:  -0.25514721066186574\n",
      "train loss:  1.6364649534225464\n",
      "train r2:  0.8853959287698465\n",
      "test loss:  6.774834156036377\n",
      "test r2:  -0.2554278155541927\n",
      "train loss:  1.6364636421203613\n",
      "train r2:  0.8853358695976514\n",
      "test loss:  6.773592948913574\n",
      "test r2:  -0.25507629266861387\n",
      "train loss:  1.6364684104919434\n",
      "train r2:  0.885410781207401\n",
      "test loss:  6.774737358093262\n",
      "test r2:  -0.2555121101059361\n",
      "train loss:  1.6364686489105225\n",
      "train r2:  0.8853167972805744\n",
      "test loss:  6.7726216316223145\n",
      "test r2:  -0.2549621227283141\n",
      "train loss:  1.636474609375\n",
      "train r2:  0.8854335194334013\n",
      "test loss:  6.7749714851379395\n",
      "test r2:  -0.25564582663566204\n",
      "train loss:  1.6364816427230835\n",
      "train r2:  0.8852874524288313\n",
      "test loss:  6.772138595581055\n",
      "test r2:  -0.2548115747858719\n",
      "train loss:  1.6364938020706177\n",
      "train r2:  0.8854654528312048\n",
      "test loss:  6.775677680969238\n",
      "test r2:  -0.25581775826287756\n",
      "train loss:  1.6365100145339966\n",
      "train r2:  0.8852506166241871\n",
      "test loss:  6.771936416625977\n",
      "test r2:  -0.2546156732263358\n",
      "train loss:  1.6365346908569336\n",
      "train r2:  0.8855079289733689\n",
      "test loss:  6.776729106903076\n",
      "test r2:  -0.25604422317184494\n",
      "train loss:  1.636565089225769\n",
      "train r2:  0.8852021653680935\n",
      "test loss:  6.77113676071167\n",
      "test r2:  -0.2543752020525807\n",
      "train loss:  1.6366066932678223\n",
      "train r2:  0.885558259225492\n",
      "test loss:  6.777282238006592\n",
      "test r2:  -0.25629100891841183\n",
      "train loss:  1.636650800704956\n",
      "train r2:  0.8851473803557361\n",
      "test loss:  6.770020961761475\n",
      "test r2:  -0.25413956590605546\n",
      "train loss:  1.636703610420227\n",
      "train r2:  0.8856062677302006\n",
      "test loss:  6.777682304382324\n",
      "test r2:  -0.2564807440387562\n",
      "train loss:  1.6367378234863281\n",
      "train r2:  0.885104895351359\n",
      "test loss:  6.769632339477539\n",
      "test r2:  -0.25401983498605185\n",
      "train loss:  1.6367638111114502\n",
      "train r2:  0.8856310283245324\n",
      "test loss:  6.77781343460083\n",
      "test r2:  -0.25647878191855633\n",
      "train loss:  1.6367336511611938\n",
      "train r2:  0.8851057606097408\n",
      "test loss:  6.770384311676025\n",
      "test r2:  -0.25419021993978475\n",
      "train loss:  1.6366828680038452\n",
      "train r2:  0.8855963053806227\n",
      "test loss:  6.776759624481201\n",
      "test r2:  -0.2561167955078252\n",
      "train loss:  1.6365889310836792\n",
      "train r2:  0.8851857074807139\n",
      "test loss:  6.772099018096924\n",
      "test r2:  -0.2547343795028665\n",
      "train loss:  1.6365106105804443\n",
      "train r2:  0.8854823046689213\n",
      "test loss:  6.774282932281494\n",
      "test r2:  -0.25544978476716285\n",
      "train loss:  1.636459469795227\n",
      "train r2:  0.8853295615621585\n",
      "test loss:  6.774127006530762\n",
      "test r2:  -0.255418527050421\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853362181234153\n",
      "test loss:  6.772250175476074\n",
      "test r2:  -0.25483742049906577\n",
      "train loss:  1.6364796161651611\n",
      "train r2:  0.8854601707401405\n",
      "test loss:  6.775693893432617\n",
      "test r2:  -0.2558883640169647\n",
      "train loss:  1.63651704788208\n",
      "train r2:  0.8852348294640351\n",
      "test loss:  6.771413803100586\n",
      "test r2:  -0.2545574776981707\n",
      "train loss:  1.6365455389022827\n",
      "train r2:  0.8855193114840866\n",
      "test loss:  6.776128768920898\n",
      "test r2:  -0.2559593933838309\n",
      "train loss:  1.6365481615066528\n",
      "train r2:  0.8852197297354167\n",
      "test loss:  6.771940231323242\n",
      "test r2:  -0.2546874925830205\n",
      "train loss:  1.6365317106246948\n",
      "train r2:  0.8854920051736392\n",
      "test loss:  6.775091171264648\n",
      "test r2:  -0.2556731299998505\n",
      "train loss:  1.6364973783493042\n",
      "train r2:  0.8852814686198758\n",
      "test loss:  6.773074150085449\n",
      "test r2:  -0.2550715579405156\n",
      "train loss:  1.6364738941192627\n",
      "train r2:  0.8854103947270076\n",
      "test loss:  6.773642063140869\n",
      "test r2:  -0.2552595119491534\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853703039134098\n",
      "test loss:  6.774322509765625\n",
      "test r2:  -0.25545462098335836\n",
      "train loss:  1.636459469795227\n",
      "train r2:  0.885328623211348\n",
      "test loss:  6.772694110870361\n",
      "test r2:  -0.25495344994743574\n",
      "train loss:  1.6364704370498657\n",
      "train r2:  0.8854356881687735\n",
      "test loss:  6.775078296661377\n",
      "test r2:  -0.25565405761710713\n",
      "train loss:  1.6364818811416626\n",
      "train r2:  0.8852858905780776\n",
      "test loss:  6.772515773773193\n",
      "test r2:  -0.2548699193398931\n",
      "train loss:  1.6364866495132446\n",
      "train r2:  0.885453574532868\n",
      "test loss:  6.774970531463623\n",
      "test r2:  -0.2556273257898798\n",
      "train loss:  1.636481761932373\n",
      "train r2:  0.8852915468980704\n",
      "test loss:  6.772819519042969\n",
      "test r2:  -0.25498868012604237\n",
      "train loss:  1.6364728212356567\n",
      "train r2:  0.8854281493991332\n",
      "test loss:  6.7742390632629395\n",
      "test r2:  -0.2554404412655389\n",
      "train loss:  1.6364620923995972\n",
      "train r2:  0.8853315235849591\n",
      "test loss:  6.773507595062256\n",
      "test r2:  -0.2552124596632388\n",
      "train loss:  1.6364598274230957\n",
      "train r2:  0.8853803664696327\n",
      "test loss:  6.7734785079956055\n",
      "test r2:  -0.2552106853652987\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853807401255429\n",
      "test loss:  6.774208068847656\n",
      "test r2:  -0.25541804628459763\n",
      "train loss:  1.636460304260254\n",
      "train r2:  0.8853364403171551\n",
      "test loss:  6.773002624511719\n",
      "test r2:  -0.2550494637036127\n",
      "train loss:  1.6364619731903076\n",
      "train r2:  0.8854152845085276\n",
      "test loss:  6.774549961090088\n",
      "test r2:  -0.2555168746772247\n",
      "train loss:  1.636462688446045\n",
      "train r2:  0.8853153190224281\n",
      "test loss:  6.772879123687744\n",
      "test r2:  -0.25501927807081426\n",
      "train loss:  1.6364610195159912\n",
      "train r2:  0.885421644532427\n",
      "test loss:  6.774369716644287\n",
      "test r2:  -0.25547872818589457\n",
      "train loss:  1.636457920074463\n",
      "train r2:  0.8853233883933826\n",
      "test loss:  6.773189067840576\n",
      "test r2:  -0.2551171520960547\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8854007959706829\n",
      "test loss:  6.773921489715576\n",
      "test r2:  -0.25534098835105845\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853529359865966\n",
      "test loss:  6.773746967315674\n",
      "test r2:  -0.25527405366091793\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853673560939465\n",
      "test loss:  6.773472309112549\n",
      "test r2:  -0.2551899830970852\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853853520874982\n",
      "test loss:  6.7741899490356445\n",
      "test r2:  -0.25539873756242404\n",
      "train loss:  1.6364572048187256\n",
      "train r2:  0.8853407341857615\n",
      "test loss:  6.773190021514893\n",
      "test r2:  -0.2551076487307844\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8854029090550745\n",
      "test loss:  6.774250507354736\n",
      "test r2:  -0.25543042697481155\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853338955765186\n",
      "test loss:  6.773223876953125\n",
      "test r2:  -0.25512540876226675\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853991088136981\n",
      "test loss:  6.774042129516602\n",
      "test r2:  -0.2553718855487972\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853464172998271\n",
      "test loss:  6.773526191711426\n",
      "test r2:  -0.25521072027797853\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853809503551903\n",
      "test loss:  6.773745536804199\n",
      "test r2:  -0.25527535337033047\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853671265726379\n",
      "test loss:  6.773857116699219\n",
      "test r2:  -0.2553027709997844\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853612868953774\n",
      "test loss:  6.7734880447387695\n",
      "test r2:  -0.2551998364529706\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853832068908194\n",
      "test loss:  6.773997783660889\n",
      "test r2:  -0.25535328405736935\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853504118630985\n",
      "test loss:  6.773388385772705\n",
      "test r2:  -0.255177622295931\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853879240316309\n",
      "test loss:  6.773969650268555\n",
      "test r2:  -0.25534944606075616\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853511877619121\n",
      "test loss:  6.773474216461182\n",
      "test r2:  -0.2552016885339421\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.885382795240119\n",
      "test loss:  6.773853778839111\n",
      "test r2:  -0.2553109308904937\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853594752393561\n",
      "test loss:  6.773640155792236\n",
      "test r2:  -0.2552463997923944\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853732928930788\n",
      "test loss:  6.773704528808594\n",
      "test r2:  -0.2552657011672521\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853691902111946\n",
      "test loss:  6.773770332336426\n",
      "test r2:  -0.25528775700957773\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853644339809592\n",
      "test loss:  6.7735795974731445\n",
      "test r2:  -0.25523170691302277\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853764112181842\n",
      "test loss:  6.773853778839111\n",
      "test r2:  -0.2553132509374749\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.885358974256961\n",
      "test loss:  6.773535251617432\n",
      "test r2:  -0.25521610213030965\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.885379740338096\n",
      "test loss:  6.773892402648926\n",
      "test r2:  -0.2553194984223133\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853576639917387\n",
      "test loss:  6.773558139801025\n",
      "test r2:  -0.25521900921088414\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853791584273958\n",
      "test loss:  6.773862838745117\n",
      "test r2:  -0.25530864486037164\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853600368784628\n",
      "test loss:  6.773611068725586\n",
      "test r2:  -0.2552376113858905\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853751780041792\n",
      "test loss:  6.773768901824951\n",
      "test r2:  -0.25528376691651\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853653076137392\n",
      "test loss:  6.773697376251221\n",
      "test r2:  -0.25526625665408553\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853690127523257\n",
      "test loss:  6.773667812347412\n",
      "test r2:  -0.25525374150374014\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853717422076988\n",
      "test loss:  6.773796081542969\n",
      "test r2:  -0.2552947524963902\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853629486813903\n",
      "test loss:  6.773587226867676\n",
      "test r2:  -0.2552286612373076\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853771042379797\n",
      "test loss:  6.773857593536377\n",
      "test r2:  -0.25531384267009405\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853588465939645\n",
      "test loss:  6.7735371589660645\n",
      "test r2:  -0.255216447327939\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853796782182102\n",
      "test loss:  6.773862838745117\n",
      "test r2:  -0.2553179950280373\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853579319004607\n",
      "test loss:  6.773542881011963\n",
      "test r2:  -0.2552196742202937\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853789842556603\n",
      "test loss:  6.773833751678467\n",
      "test r2:  -0.2553083594620289\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853600184350285\n",
      "test loss:  6.773599624633789\n",
      "test r2:  -0.2552348192724532\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853757957793094\n",
      "test loss:  6.7737812995910645\n",
      "test r2:  -0.2552899558542647\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853639931140045\n",
      "test loss:  6.773670673370361\n",
      "test r2:  -0.2552545470458638\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853715879638492\n",
      "test loss:  6.773719310760498\n",
      "test r2:  -0.25527121252543505\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853680003799586\n",
      "test loss:  6.773723125457764\n",
      "test r2:  -0.255271222681567\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853680281929406\n",
      "test loss:  6.773674488067627\n",
      "test r2:  -0.2552580948311789\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853708164777296\n",
      "test loss:  6.773757457733154\n",
      "test r2:  -0.25528096767465547\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853659148405584\n",
      "test loss:  6.773656845092773\n",
      "test r2:  -0.25525147949051874\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853722234372644\n",
      "test loss:  6.773771286010742\n",
      "test r2:  -0.25528435845788056\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853652032994608\n",
      "test loss:  6.773654460906982\n",
      "test r2:  -0.25525067928158673\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.885372367232399\n",
      "test loss:  6.77376127243042\n",
      "test r2:  -0.2552825191644339\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853655778433037\n",
      "test loss:  6.773660659790039\n",
      "test r2:  -0.2552542737637564\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853716107165314\n",
      "test loss:  6.77374267578125\n",
      "test r2:  -0.25527788021591324\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853665701637292\n",
      "test loss:  6.773677349090576\n",
      "test r2:  -0.2552599274678007\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853704092593093\n",
      "test loss:  6.7737226486206055\n",
      "test r2:  -0.2552712168237865\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853680015661737\n",
      "test loss:  6.773702621459961\n",
      "test r2:  -0.2552674903290546\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853687835947861\n",
      "test loss:  6.773694038391113\n",
      "test r2:  -0.25526276273935844\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853698029208046\n",
      "test loss:  6.773727893829346\n",
      "test r2:  -0.2552761987461305\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853669219752783\n",
      "test loss:  6.773664951324463\n",
      "test r2:  -0.2552542634990713\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853716213200213\n",
      "test loss:  6.773753643035889\n",
      "test r2:  -0.2552847290889797\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853650368083632\n",
      "test loss:  6.773637294769287\n",
      "test r2:  -0.2552451844053243\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853735617322929\n",
      "test loss:  6.773786544799805\n",
      "test r2:  -0.2552943508646257\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853630104324887\n",
      "test loss:  6.773608684539795\n",
      "test r2:  -0.25523556968564143\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.885375572774433\n",
      "test loss:  6.773816108703613\n",
      "test r2:  -0.25530370653138523\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853609893895368\n",
      "test loss:  6.77357816696167\n",
      "test r2:  -0.25522647469523996\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853775382436189\n",
      "test loss:  6.773841857910156\n",
      "test r2:  -0.2553130817177651\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853589465989603\n",
      "test loss:  6.773542881011963\n",
      "test r2:  -0.25521651463250716\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853796246272337\n",
      "test loss:  6.773871898651123\n",
      "test r2:  -0.25532359436813934\n",
      "train loss:  1.6364543437957764\n",
      "train r2:  0.8853566627489269\n",
      "test loss:  6.773502826690674\n",
      "test r2:  -0.25520489970092086\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853821140901874\n",
      "test loss:  6.773910045623779\n",
      "test r2:  -0.2553362569791511\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853539497922138\n",
      "test loss:  6.773451328277588\n",
      "test r2:  -0.25519040955068295\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853851675016331\n",
      "test loss:  6.773959636688232\n",
      "test r2:  -0.25535223106779426\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.885350551785032\n",
      "test loss:  6.773388385772705\n",
      "test r2:  -0.25517239478229414\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.8853890463718838\n",
      "test loss:  6.774026870727539\n",
      "test r2:  -0.25537199652199316\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.885346289854452\n",
      "test loss:  6.773318767547607\n",
      "test r2:  -0.2551507291447084\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853936663225719\n",
      "test loss:  6.774111747741699\n",
      "test r2:  -0.25539532342565097\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853413329080272\n",
      "test loss:  6.7732462882995605\n",
      "test r2:  -0.25512649303822776\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853988812677417\n",
      "test loss:  6.774207592010498\n",
      "test r2:  -0.2554209614905387\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.8853358679448022\n",
      "test loss:  6.773168563842773\n",
      "test r2:  -0.255100645884367\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8854044047028004\n",
      "test loss:  6.774304389953613\n",
      "test r2:  -0.25544792967665386\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853301135950318\n",
      "test loss:  6.7730865478515625\n",
      "test r2:  -0.25507319620635016\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.8854102357895056\n",
      "test loss:  6.774408340454102\n",
      "test r2:  -0.2554774258635226\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.8853237975799768\n",
      "test loss:  6.7729878425598145\n",
      "test r2:  -0.2550417640048086\n",
      "train loss:  1.636461615562439\n",
      "train r2:  0.8854169750297336\n",
      "test loss:  6.7745256423950195\n",
      "test r2:  -0.2555123456440178\n",
      "train loss:  1.6364635229110718\n",
      "train r2:  0.8853162569752049\n",
      "test loss:  6.772860527038574\n",
      "test r2:  -0.25500257953753813\n",
      "train loss:  1.6364668607711792\n",
      "train r2:  0.8854252654502898\n",
      "test loss:  6.7746663093566895\n",
      "test r2:  -0.25555670829462906\n",
      "train loss:  1.6364693641662598\n",
      "train r2:  0.8853066665936244\n",
      "test loss:  6.772692680358887\n",
      "test r2:  -0.25495248273543125\n",
      "train loss:  1.6364742517471313\n",
      "train r2:  0.885435866152223\n",
      "test loss:  6.774842739105225\n",
      "test r2:  -0.25561239404593405\n",
      "train loss:  1.636478066444397\n",
      "train r2:  0.8852945999241563\n",
      "test loss:  6.772482395172119\n",
      "test r2:  -0.2548903944516694\n",
      "train loss:  1.6364853382110596\n",
      "train r2:  0.8854489570950415\n",
      "test loss:  6.775059700012207\n",
      "test r2:  -0.25568074084677317\n",
      "train loss:  1.6364898681640625\n",
      "train r2:  0.885279775992423\n",
      "test loss:  6.772227764129639\n",
      "test r2:  -0.2548148047918366\n",
      "train loss:  1.636499285697937\n",
      "train r2:  0.8854649220332705\n",
      "test loss:  6.775321960449219\n",
      "test r2:  -0.2557623848480257\n",
      "train loss:  1.6365052461624146\n",
      "train r2:  0.8852620664986273\n",
      "test loss:  6.771937847137451\n",
      "test r2:  -0.2547281458304087\n",
      "train loss:  1.6365160942077637\n",
      "train r2:  0.8854831815003676\n",
      "test loss:  6.7756123542785645\n",
      "test r2:  -0.255850841476815\n",
      "train loss:  1.6365236043930054\n",
      "train r2:  0.885242847688063\n",
      "test loss:  6.771650791168213\n",
      "test r2:  -0.25464142628857145\n",
      "train loss:  1.6365349292755127\n",
      "train r2:  0.8855014207891715\n",
      "test loss:  6.775879383087158\n",
      "test r2:  -0.25593021438938224\n",
      "train loss:  1.6365416049957275\n",
      "train r2:  0.8852256525551743\n",
      "test loss:  6.7714433670043945\n",
      "test r2:  -0.2545769721614022\n",
      "train loss:  1.636549711227417\n",
      "train r2:  0.8855150113960396\n",
      "test loss:  6.776031017303467\n",
      "test r2:  -0.2559728319815444\n",
      "train loss:  1.6365509033203125\n",
      "train r2:  0.885216424590997\n",
      "test loss:  6.771412372589111\n",
      "test r2:  -0.25456477179891945\n",
      "train loss:  1.6365514993667603\n",
      "train r2:  0.8855175888994622\n",
      "test loss:  6.775959491729736\n",
      "test r2:  -0.25594802307475084\n",
      "train loss:  1.6365429162979126\n",
      "train r2:  0.88522187710435\n",
      "test loss:  6.771646022796631\n",
      "test r2:  -0.25463311940161915\n",
      "train loss:  1.6365329027175903\n",
      "train r2:  0.8855032964643458\n",
      "test loss:  6.7755961418151855\n",
      "test r2:  -0.25583540579424935\n",
      "train loss:  1.6365156173706055\n",
      "train r2:  0.8852463833328497\n",
      "test loss:  6.772160053253174\n",
      "test r2:  -0.2547872831314759\n",
      "train loss:  1.6364996433258057\n",
      "train r2:  0.8854708295434823\n",
      "test loss:  6.7749786376953125\n",
      "test r2:  -0.25564775254475536\n",
      "train loss:  1.6364811658859253\n",
      "train r2:  0.8852870329864888\n",
      "test loss:  6.772851943969727\n",
      "test r2:  -0.2549971257261612\n",
      "train loss:  1.6364680528640747\n",
      "train r2:  0.8854264385744329\n",
      "test loss:  6.7742533683776855\n",
      "test r2:  -0.25542822715288893\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853343448242409\n",
      "test loss:  6.773560047149658\n",
      "test r2:  -0.25521316017904283\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853804506714197\n",
      "test loss:  6.773584365844727\n",
      "test r2:  -0.25522621467583395\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853776424848118\n",
      "test loss:  6.774143695831299\n",
      "test r2:  -0.2553919962784563\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853421973446951\n",
      "test loss:  6.773090839385986\n",
      "test r2:  -0.25507613771009074\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8854096621272056\n",
      "test loss:  6.774528980255127\n",
      "test r2:  -0.2555099834013024\n",
      "train loss:  1.6364600658416748\n",
      "train r2:  0.8853168300719665\n",
      "test loss:  6.772814750671387\n",
      "test r2:  -0.2549908582877456\n",
      "train loss:  1.6364637613296509\n",
      "train r2:  0.8854278055223272\n",
      "test loss:  6.774704456329346\n",
      "test r2:  -0.2555632999558257\n",
      "train loss:  1.6364660263061523\n",
      "train r2:  0.8853053297700131\n",
      "test loss:  6.77274751663208\n",
      "test r2:  -0.25496739501761767\n",
      "train loss:  1.6364673376083374\n",
      "train r2:  0.8854327850951285\n",
      "test loss:  6.774697780609131\n",
      "test r2:  -0.2555606382064257\n",
      "train loss:  1.6364673376083374\n",
      "train r2:  0.8853058780143801\n",
      "test loss:  6.772839546203613\n",
      "test r2:  -0.2549926827081135\n",
      "train loss:  1.6364665031433105\n",
      "train r2:  0.8854274218009529\n",
      "test loss:  6.7745561599731445\n",
      "test r2:  -0.2555176531859982\n",
      "train loss:  1.6364645957946777\n",
      "train r2:  0.8853151108789504\n",
      "test loss:  6.773033618927002\n",
      "test r2:  -0.25504989834683855\n",
      "train loss:  1.6364635229110718\n",
      "train r2:  0.8854152547343966\n",
      "test loss:  6.774332046508789\n",
      "test r2:  -0.2554508874139738\n",
      "train loss:  1.636460542678833\n",
      "train r2:  0.885329484370582\n",
      "test loss:  6.7732696533203125\n",
      "test r2:  -0.25512246234290603\n",
      "train loss:  1.6364600658416748\n",
      "train r2:  0.8853997763565894\n",
      "test loss:  6.774078369140625\n",
      "test r2:  -0.25537665086971795\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.885345399005946\n",
      "test loss:  6.773491382598877\n",
      "test r2:  -0.2551935391375697\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853845764436499\n",
      "test loss:  6.773847579956055\n",
      "test r2:  -0.2553096120490781\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853597606065965\n",
      "test loss:  6.773676872253418\n",
      "test r2:  -0.2552535347788729\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853717937216643\n",
      "test loss:  6.773669242858887\n",
      "test r2:  -0.255256351133742\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853711452979921\n",
      "test loss:  6.773819446563721\n",
      "test r2:  -0.2552985682032263\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853621714995185\n",
      "test loss:  6.773553371429443\n",
      "test r2:  -0.2552189024712659\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853792073860232\n",
      "test loss:  6.773925304412842\n",
      "test r2:  -0.25532897064431403\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853556769156733\n",
      "test loss:  6.773491382598877\n",
      "test r2:  -0.2551957875800954\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853841759004214\n",
      "test loss:  6.773993015289307\n",
      "test r2:  -0.255346791749816\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853518905615819\n",
      "test loss:  6.77346658706665\n",
      "test r2:  -0.25518357869157193\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853868398017306\n",
      "test loss:  6.774033069610596\n",
      "test r2:  -0.2553563034068669\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853498749860197\n",
      "test loss:  6.7734575271606445\n",
      "test r2:  -0.25517682702002853\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853882775361008\n",
      "test loss:  6.774057388305664\n",
      "test r2:  -0.2553624512822963\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.885348545941735\n",
      "test loss:  6.773443698883057\n",
      "test r2:  -0.25517115196427165\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853894680674672\n",
      "test loss:  6.774075508117676\n",
      "test r2:  -0.2553687518829699\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853471822954029\n",
      "test loss:  6.773412704467773\n",
      "test r2:  -0.25516321094999594\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853911324563128\n",
      "test loss:  6.77409553527832\n",
      "test r2:  -0.2553780839716504\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853451113170487\n",
      "test loss:  6.773361682891846\n",
      "test r2:  -0.255151495055157\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.88539357672463\n",
      "test loss:  6.774122714996338\n",
      "test r2:  -0.25539024929933096\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853425070306202\n",
      "test loss:  6.7733049392700195\n",
      "test r2:  -0.25513802674917674\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.885396467399209\n",
      "test loss:  6.774162292480469\n",
      "test r2:  -0.2554047099433032\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853393670345985\n",
      "test loss:  6.77324104309082\n",
      "test r2:  -0.2551207365032513\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8854001144896093\n",
      "test loss:  6.774225234985352\n",
      "test r2:  -0.25542380872420667\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853352786980435\n",
      "test loss:  6.773172378540039\n",
      "test r2:  -0.2550994992056328\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8854046749796239\n",
      "test loss:  6.774311542510986\n",
      "test r2:  -0.25544750720061193\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853301829348911\n",
      "test loss:  6.773095607757568\n",
      "test r2:  -0.2550733555075164\n",
      "train loss:  1.636457920074463\n",
      "train r2:  0.8854102321103491\n",
      "test loss:  6.774421691894531\n",
      "test r2:  -0.2554770296468769\n",
      "train loss:  1.6364587545394897\n",
      "train r2:  0.8853239046549273\n",
      "test loss:  6.773003101348877\n",
      "test r2:  -0.25504168508171143\n",
      "train loss:  1.636460304260254\n",
      "train r2:  0.8854170360813726\n",
      "test loss:  6.774551868438721\n",
      "test r2:  -0.25551240459407976\n",
      "train loss:  1.6364617347717285\n",
      "train r2:  0.885316314165618\n",
      "test loss:  6.77288818359375\n",
      "test r2:  -0.25500369264412304\n",
      "train loss:  1.6364638805389404\n",
      "train r2:  0.8854251211574447\n",
      "test loss:  6.7746992111206055\n",
      "test r2:  -0.25555447239615137\n",
      "train loss:  1.6364662647247314\n",
      "train r2:  0.8853072858033775\n",
      "test loss:  6.772745132446289\n",
      "test r2:  -0.2549583161793805\n",
      "train loss:  1.6364697217941284\n",
      "train r2:  0.8854347614217275\n",
      "test loss:  6.774864196777344\n",
      "test r2:  -0.2556044692460362\n",
      "train loss:  1.6364730596542358\n",
      "train r2:  0.8852964969022129\n",
      "test loss:  6.77256441116333\n",
      "test r2:  -0.25490330931387106\n",
      "train loss:  1.636478304862976\n",
      "train r2:  0.8854464088285082\n",
      "test loss:  6.775058269500732\n",
      "test r2:  -0.25566504644180865\n",
      "train loss:  1.6364834308624268\n",
      "train r2:  0.8852833407146669\n",
      "test loss:  6.772339344024658\n",
      "test r2:  -0.25483646133091664\n",
      "train loss:  1.636491060256958\n",
      "train r2:  0.8854604923484032\n",
      "test loss:  6.77528715133667\n",
      "test r2:  -0.25573748913701344\n",
      "train loss:  1.6364973783493042\n",
      "train r2:  0.8852676638873096\n",
      "test loss:  6.772076606750488\n",
      "test r2:  -0.2547588754728358\n",
      "train loss:  1.6365078687667847\n",
      "train r2:  0.8854768474198433\n",
      "test loss:  6.775543212890625\n",
      "test r2:  -0.25581848088565873\n",
      "train loss:  1.6365150213241577\n",
      "train r2:  0.8852500430617867\n",
      "test loss:  6.771795749664307\n",
      "test r2:  -0.2546759565064294\n",
      "train loss:  1.6365268230438232\n",
      "train r2:  0.88549425307121\n",
      "test loss:  6.7758026123046875\n",
      "test r2:  -0.2558990216287198\n",
      "train loss:  1.6365336179733276\n",
      "train r2:  0.8852325126119875\n",
      "test loss:  6.771546840667725\n",
      "test r2:  -0.25460204697405686\n",
      "train loss:  1.6365439891815186\n",
      "train r2:  0.8855098033485848\n",
      "test loss:  6.7760009765625\n",
      "test r2:  -0.2559593598475247\n",
      "train loss:  1.6365474462509155\n",
      "train r2:  0.8852193745459209\n",
      "test loss:  6.7714152336120605\n",
      "test r2:  -0.25456219964002424\n",
      "train loss:  1.636551856994629\n",
      "train r2:  0.8855181740856299\n",
      "test loss:  6.776043891906738\n",
      "test r2:  -0.2559703052872706\n",
      "train loss:  1.6365478038787842\n",
      "train r2:  0.8852170624300075\n",
      "test loss:  6.7715067863464355\n",
      "test r2:  -0.254588199572382\n",
      "train loss:  1.6365418434143066\n",
      "train r2:  0.8855128041264444\n",
      "test loss:  6.7758331298828125\n",
      "test r2:  -0.2559025537808268\n",
      "train loss:  1.6365283727645874\n",
      "train r2:  0.8852318624411017\n",
      "test loss:  6.771888732910156\n",
      "test r2:  -0.25470087029207433\n",
      "train loss:  1.6365138292312622\n",
      "train r2:  0.8854891307989587\n",
      "test loss:  6.775335311889648\n",
      "test r2:  -0.2557480871340738\n",
      "train loss:  1.6364954710006714\n",
      "train r2:  0.885265427211826\n",
      "test loss:  6.772525310516357\n",
      "test r2:  -0.25489064635518166\n",
      "train loss:  1.6364794969558716\n",
      "train r2:  0.8854491243013808\n",
      "test loss:  6.774642467498779\n",
      "test r2:  -0.2555354888786028\n",
      "train loss:  1.6364654302597046\n",
      "train r2:  0.8853113976180751\n",
      "test loss:  6.773268222808838\n",
      "test r2:  -0.25511324502960253\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8854018428939999\n",
      "test loss:  6.77392578125\n",
      "test r2:  -0.255316948181707\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853583584155623\n",
      "test loss:  6.773939609527588\n",
      "test r2:  -0.255316321801647\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853585116623626\n",
      "test loss:  6.773336887359619\n",
      "test r2:  -0.2551379115580201\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853966040783818\n",
      "test loss:  6.774427890777588\n",
      "test r2:  -0.2554651436493087\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853265812780121\n",
      "test loss:  6.772953510284424\n",
      "test r2:  -0.25502183656684596\n",
      "train loss:  1.6364604234695435\n",
      "train r2:  0.8854213289559487\n",
      "test loss:  6.774693489074707\n",
      "test r2:  -0.25554808239007687\n",
      "train loss:  1.6364638805389404\n",
      "train r2:  0.8853087282228032\n",
      "test loss:  6.772782802581787\n",
      "test r2:  -0.2549698353231966\n",
      "train loss:  1.6364662647247314\n",
      "train r2:  0.8854323464385164\n",
      "test loss:  6.774763107299805\n",
      "test r2:  -0.25557103166350936\n",
      "train loss:  1.6364670991897583\n",
      "train r2:  0.8853037241807777\n",
      "test loss:  6.772793769836426\n",
      "test r2:  -0.254972672440928\n",
      "train loss:  1.6364668607711792\n",
      "train r2:  0.8854317432866173\n",
      "test loss:  6.774676322937012\n",
      "test r2:  -0.25554578231254643\n",
      "train loss:  1.6364657878875732\n",
      "train r2:  0.8853091558540243\n",
      "test loss:  6.772941589355469\n",
      "test r2:  -0.2550163177530498\n",
      "train loss:  1.6364638805389404\n",
      "train r2:  0.8854224579313245\n",
      "test loss:  6.774482250213623\n",
      "test r2:  -0.2554881691133166\n",
      "train loss:  1.636461615562439\n",
      "train r2:  0.8853215571441295\n",
      "test loss:  6.773167610168457\n",
      "test r2:  -0.25508412196722996\n",
      "train loss:  1.636460542678833\n",
      "train r2:  0.8854080028418653\n",
      "test loss:  6.774233818054199\n",
      "test r2:  -0.25541436863423206\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853373590627229\n",
      "test loss:  6.773414134979248\n",
      "test r2:  -0.2551596544635213\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853919165785259\n",
      "test loss:  6.773983955383301\n",
      "test r2:  -0.2553406021420519\n",
      "train loss:  1.6364543437957764\n",
      "train r2:  0.8853531959970196\n",
      "test loss:  6.773632526397705\n",
      "test r2:  -0.25522826713796265\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853772851771263\n",
      "test loss:  6.773776054382324\n",
      "test r2:  -0.25527851863232986\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853665054619652\n",
      "test loss:  6.773800849914551\n",
      "test r2:  -0.25528146287780884\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853658879753948\n",
      "test loss:  6.7736287117004395\n",
      "test r2:  -0.25523349819903873\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853761105851543\n",
      "test loss:  6.773920059204102\n",
      "test r2:  -0.25531800874722577\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.885358117336466\n",
      "test loss:  6.773544788360596\n",
      "test r2:  -0.25520511458110917\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853822349693337\n",
      "test loss:  6.773996353149414\n",
      "test r2:  -0.25533944113351725\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853535293434214\n",
      "test loss:  6.7735090255737305\n",
      "test r2:  -0.255190144990473\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853854795311963\n",
      "test loss:  6.774040699005127\n",
      "test r2:  -0.25535033642472116\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853512132581408\n",
      "test loss:  6.773499965667725\n",
      "test r2:  -0.2551830996610649\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853870223968391\n",
      "test loss:  6.774065971374512\n",
      "test r2:  -0.2553559340343714\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853500251162768\n",
      "test loss:  6.773496627807617\n",
      "test r2:  -0.2551793095914916\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853878125712336\n",
      "test loss:  6.774077892303467\n",
      "test r2:  -0.2553592874304653\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853493073836207\n",
      "test loss:  6.773487567901611\n",
      "test r2:  -0.25517595881398947\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853885429955883\n",
      "test loss:  6.7740864753723145\n",
      "test r2:  -0.25536363680390206\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853483484940107\n",
      "test loss:  6.773463249206543\n",
      "test r2:  -0.2551704356078819\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853896836960353\n",
      "test loss:  6.77409553527832\n",
      "test r2:  -0.25536972104509315\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853469868721056\n",
      "test loss:  6.77342414855957\n",
      "test r2:  -0.25516190994613663\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853914437972953\n",
      "test loss:  6.774118423461914\n",
      "test r2:  -0.2553800933511854\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853447388577979\n",
      "test loss:  6.773368835449219\n",
      "test r2:  -0.25514813024944805\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.885394366187037\n",
      "test loss:  6.774165630340576\n",
      "test r2:  -0.25539625662079635\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.885341280961095\n",
      "test loss:  6.773299694061279\n",
      "test r2:  -0.2551285955019418\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853985585820384\n",
      "test loss:  6.77424430847168\n",
      "test r2:  -0.2554192956119763\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.885336316229529\n",
      "test loss:  6.773214340209961\n",
      "test r2:  -0.25510181341864335\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.88540426735557\n",
      "test loss:  6.774352550506592\n",
      "test r2:  -0.25544950535819577\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.885329855825812\n",
      "test loss:  6.773114204406738\n",
      "test r2:  -0.25506885180178607\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8854113120578905\n",
      "test loss:  6.774487495422363\n",
      "test r2:  -0.2554862490577676\n",
      "train loss:  1.6364593505859375\n",
      "train r2:  0.8853220176765972\n",
      "test loss:  6.772997856140137\n",
      "test r2:  -0.25502968134454496\n",
      "train loss:  1.6364611387252808\n",
      "train r2:  0.8854196662459382\n",
      "test loss:  6.774641513824463\n",
      "test r2:  -0.255529092539571\n",
      "train loss:  1.6364631652832031\n",
      "train r2:  0.8853128299888755\n",
      "test loss:  6.772857189178467\n",
      "test r2:  -0.2549841215079709\n",
      "train loss:  1.6364659070968628\n",
      "train r2:  0.885429378587473\n",
      "test loss:  6.774813652038574\n",
      "test r2:  -0.25557919582799227\n",
      "train loss:  1.6364692449569702\n",
      "train r2:  0.8853020304757752\n",
      "test loss:  6.772680759429932\n",
      "test r2:  -0.25492911369543636\n",
      "train loss:  1.6364736557006836\n",
      "train r2:  0.8854410209446941\n",
      "test loss:  6.775015354156494\n",
      "test r2:  -0.2556405480936521\n",
      "train loss:  1.636478304862976\n",
      "train r2:  0.8852887901854902\n",
      "test loss:  6.772458076477051\n",
      "test r2:  -0.25486135739216675\n",
      "train loss:  1.6364853382110596\n",
      "train r2:  0.8854553683449253\n",
      "test loss:  6.775256633758545\n",
      "test r2:  -0.25571535894619\n",
      "train loss:  1.6364918947219849\n",
      "train r2:  0.885272580950436\n",
      "test loss:  6.7721848487854\n",
      "test r2:  -0.25477964452154067\n",
      "train loss:  1.6365019083023071\n",
      "train r2:  0.8854726014003156\n",
      "test loss:  6.775536060333252\n",
      "test r2:  -0.2558028027186259\n",
      "train loss:  1.6365103721618652\n",
      "train r2:  0.8852535343462339\n",
      "test loss:  6.7718729972839355\n",
      "test r2:  -0.25468702618079253\n",
      "train loss:  1.6365234851837158\n",
      "train r2:  0.8854920496011175\n",
      "test loss:  6.775835990905762\n",
      "test r2:  -0.25589680059538455\n",
      "train loss:  1.6365323066711426\n",
      "train r2:  0.8852331138461225\n",
      "test loss:  6.77156400680542\n",
      "test r2:  -0.2545958834569706\n",
      "train loss:  1.636546015739441\n",
      "train r2:  0.8855111700606741\n",
      "test loss:  6.776098728179932\n",
      "test r2:  -0.25597822982039364\n",
      "train loss:  1.6365525722503662\n",
      "train r2:  0.8852153801057364\n",
      "test loss:  6.771345138549805\n",
      "test r2:  -0.25453109243393746\n",
      "train loss:  1.6365617513656616\n",
      "train r2:  0.8855247815516637\n",
      "test loss:  6.77622652053833\n",
      "test r2:  -0.25601647916621006\n",
      "train loss:  1.636561393737793\n",
      "train r2:  0.8852070226543532\n",
      "test loss:  6.771337509155273\n",
      "test r2:  -0.2545286941587026\n",
      "train loss:  1.6365597248077393\n",
      "train r2:  0.8855253051145294\n",
      "test loss:  6.77609395980835\n",
      "test r2:  -0.2559743715327665\n",
      "train loss:  1.6365478038787842\n",
      "train r2:  0.8852162986954292\n",
      "test loss:  6.77164888381958\n",
      "test r2:  -0.25462096709572357\n",
      "train loss:  1.636533498764038\n",
      "train r2:  0.8855060001549606\n",
      "test loss:  6.775636196136475\n",
      "test r2:  -0.25583221795777655\n",
      "train loss:  1.6365126371383667\n",
      "train r2:  0.885247249759086\n",
      "test loss:  6.772279262542725\n",
      "test r2:  -0.2548087308739597\n",
      "train loss:  1.6364929676055908\n",
      "train r2:  0.8854664859179755\n",
      "test loss:  6.77491569519043\n",
      "test r2:  -0.2556100280524982\n",
      "train loss:  1.6364736557006836\n",
      "train r2:  0.8852953724719435\n",
      "test loss:  6.7730937004089355\n",
      "test r2:  -0.2550518407633384\n",
      "train loss:  1.636460542678833\n",
      "train r2:  0.8854149972531438\n",
      "test loss:  6.774109363555908\n",
      "test r2:  -0.2553625948132827\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853486330153897\n",
      "test loss:  6.7738871574401855\n",
      "test r2:  -0.25528951094507346\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853643592496809\n",
      "test loss:  6.773408889770508\n",
      "test r2:  -0.2551480244581348\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853945622658907\n",
      "test loss:  6.774490833282471\n",
      "test r2:  -0.25547208084377937\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853251995530071\n",
      "test loss:  6.7729339599609375\n",
      "test r2:  -0.2550030468353306\n",
      "train loss:  1.6364622116088867\n",
      "train r2:  0.8854254070590865\n",
      "test loss:  6.774833679199219\n",
      "test r2:  -0.25557716219550475\n",
      "train loss:  1.6364669799804688\n",
      "train r2:  0.8853025804065926\n",
      "test loss:  6.772716999053955\n",
      "test r2:  -0.2549374333087242\n",
      "train loss:  1.636469841003418\n",
      "train r2:  0.8854393205744454\n",
      "test loss:  6.774917125701904\n",
      "test r2:  -0.2556049167722829\n",
      "train loss:  1.636470913887024\n",
      "train r2:  0.885296561361829\n",
      "test loss:  6.772737503051758\n",
      "test r2:  -0.25494380525040694\n",
      "train loss:  1.6364703178405762\n",
      "train r2:  0.8854379459336781\n",
      "test loss:  6.774789333343506\n",
      "test r2:  -0.25556863115371575\n",
      "train loss:  1.6364679336547852\n",
      "train r2:  0.8853043733755419\n",
      "test loss:  6.772936820983887\n",
      "test r2:  -0.2550042229696381\n",
      "train loss:  1.636465311050415\n",
      "train r2:  0.8854251385790788\n",
      "test loss:  6.77452278137207\n",
      "test r2:  -0.2554901877214162\n",
      "train loss:  1.6364617347717285\n",
      "train r2:  0.8853212075487801\n",
      "test loss:  6.7732343673706055\n",
      "test r2:  -0.25509448595312323\n",
      "train loss:  1.6364598274230957\n",
      "train r2:  0.8854058760890042\n",
      "test loss:  6.774196147918701\n",
      "test r2:  -0.25539326415564445\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853419845547298\n",
      "test loss:  6.7735514640808105\n",
      "test r2:  -0.2551918714617336\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.885385116380374\n",
      "test loss:  6.773881435394287\n",
      "test r2:  -0.2552999286581823\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853619863650607\n",
      "test loss:  6.77382230758667\n",
      "test r2:  -0.2552767440555821\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853670158490732\n",
      "test loss:  6.773633003234863\n",
      "test r2:  -0.2552256644773885\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853778698139434\n",
      "test loss:  6.774017810821533\n",
      "test r2:  -0.2553375751718072\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853539713571077\n",
      "test loss:  6.773480415344238\n",
      "test r2:  -0.25517817958413436\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.885388078155662\n",
      "test loss:  6.774133205413818\n",
      "test r2:  -0.25537183563989174\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853466600651667\n",
      "test loss:  6.773423671722412\n",
      "test r2:  -0.2551566167772248\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853926792518487\n",
      "test loss:  6.774178981781006\n",
      "test r2:  -0.25538315044138016\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.885344241536246\n",
      "test loss:  6.773431777954102\n",
      "test r2:  -0.2551541122150185\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853932801459617\n",
      "test loss:  6.774178981781006\n",
      "test r2:  -0.2553803912623416\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.885344883970326\n",
      "test loss:  6.773472785949707\n",
      "test r2:  -0.2551621910269266\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853915495485316\n",
      "test loss:  6.774148464202881\n",
      "test r2:  -0.2553698832339302\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853471199155676\n",
      "test loss:  6.7735185623168945\n",
      "test r2:  -0.255174037920737\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853890350770326\n",
      "test loss:  6.77410888671875\n",
      "test r2:  -0.2553586696506922\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853495087729593\n",
      "test loss:  6.773548603057861\n",
      "test r2:  -0.25518398400928355\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853868731607235\n",
      "test loss:  6.7740702629089355\n",
      "test r2:  -0.2553498770047218\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853513552148657\n",
      "test loss:  6.773558139801025\n",
      "test r2:  -0.25519017042266245\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853855075878778\n",
      "test loss:  6.774043560028076\n",
      "test r2:  -0.2553455297398812\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853522530738841\n",
      "test loss:  6.773548603057861\n",
      "test r2:  -0.25519146304129303\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853852529600408\n",
      "test loss:  6.774035930633545\n",
      "test r2:  -0.25534594490649853\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853521668434019\n",
      "test loss:  6.773530960083008\n",
      "test r2:  -0.2551886613436767\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.885385824645189\n",
      "test loss:  6.774047374725342\n",
      "test r2:  -0.25534959676419566\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853513620493796\n",
      "test loss:  6.7735137939453125\n",
      "test r2:  -0.2551832490866992\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853870007521636\n",
      "test loss:  6.774081230163574\n",
      "test r2:  -0.25535718370840366\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853497966885554\n",
      "test loss:  6.773494243621826\n",
      "test r2:  -0.25517455917104437\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853889081873897\n",
      "test loss:  6.7741312980651855\n",
      "test r2:  -0.25536744046721305\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853476490967473\n",
      "test loss:  6.773475170135498\n",
      "test r2:  -0.25516446189236075\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853910733307632\n",
      "test loss:  6.774183750152588\n",
      "test r2:  -0.255378562760729\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853453035978999\n",
      "test loss:  6.773449420928955\n",
      "test r2:  -0.25515316990907855\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853935040581641\n",
      "test loss:  6.774237155914307\n",
      "test r2:  -0.2553916865052943\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853425217422285\n",
      "test loss:  6.773410320281982\n",
      "test r2:  -0.25513932939797646\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853965055452125\n",
      "test loss:  6.774291515350342\n",
      "test r2:  -0.2554073835339712\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853391651594018\n",
      "test loss:  6.773349285125732\n",
      "test r2:  -0.2551211835205267\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.885400335751928\n",
      "test loss:  6.774355888366699\n",
      "test r2:  -0.2554285620136352\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.885334613373351\n",
      "test loss:  6.773260593414307\n",
      "test r2:  -0.2550959599284368\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.885405692166396\n",
      "test loss:  6.77444314956665\n",
      "test r2:  -0.25545777374611367\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853282963839131\n",
      "test loss:  6.7731404304504395\n",
      "test r2:  -0.2550613852621082\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.8854130312781936\n",
      "test loss:  6.77456521987915\n",
      "test r2:  -0.2554974134458894\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8853196918160414\n",
      "test loss:  6.772983074188232\n",
      "test r2:  -0.25501498146015855\n",
      "train loss:  1.636464238166809\n",
      "train r2:  0.8854228453277437\n",
      "test loss:  6.7747344970703125\n",
      "test r2:  -0.2555511588954351\n",
      "train loss:  1.6364679336547852\n",
      "train r2:  0.8853081103682826\n",
      "test loss:  6.772775650024414\n",
      "test r2:  -0.2549523488454608\n",
      "train loss:  1.6364738941192627\n",
      "train r2:  0.8854361257393935\n",
      "test loss:  6.7749714851379395\n",
      "test r2:  -0.2556244207111402\n",
      "train loss:  1.636479139328003\n",
      "train r2:  0.8852922305102001\n",
      "test loss:  6.772494792938232\n",
      "test r2:  -0.2548667763958328\n",
      "train loss:  1.6364892721176147\n",
      "train r2:  0.8854542011403399\n",
      "test loss:  6.775296211242676\n",
      "test r2:  -0.2557233327409951\n",
      "train loss:  1.636496901512146\n",
      "train r2:  0.8852708183056053\n",
      "test loss:  6.772125244140625\n",
      "test r2:  -0.2547545279225307\n",
      "train loss:  1.636511206626892\n",
      "train r2:  0.8854778853784684\n",
      "test loss:  6.775709629058838\n",
      "test r2:  -0.2558487614572591\n",
      "train loss:  1.636522650718689\n",
      "train r2:  0.885243610038182\n",
      "test loss:  6.771673202514648\n",
      "test r2:  -0.25461782058323035\n",
      "train loss:  1.6365416049957275\n",
      "train r2:  0.8855066523480318\n",
      "test loss:  6.776188373565674\n",
      "test r2:  -0.25599269106524924\n",
      "train loss:  1.6365573406219482\n",
      "train r2:  0.885212322897032\n",
      "test loss:  6.771200180053711\n",
      "test r2:  -0.25447393995273804\n",
      "train loss:  1.6365792751312256\n",
      "train r2:  0.8855368445916575\n",
      "test loss:  6.776637077331543\n",
      "test r2:  -0.25612561553226354\n",
      "train loss:  1.6365944147109985\n",
      "train r2:  0.8851833557142701\n",
      "test loss:  6.770857334136963\n",
      "test r2:  -0.2543681546847263\n",
      "train loss:  1.6366102695465088\n",
      "train r2:  0.8855590163873065\n",
      "test loss:  6.776852130889893\n",
      "test r2:  -0.2561866410935225\n",
      "train loss:  1.6366112232208252\n",
      "train r2:  0.8851700763331753\n",
      "test loss:  6.770881175994873\n",
      "test r2:  -0.2543722517675455\n",
      "train loss:  1.6366060972213745\n",
      "train r2:  0.885558221016289\n",
      "test loss:  6.77658224105835\n",
      "test r2:  -0.256102233168634\n",
      "train loss:  1.6365824937820435\n",
      "train r2:  0.8851885859704588\n",
      "test loss:  6.771460056304932\n",
      "test r2:  -0.25454534268501705\n",
      "train loss:  1.6365536451339722\n",
      "train r2:  0.8855220047243134\n",
      "test loss:  6.775733947753906\n",
      "test r2:  -0.25584477997651134\n",
      "train loss:  1.6365162134170532\n",
      "train r2:  0.885244629077154\n",
      "test loss:  6.772534370422363\n",
      "test r2:  -0.2548696124377603\n",
      "train loss:  1.6364859342575073\n",
      "train r2:  0.8854536976239059\n",
      "test loss:  6.774531841278076\n",
      "test r2:  -0.25548119073772657\n",
      "train loss:  1.6364622116088867\n",
      "train r2:  0.8853232323789927\n",
      "test loss:  6.7737579345703125\n",
      "test r2:  -0.25524031081121423\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853749245344732\n",
      "test loss:  6.773385524749756\n",
      "test r2:  -0.2551337387116699\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853976515670394\n",
      "test loss:  6.774742603302002\n",
      "test r2:  -0.25553910165148763\n",
      "train loss:  1.636462688446045\n",
      "train r2:  0.8853108587756142\n",
      "test loss:  6.772621154785156\n",
      "test r2:  -0.2549002930814399\n",
      "train loss:  1.6364736557006836\n",
      "train r2:  0.8854472625764948\n",
      "test loss:  6.775262832641602\n",
      "test r2:  -0.2556977445588986\n",
      "train loss:  1.6364831924438477\n",
      "train r2:  0.8852766214577992\n",
      "test loss:  6.772361755371094\n",
      "test r2:  -0.25481894983062636\n",
      "train loss:  1.6364883184432983\n",
      "train r2:  0.8854644878034426\n",
      "test loss:  6.775285243988037\n",
      "test r2:  -0.25570550109148815\n",
      "train loss:  1.6364874839782715\n",
      "train r2:  0.8852749143577966\n",
      "test loss:  6.772565841674805\n",
      "test r2:  -0.25487726772086483\n",
      "train loss:  1.6364827156066895\n",
      "train r2:  0.8854521305224997\n",
      "test loss:  6.77491569519043\n",
      "test r2:  -0.2555940156268828\n",
      "train loss:  1.6364744901657104\n",
      "train r2:  0.8852989587792623\n",
      "test loss:  6.773070812225342\n",
      "test r2:  -0.25502765337270117\n",
      "train loss:  1.636467695236206\n",
      "train r2:  0.8854202403921201\n",
      "test loss:  6.774343967437744\n",
      "test r2:  -0.2554213981870599\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.8853360843222894\n",
      "test loss:  6.77366304397583\n",
      "test r2:  -0.25520751575809597\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853818938796011\n",
      "test loss:  6.773764133453369\n",
      "test r2:  -0.2552475901420608\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853733243437573\n",
      "test loss:  6.7741594314575195\n",
      "test r2:  -0.25536257888462544\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853487605301742\n",
      "test loss:  6.773329257965088\n",
      "test r2:  -0.2551182921363975\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8854009339449952\n",
      "test loss:  6.77446174621582\n",
      "test r2:  -0.25545915739537195\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853280271215459\n",
      "test loss:  6.773121356964111\n",
      "test r2:  -0.2550553107164657\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8854143735140305\n",
      "test loss:  6.77455472946167\n",
      "test r2:  -0.25548849620789493\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8853216983530648\n",
      "test loss:  6.7731404304504395\n",
      "test r2:  -0.255057009018663\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.885414017526116\n",
      "test loss:  6.774469375610352\n",
      "test r2:  -0.255460204040981\n",
      "train loss:  1.6364576816558838\n",
      "train r2:  0.8853277939537089\n",
      "test loss:  6.773329257965088\n",
      "test r2:  -0.25510808977916555\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8854031721219688\n",
      "test loss:  6.774261951446533\n",
      "test r2:  -0.25539464217395746\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853418447093733\n",
      "test loss:  6.773585796356201\n",
      "test r2:  -0.2551824339161046\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853873171014418\n",
      "test loss:  6.774013996124268\n",
      "test r2:  -0.2553190013696578\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853580701874857\n",
      "test loss:  6.773823261260986\n",
      "test r2:  -0.2552547535410796\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853718520224892\n",
      "test loss:  6.7737932205200195\n",
      "test r2:  -0.25525352860183315\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853721117331761\n",
      "test loss:  6.773991584777832\n",
      "test r2:  -0.25530934460529364\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853601968869008\n",
      "test loss:  6.773646831512451\n",
      "test r2:  -0.25521075085211153\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853812439075299\n",
      "test loss:  6.77407693862915\n",
      "test r2:  -0.25533860530758923\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853539413200514\n",
      "test loss:  6.773590087890625\n",
      "test r2:  -0.25519312056637333\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853850525230019\n",
      "test loss:  6.774099349975586\n",
      "test r2:  -0.2553463388960098\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853522858332495\n",
      "test loss:  6.773601055145264\n",
      "test r2:  -0.25519362747535923\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853849557293655\n",
      "test loss:  6.774081230163574\n",
      "test r2:  -0.25533975412538634\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853536947908716\n",
      "test loss:  6.7736496925354\n",
      "test r2:  -0.2552046764554736\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853825807271516\n",
      "test loss:  6.774044513702393\n",
      "test r2:  -0.2553268554301982\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.885356423718953\n",
      "test loss:  6.773704528808594\n",
      "test r2:  -0.2552184683188341\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853796554641046\n",
      "test loss:  6.774003505706787\n",
      "test r2:  -0.25531381175084356\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853592506937692\n",
      "test loss:  6.773748874664307\n",
      "test r2:  -0.25523091352861016\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853769915733921\n",
      "test loss:  6.773968696594238\n",
      "test r2:  -0.2553032653171019\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853614766375317\n",
      "test loss:  6.773772716522217\n",
      "test r2:  -0.25523896637836363\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853752780321066\n",
      "test loss:  6.773945331573486\n",
      "test r2:  -0.2552971378937243\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.88536277693067\n",
      "test loss:  6.773777961730957\n",
      "test r2:  -0.25524285915162603\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853744424673236\n",
      "test loss:  6.773931503295898\n",
      "test r2:  -0.25529433635484167\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853634043686606\n",
      "test loss:  6.773776054382324\n",
      "test r2:  -0.25524426232613706\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.885374121009091\n",
      "test loss:  6.773928642272949\n",
      "test r2:  -0.25529350137276197\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853635611356352\n",
      "test loss:  6.773773193359375\n",
      "test r2:  -0.25524394463780253\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853742176336088\n",
      "test loss:  6.773937702178955\n",
      "test r2:  -0.25529473354974686\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853633373630818\n",
      "test loss:  6.773773193359375\n",
      "test r2:  -0.2552427840895952\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853744746321481\n",
      "test loss:  6.773950576782227\n",
      "test r2:  -0.2552960146945009\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853630952060965\n",
      "test loss:  6.773777961730957\n",
      "test r2:  -0.255241986780111\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853746546814436\n",
      "test loss:  6.773963451385498\n",
      "test r2:  -0.25529704887901294\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853629257226063\n",
      "test loss:  6.773784160614014\n",
      "test r2:  -0.25524177102688816\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853747309666259\n",
      "test loss:  6.773971080780029\n",
      "test r2:  -0.25529725492286204\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.88536286394646\n",
      "test loss:  6.7737884521484375\n",
      "test r2:  -0.25524207536829\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853746653647719\n",
      "test loss:  6.773970127105713\n",
      "test r2:  -0.25529628241606916\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853630710851095\n",
      "test loss:  6.773792743682861\n",
      "test r2:  -0.25524361144785535\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853743462125481\n",
      "test loss:  6.773963451385498\n",
      "test r2:  -0.25529471240029133\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853634427209355\n",
      "test loss:  6.773794651031494\n",
      "test r2:  -0.2552453359723257\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.885373961828765\n",
      "test loss:  6.773952007293701\n",
      "test r2:  -0.25529258759124374\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853638521596866\n",
      "test loss:  6.773796081542969\n",
      "test r2:  -0.25524709891902364\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853735755752309\n",
      "test loss:  6.773942470550537\n",
      "test r2:  -0.2552906767381453\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853642846956695\n",
      "test loss:  6.773799419403076\n",
      "test r2:  -0.25524916854921154\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853731489645844\n",
      "test loss:  6.773932933807373\n",
      "test r2:  -0.25528825196720595\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853647897622937\n",
      "test loss:  6.773806571960449\n",
      "test r2:  -0.255251595780009\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853726068477294\n",
      "test loss:  6.773924350738525\n",
      "test r2:  -0.25528560285351\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853653454435012\n",
      "test loss:  6.773814678192139\n",
      "test r2:  -0.25525403825025283\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853720672776513\n",
      "test loss:  6.773918628692627\n",
      "test r2:  -0.25528319540142674\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853658518943566\n",
      "test loss:  6.773826599121094\n",
      "test r2:  -0.2552570009830717\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853714563345113\n",
      "test loss:  6.773911952972412\n",
      "test r2:  -0.25527969384547067\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853666178119464\n",
      "test loss:  6.7738447189331055\n",
      "test r2:  -0.25526165012023916\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853704459822314\n",
      "test loss:  6.773897171020508\n",
      "test r2:  -0.25527411871505357\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853678221262361\n",
      "test loss:  6.773867607116699\n",
      "test r2:  -0.25526861106893195\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853689461926632\n",
      "test loss:  6.773871898651123\n",
      "test r2:  -0.25526575774911175\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853695925789453\n",
      "test loss:  6.773897171020508\n",
      "test r2:  -0.25527835405532073\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853668553530215\n",
      "test loss:  6.773834228515625\n",
      "test r2:  -0.2552545531041097\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853719878716546\n",
      "test loss:  6.773936748504639\n",
      "test r2:  -0.2552918288186852\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853639349964922\n",
      "test loss:  6.773777484893799\n",
      "test r2:  -0.2552375107249998\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853755831592662\n",
      "test loss:  6.774000644683838\n",
      "test r2:  -0.2553134704531954\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853592637288371\n",
      "test loss:  6.773680210113525\n",
      "test r2:  -0.2552096713281724\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853815133277604\n",
      "test loss:  6.77410888671875\n",
      "test r2:  -0.25534828931370557\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853517659224507\n",
      "test loss:  6.773529052734375\n",
      "test r2:  -0.25516517345141243\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.8853909517395974\n",
      "test loss:  6.774287700653076\n",
      "test r2:  -0.2554039554747283\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8853398240232517\n",
      "test loss:  6.7732930183410645\n",
      "test r2:  -0.25509493775135095\n",
      "train loss:  1.6364614963531494\n",
      "train r2:  0.8854059299424666\n",
      "test loss:  6.774577617645264\n",
      "test r2:  -0.2554910919092823\n",
      "train loss:  1.6364638805389404\n",
      "train r2:  0.8853211337980813\n",
      "test loss:  6.772943019866943\n",
      "test r2:  -0.25498806096221505\n",
      "train loss:  1.6364701986312866\n",
      "train r2:  0.8854286548737409\n",
      "test loss:  6.775019645690918\n",
      "test r2:  -0.2556218315808103\n",
      "train loss:  1.6364779472351074\n",
      "train r2:  0.8852929664102337\n",
      "test loss:  6.772429943084717\n",
      "test r2:  -0.25482963336715714\n",
      "train loss:  1.6364916563034058\n",
      "train r2:  0.8854622562245639\n",
      "test loss:  6.775671005249023\n",
      "test r2:  -0.25581376927454413\n",
      "train loss:  1.6365106105804443\n",
      "train r2:  0.8852514758331937\n",
      "test loss:  6.771693706512451\n",
      "test r2:  -0.2546017418617732\n",
      "train loss:  1.6365406513214111\n",
      "train r2:  0.8855102943572314\n",
      "test loss:  6.776577949523926\n",
      "test r2:  -0.256082019366102\n",
      "train loss:  1.6365798711776733\n",
      "train r2:  0.8851931348828981\n",
      "test loss:  6.770710468292236\n",
      "test r2:  -0.2542979133383583\n",
      "train loss:  1.6366376876831055\n",
      "train r2:  0.885573872520395\n",
      "test loss:  6.777692794799805\n",
      "test r2:  -0.25641330924494743\n",
      "train loss:  1.6367027759552002\n",
      "train r2:  0.8851204618888574\n",
      "test loss:  6.769642353057861\n",
      "test r2:  -0.2539686459017958\n",
      "train loss:  1.6367852687835693\n",
      "train r2:  0.8856420973946644\n",
      "test loss:  6.778636455535889\n",
      "test r2:  -0.2566954410655937\n",
      "train loss:  1.6368401050567627\n",
      "train r2:  0.8850580950882077\n",
      "test loss:  6.7686848640441895\n",
      "test r2:  -0.2536801064454084\n",
      "train loss:  1.6368849277496338\n",
      "train r2:  0.8857022082142794\n",
      "test loss:  6.779198169708252\n",
      "test r2:  -0.25686033852916723\n",
      "train loss:  1.6368365287780762\n",
      "train r2:  0.8850227769539065\n",
      "test loss:  6.7686920166015625\n",
      "test r2:  -0.25369638197651745\n",
      "train loss:  1.6367520093917847\n",
      "train r2:  0.8857003710527265\n",
      "test loss:  6.778072834014893\n",
      "test r2:  -0.2565232464459062\n",
      "train loss:  1.6366087198257446\n",
      "train r2:  0.8850981792572999\n",
      "test loss:  6.7715229988098145\n",
      "test r2:  -0.25456487227726665\n",
      "train loss:  1.6364964246749878\n",
      "train r2:  0.8855186372358038\n",
      "test loss:  6.773959159851074\n",
      "test r2:  -0.25530161507891624\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853618487203943\n",
      "test loss:  6.775808811187744\n",
      "test r2:  -0.2558511134406656\n",
      "train loss:  1.6364829540252686\n",
      "train r2:  0.8852439058664959\n",
      "test loss:  6.770579814910889\n",
      "test r2:  -0.25427977250556366\n",
      "train loss:  1.6365492343902588\n",
      "train r2:  0.8855787140783593\n",
      "test loss:  6.777585983276367\n",
      "test r2:  -0.2563735801515479\n",
      "train loss:  1.636594533920288\n",
      "train r2:  0.8851305117421574\n",
      "test loss:  6.770905017852783\n",
      "test r2:  -0.2543539227289704\n",
      "train loss:  1.6365940570831299\n",
      "train r2:  0.8855625617621554\n",
      "test loss:  6.775623798370361\n",
      "test r2:  -0.25578839826608\n",
      "train loss:  1.636547565460205\n",
      "train r2:  0.8852565324605417\n",
      "test loss:  6.773809432983398\n",
      "test r2:  -0.2552113330243615\n",
      "train loss:  1.636497974395752\n",
      "train r2:  0.8853809404953081\n",
      "test loss:  6.77285623550415\n",
      "test r2:  -0.2549626224878889\n",
      "train loss:  1.6364638805389404\n",
      "train r2:  0.885434183514487\n",
      "test loss:  6.775622844696045\n",
      "test r2:  -0.25576634568931356\n",
      "train loss:  1.6364693641662598\n",
      "train r2:  0.8852624823439835\n",
      "test loss:  6.772282123565674\n",
      "test r2:  -0.2547779736551601\n",
      "train loss:  1.6364883184432983\n",
      "train r2:  0.8854733874338151\n",
      "test loss:  6.7750935554504395\n",
      "test r2:  -0.2556278424681484\n",
      "train loss:  1.6365090608596802\n",
      "train r2:  0.8852914231686732\n",
      "test loss:  6.773401260375977\n",
      "test r2:  -0.2550950265597087\n",
      "train loss:  1.6365123987197876\n",
      "train r2:  0.8854055648870855\n",
      "test loss:  6.773971080780029\n",
      "test r2:  -0.25529715810050724\n",
      "train loss:  1.6364940404891968\n",
      "train r2:  0.8853622942494594\n",
      "test loss:  6.774126052856445\n",
      "test r2:  -0.25531368582238545\n",
      "train loss:  1.6364706754684448\n",
      "train r2:  0.8853593441311376\n",
      "test loss:  6.7737579345703125\n",
      "test r2:  -0.255228608120704\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853775061606254\n",
      "test loss:  6.7739362716674805\n",
      "test r2:  -0.25527845239383695\n",
      "train loss:  1.6364635229110718\n",
      "train r2:  0.8853667823785167\n",
      "test loss:  6.773933410644531\n",
      "test r2:  -0.2552752160591394\n",
      "train loss:  1.6364725828170776\n",
      "train r2:  0.8853673653863039\n",
      "test loss:  6.773956298828125\n",
      "test r2:  -0.25529925986758584\n",
      "train loss:  1.6364827156066895\n",
      "train r2:  0.8853619530437109\n",
      "test loss:  6.773558139801025\n",
      "test r2:  -0.2551614152360815\n",
      "train loss:  1.636478066444397\n",
      "train r2:  0.8853916473144708\n",
      "test loss:  6.774526596069336\n",
      "test r2:  -0.2554633894145233\n",
      "train loss:  1.6364665031433105\n",
      "train r2:  0.8853271196259311\n",
      "test loss:  6.773099899291992\n",
      "test r2:  -0.255026647305024\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8854206884282407\n",
      "test loss:  6.774652481079102\n",
      "test r2:  -0.25548916861761684\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853218870004966\n",
      "test loss:  6.773513317108154\n",
      "test r2:  -0.25515190216399763\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853938898313144\n",
      "test loss:  6.773811340332031\n",
      "test r2:  -0.2552343059890345\n",
      "train loss:  1.6364617347717285\n",
      "train r2:  0.8853762832316363\n",
      "test loss:  6.774569988250732\n",
      "test r2:  -0.2554631451394389\n",
      "train loss:  1.6364679336547852\n",
      "train r2:  0.8853272837617383\n",
      "test loss:  6.772932529449463\n",
      "test r2:  -0.25497264668666286\n",
      "train loss:  1.6364648342132568\n",
      "train r2:  0.8854321430315293\n",
      "test loss:  6.774991989135742\n",
      "test r2:  -0.2555842181185861\n",
      "train loss:  1.636459469795227\n",
      "train r2:  0.885301525370928\n",
      "test loss:  6.77313232421875\n",
      "test r2:  -0.2550333514330483\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8854193419522207\n",
      "test loss:  6.774245738983154\n",
      "test r2:  -0.2553629909380166\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853489935001158\n",
      "test loss:  6.7741594314575195\n",
      "test r2:  -0.25533966619108717\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853539130030338\n",
      "test loss:  6.773252964019775\n",
      "test r2:  -0.25506970120557826\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8854115364005206\n",
      "test loss:  6.774816513061523\n",
      "test r2:  -0.2555329947830829\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853124951522333\n",
      "test loss:  6.7731099128723145\n",
      "test r2:  -0.2550255928015914\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8854209151236504\n",
      "test loss:  6.774479389190674\n",
      "test r2:  -0.25543147645560693\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853342594211229\n",
      "test loss:  6.773779392242432\n",
      "test r2:  -0.2552237385154148\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.885378685080729\n",
      "test loss:  6.773726940155029\n",
      "test r2:  -0.25520934323459676\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853817741121865\n",
      "test loss:  6.774360179901123\n",
      "test r2:  -0.2554002065217571\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853409543901434\n",
      "test loss:  6.773417949676514\n",
      "test r2:  -0.2551193148096538\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.885400997143321\n",
      "test loss:  6.7743377685546875\n",
      "test r2:  -0.2553973056817158\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853415138403354\n",
      "test loss:  6.7736663818359375\n",
      "test r2:  -0.255190604783752\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853857752664647\n",
      "test loss:  6.774011611938477\n",
      "test r2:  -0.2552979214686588\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853627802898708\n",
      "test loss:  6.7739763259887695\n",
      "test r2:  -0.25527920232596024\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.885366919943276\n",
      "test loss:  6.773855209350586\n",
      "test r2:  -0.25524606121523474\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853739656010452\n",
      "test loss:  6.774012565612793\n",
      "test r2:  -0.2552915727691545\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853642600052842\n",
      "test loss:  6.7739105224609375\n",
      "test r2:  -0.2552585929583582\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853713005528017\n",
      "test loss:  6.773950099945068\n",
      "test r2:  -0.2552768438134836\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853673597046093\n",
      "test loss:  6.773913383483887\n",
      "test r2:  -0.2552581062674202\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853714278429856\n",
      "test loss:  6.774024486541748\n",
      "test r2:  -0.25529895715448325\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853626240699817\n",
      "test loss:  6.773789882659912\n",
      "test r2:  -0.2552213915188024\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853792766571493\n",
      "test loss:  6.7741498947143555\n",
      "test r2:  -0.2553339478701926\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853551837668466\n",
      "test loss:  6.773730278015137\n",
      "test r2:  -0.2552059835014493\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853825417855561\n",
      "test loss:  6.774096965789795\n",
      "test r2:  -0.2553175710250808\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853586991253521\n",
      "test loss:  6.773881435394287\n",
      "test r2:  -0.25525396948072765\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853722412920625\n",
      "test loss:  6.773861408233643\n",
      "test r2:  -0.2552487318921177\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853733943477262\n",
      "test loss:  6.774113655090332\n",
      "test r2:  -0.25532422228049056\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853572198213655\n",
      "test loss:  6.773684978485107\n",
      "test r2:  -0.25519671196296745\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853844793279205\n",
      "test loss:  6.774181842803955\n",
      "test r2:  -0.2553436071123365\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853530916154307\n",
      "test loss:  6.773743152618408\n",
      "test r2:  -0.2552134268900925\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853809056401574\n",
      "test loss:  6.77402925491333\n",
      "test r2:  -0.2552975894103282\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853629421753642\n",
      "test loss:  6.773952007293701\n",
      "test r2:  -0.25527478198121\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853678382662454\n",
      "test loss:  6.77383279800415\n",
      "test r2:  -0.25523856689871893\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853755647474157\n",
      "test loss:  6.774099349975586\n",
      "test r2:  -0.255317376414657\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853587235938905\n",
      "test loss:  6.773778915405273\n",
      "test r2:  -0.2552206762633069\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853794207467591\n",
      "test loss:  6.774081230163574\n",
      "test r2:  -0.25531105182370895\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.885360085824071\n",
      "test loss:  6.773864269256592\n",
      "test r2:  -0.25524452176642143\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.885374306439306\n",
      "test loss:  6.7739787101745605\n",
      "test r2:  -0.25528008225575327\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.885366712892766\n",
      "test loss:  6.7739577293396\n",
      "test r2:  -0.2552726484448884\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853682893588454\n",
      "test loss:  6.7739152908325195\n",
      "test r2:  -0.2552615833256666\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.885370662846248\n",
      "test loss:  6.773977279663086\n",
      "test r2:  -0.25527982577866615\n",
      "train loss:  1.636448621749878\n",
      "train r2:  0.8853667763675743\n",
      "test loss:  6.773922443389893\n",
      "test r2:  -0.25526315695186486\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.885370344076904\n",
      "test loss:  6.773956298828125\n",
      "test r2:  -0.25527436790678215\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853679209043792\n",
      "test loss:  6.773938179016113\n",
      "test r2:  -0.25526712024635434\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853695058596914\n",
      "test loss:  6.773959159851074\n",
      "test r2:  -0.2552754214245305\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853677181549908\n",
      "test loss:  6.773914813995361\n",
      "test r2:  -0.2552603759792198\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853709316317803\n",
      "test loss:  6.773992538452148\n",
      "test r2:  -0.2552855871660251\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.885365519091169\n",
      "test loss:  6.773879528045654\n",
      "test r2:  -0.25525024638289406\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853730886025286\n",
      "test loss:  6.774013042449951\n",
      "test r2:  -0.255291332461385\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853642854848285\n",
      "test loss:  6.7738871574401855\n",
      "test r2:  -0.2552522408486424\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853726680403505\n",
      "test loss:  6.773979663848877\n",
      "test r2:  -0.2552807244743509\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853665843154414\n",
      "test loss:  6.7739481925964355\n",
      "test r2:  -0.2552695615880538\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853689804934554\n",
      "test loss:  6.773916721343994\n",
      "test r2:  -0.2552614091048253\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853706998628019\n",
      "test loss:  6.77400541305542\n",
      "test r2:  -0.25528600988836025\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853654535013729\n",
      "test loss:  6.773882865905762\n",
      "test r2:  -0.25525164401401934\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853727935958894\n",
      "test loss:  6.774011611938477\n",
      "test r2:  -0.25528721934186716\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853652071015751\n",
      "test loss:  6.77390718460083\n",
      "test r2:  -0.2552591888769349\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853711637589833\n",
      "test loss:  6.773965835571289\n",
      "test r2:  -0.25527355091945636\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853681303324475\n",
      "test loss:  6.773959159851074\n",
      "test r2:  -0.2552752800036764\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853676911847354\n",
      "test loss:  6.773916721343994\n",
      "test r2:  -0.25525846524593954\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853713364394985\n",
      "test loss:  6.773993015289307\n",
      "test r2:  -0.2552867745755363\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.885365222095805\n",
      "test loss:  6.773894786834717\n",
      "test r2:  -0.25525175783725085\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853727379864859\n",
      "test loss:  6.773994445800781\n",
      "test r2:  -0.2552890716673397\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853646959679339\n",
      "test loss:  6.773892402648926\n",
      "test r2:  -0.25525153172128645\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853727485731502\n",
      "test loss:  6.77398681640625\n",
      "test r2:  -0.25528893906643924\n",
      "train loss:  1.6364543437957764\n",
      "train r2:  0.885364701835258\n",
      "test loss:  6.77388334274292\n",
      "test r2:  -0.2552498351692547\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853731034298188\n",
      "test loss:  6.773996353149414\n",
      "test r2:  -0.2552934772959523\n",
      "train loss:  1.6364543437957764\n",
      "train r2:  0.88536370839659\n",
      "test loss:  6.773852348327637\n",
      "test r2:  -0.2552419445958978\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.8853748105218372\n",
      "test loss:  6.774026870727539\n",
      "test r2:  -0.25530280423552076\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853617071855443\n",
      "test loss:  6.7738189697265625\n",
      "test r2:  -0.2552326024660392\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853768067760442\n",
      "test loss:  6.774056911468506\n",
      "test r2:  -0.2553098456657157\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.885360277674493\n",
      "test loss:  6.773816108703613\n",
      "test r2:  -0.255230143481872\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853773836713261\n",
      "test loss:  6.774062633514404\n",
      "test r2:  -0.25530747444789714\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853608203923534\n",
      "test loss:  6.773852348327637\n",
      "test r2:  -0.25523735553733684\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853758566741482\n",
      "test loss:  6.774044990539551\n",
      "test r2:  -0.2552975672408815\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853629875356481\n",
      "test loss:  6.773904800415039\n",
      "test r2:  -0.25524937811438564\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853733327752793\n",
      "test loss:  6.774024486541748\n",
      "test r2:  -0.25528677993151416\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.885365354359226\n",
      "test loss:  6.773946762084961\n",
      "test r2:  -0.2552587912298949\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853713859392548\n",
      "test loss:  6.774011611938477\n",
      "test r2:  -0.25528051145134545\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853667142575017\n",
      "test loss:  6.7739644050598145\n",
      "test r2:  -0.2552629117504932\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853704927921744\n",
      "test loss:  6.7740068435668945\n",
      "test r2:  -0.2552782175444541\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853671837239911\n",
      "test loss:  6.773965358734131\n",
      "test r2:  -0.2552639833925425\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853702864000824\n",
      "test loss:  6.774000644683838\n",
      "test r2:  -0.2552774795060835\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853673454986036\n",
      "test loss:  6.773963451385498\n",
      "test r2:  -0.25526483560591906\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853700528527823\n",
      "test loss:  6.773985385894775\n",
      "test r2:  -0.25527518162778096\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853678296809567\n",
      "test loss:  6.7739667892456055\n",
      "test r2:  -0.2552677278712756\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853694275461338\n",
      "test loss:  6.773967266082764\n",
      "test r2:  -0.2552720874251664\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853684708047\n",
      "test loss:  6.773968696594238\n",
      "test r2:  -0.2552693051442494\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.885369053197999\n",
      "test loss:  6.773962497711182\n",
      "test r2:  -0.25527204554305905\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.885368445055202\n",
      "test loss:  6.773961067199707\n",
      "test r2:  -0.25526688657108787\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853695741649598\n",
      "test loss:  6.773977756500244\n",
      "test r2:  -0.2552772542027326\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853672856126924\n",
      "test loss:  6.773936748504639\n",
      "test r2:  -0.25525871730204086\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853713258823195\n",
      "test loss:  6.774013996124268\n",
      "test r2:  -0.2552883190142161\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853649438245239\n",
      "test loss:  6.773898124694824\n",
      "test r2:  -0.2552462366972399\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853739735763207\n",
      "test loss:  6.774057388305664\n",
      "test r2:  -0.2553020368319523\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853619752054006\n",
      "test loss:  6.773849964141846\n",
      "test r2:  -0.25523149749762175\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853770844988584\n",
      "test loss:  6.774104595184326\n",
      "test r2:  -0.25531717963265543\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853587034314296\n",
      "test loss:  6.7737956047058105\n",
      "test r2:  -0.25521573947070775\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853804662292014\n",
      "test loss:  6.7741546630859375\n",
      "test r2:  -0.255333085790757\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.885355304751784\n",
      "test loss:  6.773739337921143\n",
      "test r2:  -0.25519935175490693\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853839499802356\n",
      "test loss:  6.774209499359131\n",
      "test r2:  -0.2553500163620397\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.885351670590314\n",
      "test loss:  6.773676872253418\n",
      "test r2:  -0.25518030478131104\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853880371999976\n",
      "test loss:  6.774286270141602\n",
      "test r2:  -0.2553716324163797\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853470509934283\n",
      "test loss:  6.773603916168213\n",
      "test r2:  -0.25515627063717883\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853931766903619\n",
      "test loss:  6.774383544921875\n",
      "test r2:  -0.25539805594154696\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853414287214935\n",
      "test loss:  6.773524761199951\n",
      "test r2:  -0.2551290860767317\n",
      "train loss:  1.6364576816558838\n",
      "train r2:  0.8853990130813897\n",
      "test loss:  6.774488925933838\n",
      "test r2:  -0.25542668107157285\n",
      "train loss:  1.6364587545394897\n",
      "train r2:  0.8853352756197314\n",
      "test loss:  6.773439407348633\n",
      "test r2:  -0.2550998441229182\n",
      "train loss:  1.636460781097412\n",
      "train r2:  0.8854052257498032\n",
      "test loss:  6.774599075317383\n",
      "test r2:  -0.25545766005038084\n",
      "train loss:  1.6364620923995972\n",
      "train r2:  0.8853286458091794\n",
      "test loss:  6.773342609405518\n",
      "test r2:  -0.2550676357393302\n",
      "train loss:  1.6364648342132568\n",
      "train r2:  0.8854120920007386\n",
      "test loss:  6.774717807769775\n",
      "test r2:  -0.2554927851652884\n",
      "train loss:  1.636467456817627\n",
      "train r2:  0.8853210944800203\n",
      "test loss:  6.773221015930176\n",
      "test r2:  -0.2550292806590373\n",
      "train loss:  1.6364718675613403\n",
      "train r2:  0.8854202203549403\n",
      "test loss:  6.774857044219971\n",
      "test r2:  -0.25553606372657867\n",
      "train loss:  1.6364753246307373\n",
      "train r2:  0.8853116857778119\n",
      "test loss:  6.773058891296387\n",
      "test r2:  -0.25498021216241207\n",
      "train loss:  1.6364818811416626\n",
      "train r2:  0.8854305894586781\n",
      "test loss:  6.775030136108398\n",
      "test r2:  -0.2555910456983128\n",
      "train loss:  1.636486530303955\n",
      "train r2:  0.8852997745196821\n",
      "test loss:  6.772851943969727\n",
      "test r2:  -0.25491906004595344\n",
      "train loss:  1.6364953517913818\n",
      "train r2:  0.8854434589447078\n",
      "test loss:  6.775238037109375\n",
      "test r2:  -0.2556575252511881\n",
      "train loss:  1.6365011930465698\n",
      "train r2:  0.8852852707215444\n",
      "test loss:  6.772607326507568\n",
      "test r2:  -0.2548469548940919\n",
      "train loss:  1.636512041091919\n",
      "train r2:  0.8854585977702771\n",
      "test loss:  6.775477409362793\n",
      "test r2:  -0.25573227818594413\n",
      "train loss:  1.6365187168121338\n",
      "train r2:  0.8852690054936114\n",
      "test loss:  6.772353649139404\n",
      "test r2:  -0.2547713028560641\n",
      "train loss:  1.6365300416946411\n",
      "train r2:  0.8854744823432853\n",
      "test loss:  6.7757158279418945\n",
      "test r2:  -0.25580485717030066\n",
      "train loss:  1.6365362405776978\n",
      "train r2:  0.8852532427190463\n",
      "test loss:  6.772137641906738\n",
      "test r2:  -0.2547058857223059\n",
      "train loss:  1.6365455389022827\n",
      "train r2:  0.8854882859740617\n",
      "test loss:  6.775900363922119\n",
      "test r2:  -0.2558580682729956\n",
      "train loss:  1.6365474462509155\n",
      "train r2:  0.8852416947205214\n",
      "test loss:  6.77203369140625\n",
      "test r2:  -0.2546721800695093\n",
      "train loss:  1.636549711227417\n",
      "train r2:  0.8854954465554025\n",
      "test loss:  6.775941371917725\n",
      "test r2:  -0.2558655850846179\n",
      "train loss:  1.6365432739257812\n",
      "train r2:  0.8852401948581621\n",
      "test loss:  6.772132873535156\n",
      "test r2:  -0.25469864124166985\n",
      "train loss:  1.6365352869033813\n",
      "train r2:  0.8854899983599708\n",
      "test loss:  6.775747776031494\n",
      "test r2:  -0.255801559276166\n",
      "train loss:  1.6365199089050293\n",
      "train r2:  0.8852542622494683\n",
      "test loss:  6.772485733032227\n",
      "test r2:  -0.254802831862039\n",
      "train loss:  1.6365047693252563\n",
      "train r2:  0.8854681745075431\n",
      "test loss:  6.775296211242676\n",
      "test r2:  -0.25566087794834225\n",
      "train loss:  1.6364870071411133\n",
      "train r2:  0.8852848984445322\n",
      "test loss:  6.773055553436279\n",
      "test r2:  -0.2549742926226568\n",
      "train loss:  1.6364729404449463\n",
      "train r2:  0.8854320135620101\n",
      "test loss:  6.774669170379639\n",
      "test r2:  -0.2554695887800491\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8853261907014929\n",
      "test loss:  6.773708820343018\n",
      "test r2:  -0.2551728046203279\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.885389809178946\n",
      "test loss:  6.774029731750488\n",
      "test r2:  -0.255275820950259\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853677559250499\n",
      "test loss:  6.774289131164551\n",
      "test r2:  -0.2553504175339889\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853518473330844\n",
      "test loss:  6.773522853851318\n",
      "test r2:  -0.2551223922464194\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8854005246396565\n",
      "test loss:  6.774688720703125\n",
      "test r2:  -0.25547324774798597\n",
      "train loss:  1.636457920074463\n",
      "train r2:  0.8853254798457558\n",
      "test loss:  6.773229598999023\n",
      "test r2:  -0.255032396696222\n",
      "train loss:  1.6364613771438599\n",
      "train r2:  0.8854196863639958\n",
      "test loss:  6.774874687194824\n",
      "test r2:  -0.2555308265342906\n",
      "train loss:  1.6364641189575195\n",
      "train r2:  0.8853130333192282\n",
      "test loss:  6.773143291473389\n",
      "test r2:  -0.25500412804594164\n",
      "train loss:  1.6364657878875732\n",
      "train r2:  0.8854257005205611\n",
      "test loss:  6.774885654449463\n",
      "test r2:  -0.2555342967669938\n",
      "train loss:  1.636466383934021\n",
      "train r2:  0.8853122925979243\n",
      "test loss:  6.773212909698486\n",
      "test r2:  -0.2550218135474065\n",
      "train loss:  1.6364659070968628\n",
      "train r2:  0.8854219561553425\n",
      "test loss:  6.774777412414551\n",
      "test r2:  -0.25550103626968124\n",
      "train loss:  1.6364647150039673\n",
      "train r2:  0.8853194462451063\n",
      "test loss:  6.773366928100586\n",
      "test r2:  -0.2550662297583073\n",
      "train loss:  1.6364637613296509\n",
      "train r2:  0.8854124907596576\n",
      "test loss:  6.7746076583862305\n",
      "test r2:  -0.2554499001326702\n",
      "train loss:  1.6364611387252808\n",
      "train r2:  0.8853303865401336\n",
      "test loss:  6.773547649383545\n",
      "test r2:  -0.25512123595380776\n",
      "train loss:  1.6364610195159912\n",
      "train r2:  0.8854007528370553\n",
      "test loss:  6.774411201477051\n",
      "test r2:  -0.2553925570651987\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853427255697333\n",
      "test loss:  6.773726940155029\n",
      "test r2:  -0.2551789281491006\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853884410224868\n",
      "test loss:  6.774212837219238\n",
      "test r2:  -0.25533550878541655\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853549199939303\n",
      "test loss:  6.7738871574401855\n",
      "test r2:  -0.25523223571162323\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853770754979122\n",
      "test loss:  6.774040699005127\n",
      "test r2:  -0.25528559726762445\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853656200844965\n",
      "test loss:  6.774024486541748\n",
      "test r2:  -0.25527656818800804\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853676136702571\n",
      "test loss:  6.773918151855469\n",
      "test r2:  -0.25524702795897514\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853739271958466\n",
      "test loss:  6.774133682250977\n",
      "test r2:  -0.255308435428073\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853607722896432\n",
      "test loss:  6.77385139465332\n",
      "test r2:  -0.255221943532699\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853793266223507\n",
      "test loss:  6.774211406707764\n",
      "test r2:  -0.25532828760481974\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853565787867543\n",
      "test loss:  6.773827075958252\n",
      "test r2:  -0.25520819739484635\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853823229884322\n",
      "test loss:  6.774258613586426\n",
      "test r2:  -0.2553384469923632\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853544513695156\n",
      "test loss:  6.7738237380981445\n",
      "test r2:  -0.25520207001140816\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853836670353817\n",
      "test loss:  6.7742838859558105\n",
      "test r2:  -0.2553439603585259\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853532941527771\n",
      "test loss:  6.77381706237793\n",
      "test r2:  -0.25519710099794346\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853847102642082\n",
      "test loss:  6.774302959442139\n",
      "test r2:  -0.2553500550402892\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853519443087181\n",
      "test loss:  6.773788928985596\n",
      "test r2:  -0.25518946300758105\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853863170686249\n",
      "test loss:  6.77432107925415\n",
      "test r2:  -0.25535893165785195\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853500115278791\n",
      "test loss:  6.773739337921143\n",
      "test r2:  -0.25517813252833665\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853887056789264\n",
      "test loss:  6.774348258972168\n",
      "test r2:  -0.25537176182161514\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853471979588182\n",
      "test loss:  6.7736711502075195\n",
      "test r2:  -0.2551621782708924\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853920498548156\n",
      "test loss:  6.774392604827881\n",
      "test r2:  -0.25538917344418555\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853434266042437\n",
      "test loss:  6.773594379425049\n",
      "test r2:  -0.25514184200080603\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853963575201894\n",
      "test loss:  6.77446174621582\n",
      "test r2:  -0.25541116299655786\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853387172527987\n",
      "test loss:  6.7735137939453125\n",
      "test r2:  -0.2551175535521881\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8854015634624358\n",
      "test loss:  6.774557590484619\n",
      "test r2:  -0.2554379899354018\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853329725227274\n",
      "test loss:  6.773428440093994\n",
      "test r2:  -0.2550888885283207\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.8854077149373942\n",
      "test loss:  6.77467679977417\n",
      "test r2:  -0.25546941522742483\n",
      "train loss:  1.636459469795227\n",
      "train r2:  0.8853262561044354\n",
      "test loss:  6.773334980010986\n",
      "test r2:  -0.2550555459324719\n",
      "train loss:  1.6364611387252808\n",
      "train r2:  0.8854147998353633\n",
      "test loss:  6.774815082550049\n",
      "test r2:  -0.25550619895806603\n",
      "train loss:  1.6364630460739136\n",
      "train r2:  0.8853183844168451\n",
      "test loss:  6.773219585418701\n",
      "test r2:  -0.2550160949069966\n",
      "train loss:  1.6364655494689941\n",
      "train r2:  0.8854232382543938\n",
      "test loss:  6.774972915649414\n",
      "test r2:  -0.2555507898905869\n",
      "train loss:  1.636468529701233\n",
      "train r2:  0.8853088157226876\n",
      "test loss:  6.773068428039551\n",
      "test r2:  -0.2549675354883747\n",
      "train loss:  1.636472463607788\n",
      "train r2:  0.8854335674983681\n",
      "test loss:  6.7751545906066895\n",
      "test r2:  -0.25560476799438403\n",
      "train loss:  1.6364768743515015\n",
      "train r2:  0.8852971465840684\n",
      "test loss:  6.772874355316162\n",
      "test r2:  -0.25490798514925594\n",
      "train loss:  1.636482834815979\n",
      "train r2:  0.8854461080579439\n",
      "test loss:  6.775362968444824\n",
      "test r2:  -0.2556697901683078\n",
      "train loss:  1.6364887952804565\n",
      "train r2:  0.8852830633688691\n",
      "test loss:  6.772636890411377\n",
      "test r2:  -0.25483744375702133\n",
      "train loss:  1.6364974975585938\n",
      "train r2:  0.8854609856351419\n",
      "test loss:  6.775599956512451\n",
      "test r2:  -0.25574504253313846\n",
      "train loss:  1.6365050077438354\n",
      "train r2:  0.8852666989215394\n",
      "test loss:  6.772366046905518\n",
      "test r2:  -0.2547577951780149\n",
      "train loss:  1.6365165710449219\n",
      "train r2:  0.8854777175230213\n",
      "test loss:  6.775856018066406\n",
      "test r2:  -0.255826474314782\n",
      "train loss:  1.6365246772766113\n",
      "train r2:  0.885248955034458\n",
      "test loss:  6.772087574005127\n",
      "test r2:  -0.2546765209163935\n",
      "train loss:  1.6365371942520142\n",
      "train r2:  0.8854947804982705\n",
      "test loss:  6.776098728179932\n",
      "test r2:  -0.2559023279080832\n",
      "train loss:  1.6365431547164917\n",
      "train r2:  0.8852324331238379\n",
      "test loss:  6.771865367889404\n",
      "test r2:  -0.2546111551508652\n",
      "train loss:  1.6365524530410767\n",
      "train r2:  0.8855084871526272\n",
      "test loss:  6.776252746582031\n",
      "test r2:  -0.2559490156833577\n",
      "train loss:  1.6365529298782349\n",
      "train r2:  0.8852222799891448\n",
      "test loss:  6.771797180175781\n",
      "test r2:  -0.2545908237897423\n",
      "train loss:  1.636553168296814\n",
      "train r2:  0.885512829017267\n",
      "test loss:  6.77621603012085\n",
      "test r2:  -0.2559350768178661\n",
      "train loss:  1.6365437507629395\n",
      "train r2:  0.8852254405917892\n",
      "test loss:  6.7719879150390625\n",
      "test r2:  -0.2546462412961703\n",
      "train loss:  1.6365330219268799\n",
      "train r2:  0.8855012815603774\n",
      "test loss:  6.775903701782227\n",
      "test r2:  -0.2558354574067243\n",
      "train loss:  1.6365151405334473\n",
      "train r2:  0.8852471982319308\n",
      "test loss:  6.772474765777588\n",
      "test r2:  -0.25478984426376505\n",
      "train loss:  1.636497974395752\n",
      "train r2:  0.8854711411181178\n",
      "test loss:  6.775323867797852\n",
      "test r2:  -0.2556547926974011\n",
      "train loss:  1.6364798545837402\n",
      "train r2:  0.885286417613041\n",
      "test loss:  6.7731781005859375\n",
      "test r2:  -0.25499872202360896\n",
      "train loss:  1.6364660263061523\n",
      "train r2:  0.8854269982444198\n",
      "test loss:  6.774601936340332\n",
      "test r2:  -0.2554323541011727\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853343850082838\n",
      "test loss:  6.773924350738525\n",
      "test r2:  -0.2552216530512976\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853795780595176\n",
      "test loss:  6.7739176750183105\n",
      "test r2:  -0.2552228070299838\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.885379282441908\n",
      "test loss:  6.774540901184082\n",
      "test r2:  -0.25540753987270826\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853397875942521\n",
      "test loss:  6.773406982421875\n",
      "test r2:  -0.2550675270150302\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8854123966723094\n",
      "test loss:  6.774932861328125\n",
      "test r2:  -0.2555279825561969\n",
      "train loss:  1.6364614963531494\n",
      "train r2:  0.8853138869827469\n",
      "test loss:  6.773125171661377\n",
      "test r2:  -0.2549829983947709\n",
      "train loss:  1.6364649534225464\n",
      "train r2:  0.8854303615392867\n",
      "test loss:  6.775086879730225\n",
      "test r2:  -0.2555772643113676\n",
      "train loss:  1.6364670991897583\n",
      "train r2:  0.8853032341697148\n",
      "test loss:  6.773067951202393\n",
      "test r2:  -0.25496581297777254\n",
      "train loss:  1.6364681720733643\n",
      "train r2:  0.8854339752971877\n",
      "test loss:  6.775041103363037\n",
      "test r2:  -0.25556589563519516\n",
      "train loss:  1.636467456817627\n",
      "train r2:  0.885305621833702\n",
      "test loss:  6.773182392120361\n",
      "test r2:  -0.2549999793798339\n",
      "train loss:  1.6364660263061523\n",
      "train r2:  0.885426700143283\n",
      "test loss:  6.774862289428711\n",
      "test r2:  -0.25551370265419937\n",
      "train loss:  1.6364636421203613\n",
      "train r2:  0.8853168623703636\n",
      "test loss:  6.7733988761901855\n",
      "test r2:  -0.25506509123719834\n",
      "train loss:  1.6364619731903076\n",
      "train r2:  0.8854128492420644\n",
      "test loss:  6.77461576461792\n",
      "test r2:  -0.25544072650514815\n",
      "train loss:  1.6364589929580688\n",
      "train r2:  0.8853325200455391\n",
      "test loss:  6.773650646209717\n",
      "test r2:  -0.2551416227621013\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.885396539479527\n",
      "test loss:  6.774357795715332\n",
      "test r2:  -0.25536441535466303\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853488531497623\n",
      "test loss:  6.773882865905762\n",
      "test r2:  -0.2552140849052402\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853810880353846\n",
      "test loss:  6.774132251739502\n",
      "test r2:  -0.2552973507549241\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853632543691936\n",
      "test loss:  6.774071216583252\n",
      "test r2:  -0.25527365671435387\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853683771622715\n",
      "test loss:  6.773960590362549\n",
      "test r2:  -0.2552453468512075\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853743496705615\n",
      "test loss:  6.7742109298706055\n",
      "test r2:  -0.2553166365800368\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853591557333567\n",
      "test loss:  6.773853778839111\n",
      "test r2:  -0.2552105983521664\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853818685003557\n",
      "test loss:  6.774306774139404\n",
      "test r2:  -0.2553442362640894\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853533203195475\n",
      "test loss:  6.773803234100342\n",
      "test r2:  -0.25519063235270023\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853861350045716\n",
      "test loss:  6.7743635177612305\n",
      "test r2:  -0.25535805398207545\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853503370526974\n",
      "test loss:  6.7737956047058105\n",
      "test r2:  -0.25518293084382115\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853878242771074\n",
      "test loss:  6.774385452270508\n",
      "test r2:  -0.25536199527199654\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853495500140063\n",
      "test loss:  6.773808002471924\n",
      "test r2:  -0.25518306285894354\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853878202498213\n",
      "test loss:  6.774383544921875\n",
      "test r2:  -0.25536037044039817\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853498595440097\n",
      "test loss:  6.7738189697265625\n",
      "test r2:  -0.2551849625556326\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853874023075181\n",
      "test loss:  6.7743754386901855\n",
      "test r2:  -0.2553596544782821\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853499785114223\n",
      "test loss:  6.773809909820557\n",
      "test r2:  -0.25518391660793927\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853876230232449\n",
      "test loss:  6.774372577667236\n",
      "test r2:  -0.25536241573673046\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853493794816296\n",
      "test loss:  6.773779392242432\n",
      "test r2:  -0.25517825550639883\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853887847675809\n",
      "test loss:  6.774384021759033\n",
      "test r2:  -0.255369932271849\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853476980863006\n",
      "test loss:  6.773730278015137\n",
      "test r2:  -0.25516725297940623\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853911163472038\n",
      "test loss:  6.774418354034424\n",
      "test r2:  -0.25538280064329344\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853449154685668\n",
      "test loss:  6.773672103881836\n",
      "test r2:  -0.25515169342116595\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853944069221018\n",
      "test loss:  6.774477005004883\n",
      "test r2:  -0.25540028881896637\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.885341220349172\n",
      "test loss:  6.773611068725586\n",
      "test r2:  -0.25513213737366325\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.885398565923637\n",
      "test loss:  6.774559497833252\n",
      "test r2:  -0.2554219925116443\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.8853365782890371\n",
      "test loss:  6.773545742034912\n",
      "test r2:  -0.2551089247504923\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8854035763009108\n",
      "test loss:  6.774661064147949\n",
      "test r2:  -0.25544798306745675\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853310534135304\n",
      "test loss:  6.773468017578125\n",
      "test r2:  -0.2550809856971481\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8854095692806482\n",
      "test loss:  6.774783134460449\n",
      "test r2:  -0.2554802557417233\n",
      "train loss:  1.6364587545394897\n",
      "train r2:  0.8853241660654582\n",
      "test loss:  6.773364067077637\n",
      "test r2:  -0.2550457844940739\n",
      "train loss:  1.636460304260254\n",
      "train r2:  0.8854170762858903\n",
      "test loss:  6.77492094039917\n",
      "test r2:  -0.25551912758784434\n",
      "train loss:  1.6364620923995972\n",
      "train r2:  0.8853158026023078\n",
      "test loss:  6.773232936859131\n",
      "test r2:  -0.2550040831699145\n",
      "train loss:  1.6364647150039673\n",
      "train r2:  0.8854259673350711\n",
      "test loss:  6.775074481964111\n",
      "test r2:  -0.2555651740170437\n",
      "train loss:  1.636467695236206\n",
      "train r2:  0.8853058632264593\n",
      "test loss:  6.7730631828308105\n",
      "test r2:  -0.2549526627861469\n",
      "train loss:  1.6364718675613403\n",
      "train r2:  0.8854368346766087\n",
      "test loss:  6.77525520324707\n",
      "test r2:  -0.25562235544510115\n",
      "train loss:  1.6364762783050537\n",
      "train r2:  0.8852935118436078\n",
      "test loss:  6.772846698760986\n",
      "test r2:  -0.25488903042495203\n",
      "train loss:  1.636482834815979\n",
      "train r2:  0.885450262128331\n",
      "test loss:  6.775475025177002\n",
      "test r2:  -0.25569241387663677\n",
      "train loss:  1.636488914489746\n",
      "train r2:  0.8852782852091265\n",
      "test loss:  6.7725830078125\n",
      "test r2:  -0.25481125141090755\n",
      "train loss:  1.6364986896514893\n",
      "train r2:  0.8854666443095193\n",
      "test loss:  6.775743007659912\n",
      "test r2:  -0.25577708327615944\n",
      "train loss:  1.6365067958831787\n",
      "train r2:  0.8852599079711729\n",
      "test loss:  6.772275924682617\n",
      "test r2:  -0.2547200460072967\n",
      "train loss:  1.6365196704864502\n",
      "train r2:  0.8854858300931819\n",
      "test loss:  6.776050090789795\n",
      "test r2:  -0.2558721169063325\n",
      "train loss:  1.636528491973877\n",
      "train r2:  0.8852392305521957\n",
      "test loss:  6.771954536437988\n",
      "test r2:  -0.2546244295832527\n",
      "train loss:  1.636542558670044\n",
      "train r2:  0.8855059278295712\n",
      "test loss:  6.776346206665039\n",
      "test r2:  -0.2559621170439299\n",
      "train loss:  1.636549949645996\n",
      "train r2:  0.8852196612943528\n",
      "test loss:  6.771698474884033\n",
      "test r2:  -0.25454729093369544\n",
      "train loss:  1.6365609169006348\n",
      "train r2:  0.8855221183747711\n",
      "test loss:  6.7765350341796875\n",
      "test r2:  -0.2560172462169803\n",
      "train loss:  1.636562466621399\n",
      "train r2:  0.8852077001685434\n",
      "test loss:  6.7716288566589355\n",
      "test r2:  -0.25452440811227794\n",
      "train loss:  1.6365635395050049\n",
      "train r2:  0.8855269931630343\n",
      "test loss:  6.776487350463867\n",
      "test r2:  -0.2559987188679529\n",
      "train loss:  1.6365540027618408\n",
      "train r2:  0.8852118067016544\n",
      "test loss:  6.771867275238037\n",
      "test r2:  -0.2545931116350595\n",
      "train loss:  1.636541724205017\n",
      "train r2:  0.8855126731518828\n",
      "test loss:  6.7761030197143555\n",
      "test r2:  -0.2558777126936189\n",
      "train loss:  1.6365214586257935\n",
      "train r2:  0.8852382052455938\n",
      "test loss:  6.772448539733887\n",
      "test r2:  -0.2547648148023143\n",
      "train loss:  1.636501431465149\n",
      "train r2:  0.8854765857580658\n",
      "test loss:  6.775410175323486\n",
      "test r2:  -0.2556645910951174\n",
      "train loss:  1.6364808082580566\n",
      "train r2:  0.8852844599266756\n",
      "test loss:  6.773257255554199\n",
      "test r2:  -0.25500690910665846\n",
      "train loss:  1.6364655494689941\n",
      "train r2:  0.8854253916579888\n",
      "test loss:  6.774577617645264\n",
      "test r2:  -0.255410615903914\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.885339173164759\n",
      "test loss:  6.774085998535156\n",
      "test r2:  -0.2552564095167156\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853722432716034\n",
      "test loss:  6.773820400238037\n",
      "test r2:  -0.25518063802451096\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853884063846145\n",
      "test loss:  6.7747416496276855\n",
      "test r2:  -0.2554555952789761\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853295968613938\n",
      "test loss:  6.773287773132324\n",
      "test r2:  -0.25501930988588506\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8854227589632174\n",
      "test loss:  6.775129795074463\n",
      "test r2:  -0.2555751580193586\n",
      "train loss:  1.6364657878875732\n",
      "train r2:  0.885303841406982\n",
      "test loss:  6.773029804229736\n",
      "test r2:  -0.25494153066395087\n",
      "train loss:  1.6364697217941284\n",
      "train r2:  0.88543924682884\n",
      "test loss:  6.775244235992432\n",
      "test r2:  -0.25561193226592516\n",
      "train loss:  1.636471152305603\n",
      "train r2:  0.8852958807362803\n",
      "test loss:  6.773035049438477\n",
      "test r2:  -0.2549418247992963\n",
      "train loss:  1.6364707946777344\n",
      "train r2:  0.8854391843526506\n",
      "test loss:  6.775134086608887\n",
      "test r2:  -0.2555797627848617\n",
      "train loss:  1.636468768119812\n",
      "train r2:  0.8853027967109214\n",
      "test loss:  6.773233413696289\n",
      "test r2:  -0.25500006094942895\n",
      "train loss:  1.6364662647247314\n",
      "train r2:  0.8854267997076952\n",
      "test loss:  6.774874687194824\n",
      "test r2:  -0.25550199878906077\n",
      "train loss:  1.636462688446045\n",
      "train r2:  0.885319498608001\n",
      "test loss:  6.7735371589660645\n",
      "test r2:  -0.2550908768782183\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8854074939393102\n",
      "test loss:  6.774548530578613\n",
      "test r2:  -0.2554049236424625\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853403458491369\n",
      "test loss:  6.773855686187744\n",
      "test r2:  -0.25518854224434606\n",
      "train loss:  1.6364567279815674\n",
      "train r2:  0.8853866751678398\n",
      "test loss:  6.77423095703125\n",
      "test r2:  -0.25531105623189365\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853604175067902\n",
      "test loss:  6.774126052856445\n",
      "test r2:  -0.25527377392117057\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853684799615185\n",
      "test loss:  6.773977279663086\n",
      "test r2:  -0.2552358859497261\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853765137019844\n",
      "test loss:  6.7743239402771\n",
      "test r2:  -0.2553366130262198\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853550357241889\n",
      "test loss:  6.773809909820557\n",
      "test r2:  -0.2551848386830302\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853874285585175\n",
      "test loss:  6.774450778961182\n",
      "test r2:  -0.2553750075512917\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853468212967874\n",
      "test loss:  6.773736953735352\n",
      "test r2:  -0.2551589297603063\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853930383120345\n",
      "test loss:  6.774511337280273\n",
      "test r2:  -0.255390557949581\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853435116317229\n",
      "test loss:  6.773737907409668\n",
      "test r2:  -0.25515344747776014\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853942277921402\n",
      "test loss:  6.774516582489014\n",
      "test r2:  -0.25538884305767784\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853439005557329\n",
      "test loss:  6.773782730102539\n",
      "test r2:  -0.2551618838728684\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853924417037975\n",
      "test loss:  6.774484634399414\n",
      "test r2:  -0.2553774232099\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853463535091705\n",
      "test loss:  6.773834705352783\n",
      "test r2:  -0.25517521517898056\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.88538964757346\n",
      "test loss:  6.774440288543701\n",
      "test r2:  -0.25536472002786925\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853490624334438\n",
      "test loss:  6.773870468139648\n",
      "test r2:  -0.2551866760783308\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853871414084443\n",
      "test loss:  6.77439546585083\n",
      "test r2:  -0.25535429901156603\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853512594395674\n",
      "test loss:  6.77388334274292\n",
      "test r2:  -0.25519463882271953\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853854216419483\n",
      "test loss:  6.7743611335754395\n",
      "test r2:  -0.2553481262677073\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853525469463578\n",
      "test loss:  6.773876667022705\n",
      "test r2:  -0.2551972127110427\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853848135152973\n",
      "test loss:  6.774347305297852\n",
      "test r2:  -0.25534676929336886\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853527935266043\n",
      "test loss:  6.77386474609375\n",
      "test r2:  -0.2551962602215765\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853850310051701\n",
      "test loss:  6.774356365203857\n",
      "test r2:  -0.25534919775819165\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853523288263502\n",
      "test loss:  6.773855209350586\n",
      "test r2:  -0.25519233400724795\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853858868121838\n",
      "test loss:  6.774389266967773\n",
      "test r2:  -0.255354874934834\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853511181983755\n",
      "test loss:  6.773846626281738\n",
      "test r2:  -0.2551857908755111\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853873432985158\n",
      "test loss:  6.774435043334961\n",
      "test r2:  -0.25536317236945827\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853494129723364\n",
      "test loss:  6.7738356590271\n",
      "test r2:  -0.2551778384354908\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853890748390429\n",
      "test loss:  6.774482250213623\n",
      "test r2:  -0.2553722627233035\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853474938286265\n",
      "test loss:  6.773817539215088\n",
      "test r2:  -0.25516893016645503\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853910090627465\n",
      "test loss:  6.774523735046387\n",
      "test r2:  -0.2553823543817948\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853453721640937\n",
      "test loss:  6.773787975311279\n",
      "test r2:  -0.25515863719898335\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853932364661417\n",
      "test loss:  6.774560451507568\n",
      "test r2:  -0.2553934364670747\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853430169827293\n",
      "test loss:  6.773743152618408\n",
      "test r2:  -0.2551463034012249\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853958376128868\n",
      "test loss:  6.774596691131592\n",
      "test r2:  -0.2554067953743935\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853400859168923\n",
      "test loss:  6.773683071136475\n",
      "test r2:  -0.2551304353688777\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853991877281271\n",
      "test loss:  6.774645805358887\n",
      "test r2:  -0.2554250251860566\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853361732717445\n",
      "test loss:  6.77360200881958\n",
      "test r2:  -0.2551079037075834\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8854039614620897\n",
      "test loss:  6.774728298187256\n",
      "test r2:  -0.25545247954184913\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853302302017636\n",
      "test loss:  6.773486137390137\n",
      "test r2:  -0.2550736901928874\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8854112168412849\n",
      "test loss:  6.774859428405762\n",
      "test r2:  -0.25549389106767384\n",
      "train loss:  1.636460542678833\n",
      "train r2:  0.8853213048343\n",
      "test loss:  6.773324966430664\n",
      "test r2:  -0.2550243467364435\n",
      "train loss:  1.6364643573760986\n",
      "train r2:  0.885421719292899\n",
      "test loss:  6.775051593780518\n",
      "test r2:  -0.2555524135577978\n",
      "train loss:  1.6364680528640747\n",
      "train r2:  0.885308654758699\n",
      "test loss:  6.7731032371521\n",
      "test r2:  -0.25495547880357905\n",
      "train loss:  1.6364747285842896\n",
      "train r2:  0.8854362774920072\n",
      "test loss:  6.775318622589111\n",
      "test r2:  -0.2556332101174097\n",
      "train loss:  1.6364805698394775\n",
      "train r2:  0.8852912038212745\n",
      "test loss:  6.772799491882324\n",
      "test r2:  -0.25486225408268814\n",
      "train loss:  1.6364916563034058\n",
      "train r2:  0.8854559909961357\n",
      "test loss:  6.775671005249023\n",
      "test r2:  -0.25574048887677114\n",
      "train loss:  1.6364998817443848\n",
      "train r2:  0.8852679483716552\n",
      "test loss:  6.772394180297852\n",
      "test r2:  -0.25474004864759037\n",
      "train loss:  1.6365159749984741\n",
      "train r2:  0.885481736865528\n",
      "test loss:  6.776118755340576\n",
      "test r2:  -0.25587729725408237\n",
      "train loss:  1.636528730392456\n",
      "train r2:  0.8852382641657814\n",
      "test loss:  6.771893501281738\n",
      "test r2:  -0.2545902768286936\n",
      "train loss:  1.6365503072738647\n",
      "train r2:  0.8855132454736727\n",
      "test loss:  6.77664041519165\n",
      "test r2:  -0.2560348550772713\n",
      "train loss:  1.636568546295166\n",
      "train r2:  0.8852039433777441\n",
      "test loss:  6.771374225616455\n",
      "test r2:  -0.2544333299587105\n",
      "train loss:  1.6365933418273926\n",
      "train r2:  0.8855461690185802\n",
      "test loss:  6.777122974395752\n",
      "test r2:  -0.25617797932184105\n",
      "train loss:  1.6366103887557983\n",
      "train r2:  0.8851727554954838\n",
      "test loss:  6.771019458770752\n",
      "test r2:  -0.2543233339438933\n",
      "train loss:  1.6366273164749146\n",
      "train r2:  0.8855691870214194\n",
      "test loss:  6.777324199676514\n",
      "test r2:  -0.2562339083840519\n",
      "train loss:  1.6366260051727295\n",
      "train r2:  0.8851605645402989\n",
      "test loss:  6.771105766296387\n",
      "test r2:  -0.25434494641290306\n",
      "train loss:  1.6366167068481445\n",
      "train r2:  0.8855647655089829\n",
      "test loss:  6.776956081390381\n",
      "test r2:  -0.25611890439999274\n",
      "train loss:  1.6365858316421509\n",
      "train r2:  0.8851858321846777\n",
      "test loss:  6.771829605102539\n",
      "test r2:  -0.2545607940944945\n",
      "train loss:  1.6365501880645752\n",
      "train r2:  0.8855196255833876\n",
      "test loss:  6.775944709777832\n",
      "test r2:  -0.25581168077042316\n",
      "train loss:  1.6365082263946533\n",
      "train r2:  0.8852527287692342\n",
      "test loss:  6.773072719573975\n",
      "test r2:  -0.2549356003513068\n",
      "train loss:  1.6364768743515015\n",
      "train r2:  0.8854406090872422\n",
      "test loss:  6.774597644805908\n",
      "test r2:  -0.25540417750560773\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853406477953465\n",
      "test loss:  6.774399280548096\n",
      "test r2:  -0.2553372075909528\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853550779778717\n",
      "test loss:  6.773402214050293\n",
      "test r2:  -0.2550415521461906\n",
      "train loss:  1.636459469795227\n",
      "train r2:  0.8854181392672675\n",
      "test loss:  6.775378704071045\n",
      "test r2:  -0.25563451976763973\n",
      "train loss:  1.6364723443984985\n",
      "train r2:  0.8852911900582967\n",
      "test loss:  6.772697925567627\n",
      "test r2:  -0.2548264563875482\n",
      "train loss:  1.636484980583191\n",
      "train r2:  0.8854637790612655\n",
      "test loss:  6.775784492492676\n",
      "test r2:  -0.25575887875843417\n",
      "train loss:  1.6364926099777222\n",
      "train r2:  0.8852642700575223\n",
      "test loss:  6.772597789764404\n",
      "test r2:  -0.25479304648457113\n",
      "train loss:  1.6364940404891968\n",
      "train r2:  0.8854708191024019\n",
      "test loss:  6.775615215301514\n",
      "test r2:  -0.2557089742781715\n",
      "train loss:  1.6364883184432983\n",
      "train r2:  0.8852749980770069\n",
      "test loss:  6.773005962371826\n",
      "test r2:  -0.25491306278409986\n",
      "train loss:  1.6364798545837402\n",
      "train r2:  0.8854454014632048\n",
      "test loss:  6.775048732757568\n",
      "test r2:  -0.25553805785386596\n",
      "train loss:  1.6364691257476807\n",
      "train r2:  0.8853118345569246\n",
      "test loss:  6.773678302764893\n",
      "test r2:  -0.255114110103982\n",
      "train loss:  1.6364630460739136\n",
      "train r2:  0.8854026811425602\n",
      "test loss:  6.774353504180908\n",
      "test r2:  -0.2553285252602022\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853568652253189\n",
      "test loss:  6.774328231811523\n",
      "test r2:  -0.2553133785930568\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853601558761222\n",
      "test loss:  6.773766994476318\n",
      "test r2:  -0.2551531872827233\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853943357353744\n",
      "test loss:  6.774769306182861\n",
      "test r2:  -0.2554533259839804\n",
      "train loss:  1.6364572048187256\n",
      "train r2:  0.8853301325166287\n",
      "test loss:  6.773425102233887\n",
      "test r2:  -0.2550516960075433\n",
      "train loss:  1.636459231376648\n",
      "train r2:  0.8854159801816889\n",
      "test loss:  6.774953842163086\n",
      "test r2:  -0.25551332217598666\n",
      "train loss:  1.636460304260254\n",
      "train r2:  0.8853172206751762\n",
      "test loss:  6.773367404937744\n",
      "test r2:  -0.2550317978641161\n",
      "train loss:  1.636460781097412\n",
      "train r2:  0.8854202185779001\n",
      "test loss:  6.774902820587158\n",
      "test r2:  -0.25549678077434756\n",
      "train loss:  1.6364598274230957\n",
      "train r2:  0.8853207966607095\n",
      "test loss:  6.773548603057861\n",
      "test r2:  -0.2550798717398026\n",
      "train loss:  1.6364587545394897\n",
      "train r2:  0.8854100259512399\n",
      "test loss:  6.774682998657227\n",
      "test r2:  -0.25542604097642063\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853359880964091\n",
      "test loss:  6.773855686187744\n",
      "test r2:  -0.25516710892613514\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853914291649643\n",
      "test loss:  6.774377822875977\n",
      "test r2:  -0.25533174236048795\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853561957198032\n",
      "test loss:  6.774169921875\n",
      "test r2:  -0.2552617172476399\n",
      "train loss:  1.6364551782608032\n",
      "train r2:  0.8853712563988108\n",
      "test loss:  6.774082660675049\n",
      "test r2:  -0.2552441815174389\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853749454566282\n",
      "test loss:  6.774400234222412\n",
      "test r2:  -0.2553358404392325\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853553784046007\n",
      "test loss:  6.773882865905762\n",
      "test r2:  -0.25518596314648967\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.885387381090033\n",
      "test loss:  6.774514675140381\n",
      "test r2:  -0.2553746756394055\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853470634813492\n",
      "test loss:  6.7738142013549805\n",
      "test r2:  -0.255165139303726\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853918319396501\n",
      "test loss:  6.774522304534912\n",
      "test r2:  -0.2553782555544424\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853462844172415\n",
      "test loss:  6.773860454559326\n",
      "test r2:  -0.2551758560181323\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853895538895464\n",
      "test loss:  6.774455547332764\n",
      "test r2:  -0.25535712692787116\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853508247166977\n",
      "test loss:  6.773968696594238\n",
      "test r2:  -0.25520439384008875\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853835223866546\n",
      "test loss:  6.7743611335754395\n",
      "test r2:  -0.25532635213931365\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853574123918597\n",
      "test loss:  6.774082660675049\n",
      "test r2:  -0.2552354790142124\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853768842083299\n",
      "test loss:  6.774271011352539\n",
      "test r2:  -0.25529815856437765\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853634310657287\n",
      "test loss:  6.774164199829102\n",
      "test r2:  -0.2552597376168235\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853717024947096\n",
      "test loss:  6.774206161499023\n",
      "test r2:  -0.2552788578162615\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853675436941942\n",
      "test loss:  6.774203777313232\n",
      "test r2:  -0.25527351389715625\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853687706612265\n",
      "test loss:  6.774171352386475\n",
      "test r2:  -0.2552696140039252\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853695512269991\n",
      "test loss:  6.77421236038208\n",
      "test r2:  -0.2552785891817193\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853676361852612\n",
      "test loss:  6.7741594314575195\n",
      "test r2:  -0.2552663713331982\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853702415217409\n",
      "test loss:  6.7742109298706055\n",
      "test r2:  -0.2552797043382715\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853674162446611\n",
      "test loss:  6.774163722991943\n",
      "test r2:  -0.2552666669882897\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853701972315442\n",
      "test loss:  6.7742085456848145\n",
      "test r2:  -0.25527850064320856\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853676885317612\n",
      "test loss:  6.774179458618164\n",
      "test r2:  -0.25526886906422885\n",
      "train loss:  1.636448621749878\n",
      "train r2:  0.8853697771503088\n",
      "test loss:  6.774208068847656\n",
      "test r2:  -0.2552764946759334\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853681467643629\n",
      "test loss:  6.774197578430176\n",
      "test r2:  -0.2552710963306728\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853692880706088\n",
      "test loss:  6.774209976196289\n",
      "test r2:  -0.25527500330546893\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853684910988088\n",
      "test loss:  6.774211406707764\n",
      "test r2:  -0.25527248461853547\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853689963487658\n",
      "test loss:  6.77421236038208\n",
      "test r2:  -0.25527445504485313\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853686192056937\n",
      "test loss:  6.7742156982421875\n",
      "test r2:  -0.2552727553657703\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853689909519795\n",
      "test loss:  6.774212837219238\n",
      "test r2:  -0.2552750825442409\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.885368437550158\n",
      "test loss:  6.774207592010498\n",
      "test r2:  -0.2552706984798394\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853693884533897\n",
      "test loss:  6.77421760559082\n",
      "test r2:  -0.2552784004761841\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.885367699126161\n",
      "test loss:  6.774183750152588\n",
      "test r2:  -0.25526515442433406\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853705732080909\n",
      "test loss:  6.774235248565674\n",
      "test r2:  -0.25528579384224837\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853661252447813\n",
      "test loss:  6.774146556854248\n",
      "test r2:  -0.25525564432261594\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.885372600861185\n",
      "test loss:  6.774266242980957\n",
      "test r2:  -0.2552969196693784\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853637333541353\n",
      "test loss:  6.774101257324219\n",
      "test r2:  -0.25524288897766323\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853753275356732\n",
      "test loss:  6.774310111999512\n",
      "test r2:  -0.255310820038396\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853607514977675\n",
      "test loss:  6.774050712585449\n",
      "test r2:  -0.25522755163873434\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853785816270886\n",
      "test loss:  6.774366855621338\n",
      "test r2:  -0.2553272833523377\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853571978595711\n",
      "test loss:  6.773995876312256\n",
      "test r2:  -0.25520975419887093\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853823704477131\n",
      "test loss:  6.774435043334961\n",
      "test r2:  -0.2553466671396145\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853530586893958\n",
      "test loss:  6.773931503295898\n",
      "test r2:  -0.2551888071870527\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853868778650981\n",
      "test loss:  6.774516582489014\n",
      "test r2:  -0.25537000422833467\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.885348073431931\n",
      "test loss:  6.773852348327637\n",
      "test r2:  -0.2551634668612748\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853922955991622\n",
      "test loss:  6.774612903594971\n",
      "test r2:  -0.25539829172745776\n",
      "train loss:  1.6364543437957764\n",
      "train r2:  0.8853420005147132\n",
      "test loss:  6.773750305175781\n",
      "test r2:  -0.2551314730685701\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853990965901724\n",
      "test loss:  6.774737358093262\n",
      "test r2:  -0.25543547493927976\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8853340350424339\n",
      "test loss:  6.773609638214111\n",
      "test r2:  -0.2550887778961457\n",
      "train loss:  1.636459231376648\n",
      "train r2:  0.8854082171169596\n",
      "test loss:  6.774896621704102\n",
      "test r2:  -0.2554842066273444\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8853235220076342\n",
      "test loss:  6.773426532745361\n",
      "test r2:  -0.25503315148456807\n",
      "train loss:  1.6364643573760986\n",
      "train r2:  0.8854199878983963\n",
      "test loss:  6.775103569030762\n",
      "test r2:  -0.25554741125483194\n",
      "train loss:  1.636467456817627\n",
      "train r2:  0.8853099418134686\n",
      "test loss:  6.773186206817627\n",
      "test r2:  -0.25496082390550545\n",
      "train loss:  1.6364730596542358\n",
      "train r2:  0.8854353334125499\n",
      "test loss:  6.775375843048096\n",
      "test r2:  -0.25563041308451195\n",
      "train loss:  1.6364785432815552\n",
      "train r2:  0.8852920109818095\n",
      "test loss:  6.772871494293213\n",
      "test r2:  -0.2548655438778267\n",
      "train loss:  1.6364874839782715\n",
      "train r2:  0.8854554875257364\n",
      "test loss:  6.7757344245910645\n",
      "test r2:  -0.2557388314115998\n",
      "train loss:  1.6364964246749878\n",
      "train r2:  0.8852685819829221\n",
      "test loss:  6.772473335266113\n",
      "test r2:  -0.25474421015831594\n",
      "train loss:  1.6365101337432861\n",
      "train r2:  0.8854811079025326\n",
      "test loss:  6.776179790496826\n",
      "test r2:  -0.25587269620908915\n",
      "train loss:  1.6365242004394531\n",
      "train r2:  0.8852395246909666\n",
      "test loss:  6.7720046043396\n",
      "test r2:  -0.25460088963201133\n",
      "train loss:  1.6365442276000977\n",
      "train r2:  0.8855112703252863\n",
      "test loss:  6.776677131652832\n",
      "test r2:  -0.25602128580189376\n",
      "train loss:  1.6365622282028198\n",
      "train r2:  0.885207171761578\n",
      "test loss:  6.771529674530029\n",
      "test r2:  -0.25445552203872723\n",
      "train loss:  1.6365861892700195\n",
      "train r2:  0.8855417444322569\n",
      "test loss:  6.777117729187012\n",
      "test r2:  -0.25615262085640067\n",
      "train loss:  1.6366020441055298\n",
      "train r2:  0.8851785239631175\n",
      "test loss:  6.771202564239502\n",
      "test r2:  -0.25435495992942014\n",
      "train loss:  1.6366186141967773\n",
      "train r2:  0.8855627583741057\n",
      "test loss:  6.777292251586914\n",
      "test r2:  -0.25620389808911814\n",
      "train loss:  1.6366180181503296\n",
      "train r2:  0.8851673048555447\n",
      "test loss:  6.771263599395752\n",
      "test r2:  -0.2543724960241964\n",
      "train loss:  1.6366113424301147\n",
      "train r2:  0.8855591103951324\n",
      "test loss:  6.7769575119018555\n",
      "test r2:  -0.25610260906712723\n",
      "train loss:  1.6365835666656494\n",
      "train r2:  0.8851895130681368\n",
      "test loss:  6.771893501281738\n",
      "test r2:  -0.2545638304054416\n",
      "train loss:  1.6365513801574707\n",
      "train r2:  0.8855191194942132\n",
      "test loss:  6.776043891906738\n",
      "test r2:  -0.2558268973223252\n",
      "train loss:  1.6365115642547607\n",
      "train r2:  0.8852495369458849\n",
      "test loss:  6.773013114929199\n",
      "test r2:  -0.25490329669532064\n",
      "train loss:  1.6364800930023193\n",
      "train r2:  0.8854475736313967\n",
      "test loss:  6.774806022644043\n",
      "test r2:  -0.2554516921957126\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.8853306054319889\n",
      "test loss:  6.774264812469482\n",
      "test r2:  -0.2552815140637512\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853671725806106\n",
      "test loss:  6.773658752441406\n",
      "test r2:  -0.2551010286639601\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8854056474110567\n",
      "test loss:  6.7752604484558105\n",
      "test r2:  -0.255580123693786\n",
      "train loss:  1.6364657878875732\n",
      "train r2:  0.8853030935032202\n",
      "test loss:  6.772922992706299\n",
      "test r2:  -0.25487275879766447\n",
      "train loss:  1.636478304862976\n",
      "train r2:  0.8854541501895107\n",
      "test loss:  6.775761127471924\n",
      "test r2:  -0.2557293611745368\n",
      "train loss:  1.6364877223968506\n",
      "train r2:  0.8852708387686443\n",
      "test loss:  6.772718906402588\n",
      "test r2:  -0.2548058859040372\n",
      "train loss:  1.6364920139312744\n",
      "train r2:  0.8854682959937215\n",
      "test loss:  6.775726795196533\n",
      "test r2:  -0.25571876136381744\n",
      "train loss:  1.6364892721176147\n",
      "train r2:  0.8852731005156639\n",
      "test loss:  6.772993087768555\n",
      "test r2:  -0.2548858327761847\n",
      "train loss:  1.636482834815979\n",
      "train r2:  0.8854513839536552\n",
      "test loss:  6.775276184082031\n",
      "test r2:  -0.25558391546590475\n",
      "train loss:  1.6364729404449463\n",
      "train r2:  0.8853021635923186\n",
      "test loss:  6.773565292358398\n",
      "test r2:  -0.2550586937942003\n",
      "train loss:  1.6364660263061523\n",
      "train r2:  0.8854146625225624\n",
      "test loss:  6.774630546569824\n",
      "test r2:  -0.25539144098133515\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853435368263033\n",
      "test loss:  6.774190902709961\n",
      "test r2:  -0.25525245469552615\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853733610222957\n",
      "test loss:  6.774014472961426\n",
      "test r2:  -0.2552098774918399\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853824062033141\n",
      "test loss:  6.7746806144714355\n",
      "test r2:  -0.2554081256384815\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.885339977079001\n",
      "test loss:  6.7735915184021\n",
      "test r2:  -0.2550854116129344\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8854088981400238\n",
      "test loss:  6.7749481201171875\n",
      "test r2:  -0.2554943893507704\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8853214675460591\n",
      "test loss:  6.773437976837158\n",
      "test r2:  -0.2550376734741011\n",
      "train loss:  1.6364593505859375\n",
      "train r2:  0.8854190789266698\n",
      "test loss:  6.774987697601318\n",
      "test r2:  -0.25550527896699315\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.8853191193009957\n",
      "test loss:  6.7735395431518555\n",
      "test r2:  -0.2550609594833839\n",
      "train loss:  1.6364589929580688\n",
      "train r2:  0.8854142086027152\n",
      "test loss:  6.774839878082275\n",
      "test r2:  -0.2554553718947652\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.885329856457112\n",
      "test loss:  6.773799419403076\n",
      "test r2:  -0.25513178988950247\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853991512362357\n",
      "test loss:  6.77458381652832\n",
      "test r2:  -0.25537409209590245\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.885347302298278\n",
      "test loss:  6.774095058441162\n",
      "test r2:  -0.2552178732241359\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853807993120029\n",
      "test loss:  6.774308681488037\n",
      "test r2:  -0.2552907914620619\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853651648762192\n",
      "test loss:  6.774335861206055\n",
      "test r2:  -0.2552932048615333\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853646792351758\n",
      "test loss:  6.7740864753723145\n",
      "test r2:  -0.2552262067701343\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853789574508575\n",
      "test loss:  6.7744832038879395\n",
      "test r2:  -0.25534315189877677\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853539948060303\n",
      "test loss:  6.773961067199707\n",
      "test r2:  -0.2551903778024336\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853866146443452\n",
      "test loss:  6.774538040161133\n",
      "test r2:  -0.25536358415812277\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853496000404091\n",
      "test loss:  6.773937702178955\n",
      "test r2:  -0.25518283212280823\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853882464990283\n",
      "test loss:  6.774525165557861\n",
      "test r2:  -0.2553602608927319\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853503036963639\n",
      "test loss:  6.773988246917725\n",
      "test r2:  -0.2551945757798917\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853857535306894\n",
      "test loss:  6.774474620819092\n",
      "test r2:  -0.2553430910690022\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853539738716075\n",
      "test loss:  6.774072647094727\n",
      "test r2:  -0.25521556238190923\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853813210055579\n",
      "test loss:  6.774412631988525\n",
      "test r2:  -0.2553219325462439\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853585354032475\n",
      "test loss:  6.774153232574463\n",
      "test r2:  -0.255236869031759\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853767677662225\n",
      "test loss:  6.774351596832275\n",
      "test r2:  -0.2553025841586003\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853626863392364\n",
      "test loss:  6.774209976196289\n",
      "test r2:  -0.25525377655492787\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853731650335424\n",
      "test loss:  6.77430534362793\n",
      "test r2:  -0.2552890099430247\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.885365581611071\n",
      "test loss:  6.774236679077148\n",
      "test r2:  -0.25526342398678237\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853711060871498\n",
      "test loss:  6.77427864074707\n",
      "test r2:  -0.25528234438264863\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853669916890958\n",
      "test loss:  6.774238109588623\n",
      "test r2:  -0.25526665944690907\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853704099399478\n",
      "test loss:  6.774271011352539\n",
      "test r2:  -0.2552811267661399\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853672648693499\n",
      "test loss:  6.774230480194092\n",
      "test r2:  -0.255266024711319\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853705286814809\n",
      "test loss:  6.77427864074707\n",
      "test r2:  -0.25528256244365255\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853669811402616\n",
      "test loss:  6.774223804473877\n",
      "test r2:  -0.25526391908291846\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853709658565246\n",
      "test loss:  6.774295330047607\n",
      "test r2:  -0.2552850641266369\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853664657024477\n",
      "test loss:  6.774223804473877\n",
      "test r2:  -0.2552618686108479\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853714242191696\n",
      "test loss:  6.774311542510986\n",
      "test r2:  -0.255286727230434\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853661378673855\n",
      "test loss:  6.77423095703125\n",
      "test r2:  -0.2552616890872814\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853714964365176\n",
      "test loss:  6.774319648742676\n",
      "test r2:  -0.2552865999056326\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853661639913403\n",
      "test loss:  6.774238586425781\n",
      "test r2:  -0.2552625845381449\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853713169248337\n",
      "test loss:  6.774319648742676\n",
      "test r2:  -0.255285379096019\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853664556464387\n",
      "test loss:  6.774244785308838\n",
      "test r2:  -0.25526445665206055\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853708886340902\n",
      "test loss:  6.774311542510986\n",
      "test r2:  -0.2552829649714936\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853669602267904\n",
      "test loss:  6.77424955368042\n",
      "test r2:  -0.25526743322388623\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.885370260748402\n",
      "test loss:  6.774293899536133\n",
      "test r2:  -0.25527894808138374\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853678135588038\n",
      "test loss:  6.774259567260742\n",
      "test r2:  -0.2552722431919505\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853692115038823\n",
      "test loss:  6.774268627166748\n",
      "test r2:  -0.2552725416684032\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853691708975316\n",
      "test loss:  6.774279594421387\n",
      "test r2:  -0.2552799631067546\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853675250945496\n",
      "test loss:  6.774232387542725\n",
      "test r2:  -0.2552625664087236\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853712731130349\n",
      "test loss:  6.774314880371094\n",
      "test r2:  -0.2552914554097485\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853650551025463\n",
      "test loss:  6.77418851852417\n",
      "test r2:  -0.2552495871408895\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853740394415776\n",
      "test loss:  6.7743611335754395\n",
      "test r2:  -0.2553057035107562\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.885362018963763\n",
      "test loss:  6.774142265319824\n",
      "test r2:  -0.25523442860149737\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853772841609737\n",
      "test loss:  6.774418830871582\n",
      "test r2:  -0.2553228643204677\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853583492448078\n",
      "test loss:  6.774081230163574\n",
      "test r2:  -0.2552147532104194\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.88538150939368\n",
      "test loss:  6.774496555328369\n",
      "test r2:  -0.2553459228143704\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853534115013778\n",
      "test loss:  6.773996353149414\n",
      "test r2:  -0.2551881798330855\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853871524537207\n",
      "test loss:  6.774597644805908\n",
      "test r2:  -0.2553765714199838\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853467964412927\n",
      "test loss:  6.7738800048828125\n",
      "test r2:  -0.2551527614865896\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853947266706205\n",
      "test loss:  6.774733066558838\n",
      "test r2:  -0.2554179382587254\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853379076791884\n",
      "test loss:  6.773718357086182\n",
      "test r2:  -0.25510400334429617\n",
      "train loss:  1.6364598274230957\n",
      "train r2:  0.8854051035670151\n",
      "test loss:  6.77492094039917\n",
      "test r2:  -0.25547548955237653\n",
      "train loss:  1.6364614963531494\n",
      "train r2:  0.8853255422534894\n",
      "test loss:  6.773491382598877\n",
      "test r2:  -0.2550359648987699\n",
      "train loss:  1.6364655494689941\n",
      "train r2:  0.8854195374436837\n",
      "test loss:  6.775183200836182\n",
      "test r2:  -0.25555511464393565\n",
      "train loss:  1.6364691257476807\n",
      "train r2:  0.8853084072206329\n",
      "test loss:  6.773184299468994\n",
      "test r2:  -0.25494270912140093\n",
      "train loss:  1.6364761590957642\n",
      "train r2:  0.8854393321535432\n",
      "test loss:  6.775547981262207\n",
      "test r2:  -0.25566450895305737\n",
      "train loss:  1.6364836692810059\n",
      "train r2:  0.8852848126146002\n",
      "test loss:  6.772768974304199\n",
      "test r2:  -0.25481576147084484\n",
      "train loss:  1.6364959478378296\n",
      "train r2:  0.8854661957624409\n",
      "test loss:  6.776038646697998\n",
      "test r2:  -0.25581088176300204\n",
      "train loss:  1.636509895324707\n",
      "train r2:  0.8852531287542238\n",
      "test loss:  6.772230625152588\n",
      "test r2:  -0.25465034045481505\n",
      "train loss:  1.6365307569503784\n",
      "train r2:  0.885501057655625\n",
      "test loss:  6.776655197143555\n",
      "test r2:  -0.2559946330188616\n",
      "train loss:  1.6365541219711304\n",
      "train r2:  0.8852131800092295\n",
      "test loss:  6.771591663360596\n",
      "test r2:  -0.2544536818159211\n",
      "train loss:  1.6365861892700195\n",
      "train r2:  0.8855422894712146\n",
      "test loss:  6.777331352233887\n",
      "test r2:  -0.2561961565537785\n",
      "train loss:  1.6366162300109863\n",
      "train r2:  0.8851691807403289\n",
      "test loss:  6.770978927612305\n",
      "test r2:  -0.2542651131642901\n",
      "train loss:  1.6366524696350098\n",
      "train r2:  0.885581652239626\n",
      "test loss:  6.777844429016113\n",
      "test r2:  -0.2563494429550244\n",
      "train loss:  1.6366723775863647\n",
      "train r2:  0.8851355546601299\n",
      "test loss:  6.770697116851807\n",
      "test r2:  -0.25417872354863325\n",
      "train loss:  1.6366868019104004\n",
      "train r2:  0.8855996441549442\n",
      "test loss:  6.777801513671875\n",
      "test r2:  -0.2563368284968641\n",
      "train loss:  1.6366665363311768\n",
      "train r2:  0.885138353929264\n",
      "test loss:  6.771148681640625\n",
      "test r2:  -0.2543173884788503\n",
      "train loss:  1.636631965637207\n",
      "train r2:  0.8855708052848612\n",
      "test loss:  6.77687406539917\n",
      "test r2:  -0.25606003404577127\n",
      "train loss:  1.6365711688995361\n",
      "train r2:  0.8851989412532293\n",
      "test loss:  6.772453784942627\n",
      "test r2:  -0.2547167226712439\n",
      "train loss:  1.636515498161316\n",
      "train r2:  0.885487082651293\n",
      "test loss:  6.7752532958984375\n",
      "test r2:  -0.2555725606865997\n",
      "train loss:  1.6364706754684448\n",
      "train r2:  0.8853046906452594\n",
      "test loss:  6.774167060852051\n",
      "test r2:  -0.25523685123619\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853767941953156\n",
      "test loss:  6.773622035980225\n",
      "test r2:  -0.2550752832941581\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8854112895809185\n",
      "test loss:  6.775590419769287\n",
      "test r2:  -0.2556638605766215\n",
      "train loss:  1.636475682258606\n",
      "train r2:  0.885285175186413\n",
      "test loss:  6.772593975067139\n",
      "test r2:  -0.25475494650447983\n",
      "train loss:  1.6364986896514893\n",
      "train r2:  0.885479228256908\n",
      "test loss:  6.776254653930664\n",
      "test r2:  -0.2558593747895179\n",
      "train loss:  1.6365137100219727\n",
      "train r2:  0.885242840535023\n",
      "test loss:  6.772421360015869\n",
      "test r2:  -0.2546936615147135\n",
      "train loss:  1.6365166902542114\n",
      "train r2:  0.8854921406085106\n",
      "test loss:  6.776045322418213\n",
      "test r2:  -0.2557941013188536\n",
      "train loss:  1.6365057229995728\n",
      "train r2:  0.8852569448394091\n",
      "test loss:  6.773013114929199\n",
      "test r2:  -0.25486848336744305\n",
      "train loss:  1.636489748954773\n",
      "train r2:  0.8854551980513333\n",
      "test loss:  6.775201320648193\n",
      "test r2:  -0.2555405113863032\n",
      "train loss:  1.6364706754684448\n",
      "train r2:  0.885311673090473\n",
      "test loss:  6.773986339569092\n",
      "test r2:  -0.2551642994782244\n",
      "train loss:  1.6364613771438599\n",
      "train r2:  0.8853923564005208\n",
      "test loss:  6.774196147918701\n",
      "test r2:  -0.25523972522619265\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853762181703473\n",
      "test loss:  6.774862289428711\n",
      "test r2:  -0.25543587623104713\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.8853342631331617\n",
      "test loss:  6.7734575271606445\n",
      "test r2:  -0.25501989168024686\n",
      "train loss:  1.6364632844924927\n",
      "train r2:  0.8854230524225775\n",
      "test loss:  6.775328159332275\n",
      "test r2:  -0.2555855342717721\n",
      "train loss:  1.6364686489105225\n",
      "train r2:  0.8853020290054086\n",
      "test loss:  6.773198127746582\n",
      "test r2:  -0.25494413024765405\n",
      "train loss:  1.6364706754684448\n",
      "train r2:  0.8854391106383996\n",
      "test loss:  6.775312900543213\n",
      "test r2:  -0.25558669799772304\n",
      "train loss:  1.6364691257476807\n",
      "train r2:  0.8853016954145269\n",
      "test loss:  6.773416519165039\n",
      "test r2:  -0.2550083377568826\n",
      "train loss:  1.6364651918411255\n",
      "train r2:  0.8854254942580211\n",
      "test loss:  6.774937629699707\n",
      "test r2:  -0.25547182755570064\n",
      "train loss:  1.6364600658416748\n",
      "train r2:  0.8853264352090009\n",
      "test loss:  6.773932933807373\n",
      "test r2:  -0.2551575433014639\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.8853937693047383\n",
      "test loss:  6.774418830871582\n",
      "test r2:  -0.2553094800342117\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853612840505938\n",
      "test loss:  6.774477005004883\n",
      "test r2:  -0.2553169043225987\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853597653575321\n",
      "test loss:  6.773968696594238\n",
      "test r2:  -0.25516985029168326\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853911529553818\n",
      "test loss:  6.774832248687744\n",
      "test r2:  -0.2554258641994569\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853364246796561\n",
      "test loss:  6.77372932434082\n",
      "test r2:  -0.2550978132155277\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8854065380112076\n",
      "test loss:  6.774923324584961\n",
      "test r2:  -0.25545728961744274\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853296862716731\n",
      "test loss:  6.773753643035889\n",
      "test r2:  -0.2551047333548446\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8854050819199865\n",
      "test loss:  6.774784564971924\n",
      "test r2:  -0.25541710091356373\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853383198810126\n",
      "test loss:  6.773982048034668\n",
      "test r2:  -0.25517032483131064\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853911279892328\n",
      "test loss:  6.774519443511963\n",
      "test r2:  -0.25533612592615884\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853556479713856\n",
      "test loss:  6.774280071258545\n",
      "test r2:  -0.2552570443618831\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853725969855627\n",
      "test loss:  6.774247646331787\n",
      "test r2:  -0.25525374494749054\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853732427900699\n",
      "test loss:  6.774513244628906\n",
      "test r2:  -0.2553278740050564\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853574374385625\n",
      "test loss:  6.7740631103515625\n",
      "test r2:  -0.25519979872353815\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853847864960409\n",
      "test loss:  6.7746124267578125\n",
      "test r2:  -0.255361355631027\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853502705392853\n",
      "test loss:  6.774014472961426\n",
      "test r2:  -0.25518635496749575\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853876776369815\n",
      "test loss:  6.774586200714111\n",
      "test r2:  -0.2553560031751283\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853514274775038\n",
      "test loss:  6.774084091186523\n",
      "test r2:  -0.25520615897474963\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.885383458052739\n",
      "test loss:  6.774484634399414\n",
      "test r2:  -0.25532547919686976\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853579407388044\n",
      "test loss:  6.774217128753662\n",
      "test r2:  -0.2552426129061973\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853757100976789\n",
      "test loss:  6.7743682861328125\n",
      "test r2:  -0.25528826580006814\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853659287982216\n",
      "test loss:  6.774350166320801\n",
      "test r2:  -0.2552782192649212\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853681264166342\n",
      "test loss:  6.7742767333984375\n",
      "test r2:  -0.2552581504726701\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853723769418216\n",
      "test loss:  6.774438381195068\n",
      "test r2:  -0.2553019301414903\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853630521859763\n",
      "test loss:  6.774226665496826\n",
      "test r2:  -0.25524244340742364\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853757356116537\n",
      "test loss:  6.774466037750244\n",
      "test r2:  -0.25531017234297826\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853612798851228\n",
      "test loss:  6.774219989776611\n",
      "test r2:  -0.2552411222423534\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853760338581258\n",
      "test loss:  6.77444314956665\n",
      "test r2:  -0.25530520763426545\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853623592619434\n",
      "test loss:  6.774245738983154\n",
      "test r2:  -0.25525083369708756\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853739230660056\n",
      "test loss:  6.774388313293457\n",
      "test r2:  -0.25529123180126234\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853652963358297\n",
      "test loss:  6.774293422698975\n",
      "test r2:  -0.25526645631300493\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.88537057920437\n",
      "test loss:  6.774327278137207\n",
      "test r2:  -0.2552744919048353\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853689083627295\n",
      "test loss:  6.774348735809326\n",
      "test r2:  -0.25528309411097827\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853670563584041\n",
      "test loss:  6.774274826049805\n",
      "test r2:  -0.255258656471242\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853722786047211\n",
      "test loss:  6.77440071105957\n",
      "test r2:  -0.25529744135082666\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853639772750171\n",
      "test loss:  6.774238109588623\n",
      "test r2:  -0.2552463316915985\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853749179870813\n",
      "test loss:  6.774444580078125\n",
      "test r2:  -0.25530782715285616\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853617820277284\n",
      "test loss:  6.774221420288086\n",
      "test r2:  -0.25523923100257906\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853764657680684\n",
      "test loss:  6.7744669914245605\n",
      "test r2:  -0.2553121163007299\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853609095254114\n",
      "test loss:  6.774226188659668\n",
      "test r2:  -0.2552387211626548\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853765833628355\n",
      "test loss:  6.774464130401611\n",
      "test r2:  -0.25530953628529107\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853614381614855\n",
      "test loss:  6.774244785308838\n",
      "test r2:  -0.25524406395321564\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853754662946213\n",
      "test loss:  6.774440288543701\n",
      "test r2:  -0.25530249858994347\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.885362970120151\n",
      "test loss:  6.7742695808410645\n",
      "test r2:  -0.2552525164817987\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853736658874596\n",
      "test loss:  6.774405002593994\n",
      "test r2:  -0.2552929013189198\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853650108920433\n",
      "test loss:  6.774297714233398\n",
      "test r2:  -0.25526214223781674\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853715609799953\n",
      "test loss:  6.7743682861328125\n",
      "test r2:  -0.25528301868078773\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.885367116007931\n",
      "test loss:  6.774325370788574\n",
      "test r2:  -0.25527176543156793\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853695291441718\n",
      "test loss:  6.774334907531738\n",
      "test r2:  -0.25527363167848627\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853691190686822\n",
      "test loss:  6.774352550506592\n",
      "test r2:  -0.2552805894632606\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853676115488897\n",
      "test loss:  6.774306774139404\n",
      "test r2:  -0.2552646036413906\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853710195719712\n",
      "test loss:  6.7743821144104\n",
      "test r2:  -0.2552897059825421\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853656641195158\n",
      "test loss:  6.774278163909912\n",
      "test r2:  -0.2552555644898733\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853729793065905\n",
      "test loss:  6.7744140625\n",
      "test r2:  -0.2552987916286569\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.885363707283583\n",
      "test loss:  6.774252414703369\n",
      "test r2:  -0.2552465488493574\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853748970439157\n",
      "test loss:  6.774446487426758\n",
      "test r2:  -0.25530813730902713\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853617113058387\n",
      "test loss:  6.774223804473877\n",
      "test r2:  -0.2552368686180275\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853769946614405\n",
      "test loss:  6.7744832038879395\n",
      "test r2:  -0.25531912189912664\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853593405450227\n",
      "test loss:  6.774188041687012\n",
      "test r2:  -0.255224806316112\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853795723954468\n",
      "test loss:  6.774523735046387\n",
      "test r2:  -0.2553322963908129\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853565282896254\n",
      "test loss:  6.774139881134033\n",
      "test r2:  -0.2552103442432816\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853826062031838\n",
      "test loss:  6.774572372436523\n",
      "test r2:  -0.25534861403956954\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.885352984767896\n",
      "test loss:  6.774072647094727\n",
      "test r2:  -0.2551909439589788\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853867223993027\n",
      "test loss:  6.774640083312988\n",
      "test r2:  -0.25537148789766095\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.885348031520295\n",
      "test loss:  6.773977279663086\n",
      "test r2:  -0.25516323033597277\n",
      "train loss:  1.6364587545394897\n",
      "train r2:  0.8853926020419793\n",
      "test loss:  6.7747416496276855\n",
      "test r2:  -0.2554043690499135\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853409781158191\n",
      "test loss:  6.773841381072998\n",
      "test r2:  -0.25512393008536716\n",
      "train loss:  1.6364604234695435\n",
      "train r2:  0.8854009701396075\n",
      "test loss:  6.774889945983887\n",
      "test r2:  -0.25545007572374057\n",
      "train loss:  1.6364600658416748\n",
      "train r2:  0.8853311581998211\n",
      "test loss:  6.773663520812988\n",
      "test r2:  -0.25507084676268055\n",
      "train loss:  1.636462688446045\n",
      "train r2:  0.8854123012360966\n",
      "test loss:  6.775097370147705\n",
      "test r2:  -0.2555110225383017\n",
      "train loss:  1.6364641189575195\n",
      "train r2:  0.8853180655078658\n",
      "test loss:  6.773440361022949\n",
      "test r2:  -0.2550013677414309\n",
      "train loss:  1.636467695236206\n",
      "train r2:  0.8854270626387863\n",
      "test loss:  6.775371074676514\n",
      "test r2:  -0.2555899517685347\n",
      "train loss:  1.6364715099334717\n",
      "train r2:  0.885301106224387\n",
      "test loss:  6.7731614112854\n",
      "test r2:  -0.25491307132806207\n",
      "train loss:  1.636478066444397\n",
      "train r2:  0.8854458431071233\n",
      "test loss:  6.7757182121276855\n",
      "test r2:  -0.2556897437128216\n",
      "train loss:  1.636484980583191\n",
      "train r2:  0.8852796000262618\n",
      "test loss:  6.772814750671387\n",
      "test r2:  -0.2548032803550242\n",
      "train loss:  1.6364954710006714\n",
      "train r2:  0.8854690780408803\n",
      "test loss:  6.776132106781006\n",
      "test r2:  -0.2558105669554258\n",
      "train loss:  1.6365067958831787\n",
      "train r2:  0.8852534728721484\n",
      "test loss:  6.772401809692383\n",
      "test r2:  -0.2546741987928187\n",
      "train loss:  1.6365227699279785\n",
      "train r2:  0.8854963110296518\n",
      "test loss:  6.776590347290039\n",
      "test r2:  -0.2559468762754302\n",
      "train loss:  1.6365388631820679\n",
      "train r2:  0.8852238778393652\n",
      "test loss:  6.771954536437988\n",
      "test r2:  -0.25453668168037713\n",
      "train loss:  1.6365605592727661\n",
      "train r2:  0.8855251922089882\n",
      "test loss:  6.777026653289795\n",
      "test r2:  -0.2560796916167023\n",
      "train loss:  1.6365783214569092\n",
      "train r2:  0.8851948533058496\n",
      "test loss:  6.7715678215026855\n",
      "test r2:  -0.25441964530144\n",
      "train loss:  1.636600136756897\n",
      "train r2:  0.8855496284360788\n",
      "test loss:  6.777304172515869\n",
      "test r2:  -0.2561668307896665\n",
      "train loss:  1.6366087198257446\n",
      "train r2:  0.8851757225987619\n",
      "test loss:  6.771417140960693\n",
      "test r2:  -0.2543775447633867\n",
      "train loss:  1.636616826057434\n",
      "train r2:  0.8855583641096416\n",
      "test loss:  6.777223110198975\n",
      "test r2:  -0.2561471872282526\n",
      "train loss:  1.6366022825241089\n",
      "train r2:  0.8851800295739001\n",
      "test loss:  6.771705627441406\n",
      "test r2:  -0.2544703722038608\n",
      "train loss:  1.6365838050842285\n",
      "train r2:  0.8855389706094858\n",
      "test loss:  6.776635646820068\n",
      "test r2:  -0.2559728716209\n",
      "train loss:  1.6365480422973633\n",
      "train r2:  0.8852180557924754\n",
      "test loss:  6.772514820098877\n",
      "test r2:  -0.25471916801405303\n",
      "train loss:  1.6365138292312622\n",
      "train r2:  0.8854867219629206\n",
      "test loss:  6.7756123542785645\n",
      "test r2:  -0.25566290337430453\n",
      "train loss:  1.636480689048767\n",
      "train r2:  0.8852853981181734\n",
      "test loss:  6.77366304397583\n",
      "test r2:  -0.25506552931521376\n",
      "train loss:  1.636459469795227\n",
      "train r2:  0.8854135168082222\n",
      "test loss:  6.774462699890137\n",
      "test r2:  -0.25530834738931696\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853617016875517\n",
      "test loss:  6.774797439575195\n",
      "test r2:  -0.2554024490117741\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853416134136793\n",
      "test loss:  6.773522853851318\n",
      "test r2:  -0.25501363774058494\n",
      "train loss:  1.6364617347717285\n",
      "train r2:  0.8854246497087073\n",
      "test loss:  6.775611400604248\n",
      "test r2:  -0.25564083900004975\n",
      "train loss:  1.6364736557006836\n",
      "train r2:  0.8852903837093082\n",
      "test loss:  6.772997856140137\n",
      "test r2:  -0.2548457950350953\n",
      "train loss:  1.6364840269088745\n",
      "train r2:  0.8854603121214087\n",
      "test loss:  6.775937080383301\n",
      "test r2:  -0.2557354338517315\n",
      "train loss:  1.6364892721176147\n",
      "train r2:  0.8852699759476867\n",
      "test loss:  6.772947788238525\n",
      "test r2:  -0.25482641360731617\n",
      "train loss:  1.636489748954773\n",
      "train r2:  0.8854643860818063\n",
      "test loss:  6.775770664215088\n",
      "test r2:  -0.25568632341923436\n",
      "train loss:  1.636483907699585\n",
      "train r2:  0.8852805574774579\n",
      "test loss:  6.77330207824707\n",
      "test r2:  -0.2549342969234325\n",
      "train loss:  1.6364772319793701\n",
      "train r2:  0.8854415040501818\n",
      "test loss:  6.775245666503906\n",
      "test r2:  -0.25553311082192787\n",
      "train loss:  1.6364673376083374\n",
      "train r2:  0.8853135066075175\n",
      "test loss:  6.773879528045654\n",
      "test r2:  -0.2551144848319433\n",
      "train loss:  1.6364622116088867\n",
      "train r2:  0.8854031297458052\n",
      "test loss:  6.774585247039795\n",
      "test r2:  -0.2553414579566322\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853546055182625\n",
      "test loss:  6.774455547332764\n",
      "test r2:  -0.2552980778017635\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853639275644134\n",
      "test loss:  6.774015426635742\n",
      "test r2:  -0.255176298360448\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853898528299082\n",
      "test loss:  6.774868965148926\n",
      "test r2:  -0.2554315720659539\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853352803399823\n",
      "test loss:  6.773681640625\n",
      "test r2:  -0.25507713677889776\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8854110356744471\n",
      "test loss:  6.775068759918213\n",
      "test r2:  -0.25549355059031975\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853219424337506\n",
      "test loss:  6.773617267608643\n",
      "test r2:  -0.2550511108080906\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.8854166025209569\n",
      "test loss:  6.7750701904296875\n",
      "test r2:  -0.2554883451626664\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.8853231233985052\n",
      "test loss:  6.773763656616211\n",
      "test r2:  -0.25508434898387944\n",
      "train loss:  1.636457920074463\n",
      "train r2:  0.885409602262956\n",
      "test loss:  6.774925708770752\n",
      "test r2:  -0.2554369302649355\n",
      "train loss:  1.6364567279815674\n",
      "train r2:  0.8853341975398653\n",
      "test loss:  6.774012565612793\n",
      "test r2:  -0.2551505874040829\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8853955564268475\n",
      "test loss:  6.77470064163208\n",
      "test r2:  -0.25536469310563237\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853497276721594\n",
      "test loss:  6.774267673492432\n",
      "test r2:  -0.2552255378044188\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.885379529936887\n",
      "test loss:  6.774458408355713\n",
      "test r2:  -0.255292862498834\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853651267316757\n",
      "test loss:  6.774464130401611\n",
      "test r2:  -0.25528998254761803\n",
      "train loss:  1.6364535093307495\n",
      "train r2:  0.8853657642287431\n",
      "test loss:  6.774256706237793\n",
      "test r2:  -0.25523693886531107\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853770442613785\n",
      "test loss:  6.774581432342529\n",
      "test r2:  -0.25533308816407985\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853564993297807\n",
      "test loss:  6.774135112762451\n",
      "test r2:  -0.25520470732351974\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853838977454208\n",
      "test loss:  6.7746262550354\n",
      "test r2:  -0.2553522097071206\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853523552941763\n",
      "test loss:  6.774105548858643\n",
      "test r2:  -0.2551959100553305\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853858020452127\n",
      "test loss:  6.774623394012451\n",
      "test r2:  -0.25535182259691713\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853524717073873\n",
      "test loss:  6.774146556854248\n",
      "test r2:  -0.25520391668596587\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853841174837924\n",
      "test loss:  6.774592876434326\n",
      "test r2:  -0.2553393152204204\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.885355162883771\n",
      "test loss:  6.7742204666137695\n",
      "test r2:  -0.255220232023357\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853806681122152\n",
      "test loss:  6.774552822113037\n",
      "test r2:  -0.2553227319172162\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853587480787626\n",
      "test loss:  6.774294853210449\n",
      "test r2:  -0.2552377204724612\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853769874523194\n",
      "test loss:  6.774510383605957\n",
      "test r2:  -0.25530750844453065\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853619973276325\n",
      "test loss:  6.7743449211120605\n",
      "test r2:  -0.25525078476413765\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853741937123829\n",
      "test loss:  6.774476528167725\n",
      "test r2:  -0.255297437599594\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853641540156238\n",
      "test loss:  6.7743611335754395\n",
      "test r2:  -0.25525768473917143\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853727163916639\n",
      "test loss:  6.7744526863098145\n",
      "test r2:  -0.25529282459940306\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853651191269751\n",
      "test loss:  6.774351596832275\n",
      "test r2:  -0.2552589789451376\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853724034334588\n",
      "test loss:  6.774441719055176\n",
      "test r2:  -0.2552929100595067\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853650964639272\n",
      "test loss:  6.774331569671631\n",
      "test r2:  -0.2552564495564895\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853729115978991\n",
      "test loss:  6.774450302124023\n",
      "test r2:  -0.25529655914755933\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853642976821787\n",
      "test loss:  6.77431058883667\n",
      "test r2:  -0.2552510561248007\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853740506721458\n",
      "test loss:  6.774477958679199\n",
      "test r2:  -0.2553027391655116\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853630053609844\n",
      "test loss:  6.774297714233398\n",
      "test r2:  -0.2552451328527585\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.885375340093131\n",
      "test loss:  6.774511337280273\n",
      "test r2:  -0.2553089096410166\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853617136760104\n",
      "test loss:  6.7742919921875\n",
      "test r2:  -0.25524000328336416\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853764967276576\n",
      "test loss:  6.774538993835449\n",
      "test r2:  -0.25531391400137404\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853607141932925\n",
      "test loss:  6.774290561676025\n",
      "test r2:  -0.25523707375402305\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853771433628763\n",
      "test loss:  6.774554252624512\n",
      "test r2:  -0.2553158197401795\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853603236408534\n",
      "test loss:  6.774293899536133\n",
      "test r2:  -0.2552365341152001\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853772442096266\n",
      "test loss:  6.774555683135986\n",
      "test r2:  -0.25531552213522546\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853603882918236\n",
      "test loss:  6.774294853210449\n",
      "test r2:  -0.255237222919539\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853771013929421\n",
      "test loss:  6.774548530578613\n",
      "test r2:  -0.25531462615798084\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853605625874725\n",
      "test loss:  6.774290084838867\n",
      "test r2:  -0.2552376597584085\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853770147726929\n",
      "test loss:  6.774540901184082\n",
      "test r2:  -0.2553145934619385\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853605287794133\n",
      "test loss:  6.774278163909912\n",
      "test r2:  -0.25523607673825555\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853773075105994\n",
      "test loss:  6.774543285369873\n",
      "test r2:  -0.2553169373668309\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853599982483915\n",
      "test loss:  6.774260997772217\n",
      "test r2:  -0.2552320742959724\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853781624521113\n",
      "test loss:  6.7745585441589355\n",
      "test r2:  -0.2553220575504631\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853589063204657\n",
      "test loss:  6.774240493774414\n",
      "test r2:  -0.25522575482392584\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853794962596551\n",
      "test loss:  6.774585247039795\n",
      "test r2:  -0.2553298183212387\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.885357271713235\n",
      "test loss:  6.774214267730713\n",
      "test r2:  -0.2552167166289063\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853814678375491\n",
      "test loss:  6.774625778198242\n",
      "test r2:  -0.2553405040815755\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853549876931208\n",
      "test loss:  6.7741804122924805\n",
      "test r2:  -0.2552048436131835\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853840155533286\n",
      "test loss:  6.774674892425537\n",
      "test r2:  -0.25535426505794434\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853520347349766\n",
      "test loss:  6.774133682250977\n",
      "test r2:  -0.2551892732513319\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853873246997694\n",
      "test loss:  6.774737358093262\n",
      "test r2:  -0.2553723835564141\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853481655593567\n",
      "test loss:  6.774067401885986\n",
      "test r2:  -0.2551681482213559\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853918548864022\n",
      "test loss:  6.774820327758789\n",
      "test r2:  -0.25539804735150073\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853426612775093\n",
      "test loss:  6.773963928222656\n",
      "test r2:  -0.2551366490096716\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853985595155885\n",
      "test loss:  6.774943828582764\n",
      "test r2:  -0.25543685867200105\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853343087178177\n",
      "test loss:  6.773805618286133\n",
      "test r2:  -0.2550885617522336\n",
      "train loss:  1.6364576816558838\n",
      "train r2:  0.8854087865745863\n",
      "test loss:  6.77513313293457\n",
      "test r2:  -0.25549609874025125\n",
      "train loss:  1.6364611387252808\n",
      "train r2:  0.8853215051583978\n",
      "test loss:  6.773565769195557\n",
      "test r2:  -0.2550155829845906\n",
      "train loss:  1.6364673376083374\n",
      "train r2:  0.8854242692256902\n",
      "test loss:  6.77541971206665\n",
      "test r2:  -0.2555853302059481\n",
      "train loss:  1.6364738941192627\n",
      "train r2:  0.8853022179927067\n",
      "test loss:  6.7732086181640625\n",
      "test r2:  -0.2549072864634965\n",
      "train loss:  1.6364867687225342\n",
      "train r2:  0.8854471387390189\n",
      "test loss:  6.775842189788818\n",
      "test r2:  -0.2557166622260836\n",
      "train loss:  1.6364974975585938\n",
      "train r2:  0.8852737704401121\n",
      "test loss:  6.772680759429932\n",
      "test r2:  -0.25474884017986543\n",
      "train loss:  1.6365207433700562\n",
      "train r2:  0.8854804858383745\n",
      "test loss:  6.776453971862793\n",
      "test r2:  -0.2559051012272102\n",
      "train loss:  1.6365388631820679\n",
      "train r2:  0.8852328168170011\n",
      "test loss:  6.7719407081604\n",
      "test r2:  -0.2545286800831317\n",
      "train loss:  1.636574149131775\n",
      "train r2:  0.8855267634869578\n",
      "test loss:  6.777266025543213\n",
      "test r2:  -0.2561526185573242\n",
      "train loss:  1.6366080045700073\n",
      "train r2:  0.885178810679955\n",
      "test loss:  6.771054267883301\n",
      "test r2:  -0.2542622801951373\n",
      "train loss:  1.6366589069366455\n",
      "train r2:  0.885582388778223\n",
      "test loss:  6.7781572341918945\n",
      "test r2:  -0.2564180978438897\n",
      "train loss:  1.6367030143737793\n",
      "train r2:  0.8851206476640894\n",
      "test loss:  6.770310878753662\n",
      "test r2:  -0.25403273433217555\n",
      "train loss:  1.6367487907409668\n",
      "train r2:  0.8856301704463089\n",
      "test loss:  6.778675556182861\n",
      "test r2:  -0.2565654546370639\n",
      "train loss:  1.6367584466934204\n",
      "train r2:  0.8850883745596564\n",
      "test loss:  6.770143508911133\n",
      "test r2:  -0.2539749523023893\n",
      "train loss:  1.6367443799972534\n",
      "train r2:  0.8856426081520019\n",
      "test loss:  6.778388500213623\n",
      "test r2:  -0.25646701818628515\n",
      "train loss:  1.6366760730743408\n",
      "train r2:  0.8851106964672562\n",
      "test loss:  6.771307468414307\n",
      "test r2:  -0.2543216657923688\n",
      "train loss:  1.6365925073623657\n",
      "train r2:  0.8855707543645983\n",
      "test loss:  6.776477336883545\n",
      "test r2:  -0.2558874242261837\n",
      "train loss:  1.6365079879760742\n",
      "train r2:  0.8852372520732823\n",
      "test loss:  6.77379035949707\n",
      "test r2:  -0.25506921669594673\n",
      "train loss:  1.6364635229110718\n",
      "train r2:  0.8854129786640721\n",
      "test loss:  6.773837566375732\n",
      "test r2:  -0.2550915395304343\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.8854082194517536\n",
      "test loss:  6.776175022125244\n",
      "test r2:  -0.25578752426114515\n",
      "train loss:  1.6364880800247192\n",
      "train r2:  0.8852589886460861\n",
      "test loss:  6.772069931030273\n",
      "test r2:  -0.25455556821376524\n",
      "train loss:  1.6365249156951904\n",
      "train r2:  0.885521752447995\n",
      "test loss:  6.777110576629639\n",
      "test r2:  -0.2560728245619861\n",
      "train loss:  1.6365467309951782\n",
      "train r2:  0.885197048547478\n",
      "test loss:  6.772040843963623\n",
      "test r2:  -0.25454270176965355\n",
      "train loss:  1.636544942855835\n",
      "train r2:  0.885524284217705\n",
      "test loss:  6.776304721832275\n",
      "test r2:  -0.2558382680169744\n",
      "train loss:  1.6365185976028442\n",
      "train r2:  0.8852475925915744\n",
      "test loss:  6.773409843444824\n",
      "test r2:  -0.2549533604795655\n",
      "train loss:  1.6364871263504028\n",
      "train r2:  0.8854374290589776\n",
      "test loss:  6.774652481079102\n",
      "test r2:  -0.25534631901539884\n",
      "train loss:  1.636462688446045\n",
      "train r2:  0.8853536020075893\n",
      "test loss:  6.774986743927002\n",
      "test r2:  -0.2554292285502151\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8853360443226636\n",
      "test loss:  6.773400783538818\n",
      "test r2:  -0.25496601221143944\n",
      "train loss:  1.6364662647247314\n",
      "train r2:  0.8854348448129654\n",
      "test loss:  6.775761604309082\n",
      "test r2:  -0.25566791317768733\n",
      "train loss:  1.6364816427230835\n",
      "train r2:  0.885284636315115\n",
      "test loss:  6.773135662078857\n",
      "test r2:  -0.25487906544608707\n",
      "train loss:  1.636488676071167\n",
      "train r2:  0.8854532042803159\n",
      "test loss:  6.775577068328857\n",
      "test r2:  -0.25562063673335156\n",
      "train loss:  1.6364866495132446\n",
      "train r2:  0.8852946311437826\n",
      "test loss:  6.773615837097168\n",
      "test r2:  -0.25502081957215483\n",
      "train loss:  1.6364762783050537\n",
      "train r2:  0.8854231127512485\n",
      "test loss:  6.7749176025390625\n",
      "test r2:  -0.25542660783344173\n",
      "train loss:  1.6364636421203613\n",
      "train r2:  0.8853363928579773\n",
      "test loss:  6.774301528930664\n",
      "test r2:  -0.2552279059074751\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853791409801622\n",
      "test loss:  6.774301528930664\n",
      "test r2:  -0.2552366089534679\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.885377187133317\n",
      "test loss:  6.7748308181762695\n",
      "test r2:  -0.25538541121647995\n",
      "train loss:  1.636461615562439\n",
      "train r2:  0.8853453819984354\n",
      "test loss:  6.773949146270752\n",
      "test r2:  -0.25512109348787226\n",
      "train loss:  1.6364648342132568\n",
      "train r2:  0.8854018265436596\n",
      "test loss:  6.775079250335693\n",
      "test r2:  -0.2554596747162554\n",
      "train loss:  1.6364692449569702\n",
      "train r2:  0.8853293995298261\n",
      "test loss:  6.773841381072998\n",
      "test r2:  -0.2550858654465362\n",
      "train loss:  1.6364659070968628\n",
      "train r2:  0.8854093819704204\n",
      "test loss:  6.775055408477783\n",
      "test r2:  -0.2554563960693339\n",
      "train loss:  1.6364604234695435\n",
      "train r2:  0.8853301858965623\n",
      "test loss:  6.773956298828125\n",
      "test r2:  -0.25512533226804934\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8854010469555185\n",
      "test loss:  6.774792671203613\n",
      "test r2:  -0.25538098304053247\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853464037304928\n",
      "test loss:  6.774295330047607\n",
      "test r2:  -0.2552304566155772\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853786231604935\n",
      "test loss:  6.774387836456299\n",
      "test r2:  -0.25525712141525214\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853728807437624\n",
      "test loss:  6.774737358093262\n",
      "test r2:  -0.2553587012832197\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.8853511350056257\n",
      "test loss:  6.774021625518799\n",
      "test r2:  -0.25514314414140227\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.885397201716859\n",
      "test loss:  6.775027275085449\n",
      "test r2:  -0.25544185176432377\n",
      "train loss:  1.636459469795227\n",
      "train r2:  0.8853333747973994\n",
      "test loss:  6.773891925811768\n",
      "test r2:  -0.25510530701692735\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.885405280392932\n",
      "test loss:  6.774971008300781\n",
      "test r2:  -0.25542672323069593\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853366455598196\n",
      "test loss:  6.774094104766846\n",
      "test r2:  -0.2551699728667669\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853915230932422\n",
      "test loss:  6.77461576461792\n",
      "test r2:  -0.25532349421929257\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.885358773534523\n",
      "test loss:  6.774508476257324\n",
      "test r2:  -0.2552934915241123\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853651576117925\n",
      "test loss:  6.774208068847656\n",
      "test r2:  -0.25520037086792313\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853850911282639\n",
      "test loss:  6.774868488311768\n",
      "test r2:  -0.2553963649651596\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853431817490112\n",
      "test loss:  6.773996353149414\n",
      "test r2:  -0.2551342057877475\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853991983127086\n",
      "test loss:  6.7749528884887695\n",
      "test r2:  -0.25541809829800277\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853385266332288\n",
      "test loss:  6.774075508117676\n",
      "test r2:  -0.2551574631983622\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853942513035361\n",
      "test loss:  6.774755477905273\n",
      "test r2:  -0.2553586726845516\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853512773689243\n",
      "test loss:  6.774350166320801\n",
      "test r2:  -0.25524037354425566\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853765451835771\n",
      "test loss:  6.774451732635498\n",
      "test r2:  -0.2552680157699281\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.885370656539054\n",
      "test loss:  6.774627208709717\n",
      "test r2:  -0.255323993847016\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853586895849566\n",
      "test loss:  6.77423095703125\n",
      "test r2:  -0.25520207553533636\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853847324407356\n",
      "test loss:  6.7747602462768555\n",
      "test r2:  -0.25536490470361994\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853498894410872\n",
      "test loss:  6.774177074432373\n",
      "test r2:  -0.2551868186292654\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853880105924468\n",
      "test loss:  6.774728775024414\n",
      "test r2:  -0.2553574923888644\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853514379147338\n",
      "test loss:  6.774251937866211\n",
      "test r2:  -0.2552101273190146\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853830101562326\n",
      "test loss:  6.7746195793151855\n",
      "test r2:  -0.25532527715669096\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853583627068291\n",
      "test loss:  6.774369716644287\n",
      "test r2:  -0.25524504712331986\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853755517128218\n",
      "test loss:  6.774516582489014\n",
      "test r2:  -0.2552924370324565\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853654027273566\n",
      "test loss:  6.7744669914245605\n",
      "test r2:  -0.2552731676767195\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853695744692164\n",
      "test loss:  6.774452209472656\n",
      "test r2:  -0.2552705062514431\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853701086331409\n",
      "test loss:  6.77452278137207\n",
      "test r2:  -0.2552898712569547\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.885366022844824\n",
      "test loss:  6.774414539337158\n",
      "test r2:  -0.25525781033428907\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853728286722538\n",
      "test loss:  6.7745585441589355\n",
      "test r2:  -0.2553007671682437\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853636885777247\n",
      "test loss:  6.774385452270508\n",
      "test r2:  -0.2552484332932867\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853748542001062\n",
      "test loss:  6.774586200714111\n",
      "test r2:  -0.25530840865944926\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853620464627012\n",
      "test loss:  6.774371147155762\n",
      "test r2:  -0.25524379243177076\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853758569527395\n",
      "test loss:  6.7745890617370605\n",
      "test r2:  -0.25530869529335387\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853619642763674\n",
      "test loss:  6.774383544921875\n",
      "test r2:  -0.25524837842267734\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853748770261021\n",
      "test loss:  6.774552822113037\n",
      "test r2:  -0.2552983967988818\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853641572822554\n",
      "test loss:  6.774429798126221\n",
      "test r2:  -0.2552635418930509\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853716033547276\n",
      "test loss:  6.774487018585205\n",
      "test r2:  -0.25527901367828587\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853682995102324\n",
      "test loss:  6.774500846862793\n",
      "test r2:  -0.25528521305763685\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853669975615979\n",
      "test loss:  6.774415969848633\n",
      "test r2:  -0.2552574535391243\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853729263342586\n",
      "test loss:  6.774567127227783\n",
      "test r2:  -0.2553045875185487\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853628359732637\n",
      "test loss:  6.774367809295654\n",
      "test r2:  -0.2552424030153635\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853761167800689\n",
      "test loss:  6.774599075317383\n",
      "test r2:  -0.25531370327283676\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853608966114136\n",
      "test loss:  6.774362087249756\n",
      "test r2:  -0.25523996466502386\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853766806403591\n",
      "test loss:  6.7745890617370605\n",
      "test r2:  -0.25531045579504275\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853615746637089\n",
      "test loss:  6.774388313293457\n",
      "test r2:  -0.25524737643189255\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853750947974823\n",
      "test loss:  6.7745561599731445\n",
      "test r2:  -0.25530101116221604\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853635848857492\n",
      "test loss:  6.7744245529174805\n",
      "test r2:  -0.25525730357482\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853729783199717\n",
      "test loss:  6.774525165557861\n",
      "test r2:  -0.25529199008686754\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853655111386232\n",
      "test loss:  6.774450778961182\n",
      "test r2:  -0.25526457159666815\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853714277199658\n",
      "test loss:  6.774505615234375\n",
      "test r2:  -0.2552873717050965\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853664677356752\n",
      "test loss:  6.774454116821289\n",
      "test r2:  -0.2552660449298789\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853710969796535\n",
      "test loss:  6.774505138397217\n",
      "test r2:  -0.2552887768033558\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853661390156704\n",
      "test loss:  6.774438858032227\n",
      "test r2:  -0.2552620920298778\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853718926554119\n",
      "test loss:  6.774516582489014\n",
      "test r2:  -0.25529442868298813\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853649012568201\n",
      "test loss:  6.774409770965576\n",
      "test r2:  -0.255254535229686\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853734504409769\n",
      "test loss:  6.774539470672607\n",
      "test r2:  -0.2553029159731981\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853630530249113\n",
      "test loss:  6.77437162399292\n",
      "test r2:  -0.25524451299920825\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853756020638635\n",
      "test loss:  6.774572372436523\n",
      "test r2:  -0.2553134184228927\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853608287230518\n",
      "test loss:  6.7743330001831055\n",
      "test r2:  -0.2552334672301202\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853780059709122\n",
      "test loss:  6.774613857269287\n",
      "test r2:  -0.25532498684221583\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853583933605109\n",
      "test loss:  6.774299144744873\n",
      "test r2:  -0.2552218161157296\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.885380499077648\n",
      "test loss:  6.774665832519531\n",
      "test r2:  -0.25533691945471193\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853558877244803\n",
      "test loss:  6.774273872375488\n",
      "test r2:  -0.2552106840334729\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.885382947980738\n",
      "test loss:  6.774720668792725\n",
      "test r2:  -0.25534830563766064\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853534918900111\n",
      "test loss:  6.774254322052002\n",
      "test r2:  -0.25520068261245354\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853850983564963\n",
      "test loss:  6.774766445159912\n",
      "test r2:  -0.2553576568798501\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853515262788012\n",
      "test loss:  6.7742390632629395\n",
      "test r2:  -0.2551929903930725\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.885386787110667\n",
      "test loss:  6.77479887008667\n",
      "test r2:  -0.25536524838431984\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853499326092198\n",
      "test loss:  6.774221420288086\n",
      "test r2:  -0.25518629607939114\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853881948206643\n",
      "test loss:  6.7748188972473145\n",
      "test r2:  -0.25537136994018783\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853485959348588\n",
      "test loss:  6.77419900894165\n",
      "test r2:  -0.25518024486195023\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853894993695608\n",
      "test loss:  6.774831771850586\n",
      "test r2:  -0.2553770361324674\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.88534736565236\n",
      "test loss:  6.774174213409424\n",
      "test r2:  -0.25517431701838134\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853907611016559\n",
      "test loss:  6.774843215942383\n",
      "test r2:  -0.2553835952430421\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853459280498096\n",
      "test loss:  6.774138927459717\n",
      "test r2:  -0.2551655347571704\n",
      "train loss:  1.6364545822143555\n",
      "train r2:  0.8853925812675274\n",
      "test loss:  6.774868488311768\n",
      "test r2:  -0.25539410329756773\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853436206942777\n",
      "test loss:  6.774092197418213\n",
      "test r2:  -0.25515215368245303\n",
      "train loss:  1.636457085609436\n",
      "train r2:  0.8853954093548999\n",
      "test loss:  6.7749176025390625\n",
      "test r2:  -0.255410900577715\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.885339973833969\n",
      "test loss:  6.774020671844482\n",
      "test r2:  -0.2551306515701388\n",
      "train loss:  1.6364604234695435\n",
      "train r2:  0.8853999658807599\n",
      "test loss:  6.7750020027160645\n",
      "test r2:  -0.2554375800679254\n",
      "train loss:  1.636460542678833\n",
      "train r2:  0.8853342117898847\n",
      "test loss:  6.77391242980957\n",
      "test r2:  -0.25509798282387885\n",
      "train loss:  1.6364638805389404\n",
      "train r2:  0.8854068813754141\n",
      "test loss:  6.775129318237305\n",
      "test r2:  -0.2554765960410519\n",
      "train loss:  1.6364641189575195\n",
      "train r2:  0.8853258185335272\n",
      "test loss:  6.773760795593262\n",
      "test r2:  -0.2550520248656003\n",
      "train loss:  1.6364675760269165\n",
      "train r2:  0.8854166426031307\n",
      "test loss:  6.775305271148682\n",
      "test r2:  -0.2555294855643919\n",
      "train loss:  1.636468768119812\n",
      "train r2:  0.88531447267328\n",
      "test loss:  6.773565769195557\n",
      "test r2:  -0.25499229457382233\n",
      "train loss:  1.6364729404449463\n",
      "train r2:  0.8854293600911676\n",
      "test loss:  6.775533676147461\n",
      "test r2:  -0.25559661113522947\n",
      "train loss:  1.6364763975143433\n",
      "train r2:  0.8852999822008705\n",
      "test loss:  6.773324966430664\n",
      "test r2:  -0.2549175353552655\n",
      "train loss:  1.6364827156066895\n",
      "train r2:  0.8854452001370362\n",
      "test loss:  6.77581787109375\n",
      "test r2:  -0.2556796058536457\n",
      "train loss:  1.636488437652588\n",
      "train r2:  0.8852821206682824\n",
      "test loss:  6.773037910461426\n",
      "test r2:  -0.25482750042736657\n",
      "train loss:  1.6364976167678833\n",
      "train r2:  0.88546427161956\n",
      "test loss:  6.776150703430176\n",
      "test r2:  -0.25577706630395713\n",
      "train loss:  1.6365069150924683\n",
      "train r2:  0.8852609993210641\n",
      "test loss:  6.772712230682373\n",
      "test r2:  -0.25472530690874695\n",
      "train loss:  1.6365196704864502\n",
      "train r2:  0.8854858194354673\n",
      "test loss:  6.776507377624512\n",
      "test r2:  -0.2558825280791064\n",
      "train loss:  1.636531114578247\n",
      "train r2:  0.8852381137394276\n",
      "test loss:  6.772378921508789\n",
      "test r2:  -0.25462172773519387\n",
      "train loss:  1.6365461349487305\n",
      "train r2:  0.8855076065524649\n",
      "test loss:  6.776829719543457\n",
      "test r2:  -0.25597922969797393\n",
      "train loss:  1.6365565061569214\n",
      "train r2:  0.8852170668960401\n",
      "test loss:  6.7721147537231445\n",
      "test r2:  -0.25454089024382776\n",
      "train loss:  1.6365693807601929\n",
      "train r2:  0.8855245798460115\n",
      "test loss:  6.777011394500732\n",
      "test r2:  -0.2560352392688252\n",
      "train loss:  1.636572003364563\n",
      "train r2:  0.8852048346271237\n",
      "test loss:  6.772039890289307\n",
      "test r2:  -0.25451997419427186\n",
      "train loss:  1.6365742683410645\n",
      "train r2:  0.8855289465980738\n",
      "test loss:  6.776922225952148\n",
      "test r2:  -0.2560105332464724\n",
      "train loss:  1.6365618705749512\n",
      "train r2:  0.8852102651442414\n",
      "test loss:  6.772280693054199\n",
      "test r2:  -0.2545966086153926\n",
      "train loss:  1.6365485191345215\n",
      "train r2:  0.8855129005991228\n",
      "test loss:  6.776475429534912\n",
      "test r2:  -0.2558775771679245\n",
      "train loss:  1.6365242004394531\n",
      "train r2:  0.8852392224636064\n",
      "test loss:  6.772876262664795\n",
      "test r2:  -0.2547807604666401\n",
      "train loss:  1.636501431465149\n",
      "train r2:  0.8854741808420866\n",
      "test loss:  6.775724411010742\n",
      "test r2:  -0.2556500113812572\n",
      "train loss:  1.6364785432815552\n",
      "train r2:  0.8852885791780918\n",
      "test loss:  6.7737202644348145\n",
      "test r2:  -0.25503640068999767\n",
      "train loss:  1.6364622116088867\n",
      "train r2:  0.8854201112091917\n",
      "test loss:  6.774857997894287\n",
      "test r2:  -0.2553835030045031\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853459695179989\n",
      "test loss:  6.774592399597168\n",
      "test r2:  -0.25529658274560796\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853646642628853\n",
      "test loss:  6.7740983963012695\n",
      "test r2:  -0.2551461333095044\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853968196290615\n",
      "test loss:  6.775285243988037\n",
      "test r2:  -0.2555010708060088\n",
      "train loss:  1.636457920074463\n",
      "train r2:  0.8853208851778175\n",
      "test loss:  6.773590564727783\n",
      "test r2:  -0.25498510836325416\n",
      "train loss:  1.6364648342132568\n",
      "train r2:  0.8854311536558314\n",
      "test loss:  6.7756805419921875\n",
      "test r2:  -0.25561670357980604\n",
      "train loss:  1.6364704370498657\n",
      "train r2:  0.8852959805137527\n",
      "test loss:  6.773382186889648\n",
      "test r2:  -0.2549170765804414\n",
      "train loss:  1.636474609375\n",
      "train r2:  0.8854455725530433\n",
      "test loss:  6.775758266448975\n",
      "test r2:  -0.2556402671413853\n",
      "train loss:  1.6364760398864746\n",
      "train r2:  0.8852908888612043\n",
      "test loss:  6.773444652557373\n",
      "test r2:  -0.2549346371273553\n",
      "train loss:  1.6364755630493164\n",
      "train r2:  0.8854418204660666\n",
      "test loss:  6.775572299957275\n",
      "test r2:  -0.2555877012573522\n",
      "train loss:  1.6364718675613403\n",
      "train r2:  0.8853021643048506\n",
      "test loss:  6.773698329925537\n",
      "test r2:  -0.2550143478213662\n",
      "train loss:  1.6364692449569702\n",
      "train r2:  0.8854248532609211\n",
      "test loss:  6.7752227783203125\n",
      "test r2:  -0.2554878873740385\n",
      "train loss:  1.6364637613296509\n",
      "train r2:  0.8853235578314257\n",
      "test loss:  6.774040222167969\n",
      "test r2:  -0.2551241618629996\n",
      "train loss:  1.6364614963531494\n",
      "train r2:  0.8854014596240318\n",
      "test loss:  6.774823188781738\n",
      "test r2:  -0.25537366161764075\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853480465435978\n",
      "test loss:  6.774375915527344\n",
      "test r2:  -0.25523318788771876\n",
      "train loss:  1.6364543437957764\n",
      "train r2:  0.885378172685495\n",
      "test loss:  6.774477005004883\n",
      "test r2:  -0.255272682241825\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853696860861977\n",
      "test loss:  6.774652481079102\n",
      "test r2:  -0.25532082443848614\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853594175935835\n",
      "test loss:  6.774238586425781\n",
      "test r2:  -0.2551983988583659\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853855698813623\n",
      "test loss:  6.7748565673828125\n",
      "test r2:  -0.25538060120233164\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853466464837064\n",
      "test loss:  6.7741169929504395\n",
      "test r2:  -0.2551541417261485\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853951168788019\n",
      "test loss:  6.774981498718262\n",
      "test r2:  -0.25541234493436926\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853398774310617\n",
      "test loss:  6.7740888595581055\n",
      "test r2:  -0.2551361059104569\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853990126165955\n",
      "test loss:  6.775030136108398\n",
      "test r2:  -0.25542122534515244\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853380490730569\n",
      "test loss:  6.774115085601807\n",
      "test r2:  -0.25513742500584624\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853987654201256\n",
      "test loss:  6.775012016296387\n",
      "test r2:  -0.2554132742425905\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.885339720393817\n",
      "test loss:  6.774167060852051\n",
      "test r2:  -0.25515141458210366\n",
      "train loss:  1.6364562511444092\n",
      "train r2:  0.8853957740795719\n",
      "test loss:  6.774943828582764\n",
      "test r2:  -0.2553952268844084\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853435563367695\n",
      "test loss:  6.774221420288086\n",
      "test r2:  -0.2551715163018409\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853914449099151\n",
      "test loss:  6.774850368499756\n",
      "test r2:  -0.25537291781263316\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853482835564322\n",
      "test loss:  6.774269104003906\n",
      "test r2:  -0.25519293438367785\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.885386810387925\n",
      "test loss:  6.774755954742432\n",
      "test r2:  -0.25535104398419883\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853529508368013\n",
      "test loss:  6.774310111999512\n",
      "test r2:  -0.25521177597293687\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853827618995401\n",
      "test loss:  6.774689197540283\n",
      "test r2:  -0.25533378964355014\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853566051397015\n",
      "test loss:  6.774348735809326\n",
      "test r2:  -0.25522553476492704\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853798494635967\n",
      "test loss:  6.774662494659424\n",
      "test r2:  -0.2553229646615871\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853589772675302\n",
      "test loss:  6.774388313293457\n",
      "test r2:  -0.2552341788757071\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853780365287842\n",
      "test loss:  6.774667739868164\n",
      "test r2:  -0.2553174285530009\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.885360233240585\n",
      "test loss:  6.774425983428955\n",
      "test r2:  -0.255239326164888\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853770010946804\n",
      "test loss:  6.774682521820068\n",
      "test r2:  -0.2553141781575816\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853610277527624\n",
      "test loss:  6.774459362030029\n",
      "test r2:  -0.2552438600287157\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853760683925859\n",
      "test loss:  6.774685859680176\n",
      "test r2:  -0.2553098154658866\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853620154147002\n",
      "test loss:  6.774487495422363\n",
      "test r2:  -0.25524985041535775\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853748016382854\n",
      "test loss:  6.7746686935424805\n",
      "test r2:  -0.25530320883253066\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853634422731846\n",
      "test loss:  6.774508953094482\n",
      "test r2:  -0.25525775026438735\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853731166307375\n",
      "test loss:  6.774628162384033\n",
      "test r2:  -0.2552935314031044\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853654502063424\n",
      "test loss:  6.7745280265808105\n",
      "test r2:  -0.2552675388032133\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853709773662667\n",
      "test loss:  6.774577617645264\n",
      "test r2:  -0.25528271785405443\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853677348397655\n",
      "test loss:  6.7745442390441895\n",
      "test r2:  -0.2552773719482193\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853688353024967\n",
      "test loss:  6.774532794952393\n",
      "test r2:  -0.25527251517116256\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853699115331998\n",
      "test loss:  6.774567127227783\n",
      "test r2:  -0.255287196486794\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853666885449406\n",
      "test loss:  6.774491786956787\n",
      "test r2:  -0.2552613222386495\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853722359448837\n",
      "test loss:  6.7746052742004395\n",
      "test r2:  -0.2552992668820733\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853641102469949\n",
      "test loss:  6.774451732635498\n",
      "test r2:  -0.2552480822627108\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853751004594586\n",
      "test loss:  6.774660110473633\n",
      "test r2:  -0.255314466627675\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853608637681288\n",
      "test loss:  6.774405002593994\n",
      "test r2:  -0.2552312721230965\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853786986463493\n",
      "test loss:  6.774731636047363\n",
      "test r2:  -0.2553342141718635\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853566670915985\n",
      "test loss:  6.774342060089111\n",
      "test r2:  -0.25520924803951717\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853834267590321\n",
      "test loss:  6.774820327758789\n",
      "test r2:  -0.25535975008914136\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853511665085912\n",
      "test loss:  6.77424955368042\n",
      "test r2:  -0.25517969400732077\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853897177306078\n",
      "test loss:  6.774937629699707\n",
      "test r2:  -0.25539543153088995\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.88534351712913\n",
      "test loss:  6.774105548858643\n",
      "test r2:  -0.2551362800729251\n",
      "train loss:  1.6364586353302002\n",
      "train r2:  0.885398958012485\n",
      "test loss:  6.775104999542236\n",
      "test r2:  -0.25544800349902697\n",
      "train loss:  1.636459469795227\n",
      "train r2:  0.8853321932987279\n",
      "test loss:  6.773889541625977\n",
      "test r2:  -0.2550726953830045\n",
      "train loss:  1.6364637613296509\n",
      "train r2:  0.8854124455309631\n",
      "test loss:  6.775346279144287\n",
      "test r2:  -0.2555235825631381\n",
      "train loss:  1.6364666223526\n",
      "train r2:  0.8853159194037326\n",
      "test loss:  6.773585319519043\n",
      "test r2:  -0.25498214390638396\n",
      "train loss:  1.6364731788635254\n",
      "train r2:  0.8854316846709535\n",
      "test loss:  6.775697708129883\n",
      "test r2:  -0.2556311019871633\n",
      "train loss:  1.6364794969558716\n",
      "train r2:  0.8852927006120261\n",
      "test loss:  6.773163318634033\n",
      "test r2:  -0.2548547752155568\n",
      "train loss:  1.636491298675537\n",
      "train r2:  0.8854586330811364\n",
      "test loss:  6.776193618774414\n",
      "test r2:  -0.2557803701895156\n",
      "train loss:  1.6365044116973877\n",
      "train r2:  0.8852604282376061\n",
      "test loss:  6.772599697113037\n",
      "test r2:  -0.25468240528642294\n",
      "train loss:  1.636525273323059\n",
      "train r2:  0.8854949942151915\n",
      "test loss:  6.776852607727051\n",
      "test r2:  -0.25597683214011235\n",
      "train loss:  1.6365492343902588\n",
      "train r2:  0.8852177511873041\n",
      "test loss:  6.771896839141846\n",
      "test r2:  -0.25446580507152583\n",
      "train loss:  1.6365834474563599\n",
      "train r2:  0.8855404557102247\n",
      "test loss:  6.7776288986206055\n",
      "test r2:  -0.2562071054523798\n",
      "train loss:  1.6366184949874878\n",
      "train r2:  0.8851674760321258\n",
      "test loss:  6.771165370941162\n",
      "test r2:  -0.25423916816398706\n",
      "train loss:  1.6366626024246216\n",
      "train r2:  0.8855878101219211\n",
      "test loss:  6.778306484222412\n",
      "test r2:  -0.256407809592341\n",
      "train loss:  1.636693000793457\n",
      "train r2:  0.8851234839682411\n",
      "test loss:  6.770724296569824\n",
      "test r2:  -0.25410209726183974\n",
      "train loss:  1.6367188692092896\n",
      "train r2:  0.8856162990207306\n",
      "test loss:  6.7784199714660645\n",
      "test r2:  -0.25644119584299263\n",
      "train loss:  1.6367052793502808\n",
      "train r2:  0.8851161635292917\n",
      "test loss:  6.771069049835205\n",
      "test r2:  -0.25420702707575016\n",
      "train loss:  1.6366724967956543\n",
      "train r2:  0.885594524103696\n",
      "test loss:  6.777527332305908\n",
      "test r2:  -0.25617404597781523\n",
      "train loss:  1.6366031169891357\n",
      "train r2:  0.8851748317751581\n",
      "test loss:  6.772456645965576\n",
      "test r2:  -0.25463220687358423\n",
      "train loss:  1.6365350484848022\n",
      "train r2:  0.885505627566618\n",
      "test loss:  6.775711536407471\n",
      "test r2:  -0.25562841482451937\n",
      "train loss:  1.6364777088165283\n",
      "train r2:  0.8852933604059507\n",
      "test loss:  6.774418354034424\n",
      "test r2:  -0.25522990935856726\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853790140379965\n",
      "test loss:  6.773806571960449\n",
      "test r2:  -0.2550498387551856\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.8854174121807697\n",
      "test loss:  6.776060104370117\n",
      "test r2:  -0.2557251064247388\n",
      "train loss:  1.6364834308624268\n",
      "train r2:  0.8852726535104384\n",
      "test loss:  6.772633075714111\n",
      "test r2:  -0.25468606492667334\n",
      "train loss:  1.6365118026733398\n",
      "train r2:  0.8854944508788136\n",
      "test loss:  6.776754856109619\n",
      "test r2:  -0.2559312142413601\n",
      "train loss:  1.6365283727645874\n",
      "train r2:  0.8852279625115439\n",
      "test loss:  6.772542953491211\n",
      "test r2:  -0.25464890641686644\n",
      "train loss:  1.6365283727645874\n",
      "train r2:  0.8855022681663286\n",
      "test loss:  6.7763671875\n",
      "test r2:  -0.25581219190274584\n",
      "train loss:  1.6365107297897339\n",
      "train r2:  0.8852537002596736\n",
      "test loss:  6.77337646484375\n",
      "test r2:  -0.25489601573822296\n",
      "train loss:  1.6364891529083252\n",
      "train r2:  0.8854500525370838\n",
      "test loss:  6.775274753570557\n",
      "test r2:  -0.25548268310155575\n",
      "train loss:  1.6364665031433105\n",
      "train r2:  0.8853247935005577\n",
      "test loss:  6.774566173553467\n",
      "test r2:  -0.25525749921445184\n",
      "train loss:  1.6364589929580688\n",
      "train r2:  0.8853732055125867\n",
      "test loss:  6.774130344390869\n",
      "test r2:  -0.2551380945839661\n",
      "train loss:  1.6364567279815674\n",
      "train r2:  0.8853986494070439\n",
      "test loss:  6.775488376617432\n",
      "test r2:  -0.25554391113259833\n",
      "train loss:  1.6364651918411255\n",
      "train r2:  0.8853117725721726\n",
      "test loss:  6.773452281951904\n",
      "test r2:  -0.2549343963858848\n",
      "train loss:  1.6364728212356567\n",
      "train r2:  0.8854419133268102\n",
      "test loss:  6.775808334350586\n",
      "test r2:  -0.25564896828974404\n",
      "train loss:  1.6364768743515015\n",
      "train r2:  0.8852890467147407\n",
      "test loss:  6.773420333862305\n",
      "test r2:  -0.2549254941866159\n",
      "train loss:  1.6364755630493164\n",
      "train r2:  0.885443808035295\n",
      "test loss:  6.7755351066589355\n",
      "test r2:  -0.2555713033088689\n",
      "train loss:  1.6364693641662598\n",
      "train r2:  0.8853057210791865\n",
      "test loss:  6.773904323577881\n",
      "test r2:  -0.2550696262879435\n",
      "train loss:  1.6364628076553345\n",
      "train r2:  0.8854131904053999\n",
      "test loss:  6.774928569793701\n",
      "test r2:  -0.255386606371677\n",
      "train loss:  1.6364569664001465\n",
      "train r2:  0.885345423839643\n",
      "test loss:  6.774581432342529\n",
      "test r2:  -0.25526962544195886\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8853705413499289\n",
      "test loss:  6.774319648742676\n",
      "test r2:  -0.2551976277051011\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853858961160652\n",
      "test loss:  6.775111675262451\n",
      "test r2:  -0.25542869813125213\n",
      "train loss:  1.6364587545394897\n",
      "train r2:  0.8853365139525295\n",
      "test loss:  6.773949146270752\n",
      "test r2:  -0.25508272369246576\n",
      "train loss:  1.6364587545394897\n",
      "train r2:  0.8854104768568555\n",
      "test loss:  6.775310039520264\n",
      "test r2:  -0.25549186073633234\n",
      "train loss:  1.6364588737487793\n",
      "train r2:  0.8853229620703861\n",
      "test loss:  6.773913860321045\n",
      "test r2:  -0.25507129937556994\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8854129112036828\n",
      "test loss:  6.775179862976074\n",
      "test r2:  -0.2554556037625173\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853307640136674\n",
      "test loss:  6.774168491363525\n",
      "test r2:  -0.2551460669547776\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853970192012973\n",
      "test loss:  6.774850368499756\n",
      "test r2:  -0.2553554380488152\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853522207302624\n",
      "test loss:  6.7745561599731445\n",
      "test r2:  -0.2552589529957838\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853729131525617\n",
      "test loss:  6.774487495422363\n",
      "test r2:  -0.25524418543764593\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853760129768853\n",
      "test loss:  6.77488374710083\n",
      "test r2:  -0.2553567422560201\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853519971415047\n",
      "test loss:  6.774238586425781\n",
      "test r2:  -0.25516966993348533\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853919149638284\n",
      "test loss:  6.775018692016602\n",
      "test r2:  -0.25540162824249313\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853423699464651\n",
      "test loss:  6.774181842803955\n",
      "test r2:  -0.25515502014643654\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853950438135959\n",
      "test loss:  6.774954319000244\n",
      "test r2:  -0.25538663016123\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853455733803333\n",
      "test loss:  6.774309158325195\n",
      "test r2:  -0.2551933632838206\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853869159837716\n",
      "test loss:  6.774770736694336\n",
      "test r2:  -0.2553319031770478\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853572814377372\n",
      "test loss:  6.774531841278076\n",
      "test r2:  -0.25525633413977755\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853734777674885\n",
      "test loss:  6.774569988250732\n",
      "test r2:  -0.25526871865751866\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853708196302388\n",
      "test loss:  6.7747392654418945\n",
      "test r2:  -0.25531402840321515\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853611446447374\n",
      "test loss:  6.774426460266113\n",
      "test r2:  -0.2552233200425311\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853805434028399\n",
      "test loss:  6.774848461151123\n",
      "test r2:  -0.2553449074971348\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853545804383904\n",
      "test loss:  6.7743821144104\n",
      "test r2:  -0.25520971743617693\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853834471657239\n",
      "test loss:  6.774836540222168\n",
      "test r2:  -0.2553422710257991\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853551224871006\n",
      "test loss:  6.774433612823486\n",
      "test r2:  -0.25522575466621644\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853799942249975\n",
      "test loss:  6.7747392654418945\n",
      "test r2:  -0.2553151802425824\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853609023576379\n",
      "test loss:  6.774540901184082\n",
      "test r2:  -0.25525891937191836\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853729480025099\n",
      "test loss:  6.774613857269287\n",
      "test r2:  -0.2552794146413213\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853685447221832\n",
      "test loss:  6.774652481079102\n",
      "test r2:  -0.25529289493168594\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853656998868698\n",
      "test loss:  6.7745137214660645\n",
      "test r2:  -0.25525026620513214\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853747638745302\n",
      "test loss:  6.774730205535889\n",
      "test r2:  -0.255315273939422\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853609089510248\n",
      "test loss:  6.774466037750244\n",
      "test r2:  -0.25523518820919944\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853779940947922\n",
      "test loss:  6.774764537811279\n",
      "test r2:  -0.2553235860584373\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853591464909198\n",
      "test loss:  6.774466037750244\n",
      "test r2:  -0.2552336898708436\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853783659679525\n",
      "test loss:  6.7747578620910645\n",
      "test r2:  -0.25531976675474977\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853599405032953\n",
      "test loss:  6.774497985839844\n",
      "test r2:  -0.2552424908042421\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853764815515481\n",
      "test loss:  6.77471923828125\n",
      "test r2:  -0.2553070516523399\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.885362684536034\n",
      "test loss:  6.7745513916015625\n",
      "test r2:  -0.2552584929388022\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853730745972415\n",
      "test loss:  6.774661540985107\n",
      "test r2:  -0.2552892322376066\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853665101975925\n",
      "test loss:  6.7746124267578125\n",
      "test r2:  -0.2552775307155801\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.885368996363027\n",
      "test loss:  6.774594306945801\n",
      "test r2:  -0.2552695768152111\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853706950686198\n",
      "test loss:  6.774670600891113\n",
      "test r2:  -0.25529604383081494\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853650256183144\n",
      "test loss:  6.774534702301025\n",
      "test r2:  -0.25525275590731655\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853743015804125\n",
      "test loss:  6.774713516235352\n",
      "test r2:  -0.25531018797669836\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853619677639105\n",
      "test loss:  6.774494647979736\n",
      "test r2:  -0.255241280061409\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853767621740871\n",
      "test loss:  6.774740219116211\n",
      "test r2:  -0.2553187168346207\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853601212862563\n",
      "test loss:  6.77447509765625\n",
      "test r2:  -0.25523526220361914\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853780235773251\n",
      "test loss:  6.774754047393799\n",
      "test r2:  -0.2553225492384359\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853593168040469\n",
      "test loss:  6.774470806121826\n",
      "test r2:  -0.25523312836672796\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853785036907565\n",
      "test loss:  6.774760723114014\n",
      "test r2:  -0.2553239078953502\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853590259569581\n",
      "test loss:  6.774473667144775\n",
      "test r2:  -0.2552328712316645\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853785501400492\n",
      "test loss:  6.774758815765381\n",
      "test r2:  -0.255322988950895\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853592103114101\n",
      "test loss:  6.7744832038879395\n",
      "test r2:  -0.2552350440903868\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853780882685529\n",
      "test loss:  6.774749755859375\n",
      "test r2:  -0.25532021339516064\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853597935735251\n",
      "test loss:  6.77449369430542\n",
      "test r2:  -0.2552378234321724\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853774584802515\n",
      "test loss:  6.7747392654418945\n",
      "test r2:  -0.25531755786145993\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853603713500687\n",
      "test loss:  6.774502277374268\n",
      "test r2:  -0.25524025323445376\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853769748566186\n",
      "test loss:  6.774731636047363\n",
      "test r2:  -0.255316208183745\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853606800215282\n",
      "test loss:  6.774499893188477\n",
      "test r2:  -0.2552399568491879\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853770009443495\n",
      "test loss:  6.774736404418945\n",
      "test r2:  -0.25531833101374346\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853601790960057\n",
      "test loss:  6.774482250213623\n",
      "test r2:  -0.25523505890995724\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853780345928918\n",
      "test loss:  6.774758815765381\n",
      "test r2:  -0.2553256131096264\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853586321913042\n",
      "test loss:  6.774449348449707\n",
      "test r2:  -0.2552253713400163\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853800898724973\n",
      "test loss:  6.774798393249512\n",
      "test r2:  -0.2553373958796845\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853561057764582\n",
      "test loss:  6.7744059562683105\n",
      "test r2:  -0.2552117293656897\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.885383047605925\n",
      "test loss:  6.774852275848389\n",
      "test r2:  -0.2553527695890816\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853528415861491\n",
      "test loss:  6.774354934692383\n",
      "test r2:  -0.25519542991804056\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853865439435303\n",
      "test loss:  6.774917125701904\n",
      "test r2:  -0.2553704874532483\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.88534904088502\n",
      "test loss:  6.774296283721924\n",
      "test r2:  -0.25517645948833034\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853905807082539\n",
      "test loss:  6.774989604949951\n",
      "test r2:  -0.25539086669763145\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853446844049673\n",
      "test loss:  6.774230480194092\n",
      "test r2:  -0.25515494476233\n",
      "train loss:  1.6364543437957764\n",
      "train r2:  0.8853952069633045\n",
      "test loss:  6.775071620941162\n",
      "test r2:  -0.25541452027752776\n",
      "train loss:  1.636454463005066\n",
      "train r2:  0.8853396304281377\n",
      "test loss:  6.774148941040039\n",
      "test r2:  -0.2551292882894691\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8854006738531829\n",
      "test loss:  6.775167465209961\n",
      "test r2:  -0.2554430161293053\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.8853335160552727\n",
      "test loss:  6.774046421051025\n",
      "test r2:  -0.25509731516182677\n",
      "train loss:  1.6364582777023315\n",
      "train r2:  0.8854074756937713\n",
      "test loss:  6.77528715133667\n",
      "test r2:  -0.25547929212042586\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.885325703564993\n",
      "test loss:  6.7739105224609375\n",
      "test r2:  -0.25505606203776354\n",
      "train loss:  1.6364624500274658\n",
      "train r2:  0.8854162510560664\n",
      "test loss:  6.775439262390137\n",
      "test r2:  -0.2555261800935458\n",
      "train loss:  1.6364645957946777\n",
      "train r2:  0.8853156084020215\n",
      "test loss:  6.7737345695495605\n",
      "test r2:  -0.25500310744185417\n",
      "train loss:  1.6364686489105225\n",
      "train r2:  0.8854274757930013\n",
      "test loss:  6.775631904602051\n",
      "test r2:  -0.25558580250487184\n",
      "train loss:  1.6364718675613403\n",
      "train r2:  0.8853027137892164\n",
      "test loss:  6.773510932922363\n",
      "test r2:  -0.25493537108985764\n",
      "train loss:  1.636478304862976\n",
      "train r2:  0.8854418101013679\n",
      "test loss:  6.775880813598633\n",
      "test r2:  -0.2556621008112514\n",
      "train loss:  1.6364834308624268\n",
      "train r2:  0.8852862087047867\n",
      "test loss:  6.773228168487549\n",
      "test r2:  -0.2548497647178427\n",
      "train loss:  1.6364924907684326\n",
      "train r2:  0.8854599076123074\n",
      "test loss:  6.7761921882629395\n",
      "test r2:  -0.2557571491350321\n",
      "train loss:  1.6365002393722534\n",
      "train r2:  0.8852656683959172\n",
      "test loss:  6.772887706756592\n",
      "test r2:  -0.2547463544746946\n",
      "train loss:  1.6365127563476562\n",
      "train r2:  0.8854817070005606\n",
      "test loss:  6.776556491851807\n",
      "test r2:  -0.25586709387993145\n",
      "train loss:  1.6365236043930054\n",
      "train r2:  0.8852417860108173\n",
      "test loss:  6.772514820098877\n",
      "test r2:  -0.2546328630965786\n",
      "train loss:  1.636539101600647\n",
      "train r2:  0.8855056114139368\n",
      "test loss:  6.776933193206787\n",
      "test r2:  -0.2559800868530846\n",
      "train loss:  1.6365509033203125\n",
      "train r2:  0.8852172123063442\n",
      "test loss:  6.772171497344971\n",
      "test r2:  -0.25452764943735406\n",
      "train loss:  1.6365665197372437\n",
      "train r2:  0.8855277086284498\n",
      "test loss:  6.777231216430664\n",
      "test r2:  -0.2560684390321153\n",
      "train loss:  1.6365742683410645\n",
      "train r2:  0.8851979761058213\n",
      "test loss:  6.7719831466674805\n",
      "test r2:  -0.2544688147459566\n",
      "train loss:  1.6365817785263062\n",
      "train r2:  0.8855400546326252\n",
      "test loss:  6.77729606628418\n",
      "test r2:  -0.2560855186122286\n",
      "train loss:  1.6365766525268555\n",
      "train r2:  0.8851943319408753\n",
      "test loss:  6.772111415863037\n",
      "test r2:  -0.2545061160811535\n",
      "train loss:  1.6365681886672974\n",
      "train r2:  0.8855322980443537\n",
      "test loss:  6.776974201202393\n",
      "test r2:  -0.255986225098507\n",
      "train loss:  1.6365466117858887\n",
      "train r2:  0.885215992753732\n",
      "test loss:  6.772651195526123\n",
      "test r2:  -0.25466876766754054\n",
      "train loss:  1.6365242004394531\n",
      "train r2:  0.8854981814561828\n",
      "test loss:  6.776249408721924\n",
      "test r2:  -0.2557659317167822\n",
      "train loss:  1.636496901512146\n",
      "train r2:  0.885263903724319\n",
      "test loss:  6.773524284362793\n",
      "test r2:  -0.25493328553664485\n",
      "train loss:  1.6364758014678955\n",
      "train r2:  0.8854423230642365\n",
      "test loss:  6.775293350219727\n",
      "test r2:  -0.25547556042844977\n",
      "train loss:  1.6364593505859375\n",
      "train r2:  0.8853265549641324\n",
      "test loss:  6.774496078491211\n",
      "test r2:  -0.25522768852236877\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853797240731747\n",
      "test loss:  6.774379253387451\n",
      "test r2:  -0.2551969034069128\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853862750571218\n",
      "test loss:  6.775312423706055\n",
      "test r2:  -0.25547411685829435\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.885326954084469\n",
      "test loss:  6.773723125457764\n",
      "test r2:  -0.2549952203017507\n",
      "train loss:  1.6364630460739136\n",
      "train r2:  0.8854292473953445\n",
      "test loss:  6.775808334350586\n",
      "test r2:  -0.25562403231877906\n",
      "train loss:  1.636469841003418\n",
      "train r2:  0.8852947085471203\n",
      "test loss:  6.773422718048096\n",
      "test r2:  -0.2549006089100314\n",
      "train loss:  1.6364752054214478\n",
      "train r2:  0.8854493289164908\n",
      "test loss:  6.775944232940674\n",
      "test r2:  -0.25566513882628006\n",
      "train loss:  1.6364768743515015\n",
      "train r2:  0.8852858166051463\n",
      "test loss:  6.773462295532227\n",
      "test r2:  -0.254909444186205\n",
      "train loss:  1.6364766359329224\n",
      "train r2:  0.8854474667560422\n",
      "test loss:  6.7757720947265625\n",
      "test r2:  -0.2556139528049417\n",
      "train loss:  1.6364730596542358\n",
      "train r2:  0.8852968268846805\n",
      "test loss:  6.773752212524414\n",
      "test r2:  -0.25499524472931046\n",
      "train loss:  1.6364697217941284\n",
      "train r2:  0.8854292631893499\n",
      "test loss:  6.7754011154174805\n",
      "test r2:  -0.25550363727072156\n",
      "train loss:  1.636464238166809\n",
      "train r2:  0.8853205344109798\n",
      "test loss:  6.774158954620361\n",
      "test r2:  -0.25511955606624004\n",
      "train loss:  1.6364617347717285\n",
      "train r2:  0.8854027751746762\n",
      "test loss:  6.774960517883301\n",
      "test r2:  -0.2553741553189697\n",
      "train loss:  1.6364566087722778\n",
      "train r2:  0.8853483031590353\n",
      "test loss:  6.774555683135986\n",
      "test r2:  -0.25524456987293287\n",
      "train loss:  1.6364555358886719\n",
      "train r2:  0.8853760916840354\n",
      "test loss:  6.77456521987915\n",
      "test r2:  -0.2552584038196337\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853730870521919\n",
      "test loss:  6.774864673614502\n",
      "test r2:  -0.2553442653205247\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853547761921484\n",
      "test loss:  6.774290084838867\n",
      "test r2:  -0.25517603323647786\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853906764007876\n",
      "test loss:  6.775063991546631\n",
      "test r2:  -0.255406517200476\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.885341433920564\n",
      "test loss:  6.774162292480469\n",
      "test r2:  -0.25513331292475305\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.8853998255791274\n",
      "test loss:  6.775155544281006\n",
      "test r2:  -0.2554315087742729\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853360969017731\n",
      "test loss:  6.7741594314575195\n",
      "test r2:  -0.25512510767234287\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8854016414002056\n",
      "test loss:  6.775157451629639\n",
      "test r2:  -0.2554277118684034\n",
      "train loss:  1.6364543437957764\n",
      "train r2:  0.8853369506677822\n",
      "test loss:  6.774233818054199\n",
      "test r2:  -0.25514052211891736\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853984077228111\n",
      "test loss:  6.775094985961914\n",
      "test r2:  -0.25540582072674556\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853416197144953\n",
      "test loss:  6.7743330001831055\n",
      "test r2:  -0.2551675723800151\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853926170135958\n",
      "test loss:  6.77499532699585\n",
      "test r2:  -0.2553763491960641\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.8853479206422372\n",
      "test loss:  6.774427890777588\n",
      "test r2:  -0.2551980534049707\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853861156638904\n",
      "test loss:  6.774882793426514\n",
      "test r2:  -0.2553461938401571\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853543656528479\n",
      "test loss:  6.774499893188477\n",
      "test r2:  -0.25522533440834794\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853802590065839\n",
      "test loss:  6.774782180786133\n",
      "test r2:  -0.255320568056127\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.885359821552276\n",
      "test loss:  6.774550914764404\n",
      "test r2:  -0.25524657120313976\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853757046480544\n",
      "test loss:  6.774712085723877\n",
      "test r2:  -0.2553017401968092\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853638347044854\n",
      "test loss:  6.774591445922852\n",
      "test r2:  -0.25526132419056036\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.88537251263435\n",
      "test loss:  6.774679660797119\n",
      "test r2:  -0.25528994829189045\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853664085830256\n",
      "test loss:  6.774631977081299\n",
      "test r2:  -0.2552711666936782\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853704642551187\n",
      "test loss:  6.774675369262695\n",
      "test r2:  -0.2552824318919513\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853680366050942\n",
      "test loss:  6.77467155456543\n",
      "test r2:  -0.2552782213704452\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853689997776659\n",
      "test loss:  6.7746806144714355\n",
      "test r2:  -0.2552775302782946\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853691660123808\n",
      "test loss:  6.774703502655029\n",
      "test r2:  -0.2552836326099919\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853678854865625\n",
      "test loss:  6.7746806144714355\n",
      "test r2:  -0.2552731677760558\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853701544368074\n",
      "test loss:  6.774726390838623\n",
      "test r2:  -0.25528885855421457\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853667729200783\n",
      "test loss:  6.774665832519531\n",
      "test r2:  -0.25526748887689843\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853713552939249\n",
      "test loss:  6.774742126464844\n",
      "test r2:  -0.2552954765129545\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.885365305598397\n",
      "test loss:  6.774630546569824\n",
      "test r2:  -0.25525894364586477\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853731355326779\n",
      "test loss:  6.774758815765381\n",
      "test r2:  -0.2553046406133903\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853633181124949\n",
      "test loss:  6.774580001831055\n",
      "test r2:  -0.2552475757459505\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853755360395532\n",
      "test loss:  6.774785995483398\n",
      "test r2:  -0.2553172038671747\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853605663271277\n",
      "test loss:  6.774518013000488\n",
      "test r2:  -0.25523220878631414\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.885378814925476\n",
      "test loss:  6.774834156036377\n",
      "test r2:  -0.2553345597522456\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.885356848631449\n",
      "test loss:  6.774448871612549\n",
      "test r2:  -0.2552123137571374\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853830228257372\n",
      "test loss:  6.774905681610107\n",
      "test r2:  -0.2553563711041724\n",
      "train loss:  1.6364521980285645\n",
      "train r2:  0.8853521906174155\n",
      "test loss:  6.774374008178711\n",
      "test r2:  -0.255188348999031\n",
      "train loss:  1.6364532709121704\n",
      "train r2:  0.8853881418370692\n",
      "test loss:  6.775001049041748\n",
      "test r2:  -0.2553830114168907\n",
      "train loss:  1.63645339012146\n",
      "train r2:  0.8853464765220589\n",
      "test loss:  6.774285793304443\n",
      "test r2:  -0.255159118014219\n",
      "train loss:  1.6364548206329346\n",
      "train r2:  0.885394383129844\n",
      "test loss:  6.775118827819824\n",
      "test r2:  -0.2554162310925385\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853393691330474\n",
      "test loss:  6.774172782897949\n",
      "test r2:  -0.2551223010836845\n",
      "train loss:  1.6364567279815674\n",
      "train r2:  0.8854022891536371\n",
      "test loss:  6.775265693664551\n",
      "test r2:  -0.25545867292619184\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8853302728592258\n",
      "test loss:  6.774021625518799\n",
      "test r2:  -0.25507424048836524\n",
      "train loss:  1.636460542678833\n",
      "train r2:  0.8854125104929297\n",
      "test loss:  6.775453090667725\n",
      "test r2:  -0.2555141352390091\n",
      "train loss:  1.6364630460739136\n",
      "train r2:  0.8853183488803068\n",
      "test loss:  6.773812770843506\n",
      "test r2:  -0.25501038371887175\n",
      "train loss:  1.6364670991897583\n",
      "train r2:  0.8854260752242249\n",
      "test loss:  6.775693893432617\n",
      "test r2:  -0.2555877557316397\n",
      "train loss:  1.6364712715148926\n",
      "train r2:  0.8853024555784911\n",
      "test loss:  6.77353048324585\n",
      "test r2:  -0.2549253703672658\n",
      "train loss:  1.636478304862976\n",
      "train r2:  0.8854440674495198\n",
      "test loss:  6.776010513305664\n",
      "test r2:  -0.25568512085374007\n",
      "train loss:  1.6364854574203491\n",
      "train r2:  0.8852814485062115\n",
      "test loss:  6.773162841796875\n",
      "test r2:  -0.2548149185976587\n",
      "train loss:  1.6364965438842773\n",
      "train r2:  0.885467439747727\n",
      "test loss:  6.776414394378662\n",
      "test r2:  -0.25580869374163995\n",
      "train loss:  1.6365078687667847\n",
      "train r2:  0.8852546361243692\n",
      "test loss:  6.7727131843566895\n",
      "test r2:  -0.2546788651039338\n",
      "train loss:  1.6365253925323486\n",
      "train r2:  0.8854960933769342\n",
      "test loss:  6.776895523071289\n",
      "test r2:  -0.2559549242515513\n",
      "train loss:  1.6365422010421753\n",
      "train r2:  0.8852228693579014\n",
      "test loss:  6.772214889526367\n",
      "test r2:  -0.25452704649353697\n",
      "train loss:  1.6365654468536377\n",
      "train r2:  0.8855279530313274\n",
      "test loss:  6.7773942947387695\n",
      "test r2:  -0.25610503849356836\n",
      "train loss:  1.6365842819213867\n",
      "train r2:  0.8851901094371377\n",
      "test loss:  6.7717695236206055\n",
      "test r2:  -0.2543908223714697\n",
      "train loss:  1.6366076469421387\n",
      "train r2:  0.8855564550807363\n",
      "test loss:  6.777752876281738\n",
      "test r2:  -0.25621179103579794\n",
      "train loss:  1.6366180181503296\n",
      "train r2:  0.8851667840474075\n",
      "test loss:  6.771585464477539\n",
      "test r2:  -0.2543336982790003\n",
      "train loss:  1.6366256475448608\n",
      "train r2:  0.8855684145479095\n",
      "test loss:  6.777717590332031\n",
      "test r2:  -0.25619943380794097\n",
      "train loss:  1.6366119384765625\n",
      "train r2:  0.8851695040514115\n",
      "test loss:  6.771914482116699\n",
      "test r2:  -0.2544325884527794\n",
      "train loss:  1.636590600013733\n",
      "train r2:  0.885547798494307\n",
      "test loss:  6.777082920074463\n",
      "test r2:  -0.2560064011424201\n",
      "train loss:  1.636552095413208\n",
      "train r2:  0.8852117316282021\n",
      "test loss:  6.7728424072265625\n",
      "test r2:  -0.25471342900812677\n",
      "train loss:  1.6365147829055786\n",
      "train r2:  0.8854889035611949\n",
      "test loss:  6.775935173034668\n",
      "test r2:  -0.2556572334482019\n",
      "train loss:  1.6364796161651611\n",
      "train r2:  0.8852874949000458\n",
      "test loss:  6.77412223815918\n",
      "test r2:  -0.25510016801466295\n",
      "train loss:  1.6364587545394897\n",
      "train r2:  0.8854070371744973\n",
      "test loss:  6.774657726287842\n",
      "test r2:  -0.25526705694955276\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853714269546222\n",
      "test loss:  6.775320529937744\n",
      "test r2:  -0.25546176449792557\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853297576736401\n",
      "test loss:  6.773660659790039\n",
      "test r2:  -0.254960740800803\n",
      "train loss:  1.6364670991897583\n",
      "train r2:  0.885436722987768\n",
      "test loss:  6.776099681854248\n",
      "test r2:  -0.2556961199387744\n",
      "train loss:  1.6364802122116089\n",
      "train r2:  0.8852792872083398\n",
      "test loss:  6.773177623748779\n",
      "test r2:  -0.2548096327013043\n",
      "train loss:  1.6364902257919312\n",
      "train r2:  0.8854687257930471\n",
      "test loss:  6.7763142585754395\n",
      "test r2:  -0.25576153578013416\n",
      "train loss:  1.6364933252334595\n",
      "train r2:  0.8852651073088253\n",
      "test loss:  6.773246765136719\n",
      "test r2:  -0.2548273134371779\n",
      "train loss:  1.6364905834197998\n",
      "train r2:  0.8854649642410299\n",
      "test loss:  6.776010036468506\n",
      "test r2:  -0.25567097171235753\n",
      "train loss:  1.6364822387695312\n",
      "train r2:  0.8852845915909892\n",
      "test loss:  6.773739814758301\n",
      "test r2:  -0.25497582720654255\n",
      "train loss:  1.6364734172821045\n",
      "train r2:  0.8854334857837749\n",
      "test loss:  6.7753801345825195\n",
      "test r2:  -0.2554832825173914\n",
      "train loss:  1.6364631652832031\n",
      "train r2:  0.885325025405414\n",
      "test loss:  6.774412155151367\n",
      "test r2:  -0.25518184325160886\n",
      "train loss:  1.6364587545394897\n",
      "train r2:  0.8853896471775115\n",
      "test loss:  6.774688720703125\n",
      "test r2:  -0.2552776479008909\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853690747829539\n",
      "test loss:  6.775007247924805\n",
      "test r2:  -0.25536808245027043\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853497853567593\n",
      "test loss:  6.774160385131836\n",
      "test r2:  -0.255121004990325\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8854025349329272\n",
      "test loss:  6.775373935699463\n",
      "test r2:  -0.2554852945544335\n",
      "train loss:  1.636457920074463\n",
      "train r2:  0.8853246273366906\n",
      "test loss:  6.773909091949463\n",
      "test r2:  -0.2550447254421566\n",
      "train loss:  1.6364598274230957\n",
      "train r2:  0.8854188116767492\n",
      "test loss:  6.775485515594482\n",
      "test r2:  -0.2555203835861293\n",
      "train loss:  1.6364600658416748\n",
      "train r2:  0.8853170546307249\n",
      "test loss:  6.77393913269043\n",
      "test r2:  -0.2550480070005592\n",
      "train loss:  1.6364597082138062\n",
      "train r2:  0.8854181404331453\n",
      "test loss:  6.775381565093994\n",
      "test r2:  -0.2554851485400347\n",
      "train loss:  1.636458396911621\n",
      "train r2:  0.885324678933641\n",
      "test loss:  6.774171829223633\n",
      "test r2:  -0.2551101019063271\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.8854049652915293\n",
      "test loss:  6.775137424468994\n",
      "test r2:  -0.255406593339335\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853415178178279\n",
      "test loss:  6.7744832038879395\n",
      "test r2:  -0.2551992873710365\n",
      "train loss:  1.6364558935165405\n",
      "train r2:  0.8853859879076763\n",
      "test loss:  6.77484130859375\n",
      "test r2:  -0.25531583644099887\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853609880759528\n",
      "test loss:  6.774766445159912\n",
      "test r2:  -0.25528610646647\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853674377289684\n",
      "test loss:  6.774576187133789\n",
      "test r2:  -0.2552384873614255\n",
      "train loss:  1.6364527940750122\n",
      "train r2:  0.885377544018566\n",
      "test loss:  6.7749552726745605\n",
      "test r2:  -0.2553488382676288\n",
      "train loss:  1.6364529132843018\n",
      "train r2:  0.8853539733368061\n",
      "test loss:  6.774405002593994\n",
      "test r2:  -0.2551904964071299\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.885387797863291\n",
      "test loss:  6.775036811828613\n",
      "test r2:  -0.2553792506879371\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.8853474332986631\n",
      "test loss:  6.774351596832275\n",
      "test r2:  -0.2551750696305415\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853910451374046\n",
      "test loss:  6.775031566619873\n",
      "test r2:  -0.2553794780159091\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853473642005029\n",
      "test loss:  6.774403095245361\n",
      "test r2:  -0.25518756701808876\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853884713600606\n",
      "test loss:  6.774963855743408\n",
      "test r2:  -0.2553577333505135\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853520307736024\n",
      "test loss:  6.7745161056518555\n",
      "test r2:  -0.2552165285705943\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853822823760863\n",
      "test loss:  6.774871349334717\n",
      "test r2:  -0.25532661851062244\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.8853587226194242\n",
      "test loss:  6.774636745452881\n",
      "test r2:  -0.2552482643997487\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853755143253764\n",
      "test loss:  6.774783134460449\n",
      "test r2:  -0.25529795892568385\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853648640260221\n",
      "test loss:  6.774724960327148\n",
      "test r2:  -0.2552731693633916\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853702185088139\n",
      "test loss:  6.774718761444092\n",
      "test r2:  -0.2552785730636058\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.885368985478348\n",
      "test loss:  6.774763584136963\n",
      "test r2:  -0.2552863574877309\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853673697427101\n",
      "test loss:  6.774685859680176\n",
      "test r2:  -0.25527060205073426\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853707233963447\n",
      "test loss:  6.774759292602539\n",
      "test r2:  -0.25528896517811095\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853668133413901\n",
      "test loss:  6.774682521820068\n",
      "test r2:  -0.25527150229637563\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853705102765703\n",
      "test loss:  6.7747344970703125\n",
      "test r2:  -0.25528452243656674\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853677693718341\n",
      "test loss:  6.774699687957764\n",
      "test r2:  -0.25527713245511174\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853693010166321\n",
      "test loss:  6.774711608886719\n",
      "test r2:  -0.25527824833978996\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853690685952492\n",
      "test loss:  6.7747273445129395\n",
      "test r2:  -0.25528301154494604\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853680725425926\n",
      "test loss:  6.774701118469238\n",
      "test r2:  -0.25527339693407236\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.885370171817927\n",
      "test loss:  6.774755477905273\n",
      "test r2:  -0.2552879933856189\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.8853670507764841\n",
      "test loss:  6.774698257446289\n",
      "test r2:  -0.25526965795161716\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853709547259926\n",
      "test loss:  6.774776935577393\n",
      "test r2:  -0.25529118864314193\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853663902358875\n",
      "test loss:  6.774698257446289\n",
      "test r2:  -0.2552680887228509\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853713307088102\n",
      "test loss:  6.774785041809082\n",
      "test r2:  -0.25529194659694276\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.885366228503435\n",
      "test loss:  6.774701118469238\n",
      "test r2:  -0.25526877321168495\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853711734129189\n",
      "test loss:  6.774778366088867\n",
      "test r2:  -0.2552897219992709\n",
      "train loss:  1.6364493370056152\n",
      "train r2:  0.8853667076295549\n",
      "test loss:  6.774708271026611\n",
      "test r2:  -0.2552723290893395\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853704190713119\n",
      "test loss:  6.774757385253906\n",
      "test r2:  -0.2552848858852279\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853677159773499\n",
      "test loss:  6.774718761444092\n",
      "test r2:  -0.2552776831520316\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853692453134676\n",
      "test loss:  6.7747273445129395\n",
      "test r2:  -0.2552778627237302\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853692058819652\n",
      "test loss:  6.774737358093262\n",
      "test r2:  -0.25528550832255115\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853675191244578\n",
      "test loss:  6.774693489074707\n",
      "test r2:  -0.2552687067228028\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853711268963016\n",
      "test loss:  6.7747650146484375\n",
      "test r2:  -0.2552951310278124\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853654349791825\n",
      "test loss:  6.774658203125\n",
      "test r2:  -0.25525811842794743\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.8853733918349039\n",
      "test loss:  6.774803638458252\n",
      "test r2:  -0.2553069382889237\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853629021642104\n",
      "test loss:  6.774618625640869\n",
      "test r2:  -0.255245056509082\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853762183625907\n",
      "test loss:  6.7748565673828125\n",
      "test r2:  -0.25532230856865157\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.885359646835131\n",
      "test loss:  6.774566173553467\n",
      "test r2:  -0.25522765070486475\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853799253334194\n",
      "test loss:  6.774925708770752\n",
      "test r2:  -0.2553427351033484\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.8853552496790945\n",
      "test loss:  6.774490833282471\n",
      "test r2:  -0.2552038037444735\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853850338292081\n",
      "test loss:  6.775020122528076\n",
      "test r2:  -0.25537081399072314\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853492579634941\n",
      "test loss:  6.774385452270508\n",
      "test r2:  -0.25517137686515623\n",
      "train loss:  1.6364554166793823\n",
      "train r2:  0.8853919431700352\n",
      "test loss:  6.775142192840576\n",
      "test r2:  -0.2554083208223943\n",
      "train loss:  1.6364556550979614\n",
      "train r2:  0.8853411956696275\n",
      "test loss:  6.7742414474487305\n",
      "test r2:  -0.25512778689318805\n",
      "train loss:  1.6364578008651733\n",
      "train r2:  0.8854012145984183\n",
      "test loss:  6.775306701660156\n",
      "test r2:  -0.25545863524079526\n",
      "train loss:  1.6364589929580688\n",
      "train r2:  0.8853303719762\n",
      "test loss:  6.774047374725342\n",
      "test r2:  -0.2550694504551885\n",
      "train loss:  1.6364624500274658\n",
      "train r2:  0.8854136231647294\n",
      "test loss:  6.775528430938721\n",
      "test r2:  -0.2555261469612422\n",
      "train loss:  1.6364651918411255\n",
      "train r2:  0.8853158523453091\n",
      "test loss:  6.773788928985596\n",
      "test r2:  -0.2549910471123311\n",
      "train loss:  1.6364703178405762\n",
      "train r2:  0.8854302500308636\n",
      "test loss:  6.775829792022705\n",
      "test r2:  -0.2556169519046445\n",
      "train loss:  1.6364755630493164\n",
      "train r2:  0.8852962877947866\n",
      "test loss:  6.773448467254639\n",
      "test r2:  -0.2548866778163399\n",
      "train loss:  1.6364846229553223\n",
      "train r2:  0.8854523786059533\n",
      "test loss:  6.776228427886963\n",
      "test r2:  -0.2557366691429668\n",
      "train loss:  1.6364943981170654\n",
      "train r2:  0.8852703669363888\n",
      "test loss:  6.773004531860352\n",
      "test r2:  -0.2547506483978885\n",
      "train loss:  1.636509656906128\n",
      "train r2:  0.8854810889467979\n",
      "test loss:  6.776737689971924\n",
      "test r2:  -0.25588941543430965\n",
      "train loss:  1.6365259885787964\n",
      "train r2:  0.8852372513508151\n",
      "test loss:  6.772461414337158\n",
      "test r2:  -0.25458378968996587\n",
      "train loss:  1.6365501880645752\n",
      "train r2:  0.8855162078719434\n",
      "test loss:  6.77733039855957\n",
      "test r2:  -0.25606726202067676\n",
      "train loss:  1.6365736722946167\n",
      "train r2:  0.8851985087791747\n",
      "test loss:  6.771878242492676\n",
      "test r2:  -0.25440459187746334\n",
      "train loss:  1.6366046667099\n",
      "train r2:  0.8855537041153767\n",
      "test loss:  6.777888298034668\n",
      "test r2:  -0.2562349012379277\n",
      "train loss:  1.636628270149231\n",
      "train r2:  0.8851618443318181\n",
      "test loss:  6.77143669128418\n",
      "test r2:  -0.25426951478052784\n",
      "train loss:  1.636653184890747\n",
      "train r2:  0.8855818825286395\n",
      "test loss:  6.778146743774414\n",
      "test r2:  -0.2563130656642387\n",
      "train loss:  1.636655569076538\n",
      "train r2:  0.8851447297893857\n",
      "test loss:  6.771454334259033\n",
      "test r2:  -0.25427573939237136\n",
      "train loss:  1.6366490125656128\n",
      "train r2:  0.8855806356933156\n",
      "test loss:  6.777769088745117\n",
      "test r2:  -0.25619977857724585\n",
      "train loss:  1.6366122961044312\n",
      "train r2:  0.8851695913648089\n",
      "test loss:  6.77220344543457\n",
      "test r2:  -0.2545051076304248\n",
      "train loss:  1.6365687847137451\n",
      "train r2:  0.8855327481938039\n",
      "test loss:  6.7766432762146\n",
      "test r2:  -0.2558599930045282\n",
      "train loss:  1.6365162134170532\n",
      "train r2:  0.8852437125772359\n",
      "test loss:  6.773590087890625\n",
      "test r2:  -0.2549270188204671\n",
      "train loss:  1.6364768743515015\n",
      "train r2:  0.8854438866711472\n",
      "test loss:  6.775117874145508\n",
      "test r2:  -0.255395934044492\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853438953121516\n",
      "test loss:  6.775110244750977\n",
      "test r2:  -0.2553861253884908\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853460986045545\n",
      "test loss:  6.773782253265381\n",
      "test r2:  -0.25498486294170375\n",
      "train loss:  1.636464238166809\n",
      "train r2:  0.8854316865788628\n",
      "test loss:  6.776216506958008\n",
      "test r2:  -0.2557173779004309\n",
      "train loss:  1.6364827156066895\n",
      "train r2:  0.8852748162979462\n",
      "test loss:  6.7730560302734375\n",
      "test r2:  -0.25475696360768274\n",
      "train loss:  1.636499047279358\n",
      "train r2:  0.8854799911569798\n",
      "test loss:  6.776609420776367\n",
      "test r2:  -0.25583342269331255\n",
      "train loss:  1.6365060806274414\n",
      "train r2:  0.8852496966402599\n",
      "test loss:  6.773069858551025\n",
      "test r2:  -0.25475518754805604\n",
      "train loss:  1.636504054069519\n",
      "train r2:  0.8854803709795482\n",
      "test loss:  6.77627420425415\n",
      "test r2:  -0.2557322740255885\n",
      "train loss:  1.6364922523498535\n",
      "train r2:  0.8852715039518555\n",
      "test loss:  6.773688793182373\n",
      "test r2:  -0.25494047736023684\n",
      "train loss:  1.636479139328003\n",
      "train r2:  0.8854411326250566\n",
      "test loss:  6.775464057922363\n",
      "test r2:  -0.2554904001519871\n",
      "train loss:  1.6364648342132568\n",
      "train r2:  0.8853236496737062\n",
      "test loss:  6.7745585441589355\n",
      "test r2:  -0.2552072003488681\n",
      "train loss:  1.6364588737487793\n",
      "train r2:  0.8853843705553843\n",
      "test loss:  6.7745819091796875\n",
      "test r2:  -0.25522789119953004\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.885379880231962\n",
      "test loss:  6.775293350219727\n",
      "test r2:  -0.25543783233242867\n",
      "train loss:  1.6364575624465942\n",
      "train r2:  0.8853349779171263\n",
      "test loss:  6.773961067199707\n",
      "test r2:  -0.25504393952667015\n",
      "train loss:  1.636460542678833\n",
      "train r2:  0.8854190823080236\n",
      "test loss:  6.775674819946289\n",
      "test r2:  -0.25556135732477925\n",
      "train loss:  1.636464238166809\n",
      "train r2:  0.8853083953796429\n",
      "test loss:  6.7737579345703125\n",
      "test r2:  -0.25498258491840997\n",
      "train loss:  1.6364659070968628\n",
      "train r2:  0.8854321280156034\n",
      "test loss:  6.775669574737549\n",
      "test r2:  -0.25556211927252126\n",
      "train loss:  1.6364651918411255\n",
      "train r2:  0.8853081834305286\n",
      "test loss:  6.773948669433594\n",
      "test r2:  -0.255034485985306\n",
      "train loss:  1.636462688446045\n",
      "train r2:  0.885421163908842\n",
      "test loss:  6.775381565093994\n",
      "test r2:  -0.25547083929588155\n",
      "train loss:  1.6364593505859375\n",
      "train r2:  0.8853278497203915\n",
      "test loss:  6.7743730545043945\n",
      "test r2:  -0.25515407227970144\n",
      "train loss:  1.6364573240280151\n",
      "train r2:  0.885395711689075\n",
      "test loss:  6.774966239929199\n",
      "test r2:  -0.25533964572930645\n",
      "train loss:  1.6364549398422241\n",
      "train r2:  0.8853560250892678\n",
      "test loss:  6.77482271194458\n",
      "test r2:  -0.2552855869878341\n",
      "train loss:  1.6364561319351196\n",
      "train r2:  0.8853676714868659\n",
      "test loss:  6.774580478668213\n",
      "test r2:  -0.2552213310034226\n",
      "train loss:  1.6364539861679077\n",
      "train r2:  0.8853813631355195\n",
      "test loss:  6.775134563446045\n",
      "test r2:  -0.2553829230965108\n",
      "train loss:  1.6364550590515137\n",
      "train r2:  0.8853468395004311\n",
      "test loss:  6.774334907531738\n",
      "test r2:  -0.25514899613183273\n",
      "train loss:  1.6364541053771973\n",
      "train r2:  0.8853967838945058\n",
      "test loss:  6.7752580642700195\n",
      "test r2:  -0.2554266178264879\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.8853374633921285\n",
      "test loss:  6.774271011352539\n",
      "test r2:  -0.2551316333259781\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8854004813342258\n",
      "test loss:  6.775217056274414\n",
      "test r2:  -0.25541804275661617\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853392578671698\n",
      "test loss:  6.7743754386901855\n",
      "test r2:  -0.2551616304716282\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853941428794719\n",
      "test loss:  6.7750630378723145\n",
      "test r2:  -0.25537168343488403\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853492003220058\n",
      "test loss:  6.774575710296631\n",
      "test r2:  -0.25521847466152026\n",
      "train loss:  1.6364516019821167\n",
      "train r2:  0.8853819802514672\n",
      "test loss:  6.774866104125977\n",
      "test r2:  -0.25531113753522616\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853621678522495\n",
      "test loss:  6.774782180786133\n",
      "test r2:  -0.25527817881653636\n",
      "train loss:  1.6364526748657227\n",
      "train r2:  0.8853692198585311\n",
      "test loss:  6.774692058563232\n",
      "test r2:  -0.2552576801358979\n",
      "train loss:  1.636452317237854\n",
      "train r2:  0.8853735744452278\n",
      "test loss:  6.774930000305176\n",
      "test r2:  -0.2553226680725278\n",
      "train loss:  1.6364531517028809\n",
      "train r2:  0.8853597530370338\n",
      "test loss:  6.774583339691162\n",
      "test r2:  -0.25522466849850955\n",
      "train loss:  1.6364518404006958\n",
      "train r2:  0.8853806199866351\n",
      "test loss:  6.7749924659729\n",
      "test r2:  -0.25534288915581005\n",
      "train loss:  1.6364517211914062\n",
      "train r2:  0.8853554315957339\n",
      "test loss:  6.7745585441589355\n",
      "test r2:  -0.25521672914735216\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853823434021943\n",
      "test loss:  6.774975776672363\n",
      "test r2:  -0.25533949267942635\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.885356158210745\n",
      "test loss:  6.774601936340332\n",
      "test r2:  -0.25522890606821536\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853797595600165\n",
      "test loss:  6.774909973144531\n",
      "test r2:  -0.25532039036055654\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853602307278893\n",
      "test loss:  6.774685382843018\n",
      "test r2:  -0.25525206553714774\n",
      "train loss:  1.6364489793777466\n",
      "train r2:  0.8853748440361088\n",
      "test loss:  6.774830341339111\n",
      "test r2:  -0.25529613641447146\n",
      "train loss:  1.636448860168457\n",
      "train r2:  0.885365453061683\n",
      "test loss:  6.774772644042969\n",
      "test r2:  -0.2552760335477562\n",
      "train loss:  1.6364490985870361\n",
      "train r2:  0.8853697618405915\n",
      "test loss:  6.774763107299805\n",
      "test r2:  -0.25527481369361626\n",
      "train loss:  1.6364494562149048\n",
      "train r2:  0.8853699694295611\n",
      "test loss:  6.774838447570801\n",
      "test r2:  -0.2552937457046831\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853659722725811\n",
      "test loss:  6.774723529815674\n",
      "test r2:  -0.2552622664278863\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853726862234385\n",
      "test loss:  6.774867057800293\n",
      "test r2:  -0.25530130717983446\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853643646233698\n",
      "test loss:  6.774713039398193\n",
      "test r2:  -0.25525966973723047\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853731889789436\n",
      "test loss:  6.7748565673828125\n",
      "test r2:  -0.25529911287364726\n",
      "train loss:  1.6364507675170898\n",
      "train r2:  0.8853647927335295\n",
      "test loss:  6.774726867675781\n",
      "test r2:  -0.2552653300512475\n",
      "train loss:  1.6364502906799316\n",
      "train r2:  0.8853720025438055\n",
      "test loss:  6.77482271194458\n",
      "test r2:  -0.2552906519567635\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853666017031138\n",
      "test loss:  6.774754524230957\n",
      "test r2:  -0.25527517167569846\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.8853699034955765\n",
      "test loss:  6.774781703948975\n",
      "test r2:  -0.25527963927799124\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.885368950782444\n",
      "test loss:  6.7747883796691895\n",
      "test r2:  -0.25528605390415393\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853675390884628\n",
      "test loss:  6.774745464324951\n",
      "test r2:  -0.25526900889723536\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853712303806486\n",
      "test loss:  6.774824619293213\n",
      "test r2:  -0.255296171792599\n",
      "train loss:  1.6364496946334839\n",
      "train r2:  0.8853653789247932\n",
      "test loss:  6.774715900421143\n",
      "test r2:  -0.25525910842871546\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853733618955897\n",
      "test loss:  6.774864196777344\n",
      "test r2:  -0.255306451075189\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853631994650241\n",
      "test loss:  6.774688243865967\n",
      "test r2:  -0.2552491017991869\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853754970881591\n",
      "test loss:  6.774903774261475\n",
      "test r2:  -0.2553165419727834\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853610631217828\n",
      "test loss:  6.774661064147949\n",
      "test r2:  -0.2552394838968961\n",
      "train loss:  1.6364495754241943\n",
      "train r2:  0.8853776014515026\n",
      "test loss:  6.774940490722656\n",
      "test r2:  -0.2553263514511268\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853589521106043\n",
      "test loss:  6.774632453918457\n",
      "test r2:  -0.25523016988233627\n",
      "train loss:  1.636449933052063\n",
      "train r2:  0.8853795850783492\n",
      "test loss:  6.774969577789307\n",
      "test r2:  -0.2553350389924347\n",
      "train loss:  1.6364500522613525\n",
      "train r2:  0.885357142827004\n",
      "test loss:  6.774606704711914\n",
      "test r2:  -0.2552222260538679\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853812884628866\n",
      "test loss:  6.774993896484375\n",
      "test r2:  -0.25534296654815236\n",
      "train loss:  1.636450171470642\n",
      "train r2:  0.8853554172412061\n",
      "test loss:  6.774577617645264\n",
      "test r2:  -0.25521404985174856\n",
      "train loss:  1.6364505290985107\n",
      "train r2:  0.8853830160938565\n",
      "test loss:  6.7750163078308105\n",
      "test r2:  -0.25535068943178607\n",
      "train loss:  1.6364506483078003\n",
      "train r2:  0.8853537638118111\n",
      "test loss:  6.774549961090088\n",
      "test r2:  -0.25520621350741024\n",
      "train loss:  1.6364511251449585\n",
      "train r2:  0.885384674626991\n",
      "test loss:  6.775038242340088\n",
      "test r2:  -0.2553589095549711\n",
      "train loss:  1.6364513635635376\n",
      "train r2:  0.8853519482810397\n",
      "test loss:  6.774516582489014\n",
      "test r2:  -0.25519649066072647\n",
      "train loss:  1.636452078819275\n",
      "train r2:  0.8853867455869462\n",
      "test loss:  6.77507209777832\n",
      "test r2:  -0.25537033542848\n",
      "train loss:  1.6364524364471436\n",
      "train r2:  0.885349487610732\n",
      "test loss:  6.774473190307617\n",
      "test r2:  -0.2551829374645471\n",
      "train loss:  1.6364537477493286\n",
      "train r2:  0.885389621273571\n",
      "test loss:  6.775123119354248\n",
      "test r2:  -0.2553863142353503\n",
      "train loss:  1.6364538669586182\n",
      "train r2:  0.8853460401988528\n",
      "test loss:  6.774412631988525\n",
      "test r2:  -0.255163893272885\n",
      "train loss:  1.63645601272583\n",
      "train r2:  0.8853936490054939\n",
      "test loss:  6.775195598602295\n",
      "test r2:  -0.2554092868185509\n",
      "train loss:  1.6364564895629883\n",
      "train r2:  0.885341099937352\n",
      "test loss:  6.774322509765625\n",
      "test r2:  -0.25513629332768994\n",
      "train loss:  1.6364588737487793\n",
      "train r2:  0.8853995444805185\n",
      "test loss:  6.775301933288574\n",
      "test r2:  -0.2554425090349597\n",
      "train loss:  1.6364593505859375\n",
      "train r2:  0.8853339676784736\n",
      "test loss:  6.7741923332214355\n",
      "test r2:  -0.255096925967605\n",
      "train loss:  1.6364624500274658\n",
      "train r2:  0.885407894086594\n",
      "test loss:  6.775453090667725\n",
      "test r2:  -0.25548886324239883\n",
      "train loss:  1.6364630460739136\n",
      "train r2:  0.8853239746223602\n",
      "test loss:  6.774010181427002\n",
      "test r2:  -0.25504214855837737\n",
      "train loss:  1.6364669799804688\n",
      "train r2:  0.8854195420785902\n",
      "test loss:  6.77566385269165\n",
      "test r2:  -0.25555252152222474\n",
      "train loss:  1.6364690065383911\n",
      "train r2:  0.8853102436957181\n",
      "test loss:  6.773767471313477\n",
      "test r2:  -0.2549684186153689\n",
      "train loss:  1.6364742517471313\n",
      "train r2:  0.8854351870145233\n",
      "test loss:  6.775947093963623\n",
      "test r2:  -0.255636939706934\n",
      "train loss:  1.6364789009094238\n",
      "train r2:  0.8852920788772208\n",
      "test loss:  6.773458480834961\n",
      "test r2:  -0.2548731306448675\n",
      "train loss:  1.6364871263504028\n",
      "train r2:  0.8854553702630099\n",
      "test loss:  6.776308059692383\n",
      "test r2:  -0.2557439964133983\n",
      "train loss:  1.6364953517913818\n",
      "train r2:  0.8852689825685042\n",
      "test loss:  6.7730793952941895\n",
      "test r2:  -0.2547558150300344\n",
      "train loss:  1.6365077495574951\n",
      "train r2:  0.885480207353371\n",
      "test loss:  6.776739120483398\n",
      "test r2:  -0.2558715958567461\n",
      "train loss:  1.6365203857421875\n",
      "train r2:  0.8852413155376067\n",
      "test loss:  6.772646903991699\n",
      "test r2:  -0.25462174269096804\n",
      "train loss:  1.636537790298462\n",
      "train r2:  0.8855084137309701\n",
      "test loss:  6.777197360992432\n",
      "test r2:  -0.2560078235344454\n",
      "train loss:  1.6365536451339722\n",
      "train r2:  0.8852116890179325\n",
      "test loss:  6.772227764129639\n",
      "test r2:  -0.2544923243033044\n",
      "train loss:  1.6365734338760376\n",
      "train r2:  0.8855356078925058\n",
      "test loss:  6.777574062347412\n",
      "test r2:  -0.25612116547361397\n",
      "train loss:  1.6365866661071777\n",
      "train r2:  0.885186958986632\n",
      "test loss:  6.7719573974609375\n",
      "test r2:  -0.2544094864750963\n",
      "train loss:  1.636600375175476\n",
      "train r2:  0.8855529313538453\n",
      "test loss:  6.777693271636963\n",
      "test r2:  -0.25615832328294474\n",
      "train loss:  1.636598825454712\n",
      "train r2:  0.8851787905668737\n",
      "test loss:  6.772030353546143\n",
      "test r2:  -0.2544327623223588\n",
      "train loss:  1.6365940570831299\n",
      "train r2:  0.8855480194565656\n",
      "test loss:  6.777368068695068\n",
      "test r2:  -0.25606247915713687\n",
      "train loss:  1.6365700960159302\n",
      "train r2:  0.8851997365132399\n",
      "test loss:  6.772584438323975\n",
      "test r2:  -0.2546038692679069\n",
      "train loss:  1.6365444660186768\n",
      "train r2:  0.8855121711071744\n",
      "test loss:  6.776562213897705\n",
      "test r2:  -0.2558201221866325\n",
      "train loss:  1.636509895324707\n",
      "train r2:  0.8852524431986715\n",
      "test loss:  6.773553371429443\n",
      "test r2:  -0.2549001334958334\n",
      "train loss:  1.6364821195602417\n",
      "train r2:  0.8854497113538159\n",
      "test loss:  6.775481700897217\n",
      "test r2:  -0.2554915549786174\n",
      "train loss:  1.6364609003067017\n",
      "train r2:  0.8853234748929031\n",
      "test loss:  6.774657726287842\n",
      "test r2:  -0.25523424705330977\n",
      "train loss:  1.636451244354248\n",
      "train r2:  0.885378732267768\n",
      "test loss:  6.774461269378662\n",
      "test r2:  -0.25517672588421725\n",
      "train loss:  1.636451005935669\n",
      "train r2:  0.885391005237784\n",
      "test loss:  6.775583267211914\n",
      "test r2:  -0.2555108522386915\n",
      "train loss:  1.636458158493042\n",
      "train r2:  0.8853194729180213\n",
      "test loss:  6.7737531661987305\n",
      "test r2:  -0.25495418794228275\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10000):\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        # If use cuda please get x and y to device.\n",
    "        # device = torch.device(\"cuda:{}\".format(0) if torch.cuda.is_available() else \"cpu\")\n",
    "        # x = x.to(device)\n",
    "        # y = y.to(device)\n",
    "        bob.train()\n",
    "        h = bob.init_hidden(batch_size)\n",
    "        pre_y, _ = bob(x, h)\n",
    "\n",
    "        loss = criterion(pre_y, y)\n",
    "        # Backpropagation\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print('train loss: ', loss.data.item())\n",
    "        score = r2_score(y, pre_y.detach().numpy())\n",
    "        print('train r2: ', score)\n",
    "        train_loss.append(loss.data.item())\n",
    "        train_r2.append(score)\n",
    "    bob.eval()\n",
    "    h_test = bob.init_hidden(X_val.shape[0])\n",
    "    pre_y_test, _ = bob(X_val.clone(), h_test)\n",
    "    pre_y_test = pre_y_test.detach()\n",
    "    loss_test = criterion(pre_y_test, y_val)\n",
    "    score_test = r2_score(y_val, pre_y_test.numpy())\n",
    "    test_loss.append(loss_test.data.item())\n",
    "    test_r2.append(score_test)\n",
    "    print('test loss: ', loss_test.data.item())\n",
    "    print('test r2: ', score_test)\n",
    "    bob.train()\n",
    "    # if score_test > best_score:\n",
    "    #     best_score = score_test\n",
    "    #     flag = 0\n",
    "    # else:\n",
    "    #     flag += 1\n",
    "    # if flag == 100:\n",
    "    #     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score = format(best_score, \".2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_r2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(test_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"test_r2\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"r2\")\n",
    "plt.plot(test_r2, label=f\"bset r2:{best_score}\")\n",
    "plt.legend()\n",
    "plt.savefig('t2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.919204254243851"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_r2.sort()\n",
    "test_r2[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11ca1b389f0f7ff512e0d1900cffe853c843f5d9714fc38dfd5c75c4c45d4a2f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
